INFO - 2023-11-30 15:50:10,607: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-30T15:50:10.599558', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-30 15:50:10,608: collecting all words and their counts
INFO - 2023-11-30 15:50:10,608: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:10,654: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:10,654: Creating a fresh vocabulary
INFO - 2023-11-30 15:50:10,668: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 4777 unique words (100.00% of original 4777, drops 0)', 'datetime': '2023-11-30T15:50:10.668018', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:10,668: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 191080 word corpus (100.00% of original 191080, drops 0)', 'datetime': '2023-11-30T15:50:10.668258', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:10,687: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:10,688: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:50:10,688: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156317.36716293753 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:50:10.688774', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:10,714: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:10,714: resetting layer weights
INFO - 2023-11-30 15:50:10,718: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:10.718432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-30 15:50:10,718: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:10.718691', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:11,088: EPOCH 0: training on 191080 raw words (156470 effective words) took 0.4s, 425989 effective words/s
INFO - 2023-11-30 15:50:11,476: EPOCH 1: training on 191080 raw words (156132 effective words) took 0.4s, 405625 effective words/s
INFO - 2023-11-30 15:50:11,852: EPOCH 2: training on 191080 raw words (156395 effective words) took 0.4s, 419861 effective words/s
INFO - 2023-11-30 15:50:12,261: EPOCH 3: training on 191080 raw words (156315 effective words) took 0.4s, 384581 effective words/s
INFO - 2023-11-30 15:50:12,617: EPOCH 4: training on 191080 raw words (156317 effective words) took 0.4s, 443030 effective words/s
INFO - 2023-11-30 15:50:12,952: EPOCH 5: training on 191080 raw words (156309 effective words) took 0.3s, 469572 effective words/s
INFO - 2023-11-30 15:50:13,296: EPOCH 6: training on 191080 raw words (156331 effective words) took 0.3s, 458936 effective words/s
INFO - 2023-11-30 15:50:13,621: EPOCH 7: training on 191080 raw words (156301 effective words) took 0.3s, 484166 effective words/s
INFO - 2023-11-30 15:50:14,033: EPOCH 8: training on 191080 raw words (156384 effective words) took 0.4s, 381829 effective words/s
INFO - 2023-11-30 15:50:14,396: EPOCH 9: training on 191080 raw words (156270 effective words) took 0.4s, 434009 effective words/s
INFO - 2023-11-30 15:50:14,760: EPOCH 10: training on 191080 raw words (156195 effective words) took 0.4s, 432009 effective words/s
INFO - 2023-11-30 15:50:15,108: EPOCH 11: training on 191080 raw words (156231 effective words) took 0.3s, 478369 effective words/s
INFO - 2023-11-30 15:50:15,496: EPOCH 12: training on 191080 raw words (156341 effective words) took 0.4s, 405830 effective words/s
INFO - 2023-11-30 15:50:15,849: EPOCH 13: training on 191080 raw words (156409 effective words) took 0.4s, 445845 effective words/s
INFO - 2023-11-30 15:50:16,211: EPOCH 14: training on 191080 raw words (156251 effective words) took 0.4s, 434751 effective words/s
INFO - 2023-11-30 15:50:16,558: EPOCH 15: training on 191080 raw words (156351 effective words) took 0.3s, 452944 effective words/s
INFO - 2023-11-30 15:50:16,906: EPOCH 16: training on 191080 raw words (156272 effective words) took 0.3s, 452254 effective words/s
INFO - 2023-11-30 15:50:17,264: EPOCH 17: training on 191080 raw words (156344 effective words) took 0.4s, 440276 effective words/s
INFO - 2023-11-30 15:50:17,615: EPOCH 18: training on 191080 raw words (156460 effective words) took 0.3s, 449678 effective words/s
INFO - 2023-11-30 15:50:17,999: EPOCH 19: training on 191080 raw words (156331 effective words) took 0.4s, 410042 effective words/s
INFO - 2023-11-30 15:50:18,000: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126409 effective words) took 7.3s, 429388 effective words/s', 'datetime': '2023-11-30T15:50:17.999910', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:18,000: collecting all words and their counts
INFO - 2023-11-30 15:50:18,000: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:18,031: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:18,031: Updating model with new vocabulary
INFO - 2023-11-30 15:50:18,044: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:50:18.044936', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:18,062: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:18,062: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:50:18,062: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156265.06184198076 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:50:18.062594', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:18,091: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:18,091: updating layer weights
INFO - 2023-11-30 15:50:18,092: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:18.092692', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:50:18,092: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:50:18,092: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:18.092946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:18,453: EPOCH 0: training on 191080 raw words (156189 effective words) took 0.4s, 436791 effective words/s
INFO - 2023-11-30 15:50:18,824: EPOCH 1: training on 191080 raw words (156253 effective words) took 0.4s, 423334 effective words/s
INFO - 2023-11-30 15:50:19,202: EPOCH 2: training on 191080 raw words (156182 effective words) took 0.4s, 416603 effective words/s
INFO - 2023-11-30 15:50:19,578: EPOCH 3: training on 191080 raw words (156330 effective words) took 0.4s, 418193 effective words/s
INFO - 2023-11-30 15:50:19,951: EPOCH 4: training on 191080 raw words (156429 effective words) took 0.4s, 422747 effective words/s
INFO - 2023-11-30 15:50:20,310: EPOCH 5: training on 191080 raw words (156174 effective words) took 0.4s, 438506 effective words/s
INFO - 2023-11-30 15:50:20,676: EPOCH 6: training on 191080 raw words (156333 effective words) took 0.4s, 429987 effective words/s
INFO - 2023-11-30 15:50:21,040: EPOCH 7: training on 191080 raw words (156291 effective words) took 0.4s, 432408 effective words/s
INFO - 2023-11-30 15:50:21,409: EPOCH 8: training on 191080 raw words (156434 effective words) took 0.4s, 426376 effective words/s
INFO - 2023-11-30 15:50:21,775: EPOCH 9: training on 191080 raw words (156223 effective words) took 0.4s, 430345 effective words/s
INFO - 2023-11-30 15:50:22,147: EPOCH 10: training on 191080 raw words (156533 effective words) took 0.4s, 423332 effective words/s
INFO - 2023-11-30 15:50:22,513: EPOCH 11: training on 191080 raw words (156238 effective words) took 0.4s, 429979 effective words/s
INFO - 2023-11-30 15:50:22,872: EPOCH 12: training on 191080 raw words (156156 effective words) took 0.4s, 438508 effective words/s
INFO - 2023-11-30 15:50:23,231: EPOCH 13: training on 191080 raw words (156323 effective words) took 0.4s, 438100 effective words/s
INFO - 2023-11-30 15:50:23,594: EPOCH 14: training on 191080 raw words (156299 effective words) took 0.4s, 434996 effective words/s
INFO - 2023-11-30 15:50:23,974: EPOCH 15: training on 191080 raw words (156214 effective words) took 0.4s, 413851 effective words/s
INFO - 2023-11-30 15:50:24,512: EPOCH 16: training on 191080 raw words (156143 effective words) took 0.5s, 292297 effective words/s
INFO - 2023-11-30 15:50:25,091: EPOCH 17: training on 191080 raw words (156350 effective words) took 0.6s, 271570 effective words/s
INFO - 2023-11-30 15:50:25,609: EPOCH 18: training on 191080 raw words (156406 effective words) took 0.5s, 304380 effective words/s
INFO - 2023-11-30 15:50:26,116: EPOCH 19: training on 191080 raw words (156305 effective words) took 0.5s, 310704 effective words/s
INFO - 2023-11-30 15:50:26,116: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125805 effective words) took 8.0s, 389576 effective words/s', 'datetime': '2023-11-30T15:50:26.116708', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:26,117: collecting all words and their counts
INFO - 2023-11-30 15:50:26,117: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:26,165: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:26,166: Updating model with new vocabulary
INFO - 2023-11-30 15:50:26,185: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:50:26.185798', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:26,211: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:26,211: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:50:26,211: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156049.8701136128 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:50:26.211497', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:26,248: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:26,249: updating layer weights
INFO - 2023-11-30 15:50:26,249: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:26.249761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:50:26,249: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:50:26,250: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:26.250060', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:26,733: EPOCH 0: training on 191080 raw words (155884 effective words) took 0.5s, 325731 effective words/s
INFO - 2023-11-30 15:50:27,228: EPOCH 1: training on 191080 raw words (156084 effective words) took 0.5s, 317615 effective words/s
INFO - 2023-11-30 15:50:27,748: EPOCH 2: training on 191080 raw words (155952 effective words) took 0.5s, 302303 effective words/s
INFO - 2023-11-30 15:50:28,257: EPOCH 3: training on 191080 raw words (155911 effective words) took 0.5s, 308430 effective words/s
INFO - 2023-11-30 15:50:28,787: EPOCH 4: training on 191080 raw words (156075 effective words) took 0.5s, 296389 effective words/s
INFO - 2023-11-30 15:50:29,277: EPOCH 5: training on 191080 raw words (155963 effective words) took 0.5s, 320782 effective words/s
INFO - 2023-11-30 15:50:29,763: EPOCH 6: training on 191080 raw words (156014 effective words) took 0.5s, 323536 effective words/s
INFO - 2023-11-30 15:50:30,315: EPOCH 7: training on 191080 raw words (156071 effective words) took 0.5s, 284197 effective words/s
INFO - 2023-11-30 15:50:30,850: EPOCH 8: training on 191080 raw words (156146 effective words) took 0.5s, 294304 effective words/s
INFO - 2023-11-30 15:50:31,457: EPOCH 9: training on 191080 raw words (155960 effective words) took 0.6s, 258947 effective words/s
INFO - 2023-11-30 15:50:32,007: EPOCH 10: training on 191080 raw words (156245 effective words) took 0.5s, 286509 effective words/s
INFO - 2023-11-30 15:50:32,640: EPOCH 11: training on 191080 raw words (156035 effective words) took 0.6s, 248205 effective words/s
INFO - 2023-11-30 15:50:33,198: EPOCH 12: training on 191080 raw words (156028 effective words) took 0.6s, 281777 effective words/s
INFO - 2023-11-30 15:50:33,699: EPOCH 13: training on 191080 raw words (155980 effective words) took 0.5s, 313412 effective words/s
INFO - 2023-11-30 15:50:34,191: EPOCH 14: training on 191080 raw words (155948 effective words) took 0.5s, 319259 effective words/s
INFO - 2023-11-30 15:50:34,660: EPOCH 15: training on 191080 raw words (156089 effective words) took 0.5s, 334719 effective words/s
INFO - 2023-11-30 15:50:35,131: EPOCH 16: training on 191080 raw words (156114 effective words) took 0.5s, 334262 effective words/s
INFO - 2023-11-30 15:50:35,578: EPOCH 17: training on 191080 raw words (155986 effective words) took 0.4s, 351674 effective words/s
INFO - 2023-11-30 15:50:36,013: EPOCH 18: training on 191080 raw words (156083 effective words) took 0.4s, 362026 effective words/s
INFO - 2023-11-30 15:50:36,460: EPOCH 19: training on 191080 raw words (155877 effective words) took 0.4s, 351047 effective words/s
INFO - 2023-11-30 15:50:36,461: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120445 effective words) took 10.2s, 305594 effective words/s', 'datetime': '2023-11-30T15:50:36.461292', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:36,461: collecting all words and their counts
INFO - 2023-11-30 15:50:36,461: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:36,512: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:36,512: Updating model with new vocabulary
INFO - 2023-11-30 15:50:36,537: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:50:36.537232', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:36,561: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:36,561: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:50:36,562: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156217.01577190094 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:50:36.562202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:36,600: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:36,601: updating layer weights
INFO - 2023-11-30 15:50:36,601: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:36.601809', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:50:36,602: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:50:36,602: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:36.602253', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:37,088: EPOCH 0: training on 191080 raw words (155984 effective words) took 0.5s, 323440 effective words/s
INFO - 2023-11-30 15:50:37,579: EPOCH 1: training on 191080 raw words (156227 effective words) took 0.5s, 321027 effective words/s
INFO - 2023-11-30 15:50:38,073: EPOCH 2: training on 191080 raw words (156302 effective words) took 0.5s, 317987 effective words/s
INFO - 2023-11-30 15:50:38,587: EPOCH 3: training on 191080 raw words (156380 effective words) took 0.5s, 306228 effective words/s
INFO - 2023-11-30 15:50:39,083: EPOCH 4: training on 191080 raw words (156481 effective words) took 0.5s, 317613 effective words/s
INFO - 2023-11-30 15:50:39,581: EPOCH 5: training on 191080 raw words (156169 effective words) took 0.5s, 316141 effective words/s
INFO - 2023-11-30 15:50:40,050: EPOCH 6: training on 191080 raw words (156004 effective words) took 0.5s, 334942 effective words/s
INFO - 2023-11-30 15:50:40,525: EPOCH 7: training on 191080 raw words (156279 effective words) took 0.5s, 331320 effective words/s
INFO - 2023-11-30 15:50:41,071: EPOCH 8: training on 191080 raw words (156299 effective words) took 0.5s, 287767 effective words/s
INFO - 2023-11-30 15:50:41,537: EPOCH 9: training on 191080 raw words (156206 effective words) took 0.5s, 337641 effective words/s
INFO - 2023-11-30 15:50:41,989: EPOCH 10: training on 191080 raw words (156185 effective words) took 0.4s, 348320 effective words/s
INFO - 2023-11-30 15:50:42,352: EPOCH 11: training on 191080 raw words (156179 effective words) took 0.4s, 433416 effective words/s
INFO - 2023-11-30 15:50:42,718: EPOCH 12: training on 191080 raw words (156322 effective words) took 0.4s, 429860 effective words/s
INFO - 2023-11-30 15:50:43,079: EPOCH 13: training on 191080 raw words (156445 effective words) took 0.4s, 437403 effective words/s
INFO - 2023-11-30 15:50:43,443: EPOCH 14: training on 191080 raw words (156409 effective words) took 0.4s, 432331 effective words/s
INFO - 2023-11-30 15:50:43,779: EPOCH 15: training on 191080 raw words (156326 effective words) took 0.3s, 470241 effective words/s
INFO - 2023-11-30 15:50:44,130: EPOCH 16: training on 191080 raw words (156149 effective words) took 0.3s, 446979 effective words/s
INFO - 2023-11-30 15:50:44,481: EPOCH 17: training on 191080 raw words (156417 effective words) took 0.3s, 450058 effective words/s
INFO - 2023-11-30 15:50:44,850: EPOCH 18: training on 191080 raw words (156268 effective words) took 0.4s, 426989 effective words/s
INFO - 2023-11-30 15:50:45,277: EPOCH 19: training on 191080 raw words (156265 effective words) took 0.4s, 368137 effective words/s
INFO - 2023-11-30 15:50:45,277: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125296 effective words) took 8.7s, 360269 effective words/s', 'datetime': '2023-11-30T15:50:45.277371', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:45,277: collecting all words and their counts
INFO - 2023-11-30 15:50:45,277: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:45,310: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:45,310: Updating model with new vocabulary
INFO - 2023-11-30 15:50:45,325: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:50:45.325384', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:45,342: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:45,343: sample=0.001 downsamples 34 most-common words
INFO - 2023-11-30 15:50:45,343: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156086.14516504048 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:50:45.343154', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:45,375: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:45,376: updating layer weights
INFO - 2023-11-30 15:50:45,376: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:45.376621', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:50:45,376: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:50:45,376: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:45.376935', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:45,727: EPOCH 0: training on 191080 raw words (156078 effective words) took 0.3s, 448062 effective words/s
INFO - 2023-11-30 15:50:46,079: EPOCH 1: training on 191080 raw words (155982 effective words) took 0.3s, 446200 effective words/s
INFO - 2023-11-30 15:50:46,430: EPOCH 2: training on 191080 raw words (155999 effective words) took 0.3s, 448751 effective words/s
INFO - 2023-11-30 15:50:46,785: EPOCH 3: training on 191080 raw words (156189 effective words) took 0.4s, 444600 effective words/s
INFO - 2023-11-30 15:50:47,129: EPOCH 4: training on 191080 raw words (156139 effective words) took 0.3s, 456507 effective words/s
INFO - 2023-11-30 15:50:47,482: EPOCH 5: training on 191080 raw words (156119 effective words) took 0.3s, 447051 effective words/s
INFO - 2023-11-30 15:50:47,825: EPOCH 6: training on 191080 raw words (156026 effective words) took 0.3s, 458058 effective words/s
INFO - 2023-11-30 15:50:48,176: EPOCH 7: training on 191080 raw words (156066 effective words) took 0.3s, 447503 effective words/s
INFO - 2023-11-30 15:50:48,527: EPOCH 8: training on 191080 raw words (156110 effective words) took 0.3s, 448200 effective words/s
INFO - 2023-11-30 15:50:48,878: EPOCH 9: training on 191080 raw words (156084 effective words) took 0.3s, 448528 effective words/s
INFO - 2023-11-30 15:50:49,227: EPOCH 10: training on 191080 raw words (156192 effective words) took 0.3s, 450708 effective words/s
INFO - 2023-11-30 15:50:49,570: EPOCH 11: training on 191080 raw words (156112 effective words) took 0.3s, 458800 effective words/s
INFO - 2023-11-30 15:50:49,908: EPOCH 12: training on 191080 raw words (155966 effective words) took 0.3s, 465672 effective words/s
INFO - 2023-11-30 15:50:50,245: EPOCH 13: training on 191080 raw words (156118 effective words) took 0.3s, 467515 effective words/s
INFO - 2023-11-30 15:50:50,574: EPOCH 14: training on 191080 raw words (156161 effective words) took 0.3s, 478580 effective words/s
INFO - 2023-11-30 15:50:50,906: EPOCH 15: training on 191080 raw words (156127 effective words) took 0.3s, 473492 effective words/s
INFO - 2023-11-30 15:50:51,224: EPOCH 16: training on 191080 raw words (156030 effective words) took 0.3s, 494948 effective words/s
INFO - 2023-11-30 15:50:51,555: EPOCH 17: training on 191080 raw words (156182 effective words) took 0.3s, 475080 effective words/s
INFO - 2023-11-30 15:50:51,880: EPOCH 18: training on 191080 raw words (155983 effective words) took 0.3s, 483931 effective words/s
INFO - 2023-11-30 15:50:52,199: EPOCH 19: training on 191080 raw words (155835 effective words) took 0.3s, 491760 effective words/s
INFO - 2023-11-30 15:50:52,199: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121498 effective words) took 6.8s, 457519 effective words/s', 'datetime': '2023-11-30T15:50:52.199741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:52,200: collecting all words and their counts
INFO - 2023-11-30 15:50:52,200: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:50:52,236: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:50:52,236: Updating model with new vocabulary
INFO - 2023-11-30 15:50:52,249: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:50:52.249237', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:52,265: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:50:52,266: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:50:52,266: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156178.50114248926 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:50:52.266175', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:50:52,290: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:50:52,290: updating layer weights
INFO - 2023-11-30 15:50:52,291: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:50:52.291362', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:50:52,291: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:50:52,291: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:50:52.291654', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:50:52,704: EPOCH 0: training on 191080 raw words (156161 effective words) took 0.4s, 380526 effective words/s
INFO - 2023-11-30 15:50:53,056: EPOCH 1: training on 191080 raw words (156211 effective words) took 0.3s, 446707 effective words/s
INFO - 2023-11-30 15:50:53,390: EPOCH 2: training on 191080 raw words (156132 effective words) took 0.3s, 471030 effective words/s
INFO - 2023-11-30 15:50:53,742: EPOCH 3: training on 191080 raw words (156296 effective words) took 0.3s, 446745 effective words/s
INFO - 2023-11-30 15:50:54,088: EPOCH 4: training on 191080 raw words (156150 effective words) took 0.3s, 454885 effective words/s
INFO - 2023-11-30 15:50:54,440: EPOCH 5: training on 191080 raw words (156151 effective words) took 0.3s, 446983 effective words/s
INFO - 2023-11-30 15:50:54,797: EPOCH 6: training on 191080 raw words (155839 effective words) took 0.4s, 439529 effective words/s
INFO - 2023-11-30 15:50:55,150: EPOCH 7: training on 191080 raw words (155998 effective words) took 0.4s, 445086 effective words/s
INFO - 2023-11-30 15:50:55,497: EPOCH 8: training on 191080 raw words (156367 effective words) took 0.3s, 453140 effective words/s
INFO - 2023-11-30 15:50:55,846: EPOCH 9: training on 191080 raw words (156294 effective words) took 0.3s, 450557 effective words/s
INFO - 2023-11-30 15:50:56,226: EPOCH 10: training on 191080 raw words (156265 effective words) took 0.4s, 414743 effective words/s
INFO - 2023-11-30 15:50:56,712: EPOCH 11: training on 191080 raw words (156035 effective words) took 0.5s, 323158 effective words/s
INFO - 2023-11-30 15:50:57,160: EPOCH 12: training on 191080 raw words (156039 effective words) took 0.4s, 351696 effective words/s
INFO - 2023-11-30 15:50:57,602: EPOCH 13: training on 191080 raw words (156342 effective words) took 0.4s, 355855 effective words/s
INFO - 2023-11-30 15:50:58,031: EPOCH 14: training on 191080 raw words (156253 effective words) took 0.4s, 367349 effective words/s
INFO - 2023-11-30 15:50:58,508: EPOCH 15: training on 191080 raw words (156143 effective words) took 0.5s, 329411 effective words/s
INFO - 2023-11-30 15:50:58,981: EPOCH 16: training on 191080 raw words (156108 effective words) took 0.5s, 333003 effective words/s
INFO - 2023-11-30 15:50:59,538: EPOCH 17: training on 191080 raw words (156278 effective words) took 0.6s, 282105 effective words/s
INFO - 2023-11-30 15:51:00,068: EPOCH 18: training on 191080 raw words (156189 effective words) took 0.5s, 296560 effective words/s
INFO - 2023-11-30 15:51:00,660: EPOCH 19: training on 191080 raw words (156149 effective words) took 0.6s, 265662 effective words/s
INFO - 2023-11-30 15:51:00,660: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123400 effective words) took 8.4s, 373223 effective words/s', 'datetime': '2023-11-30T15:51:00.660536', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:00,660: collecting all words and their counts
INFO - 2023-11-30 15:51:00,661: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:00,717: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:00,717: Updating model with new vocabulary
INFO - 2023-11-30 15:51:00,744: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:00.744601', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:00,777: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:00,777: sample=0.001 downsamples 34 most-common words
INFO - 2023-11-30 15:51:00,778: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156301.22656928233 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:51:00.778169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:00,828: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:00,829: updating layer weights
INFO - 2023-11-30 15:51:00,829: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:00.829667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:00,829: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:00,829: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:00.829939', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:01,529: EPOCH 0: training on 191080 raw words (156284 effective words) took 0.7s, 225272 effective words/s
INFO - 2023-11-30 15:51:02,192: EPOCH 1: training on 191080 raw words (156323 effective words) took 0.7s, 237177 effective words/s
INFO - 2023-11-30 15:51:02,777: EPOCH 2: training on 191080 raw words (156322 effective words) took 0.6s, 268577 effective words/s
INFO - 2023-11-30 15:51:03,315: EPOCH 3: training on 191080 raw words (156242 effective words) took 0.5s, 292033 effective words/s
INFO - 2023-11-30 15:51:03,893: EPOCH 4: training on 191080 raw words (156200 effective words) took 0.6s, 271898 effective words/s
INFO - 2023-11-30 15:51:04,407: EPOCH 5: training on 191080 raw words (156258 effective words) took 0.5s, 306411 effective words/s
INFO - 2023-11-30 15:51:04,894: EPOCH 6: training on 191080 raw words (156294 effective words) took 0.5s, 322839 effective words/s
INFO - 2023-11-30 15:51:05,337: EPOCH 7: training on 191080 raw words (156298 effective words) took 0.4s, 357679 effective words/s
INFO - 2023-11-30 15:51:05,751: EPOCH 8: training on 191080 raw words (156127 effective words) took 0.4s, 380066 effective words/s
INFO - 2023-11-30 15:51:06,210: EPOCH 9: training on 191080 raw words (156108 effective words) took 0.5s, 341869 effective words/s
INFO - 2023-11-30 15:51:06,696: EPOCH 10: training on 191080 raw words (156174 effective words) took 0.5s, 323517 effective words/s
INFO - 2023-11-30 15:51:07,129: EPOCH 11: training on 191080 raw words (156332 effective words) took 0.4s, 362950 effective words/s
INFO - 2023-11-30 15:51:07,555: EPOCH 12: training on 191080 raw words (156300 effective words) took 0.4s, 370103 effective words/s
INFO - 2023-11-30 15:51:07,910: EPOCH 13: training on 191080 raw words (156446 effective words) took 0.4s, 444080 effective words/s
INFO - 2023-11-30 15:51:08,250: EPOCH 14: training on 191080 raw words (156376 effective words) took 0.3s, 463980 effective words/s
INFO - 2023-11-30 15:51:08,574: EPOCH 15: training on 191080 raw words (156188 effective words) took 0.3s, 487756 effective words/s
INFO - 2023-11-30 15:51:08,901: EPOCH 16: training on 191080 raw words (156324 effective words) took 0.3s, 481249 effective words/s
INFO - 2023-11-30 15:51:09,249: EPOCH 17: training on 191080 raw words (156352 effective words) took 0.3s, 451837 effective words/s
INFO - 2023-11-30 15:51:09,572: EPOCH 18: training on 191080 raw words (156125 effective words) took 0.3s, 487312 effective words/s
INFO - 2023-11-30 15:51:09,903: EPOCH 19: training on 191080 raw words (156367 effective words) took 0.3s, 477541 effective words/s
INFO - 2023-11-30 15:51:09,903: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125440 effective words) took 9.1s, 344454 effective words/s', 'datetime': '2023-11-30T15:51:09.903639', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:09,903: collecting all words and their counts
INFO - 2023-11-30 15:51:09,904: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:09,941: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:09,941: Updating model with new vocabulary
INFO - 2023-11-30 15:51:09,956: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:09.956018', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:09,971: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:09,971: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:51:09,972: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156145.62182828685 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:51:09.972080', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:09,995: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:09,996: updating layer weights
INFO - 2023-11-30 15:51:09,996: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:09.996861', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:09,997: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:09,997: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:09.997280', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:10,400: EPOCH 0: training on 191080 raw words (156073 effective words) took 0.4s, 389120 effective words/s
INFO - 2023-11-30 15:51:10,737: EPOCH 1: training on 191080 raw words (156012 effective words) took 0.3s, 467793 effective words/s
INFO - 2023-11-30 15:51:11,070: EPOCH 2: training on 191080 raw words (156159 effective words) took 0.3s, 472366 effective words/s
INFO - 2023-11-30 15:51:11,403: EPOCH 3: training on 191080 raw words (156152 effective words) took 0.3s, 474210 effective words/s
INFO - 2023-11-30 15:51:11,762: EPOCH 4: training on 191080 raw words (156353 effective words) took 0.4s, 438703 effective words/s
INFO - 2023-11-30 15:51:12,182: EPOCH 5: training on 191080 raw words (156135 effective words) took 0.4s, 374905 effective words/s
INFO - 2023-11-30 15:51:12,521: EPOCH 6: training on 191080 raw words (156242 effective words) took 0.3s, 463885 effective words/s
INFO - 2023-11-30 15:51:12,866: EPOCH 7: training on 191080 raw words (156146 effective words) took 0.3s, 456004 effective words/s
INFO - 2023-11-30 15:51:13,205: EPOCH 8: training on 191080 raw words (156134 effective words) took 0.3s, 463417 effective words/s
INFO - 2023-11-30 15:51:13,546: EPOCH 9: training on 191080 raw words (156260 effective words) took 0.3s, 461481 effective words/s
INFO - 2023-11-30 15:51:13,885: EPOCH 10: training on 191080 raw words (155966 effective words) took 0.3s, 463663 effective words/s
INFO - 2023-11-30 15:51:14,218: EPOCH 11: training on 191080 raw words (156073 effective words) took 0.3s, 471814 effective words/s
INFO - 2023-11-30 15:51:14,555: EPOCH 12: training on 191080 raw words (156262 effective words) took 0.3s, 467583 effective words/s
INFO - 2023-11-30 15:51:14,893: EPOCH 13: training on 191080 raw words (155959 effective words) took 0.3s, 464822 effective words/s
INFO - 2023-11-30 15:51:15,241: EPOCH 14: training on 191080 raw words (156208 effective words) took 0.3s, 452376 effective words/s
INFO - 2023-11-30 15:51:15,581: EPOCH 15: training on 191080 raw words (156285 effective words) took 0.3s, 461734 effective words/s
INFO - 2023-11-30 15:51:15,918: EPOCH 16: training on 191080 raw words (156100 effective words) took 0.3s, 466775 effective words/s
INFO - 2023-11-30 15:51:16,265: EPOCH 17: training on 191080 raw words (156099 effective words) took 0.3s, 453730 effective words/s
INFO - 2023-11-30 15:51:16,595: EPOCH 18: training on 191080 raw words (156343 effective words) took 0.3s, 476658 effective words/s
INFO - 2023-11-30 15:51:16,933: EPOCH 19: training on 191080 raw words (156136 effective words) took 0.3s, 464905 effective words/s
INFO - 2023-11-30 15:51:16,934: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123097 effective words) took 6.9s, 450230 effective words/s', 'datetime': '2023-11-30T15:51:16.934132', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:16,934: collecting all words and their counts
INFO - 2023-11-30 15:51:16,934: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:16,964: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:16,964: Updating model with new vocabulary
INFO - 2023-11-30 15:51:16,977: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:16.977269', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:16,992: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:16,993: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:51:16,993: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156412.89964728546 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:51:16.993218', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:17,017: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:17,018: updating layer weights
INFO - 2023-11-30 15:51:17,018: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:17.018432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:17,018: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:17,018: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:17.018725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:17,336: EPOCH 0: training on 191080 raw words (156205 effective words) took 0.3s, 495208 effective words/s
INFO - 2023-11-30 15:51:17,661: EPOCH 1: training on 191080 raw words (156404 effective words) took 0.3s, 484926 effective words/s
INFO - 2023-11-30 15:51:17,991: EPOCH 2: training on 191080 raw words (156341 effective words) took 0.3s, 477829 effective words/s
INFO - 2023-11-30 15:51:18,321: EPOCH 3: training on 191080 raw words (156547 effective words) took 0.3s, 477294 effective words/s
INFO - 2023-11-30 15:51:18,650: EPOCH 4: training on 191080 raw words (156528 effective words) took 0.3s, 480307 effective words/s
INFO - 2023-11-30 15:51:18,973: EPOCH 5: training on 191080 raw words (156394 effective words) took 0.3s, 487652 effective words/s
INFO - 2023-11-30 15:51:19,298: EPOCH 6: training on 191080 raw words (156436 effective words) took 0.3s, 484689 effective words/s
INFO - 2023-11-30 15:51:19,623: EPOCH 7: training on 191080 raw words (156369 effective words) took 0.3s, 485777 effective words/s
INFO - 2023-11-30 15:51:19,955: EPOCH 8: training on 191080 raw words (156514 effective words) took 0.3s, 474421 effective words/s
INFO - 2023-11-30 15:51:20,283: EPOCH 9: training on 191080 raw words (156307 effective words) took 0.3s, 480937 effective words/s
INFO - 2023-11-30 15:51:20,614: EPOCH 10: training on 191080 raw words (156485 effective words) took 0.3s, 476718 effective words/s
INFO - 2023-11-30 15:51:20,943: EPOCH 11: training on 191080 raw words (156356 effective words) took 0.3s, 478953 effective words/s
INFO - 2023-11-30 15:51:21,303: EPOCH 12: training on 191080 raw words (156457 effective words) took 0.4s, 438156 effective words/s
INFO - 2023-11-30 15:51:21,683: EPOCH 13: training on 191080 raw words (156343 effective words) took 0.4s, 414685 effective words/s
INFO - 2023-11-30 15:51:22,036: EPOCH 14: training on 191080 raw words (156303 effective words) took 0.3s, 447204 effective words/s
INFO - 2023-11-30 15:51:22,377: EPOCH 15: training on 191080 raw words (156362 effective words) took 0.3s, 463055 effective words/s
INFO - 2023-11-30 15:51:22,838: EPOCH 16: training on 191080 raw words (156376 effective words) took 0.5s, 340878 effective words/s
INFO - 2023-11-30 15:51:23,299: EPOCH 17: training on 191080 raw words (156563 effective words) took 0.5s, 342321 effective words/s
INFO - 2023-11-30 15:51:23,749: EPOCH 18: training on 191080 raw words (156188 effective words) took 0.4s, 350043 effective words/s
INFO - 2023-11-30 15:51:24,207: EPOCH 19: training on 191080 raw words (156515 effective words) took 0.5s, 344437 effective words/s
INFO - 2023-11-30 15:51:24,207: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127993 effective words) took 7.2s, 435116 effective words/s', 'datetime': '2023-11-30T15:51:24.207747', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:24,208: collecting all words and their counts
INFO - 2023-11-30 15:51:24,208: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:24,251: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:24,252: Updating model with new vocabulary
INFO - 2023-11-30 15:51:24,270: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:24.270528', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:24,294: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:24,294: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:51:24,294: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156202.28909104934 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:51:24.294551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:24,330: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:24,330: updating layer weights
INFO - 2023-11-30 15:51:24,331: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:24.331201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:24,331: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:24,331: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:24.331644', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:24,805: EPOCH 0: training on 191080 raw words (156188 effective words) took 0.5s, 332225 effective words/s
INFO - 2023-11-30 15:51:25,290: EPOCH 1: training on 191080 raw words (156317 effective words) took 0.5s, 324746 effective words/s
INFO - 2023-11-30 15:51:25,777: EPOCH 2: training on 191080 raw words (155964 effective words) took 0.5s, 322317 effective words/s
INFO - 2023-11-30 15:51:26,267: EPOCH 3: training on 191080 raw words (156269 effective words) took 0.5s, 320894 effective words/s
INFO - 2023-11-30 15:51:26,770: EPOCH 4: training on 191080 raw words (156219 effective words) took 0.5s, 313064 effective words/s
INFO - 2023-11-30 15:51:27,252: EPOCH 5: training on 191080 raw words (156101 effective words) took 0.5s, 325611 effective words/s
INFO - 2023-11-30 15:51:27,746: EPOCH 6: training on 191080 raw words (156082 effective words) took 0.5s, 319503 effective words/s
INFO - 2023-11-30 15:51:28,243: EPOCH 7: training on 191080 raw words (156266 effective words) took 0.5s, 316611 effective words/s
INFO - 2023-11-30 15:51:28,692: EPOCH 8: training on 191080 raw words (156252 effective words) took 0.4s, 351222 effective words/s
INFO - 2023-11-30 15:51:29,122: EPOCH 9: training on 191080 raw words (156087 effective words) took 0.4s, 365057 effective words/s
INFO - 2023-11-30 15:51:29,607: EPOCH 10: training on 191080 raw words (156241 effective words) took 0.5s, 324404 effective words/s
INFO - 2023-11-30 15:51:30,052: EPOCH 11: training on 191080 raw words (156058 effective words) took 0.4s, 352947 effective words/s
INFO - 2023-11-30 15:51:30,493: EPOCH 12: training on 191080 raw words (156144 effective words) took 0.4s, 356581 effective words/s
INFO - 2023-11-30 15:51:30,933: EPOCH 13: training on 191080 raw words (156354 effective words) took 0.4s, 358199 effective words/s
INFO - 2023-11-30 15:51:31,361: EPOCH 14: training on 191080 raw words (156218 effective words) took 0.4s, 367201 effective words/s
INFO - 2023-11-30 15:51:31,773: EPOCH 15: training on 191080 raw words (156290 effective words) took 0.4s, 382470 effective words/s
INFO - 2023-11-30 15:51:32,182: EPOCH 16: training on 191080 raw words (156066 effective words) took 0.4s, 383556 effective words/s
INFO - 2023-11-30 15:51:32,588: EPOCH 17: training on 191080 raw words (156393 effective words) took 0.4s, 388452 effective words/s
INFO - 2023-11-30 15:51:33,072: EPOCH 18: training on 191080 raw words (156292 effective words) took 0.5s, 324702 effective words/s
INFO - 2023-11-30 15:51:33,474: EPOCH 19: training on 191080 raw words (156045 effective words) took 0.4s, 391598 effective words/s
INFO - 2023-11-30 15:51:33,474: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123846 effective words) took 9.1s, 341665 effective words/s', 'datetime': '2023-11-30T15:51:33.474839', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:33,475: collecting all words and their counts
INFO - 2023-11-30 15:51:33,475: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:33,514: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:33,514: Updating model with new vocabulary
INFO - 2023-11-30 15:51:33,530: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:33.529989', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:33,549: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:33,549: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:51:33,550: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156260.31861037717 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:51:33.550051', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:33,580: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:33,580: updating layer weights
INFO - 2023-11-30 15:51:33,581: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:33.581388', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:33,581: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:33,581: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:33.581800', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:33,967: EPOCH 0: training on 191080 raw words (156288 effective words) took 0.4s, 408357 effective words/s
INFO - 2023-11-30 15:51:34,362: EPOCH 1: training on 191080 raw words (156113 effective words) took 0.4s, 397947 effective words/s
INFO - 2023-11-30 15:51:34,692: EPOCH 2: training on 191080 raw words (156142 effective words) took 0.3s, 479075 effective words/s
INFO - 2023-11-30 15:51:35,024: EPOCH 3: training on 191080 raw words (156057 effective words) took 0.3s, 474011 effective words/s
INFO - 2023-11-30 15:51:35,370: EPOCH 4: training on 191080 raw words (156282 effective words) took 0.3s, 453525 effective words/s
INFO - 2023-11-30 15:51:35,694: EPOCH 5: training on 191080 raw words (156312 effective words) took 0.3s, 486527 effective words/s
INFO - 2023-11-30 15:51:36,016: EPOCH 6: training on 191080 raw words (156354 effective words) took 0.3s, 490571 effective words/s
INFO - 2023-11-30 15:51:36,337: EPOCH 7: training on 191080 raw words (156215 effective words) took 0.3s, 489742 effective words/s
INFO - 2023-11-30 15:51:36,665: EPOCH 8: training on 191080 raw words (156185 effective words) took 0.3s, 478954 effective words/s
INFO - 2023-11-30 15:51:36,989: EPOCH 9: training on 191080 raw words (156313 effective words) took 0.3s, 487119 effective words/s
INFO - 2023-11-30 15:51:37,308: EPOCH 10: training on 191080 raw words (156286 effective words) took 0.3s, 493393 effective words/s
INFO - 2023-11-30 15:51:37,631: EPOCH 11: training on 191080 raw words (156319 effective words) took 0.3s, 488998 effective words/s
INFO - 2023-11-30 15:51:37,950: EPOCH 12: training on 191080 raw words (156152 effective words) took 0.3s, 493424 effective words/s
INFO - 2023-11-30 15:51:38,264: EPOCH 13: training on 191080 raw words (156265 effective words) took 0.3s, 501275 effective words/s
INFO - 2023-11-30 15:51:38,582: EPOCH 14: training on 191080 raw words (156446 effective words) took 0.3s, 496482 effective words/s
INFO - 2023-11-30 15:51:38,899: EPOCH 15: training on 191080 raw words (156192 effective words) took 0.3s, 495577 effective words/s
INFO - 2023-11-30 15:51:39,226: EPOCH 16: training on 191080 raw words (156191 effective words) took 0.3s, 482093 effective words/s
INFO - 2023-11-30 15:51:39,547: EPOCH 17: training on 191080 raw words (156324 effective words) took 0.3s, 491325 effective words/s
INFO - 2023-11-30 15:51:39,864: EPOCH 18: training on 191080 raw words (156253 effective words) took 0.3s, 496604 effective words/s
INFO - 2023-11-30 15:51:40,183: EPOCH 19: training on 191080 raw words (156452 effective words) took 0.3s, 493965 effective words/s
INFO - 2023-11-30 15:51:40,183: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125141 effective words) took 6.6s, 473390 effective words/s', 'datetime': '2023-11-30T15:51:40.183616', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:40,183: collecting all words and their counts
INFO - 2023-11-30 15:51:40,183: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:40,213: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:40,213: Updating model with new vocabulary
INFO - 2023-11-30 15:51:40,226: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:40.226406', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:40,242: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:40,242: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:51:40,242: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 155976.69533311634 word corpus (81.6%% of prior 191080)', 'datetime': '2023-11-30T15:51:40.242880', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:40,266: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:40,266: updating layer weights
INFO - 2023-11-30 15:51:40,267: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:40.267262', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:40,267: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:40,267: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:40.267525', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:40,598: EPOCH 0: training on 191080 raw words (156019 effective words) took 0.3s, 475594 effective words/s
INFO - 2023-11-30 15:51:40,942: EPOCH 1: training on 191080 raw words (155793 effective words) took 0.3s, 456349 effective words/s
INFO - 2023-11-30 15:51:41,279: EPOCH 2: training on 191080 raw words (156010 effective words) took 0.3s, 466289 effective words/s
INFO - 2023-11-30 15:51:41,619: EPOCH 3: training on 191080 raw words (156029 effective words) took 0.3s, 462224 effective words/s
INFO - 2023-11-30 15:51:41,952: EPOCH 4: training on 191080 raw words (155908 effective words) took 0.3s, 471673 effective words/s
INFO - 2023-11-30 15:51:42,291: EPOCH 5: training on 191080 raw words (155868 effective words) took 0.3s, 462962 effective words/s
INFO - 2023-11-30 15:51:42,635: EPOCH 6: training on 191080 raw words (156003 effective words) took 0.3s, 456629 effective words/s
INFO - 2023-11-30 15:51:42,977: EPOCH 7: training on 191080 raw words (156001 effective words) took 0.3s, 460383 effective words/s
INFO - 2023-11-30 15:51:43,314: EPOCH 8: training on 191080 raw words (155979 effective words) took 0.3s, 465289 effective words/s
INFO - 2023-11-30 15:51:43,646: EPOCH 9: training on 191080 raw words (155888 effective words) took 0.3s, 472739 effective words/s
INFO - 2023-11-30 15:51:43,979: EPOCH 10: training on 191080 raw words (155955 effective words) took 0.3s, 472361 effective words/s
INFO - 2023-11-30 15:51:44,310: EPOCH 11: training on 191080 raw words (155924 effective words) took 0.3s, 474658 effective words/s
INFO - 2023-11-30 15:51:44,647: EPOCH 12: training on 191080 raw words (156082 effective words) took 0.3s, 467246 effective words/s
INFO - 2023-11-30 15:51:44,985: EPOCH 13: training on 191080 raw words (155936 effective words) took 0.3s, 465410 effective words/s
INFO - 2023-11-30 15:51:45,320: EPOCH 14: training on 191080 raw words (155961 effective words) took 0.3s, 468676 effective words/s
INFO - 2023-11-30 15:51:45,650: EPOCH 15: training on 191080 raw words (156062 effective words) took 0.3s, 476408 effective words/s
INFO - 2023-11-30 15:51:45,981: EPOCH 16: training on 191080 raw words (156002 effective words) took 0.3s, 475146 effective words/s
INFO - 2023-11-30 15:51:46,321: EPOCH 17: training on 191080 raw words (156036 effective words) took 0.3s, 462857 effective words/s
INFO - 2023-11-30 15:51:46,656: EPOCH 18: training on 191080 raw words (156117 effective words) took 0.3s, 468407 effective words/s
INFO - 2023-11-30 15:51:46,992: EPOCH 19: training on 191080 raw words (156061 effective words) took 0.3s, 468677 effective words/s
INFO - 2023-11-30 15:51:46,992: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3119634 effective words) took 6.7s, 463868 effective words/s', 'datetime': '2023-11-30T15:51:46.992914', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:46,993: collecting all words and their counts
INFO - 2023-11-30 15:51:46,993: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:47,026: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:47,027: Updating model with new vocabulary
INFO - 2023-11-30 15:51:47,040: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:47.040745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:47,057: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:47,057: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:51:47,057: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156210.9854433542 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:51:47.057636', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:47,083: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:47,083: updating layer weights
INFO - 2023-11-30 15:51:47,084: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:47.084406', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:47,084: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:47,084: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:47.084764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:47,410: EPOCH 0: training on 191080 raw words (156326 effective words) took 0.3s, 483422 effective words/s
INFO - 2023-11-30 15:51:47,734: EPOCH 1: training on 191080 raw words (156278 effective words) took 0.3s, 486617 effective words/s
INFO - 2023-11-30 15:51:48,062: EPOCH 2: training on 191080 raw words (156345 effective words) took 0.3s, 480843 effective words/s
INFO - 2023-11-30 15:51:48,381: EPOCH 3: training on 191080 raw words (156164 effective words) took 0.3s, 493052 effective words/s
INFO - 2023-11-30 15:51:48,702: EPOCH 4: training on 191080 raw words (156084 effective words) took 0.3s, 489862 effective words/s
INFO - 2023-11-30 15:51:49,024: EPOCH 5: training on 191080 raw words (155936 effective words) took 0.3s, 488881 effective words/s
INFO - 2023-11-30 15:51:49,344: EPOCH 6: training on 191080 raw words (156025 effective words) took 0.3s, 491663 effective words/s
INFO - 2023-11-30 15:51:49,672: EPOCH 7: training on 191080 raw words (156196 effective words) took 0.3s, 479475 effective words/s
INFO - 2023-11-30 15:51:49,996: EPOCH 8: training on 191080 raw words (156126 effective words) took 0.3s, 484958 effective words/s
INFO - 2023-11-30 15:51:50,314: EPOCH 9: training on 191080 raw words (156058 effective words) took 0.3s, 494553 effective words/s
INFO - 2023-11-30 15:51:50,635: EPOCH 10: training on 191080 raw words (156223 effective words) took 0.3s, 491071 effective words/s
INFO - 2023-11-30 15:51:50,961: EPOCH 11: training on 191080 raw words (156119 effective words) took 0.3s, 482024 effective words/s
INFO - 2023-11-30 15:51:51,284: EPOCH 12: training on 191080 raw words (156018 effective words) took 0.3s, 486761 effective words/s
INFO - 2023-11-30 15:51:51,643: EPOCH 13: training on 191080 raw words (156288 effective words) took 0.4s, 438778 effective words/s
INFO - 2023-11-30 15:51:52,065: EPOCH 14: training on 191080 raw words (156228 effective words) took 0.4s, 396926 effective words/s
INFO - 2023-11-30 15:51:52,497: EPOCH 15: training on 191080 raw words (156391 effective words) took 0.4s, 364608 effective words/s
INFO - 2023-11-30 15:51:52,997: EPOCH 16: training on 191080 raw words (156204 effective words) took 0.5s, 314436 effective words/s
INFO - 2023-11-30 15:51:53,424: EPOCH 17: training on 191080 raw words (156064 effective words) took 0.4s, 367907 effective words/s
INFO - 2023-11-30 15:51:53,850: EPOCH 18: training on 191080 raw words (156126 effective words) took 0.4s, 370023 effective words/s
INFO - 2023-11-30 15:51:54,279: EPOCH 19: training on 191080 raw words (156280 effective words) took 0.4s, 367007 effective words/s
INFO - 2023-11-30 15:51:54,279: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123479 effective words) took 7.2s, 434129 effective words/s', 'datetime': '2023-11-30T15:51:54.279715', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:54,279: collecting all words and their counts
INFO - 2023-11-30 15:51:54,280: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:51:54,324: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:51:54,324: Updating model with new vocabulary
INFO - 2023-11-30 15:51:54,342: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:51:54.342162', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:54,365: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:51:54,365: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:51:54,366: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156152.5645405891 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:51:54.366209', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:51:54,397: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:51:54,397: updating layer weights
INFO - 2023-11-30 15:51:54,398: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:51:54.398157', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:51:54,398: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:51:54,398: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:51:54.398520', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:51:54,868: EPOCH 0: training on 191080 raw words (156066 effective words) took 0.4s, 354541 effective words/s
INFO - 2023-11-30 15:51:55,347: EPOCH 1: training on 191080 raw words (156236 effective words) took 0.5s, 328653 effective words/s
INFO - 2023-11-30 15:51:55,835: EPOCH 2: training on 191080 raw words (156209 effective words) took 0.5s, 321516 effective words/s
INFO - 2023-11-30 15:51:56,319: EPOCH 3: training on 191080 raw words (156146 effective words) took 0.5s, 325540 effective words/s
INFO - 2023-11-30 15:51:56,798: EPOCH 4: training on 191080 raw words (156073 effective words) took 0.5s, 327483 effective words/s
INFO - 2023-11-30 15:51:57,280: EPOCH 5: training on 191080 raw words (156065 effective words) took 0.5s, 326335 effective words/s
INFO - 2023-11-30 15:51:57,785: EPOCH 6: training on 191080 raw words (156234 effective words) took 0.5s, 311861 effective words/s
INFO - 2023-11-30 15:51:58,306: EPOCH 7: training on 191080 raw words (156223 effective words) took 0.5s, 301933 effective words/s
INFO - 2023-11-30 15:51:58,822: EPOCH 8: training on 191080 raw words (155942 effective words) took 0.5s, 304147 effective words/s
INFO - 2023-11-30 15:51:59,340: EPOCH 9: training on 191080 raw words (156109 effective words) took 0.5s, 303323 effective words/s
INFO - 2023-11-30 15:51:59,862: EPOCH 10: training on 191080 raw words (156193 effective words) took 0.5s, 301305 effective words/s
INFO - 2023-11-30 15:52:00,378: EPOCH 11: training on 191080 raw words (155973 effective words) took 0.5s, 304102 effective words/s
INFO - 2023-11-30 15:52:00,798: EPOCH 12: training on 191080 raw words (155818 effective words) took 0.4s, 374593 effective words/s
INFO - 2023-11-30 15:52:01,126: EPOCH 13: training on 191080 raw words (156187 effective words) took 0.3s, 479379 effective words/s
INFO - 2023-11-30 15:52:01,469: EPOCH 14: training on 191080 raw words (156316 effective words) took 0.3s, 461852 effective words/s
INFO - 2023-11-30 15:52:01,806: EPOCH 15: training on 191080 raw words (156176 effective words) took 0.3s, 466406 effective words/s
INFO - 2023-11-30 15:52:02,145: EPOCH 16: training on 191080 raw words (156009 effective words) took 0.3s, 492132 effective words/s
INFO - 2023-11-30 15:52:02,478: EPOCH 17: training on 191080 raw words (156299 effective words) took 0.3s, 472083 effective words/s
INFO - 2023-11-30 15:52:02,806: EPOCH 18: training on 191080 raw words (156166 effective words) took 0.3s, 479437 effective words/s
INFO - 2023-11-30 15:52:03,142: EPOCH 19: training on 191080 raw words (156246 effective words) took 0.3s, 468262 effective words/s
INFO - 2023-11-30 15:52:03,143: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122686 effective words) took 8.7s, 357111 effective words/s', 'datetime': '2023-11-30T15:52:03.143016', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:03,143: collecting all words and their counts
INFO - 2023-11-30 15:52:03,143: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:03,174: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:03,174: Updating model with new vocabulary
INFO - 2023-11-30 15:52:03,186: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:03.186821', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:03,202: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:03,202: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:52:03,202: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156191.21846174033 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:52:03.202529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:03,227: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:03,227: updating layer weights
INFO - 2023-11-30 15:52:03,228: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:03.227962', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:03,228: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:03,228: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:03.228342', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:03,545: EPOCH 0: training on 191080 raw words (155969 effective words) took 0.3s, 495010 effective words/s
INFO - 2023-11-30 15:52:03,868: EPOCH 1: training on 191080 raw words (156225 effective words) took 0.3s, 488193 effective words/s
INFO - 2023-11-30 15:52:04,191: EPOCH 2: training on 191080 raw words (156353 effective words) took 0.3s, 487448 effective words/s
INFO - 2023-11-30 15:52:04,518: EPOCH 3: training on 191080 raw words (156302 effective words) took 0.3s, 480980 effective words/s
INFO - 2023-11-30 15:52:04,838: EPOCH 4: training on 191080 raw words (156029 effective words) took 0.3s, 491589 effective words/s
INFO - 2023-11-30 15:52:05,167: EPOCH 5: training on 191080 raw words (156238 effective words) took 0.3s, 478695 effective words/s
INFO - 2023-11-30 15:52:05,488: EPOCH 6: training on 191080 raw words (156295 effective words) took 0.3s, 490357 effective words/s
INFO - 2023-11-30 15:52:05,814: EPOCH 7: training on 191080 raw words (156312 effective words) took 0.3s, 482549 effective words/s
INFO - 2023-11-30 15:52:06,147: EPOCH 8: training on 191080 raw words (156296 effective words) took 0.3s, 473219 effective words/s
INFO - 2023-11-30 15:52:06,475: EPOCH 9: training on 191080 raw words (156242 effective words) took 0.3s, 480105 effective words/s
INFO - 2023-11-30 15:52:06,797: EPOCH 10: training on 191080 raw words (156268 effective words) took 0.3s, 489320 effective words/s
INFO - 2023-11-30 15:52:07,119: EPOCH 11: training on 191080 raw words (156210 effective words) took 0.3s, 489199 effective words/s
INFO - 2023-11-30 15:52:07,444: EPOCH 12: training on 191080 raw words (156226 effective words) took 0.3s, 484893 effective words/s
INFO - 2023-11-30 15:52:07,776: EPOCH 13: training on 191080 raw words (156308 effective words) took 0.3s, 473211 effective words/s
INFO - 2023-11-30 15:52:08,105: EPOCH 14: training on 191080 raw words (156053 effective words) took 0.3s, 478290 effective words/s
INFO - 2023-11-30 15:52:08,449: EPOCH 15: training on 191080 raw words (156195 effective words) took 0.3s, 456671 effective words/s
INFO - 2023-11-30 15:52:08,797: EPOCH 16: training on 191080 raw words (156186 effective words) took 0.3s, 453103 effective words/s
INFO - 2023-11-30 15:52:09,121: EPOCH 17: training on 191080 raw words (156170 effective words) took 0.3s, 485050 effective words/s
INFO - 2023-11-30 15:52:09,461: EPOCH 18: training on 191080 raw words (156238 effective words) took 0.3s, 463199 effective words/s
INFO - 2023-11-30 15:52:09,786: EPOCH 19: training on 191080 raw words (156184 effective words) took 0.3s, 484622 effective words/s
INFO - 2023-11-30 15:52:09,786: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3124299 effective words) took 6.6s, 476403 effective words/s', 'datetime': '2023-11-30T15:52:09.786623', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:09,786: collecting all words and their counts
INFO - 2023-11-30 15:52:09,786: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:09,819: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:09,819: Updating model with new vocabulary
INFO - 2023-11-30 15:52:09,834: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:09.834533', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:09,852: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:09,852: sample=0.001 downsamples 34 most-common words
INFO - 2023-11-30 15:52:09,853: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156254.48432552896 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:52:09.852975', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:09,877: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:09,877: updating layer weights
INFO - 2023-11-30 15:52:09,878: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:09.878315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:09,878: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:09,879: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:09.879075', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:10,221: EPOCH 0: training on 191080 raw words (156204 effective words) took 0.3s, 459310 effective words/s
INFO - 2023-11-30 15:52:10,555: EPOCH 1: training on 191080 raw words (156270 effective words) took 0.3s, 470660 effective words/s
INFO - 2023-11-30 15:52:10,901: EPOCH 2: training on 191080 raw words (156367 effective words) took 0.3s, 456017 effective words/s
INFO - 2023-11-30 15:52:11,302: EPOCH 3: training on 191080 raw words (156360 effective words) took 0.4s, 392050 effective words/s
INFO - 2023-11-30 15:52:11,667: EPOCH 4: training on 191080 raw words (156263 effective words) took 0.4s, 432052 effective words/s
INFO - 2023-11-30 15:52:12,031: EPOCH 5: training on 191080 raw words (156429 effective words) took 0.4s, 432992 effective words/s
INFO - 2023-11-30 15:52:12,374: EPOCH 6: training on 191080 raw words (156319 effective words) took 0.3s, 459240 effective words/s
INFO - 2023-11-30 15:52:12,712: EPOCH 7: training on 191080 raw words (156303 effective words) took 0.3s, 464658 effective words/s
INFO - 2023-11-30 15:52:13,070: EPOCH 8: training on 191080 raw words (156169 effective words) took 0.4s, 440674 effective words/s
INFO - 2023-11-30 15:52:13,424: EPOCH 9: training on 191080 raw words (156354 effective words) took 0.4s, 443835 effective words/s
INFO - 2023-11-30 15:52:13,768: EPOCH 10: training on 191080 raw words (156282 effective words) took 0.3s, 457036 effective words/s
INFO - 2023-11-30 15:52:14,130: EPOCH 11: training on 191080 raw words (156295 effective words) took 0.4s, 435334 effective words/s
INFO - 2023-11-30 15:52:14,493: EPOCH 12: training on 191080 raw words (156185 effective words) took 0.4s, 433649 effective words/s
INFO - 2023-11-30 15:52:14,843: EPOCH 13: training on 191080 raw words (156345 effective words) took 0.3s, 450464 effective words/s
INFO - 2023-11-30 15:52:15,266: EPOCH 14: training on 191080 raw words (156343 effective words) took 0.4s, 371879 effective words/s
INFO - 2023-11-30 15:52:15,629: EPOCH 15: training on 191080 raw words (156273 effective words) took 0.4s, 433111 effective words/s
INFO - 2023-11-30 15:52:16,083: EPOCH 16: training on 191080 raw words (156224 effective words) took 0.5s, 346069 effective words/s
INFO - 2023-11-30 15:52:16,580: EPOCH 17: training on 191080 raw words (156456 effective words) took 0.5s, 316972 effective words/s
INFO - 2023-11-30 15:52:17,086: EPOCH 18: training on 191080 raw words (156284 effective words) took 0.5s, 310533 effective words/s
INFO - 2023-11-30 15:52:17,580: EPOCH 19: training on 191080 raw words (156241 effective words) took 0.5s, 318633 effective words/s
INFO - 2023-11-30 15:52:17,580: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125966 effective words) took 7.7s, 405882 effective words/s', 'datetime': '2023-11-30T15:52:17.580933', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:17,581: collecting all words and their counts
INFO - 2023-11-30 15:52:17,581: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:17,642: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:17,642: Updating model with new vocabulary
INFO - 2023-11-30 15:52:17,669: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:17.669865', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:17,699: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:17,700: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:52:17,700: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156425.6138962683 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:52:17.700175', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:17,735: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:17,735: updating layer weights
INFO - 2023-11-30 15:52:17,735: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:17.735835', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:17,736: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:17,736: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:17.736144', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:18,207: EPOCH 0: training on 191080 raw words (156521 effective words) took 0.5s, 334471 effective words/s
INFO - 2023-11-30 15:52:18,778: EPOCH 1: training on 191080 raw words (156321 effective words) took 0.6s, 277688 effective words/s
INFO - 2023-11-30 15:52:19,260: EPOCH 2: training on 191080 raw words (156535 effective words) took 0.5s, 327213 effective words/s
INFO - 2023-11-30 15:52:19,736: EPOCH 3: training on 191080 raw words (156405 effective words) took 0.5s, 331069 effective words/s
INFO - 2023-11-30 15:52:20,212: EPOCH 4: training on 191080 raw words (156382 effective words) took 0.5s, 330830 effective words/s
INFO - 2023-11-30 15:52:20,678: EPOCH 5: training on 191080 raw words (156324 effective words) took 0.5s, 337961 effective words/s
INFO - 2023-11-30 15:52:21,154: EPOCH 6: training on 191080 raw words (156548 effective words) took 0.5s, 331409 effective words/s
INFO - 2023-11-30 15:52:21,621: EPOCH 7: training on 191080 raw words (156448 effective words) took 0.5s, 337814 effective words/s
INFO - 2023-11-30 15:52:22,142: EPOCH 8: training on 191080 raw words (156395 effective words) took 0.5s, 302628 effective words/s
INFO - 2023-11-30 15:52:22,713: EPOCH 9: training on 191080 raw words (156316 effective words) took 0.6s, 276316 effective words/s
INFO - 2023-11-30 15:52:23,251: EPOCH 10: training on 191080 raw words (156408 effective words) took 0.5s, 292698 effective words/s
INFO - 2023-11-30 15:52:23,805: EPOCH 11: training on 191080 raw words (156315 effective words) took 0.5s, 284318 effective words/s
INFO - 2023-11-30 15:52:24,409: EPOCH 12: training on 191080 raw words (156490 effective words) took 0.6s, 260846 effective words/s
INFO - 2023-11-30 15:52:24,896: EPOCH 13: training on 191080 raw words (156341 effective words) took 0.5s, 323526 effective words/s
INFO - 2023-11-30 15:52:25,227: EPOCH 14: training on 191080 raw words (156432 effective words) took 0.3s, 475935 effective words/s
INFO - 2023-11-30 15:52:25,566: EPOCH 15: training on 191080 raw words (156484 effective words) took 0.3s, 465421 effective words/s
INFO - 2023-11-30 15:52:25,913: EPOCH 16: training on 191080 raw words (156455 effective words) took 0.3s, 455085 effective words/s
INFO - 2023-11-30 15:52:26,252: EPOCH 17: training on 191080 raw words (156352 effective words) took 0.3s, 494372 effective words/s
INFO - 2023-11-30 15:52:26,591: EPOCH 18: training on 191080 raw words (156445 effective words) took 0.3s, 465056 effective words/s
INFO - 2023-11-30 15:52:26,947: EPOCH 19: training on 191080 raw words (156408 effective words) took 0.4s, 443378 effective words/s
INFO - 2023-11-30 15:52:26,947: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128325 effective words) took 9.2s, 339622 effective words/s', 'datetime': '2023-11-30T15:52:26.947516', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:26,947: collecting all words and their counts
INFO - 2023-11-30 15:52:26,947: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:26,979: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:26,979: Updating model with new vocabulary
INFO - 2023-11-30 15:52:26,995: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:26.995369', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:27,011: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:27,011: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:52:27,011: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156119.6273431494 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:52:27.011591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:27,035: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:27,035: updating layer weights
INFO - 2023-11-30 15:52:27,036: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:27.036057', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:27,036: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:27,036: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:27.036477', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:27,425: EPOCH 0: training on 191080 raw words (156157 effective words) took 0.4s, 404644 effective words/s
INFO - 2023-11-30 15:52:27,811: EPOCH 1: training on 191080 raw words (156037 effective words) took 0.4s, 406475 effective words/s
INFO - 2023-11-30 15:52:28,171: EPOCH 2: training on 191080 raw words (156312 effective words) took 0.4s, 438415 effective words/s
INFO - 2023-11-30 15:52:28,522: EPOCH 3: training on 191080 raw words (156251 effective words) took 0.3s, 448541 effective words/s
INFO - 2023-11-30 15:52:28,927: EPOCH 4: training on 191080 raw words (156180 effective words) took 0.4s, 399051 effective words/s
INFO - 2023-11-30 15:52:29,333: EPOCH 5: training on 191080 raw words (156293 effective words) took 0.4s, 387359 effective words/s
INFO - 2023-11-30 15:52:29,728: EPOCH 6: training on 191080 raw words (155938 effective words) took 0.4s, 398353 effective words/s
INFO - 2023-11-30 15:52:30,106: EPOCH 7: training on 191080 raw words (156144 effective words) took 0.4s, 415715 effective words/s
INFO - 2023-11-30 15:52:30,497: EPOCH 8: training on 191080 raw words (156099 effective words) took 0.4s, 402817 effective words/s
INFO - 2023-11-30 15:52:30,905: EPOCH 9: training on 191080 raw words (156012 effective words) took 0.4s, 385210 effective words/s
INFO - 2023-11-30 15:52:31,296: EPOCH 10: training on 191080 raw words (156111 effective words) took 0.4s, 401626 effective words/s
INFO - 2023-11-30 15:52:31,694: EPOCH 11: training on 191080 raw words (156116 effective words) took 0.4s, 394859 effective words/s
INFO - 2023-11-30 15:52:32,061: EPOCH 12: training on 191080 raw words (156154 effective words) took 0.4s, 428848 effective words/s
INFO - 2023-11-30 15:52:32,420: EPOCH 13: training on 191080 raw words (156376 effective words) took 0.4s, 439832 effective words/s
INFO - 2023-11-30 15:52:32,789: EPOCH 14: training on 191080 raw words (156099 effective words) took 0.4s, 426021 effective words/s
INFO - 2023-11-30 15:52:33,157: EPOCH 15: training on 191080 raw words (156198 effective words) took 0.4s, 427525 effective words/s
INFO - 2023-11-30 15:52:33,533: EPOCH 16: training on 191080 raw words (156053 effective words) took 0.4s, 418697 effective words/s
INFO - 2023-11-30 15:52:33,897: EPOCH 17: training on 191080 raw words (156058 effective words) took 0.4s, 431508 effective words/s
INFO - 2023-11-30 15:52:34,317: EPOCH 18: training on 191080 raw words (156180 effective words) took 0.4s, 374554 effective words/s
INFO - 2023-11-30 15:52:34,704: EPOCH 19: training on 191080 raw words (156007 effective words) took 0.4s, 405984 effective words/s
INFO - 2023-11-30 15:52:34,705: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122775 effective words) took 7.7s, 407212 effective words/s', 'datetime': '2023-11-30T15:52:34.705333', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:34,705: collecting all words and their counts
INFO - 2023-11-30 15:52:34,705: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:34,739: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:34,739: Updating model with new vocabulary
INFO - 2023-11-30 15:52:34,758: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:34.758365', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:34,774: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:34,775: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:52:34,775: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156012.7946119363 word corpus (81.6%% of prior 191080)', 'datetime': '2023-11-30T15:52:34.775339', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:34,804: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:34,805: updating layer weights
INFO - 2023-11-30 15:52:34,805: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:34.805515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:34,805: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:34,805: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:34.805861', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:35,140: EPOCH 0: training on 191080 raw words (155937 effective words) took 0.3s, 469723 effective words/s
INFO - 2023-11-30 15:52:35,482: EPOCH 1: training on 191080 raw words (156061 effective words) took 0.3s, 458744 effective words/s
INFO - 2023-11-30 15:52:35,856: EPOCH 2: training on 191080 raw words (156252 effective words) took 0.4s, 421832 effective words/s
INFO - 2023-11-30 15:52:36,187: EPOCH 3: training on 191080 raw words (156263 effective words) took 0.3s, 478264 effective words/s
INFO - 2023-11-30 15:52:36,507: EPOCH 4: training on 191080 raw words (156032 effective words) took 0.3s, 490904 effective words/s
INFO - 2023-11-30 15:52:36,831: EPOCH 5: training on 191080 raw words (155885 effective words) took 0.3s, 485361 effective words/s
INFO - 2023-11-30 15:52:37,158: EPOCH 6: training on 191080 raw words (156162 effective words) took 0.3s, 481370 effective words/s
INFO - 2023-11-30 15:52:37,486: EPOCH 7: training on 191080 raw words (156036 effective words) took 0.3s, 479445 effective words/s
INFO - 2023-11-30 15:52:37,804: EPOCH 8: training on 191080 raw words (155856 effective words) took 0.3s, 493355 effective words/s
INFO - 2023-11-30 15:52:38,126: EPOCH 9: training on 191080 raw words (155851 effective words) took 0.3s, 487994 effective words/s
INFO - 2023-11-30 15:52:38,443: EPOCH 10: training on 191080 raw words (156035 effective words) took 0.3s, 496298 effective words/s
INFO - 2023-11-30 15:52:38,767: EPOCH 11: training on 191080 raw words (156061 effective words) took 0.3s, 484171 effective words/s
INFO - 2023-11-30 15:52:39,149: EPOCH 12: training on 191080 raw words (155946 effective words) took 0.4s, 411128 effective words/s
INFO - 2023-11-30 15:52:39,487: EPOCH 13: training on 191080 raw words (156056 effective words) took 0.3s, 465750 effective words/s
INFO - 2023-11-30 15:52:39,807: EPOCH 14: training on 191080 raw words (155910 effective words) took 0.3s, 491026 effective words/s
INFO - 2023-11-30 15:52:40,184: EPOCH 15: training on 191080 raw words (155866 effective words) took 0.4s, 415382 effective words/s
INFO - 2023-11-30 15:52:40,603: EPOCH 16: training on 191080 raw words (155744 effective words) took 0.4s, 375006 effective words/s
INFO - 2023-11-30 15:52:41,047: EPOCH 17: training on 191080 raw words (155899 effective words) took 0.4s, 353783 effective words/s
INFO - 2023-11-30 15:52:41,494: EPOCH 18: training on 191080 raw words (156129 effective words) took 0.4s, 352522 effective words/s
INFO - 2023-11-30 15:52:41,926: EPOCH 19: training on 191080 raw words (156019 effective words) took 0.4s, 363943 effective words/s
INFO - 2023-11-30 15:52:41,926: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120000 effective words) took 7.1s, 438178 effective words/s', 'datetime': '2023-11-30T15:52:41.926405', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:41,926: collecting all words and their counts
INFO - 2023-11-30 15:52:41,926: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:41,967: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:41,967: Updating model with new vocabulary
INFO - 2023-11-30 15:52:41,984: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:41.984378', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:42,004: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:42,005: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:52:42,005: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156378.90941369667 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:52:42.005597', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:42,037: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:42,037: updating layer weights
INFO - 2023-11-30 15:52:42,038: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:42.037970', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:42,038: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:42,038: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:42.038287', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:42,501: EPOCH 0: training on 191080 raw words (156159 effective words) took 0.5s, 339803 effective words/s
INFO - 2023-11-30 15:52:42,953: EPOCH 1: training on 191080 raw words (156402 effective words) took 0.4s, 348780 effective words/s
INFO - 2023-11-30 15:52:43,436: EPOCH 2: training on 191080 raw words (156349 effective words) took 0.5s, 325890 effective words/s
INFO - 2023-11-30 15:52:43,915: EPOCH 3: training on 191080 raw words (156177 effective words) took 0.5s, 328887 effective words/s
INFO - 2023-11-30 15:52:44,390: EPOCH 4: training on 191080 raw words (156427 effective words) took 0.5s, 331062 effective words/s
INFO - 2023-11-30 15:52:44,868: EPOCH 5: training on 191080 raw words (156482 effective words) took 0.5s, 330417 effective words/s
INFO - 2023-11-30 15:52:45,345: EPOCH 6: training on 191080 raw words (156289 effective words) took 0.5s, 329738 effective words/s
INFO - 2023-11-30 15:52:45,826: EPOCH 7: training on 191080 raw words (156445 effective words) took 0.5s, 327135 effective words/s
INFO - 2023-11-30 15:52:46,336: EPOCH 8: training on 191080 raw words (156426 effective words) took 0.5s, 308731 effective words/s
INFO - 2023-11-30 15:52:46,852: EPOCH 9: training on 191080 raw words (156432 effective words) took 0.5s, 305292 effective words/s
INFO - 2023-11-30 15:52:47,378: EPOCH 10: training on 191080 raw words (156274 effective words) took 0.5s, 299827 effective words/s
INFO - 2023-11-30 15:52:47,923: EPOCH 11: training on 191080 raw words (156284 effective words) took 0.5s, 288598 effective words/s
INFO - 2023-11-30 15:52:48,494: EPOCH 12: training on 191080 raw words (156281 effective words) took 0.6s, 275558 effective words/s
INFO - 2023-11-30 15:52:49,043: EPOCH 13: training on 191080 raw words (156456 effective words) took 0.5s, 286659 effective words/s
INFO - 2023-11-30 15:52:49,415: EPOCH 14: training on 191080 raw words (156372 effective words) took 0.4s, 423519 effective words/s
INFO - 2023-11-30 15:52:49,772: EPOCH 15: training on 191080 raw words (156402 effective words) took 0.4s, 442979 effective words/s
INFO - 2023-11-30 15:52:50,132: EPOCH 16: training on 191080 raw words (156459 effective words) took 0.4s, 438426 effective words/s
INFO - 2023-11-30 15:52:50,489: EPOCH 17: training on 191080 raw words (156135 effective words) took 0.4s, 440186 effective words/s
INFO - 2023-11-30 15:52:50,840: EPOCH 18: training on 191080 raw words (156319 effective words) took 0.3s, 447848 effective words/s
INFO - 2023-11-30 15:52:51,181: EPOCH 19: training on 191080 raw words (156159 effective words) took 0.3s, 462002 effective words/s
INFO - 2023-11-30 15:52:51,182: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126729 effective words) took 9.1s, 341954 effective words/s', 'datetime': '2023-11-30T15:52:51.182161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:51,182: collecting all words and their counts
INFO - 2023-11-30 15:52:51,182: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:51,213: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:51,213: Updating model with new vocabulary
INFO - 2023-11-30 15:52:51,226: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:51.226420', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:51,242: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:51,242: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:52:51,243: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156223.74858403252 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:52:51.243028', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:51,271: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:51,271: updating layer weights
INFO - 2023-11-30 15:52:51,271: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:51.271820', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:51,272: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:51,272: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:51.272512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:51,603: EPOCH 0: training on 191080 raw words (156180 effective words) took 0.3s, 477758 effective words/s
INFO - 2023-11-30 15:52:51,928: EPOCH 1: training on 191080 raw words (156212 effective words) took 0.3s, 484369 effective words/s
INFO - 2023-11-30 15:52:52,250: EPOCH 2: training on 191080 raw words (156329 effective words) took 0.3s, 487987 effective words/s
INFO - 2023-11-30 15:52:52,576: EPOCH 3: training on 191080 raw words (156475 effective words) took 0.3s, 485821 effective words/s
INFO - 2023-11-30 15:52:52,899: EPOCH 4: training on 191080 raw words (156032 effective words) took 0.3s, 485966 effective words/s
INFO - 2023-11-30 15:52:53,258: EPOCH 5: training on 191080 raw words (156418 effective words) took 0.3s, 465095 effective words/s
INFO - 2023-11-30 15:52:53,579: EPOCH 6: training on 191080 raw words (156205 effective words) took 0.3s, 491135 effective words/s
INFO - 2023-11-30 15:52:53,927: EPOCH 7: training on 191080 raw words (156346 effective words) took 0.3s, 452363 effective words/s
INFO - 2023-11-30 15:52:54,268: EPOCH 8: training on 191080 raw words (156297 effective words) took 0.3s, 462392 effective words/s
INFO - 2023-11-30 15:52:54,628: EPOCH 9: training on 191080 raw words (156159 effective words) took 0.4s, 438351 effective words/s
INFO - 2023-11-30 15:52:54,953: EPOCH 10: training on 191080 raw words (156411 effective words) took 0.3s, 484404 effective words/s
INFO - 2023-11-30 15:52:55,270: EPOCH 11: training on 191080 raw words (156206 effective words) took 0.3s, 527414 effective words/s
INFO - 2023-11-30 15:52:55,593: EPOCH 12: training on 191080 raw words (156151 effective words) took 0.3s, 488569 effective words/s
INFO - 2023-11-30 15:52:55,913: EPOCH 13: training on 191080 raw words (156329 effective words) took 0.3s, 521930 effective words/s
INFO - 2023-11-30 15:52:56,241: EPOCH 14: training on 191080 raw words (156202 effective words) took 0.3s, 480310 effective words/s
INFO - 2023-11-30 15:52:56,565: EPOCH 15: training on 191080 raw words (156036 effective words) took 0.3s, 484604 effective words/s
INFO - 2023-11-30 15:52:56,884: EPOCH 16: training on 191080 raw words (156452 effective words) took 0.3s, 494065 effective words/s
INFO - 2023-11-30 15:52:57,205: EPOCH 17: training on 191080 raw words (156393 effective words) took 0.3s, 491346 effective words/s
INFO - 2023-11-30 15:52:57,532: EPOCH 18: training on 191080 raw words (156102 effective words) took 0.3s, 481301 effective words/s
INFO - 2023-11-30 15:52:57,855: EPOCH 19: training on 191080 raw words (156132 effective words) took 0.3s, 487635 effective words/s
INFO - 2023-11-30 15:52:57,855: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125067 effective words) took 6.6s, 474724 effective words/s', 'datetime': '2023-11-30T15:52:57.855653', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:57,855: collecting all words and their counts
INFO - 2023-11-30 15:52:57,856: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:52:57,885: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:52:57,885: Updating model with new vocabulary
INFO - 2023-11-30 15:52:57,899: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:52:57.899215', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:57,914: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:52:57,914: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:52:57,914: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156085.84161540677 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:52:57.914549', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:52:57,938: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:52:57,938: updating layer weights
INFO - 2023-11-30 15:52:57,939: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:52:57.939203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:52:57,939: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:52:57,939: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:52:57.939523', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:52:58,269: EPOCH 0: training on 191080 raw words (155804 effective words) took 0.3s, 476450 effective words/s
INFO - 2023-11-30 15:52:58,601: EPOCH 1: training on 191080 raw words (156123 effective words) took 0.3s, 474049 effective words/s
INFO - 2023-11-30 15:52:58,940: EPOCH 2: training on 191080 raw words (156157 effective words) took 0.3s, 462911 effective words/s
INFO - 2023-11-30 15:52:59,284: EPOCH 3: training on 191080 raw words (156141 effective words) took 0.3s, 457624 effective words/s
INFO - 2023-11-30 15:52:59,619: EPOCH 4: training on 191080 raw words (155862 effective words) took 0.3s, 467974 effective words/s
INFO - 2023-11-30 15:52:59,957: EPOCH 5: training on 191080 raw words (156193 effective words) took 0.3s, 466270 effective words/s
INFO - 2023-11-30 15:53:00,299: EPOCH 6: training on 191080 raw words (156185 effective words) took 0.3s, 459339 effective words/s
INFO - 2023-11-30 15:53:00,637: EPOCH 7: training on 191080 raw words (155976 effective words) took 0.3s, 465401 effective words/s
INFO - 2023-11-30 15:53:00,977: EPOCH 8: training on 191080 raw words (156083 effective words) took 0.3s, 462244 effective words/s
INFO - 2023-11-30 15:53:01,319: EPOCH 9: training on 191080 raw words (155953 effective words) took 0.3s, 459890 effective words/s
INFO - 2023-11-30 15:53:01,750: EPOCH 10: training on 191080 raw words (156095 effective words) took 0.4s, 364163 effective words/s
INFO - 2023-11-30 15:53:02,091: EPOCH 11: training on 191080 raw words (156001 effective words) took 0.3s, 461169 effective words/s
INFO - 2023-11-30 15:53:02,456: EPOCH 12: training on 191080 raw words (155943 effective words) took 0.4s, 430335 effective words/s
INFO - 2023-11-30 15:53:02,797: EPOCH 13: training on 191080 raw words (156100 effective words) took 0.3s, 461843 effective words/s
INFO - 2023-11-30 15:53:03,142: EPOCH 14: training on 191080 raw words (156012 effective words) took 0.3s, 454186 effective words/s
INFO - 2023-11-30 15:53:03,478: EPOCH 15: training on 191080 raw words (156087 effective words) took 0.3s, 468400 effective words/s
INFO - 2023-11-30 15:53:03,813: EPOCH 16: training on 191080 raw words (155931 effective words) took 0.3s, 468788 effective words/s
INFO - 2023-11-30 15:53:04,161: EPOCH 17: training on 191080 raw words (155967 effective words) took 0.3s, 450972 effective words/s
INFO - 2023-11-30 15:53:04,609: EPOCH 18: training on 191080 raw words (156055 effective words) took 0.4s, 350968 effective words/s
INFO - 2023-11-30 15:53:05,090: EPOCH 19: training on 191080 raw words (155900 effective words) took 0.5s, 326578 effective words/s
INFO - 2023-11-30 15:53:05,090: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120568 effective words) took 7.2s, 436375 effective words/s', 'datetime': '2023-11-30T15:53:05.090803', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:05,091: collecting all words and their counts
INFO - 2023-11-30 15:53:05,091: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:05,139: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:05,139: Updating model with new vocabulary
INFO - 2023-11-30 15:53:05,159: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:05.159204', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:05,184: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:05,184: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:53:05,185: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156219.52501566795 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:53:05.185068', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:05,234: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:05,235: updating layer weights
INFO - 2023-11-30 15:53:05,235: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:05.235579', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:05,235: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:05,235: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:05.235973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:05,741: EPOCH 0: training on 191080 raw words (155950 effective words) took 0.5s, 310875 effective words/s
INFO - 2023-11-30 15:53:06,236: EPOCH 1: training on 191080 raw words (156416 effective words) took 0.5s, 318864 effective words/s
INFO - 2023-11-30 15:53:06,674: EPOCH 2: training on 191080 raw words (156352 effective words) took 0.4s, 359836 effective words/s
INFO - 2023-11-30 15:53:07,108: EPOCH 3: training on 191080 raw words (156231 effective words) took 0.4s, 362629 effective words/s
INFO - 2023-11-30 15:53:07,568: EPOCH 4: training on 191080 raw words (156226 effective words) took 0.5s, 341995 effective words/s
INFO - 2023-11-30 15:53:08,029: EPOCH 5: training on 191080 raw words (156109 effective words) took 0.5s, 342068 effective words/s
INFO - 2023-11-30 15:53:08,490: EPOCH 6: training on 191080 raw words (156167 effective words) took 0.5s, 340699 effective words/s
INFO - 2023-11-30 15:53:08,954: EPOCH 7: training on 191080 raw words (156414 effective words) took 0.5s, 339588 effective words/s
INFO - 2023-11-30 15:53:09,426: EPOCH 8: training on 191080 raw words (156311 effective words) took 0.5s, 333991 effective words/s
INFO - 2023-11-30 15:53:09,897: EPOCH 9: training on 191080 raw words (156110 effective words) took 0.5s, 333988 effective words/s
INFO - 2023-11-30 15:53:10,375: EPOCH 10: training on 191080 raw words (156289 effective words) took 0.5s, 328591 effective words/s
INFO - 2023-11-30 15:53:10,865: EPOCH 11: training on 191080 raw words (156268 effective words) took 0.5s, 321715 effective words/s
INFO - 2023-11-30 15:53:11,378: EPOCH 12: training on 191080 raw words (156308 effective words) took 0.5s, 306243 effective words/s
INFO - 2023-11-30 15:53:11,877: EPOCH 13: training on 191080 raw words (156262 effective words) took 0.5s, 315616 effective words/s
INFO - 2023-11-30 15:53:12,376: EPOCH 14: training on 191080 raw words (156281 effective words) took 0.5s, 316082 effective words/s
INFO - 2023-11-30 15:53:12,867: EPOCH 15: training on 191080 raw words (155995 effective words) took 0.5s, 320115 effective words/s
INFO - 2023-11-30 15:53:13,280: EPOCH 16: training on 191080 raw words (156047 effective words) took 0.4s, 381227 effective words/s
INFO - 2023-11-30 15:53:13,608: EPOCH 17: training on 191080 raw words (156194 effective words) took 0.3s, 480411 effective words/s
INFO - 2023-11-30 15:53:13,922: EPOCH 18: training on 191080 raw words (156322 effective words) took 0.3s, 501628 effective words/s
INFO - 2023-11-30 15:53:14,254: EPOCH 19: training on 191080 raw words (156192 effective words) took 0.3s, 474579 effective words/s
INFO - 2023-11-30 15:53:14,254: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3124444 effective words) took 9.0s, 346446 effective words/s', 'datetime': '2023-11-30T15:53:14.254741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:14,255: collecting all words and their counts
INFO - 2023-11-30 15:53:14,255: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:14,284: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:14,285: Updating model with new vocabulary
INFO - 2023-11-30 15:53:14,298: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:14.298219', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:14,313: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:14,314: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:53:14,314: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156388.93384413334 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:53:14.314162', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:14,337: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:14,337: updating layer weights
INFO - 2023-11-30 15:53:14,338: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:14.338086', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:14,338: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:14,338: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:14.338386', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:14,668: EPOCH 0: training on 191080 raw words (156368 effective words) took 0.3s, 477093 effective words/s
INFO - 2023-11-30 15:53:15,008: EPOCH 1: training on 191080 raw words (156370 effective words) took 0.3s, 463973 effective words/s
INFO - 2023-11-30 15:53:15,349: EPOCH 2: training on 191080 raw words (156581 effective words) took 0.3s, 462139 effective words/s
INFO - 2023-11-30 15:53:15,696: EPOCH 3: training on 191080 raw words (156238 effective words) took 0.3s, 452425 effective words/s
INFO - 2023-11-30 15:53:16,032: EPOCH 4: training on 191080 raw words (156552 effective words) took 0.3s, 470225 effective words/s
INFO - 2023-11-30 15:53:16,367: EPOCH 5: training on 191080 raw words (156690 effective words) took 0.3s, 470502 effective words/s
INFO - 2023-11-30 15:53:16,707: EPOCH 6: training on 191080 raw words (156397 effective words) took 0.3s, 463850 effective words/s
INFO - 2023-11-30 15:53:17,040: EPOCH 7: training on 191080 raw words (156386 effective words) took 0.3s, 472661 effective words/s
INFO - 2023-11-30 15:53:17,379: EPOCH 8: training on 191080 raw words (156438 effective words) took 0.3s, 464704 effective words/s
INFO - 2023-11-30 15:53:17,715: EPOCH 9: training on 191080 raw words (156462 effective words) took 0.3s, 468991 effective words/s
INFO - 2023-11-30 15:53:18,057: EPOCH 10: training on 191080 raw words (156193 effective words) took 0.3s, 460401 effective words/s
INFO - 2023-11-30 15:53:18,391: EPOCH 11: training on 191080 raw words (156286 effective words) took 0.3s, 471707 effective words/s
INFO - 2023-11-30 15:53:18,727: EPOCH 12: training on 191080 raw words (156451 effective words) took 0.3s, 469429 effective words/s
INFO - 2023-11-30 15:53:19,087: EPOCH 13: training on 191080 raw words (156437 effective words) took 0.4s, 437145 effective words/s
INFO - 2023-11-30 15:53:19,426: EPOCH 14: training on 191080 raw words (156449 effective words) took 0.3s, 464866 effective words/s
INFO - 2023-11-30 15:53:19,772: EPOCH 15: training on 191080 raw words (156469 effective words) took 0.3s, 455119 effective words/s
INFO - 2023-11-30 15:53:20,137: EPOCH 16: training on 191080 raw words (156228 effective words) took 0.4s, 432744 effective words/s
INFO - 2023-11-30 15:53:20,478: EPOCH 17: training on 191080 raw words (156373 effective words) took 0.3s, 460805 effective words/s
INFO - 2023-11-30 15:53:20,810: EPOCH 18: training on 191080 raw words (156655 effective words) took 0.3s, 476140 effective words/s
INFO - 2023-11-30 15:53:21,141: EPOCH 19: training on 191080 raw words (156533 effective words) took 0.3s, 476604 effective words/s
INFO - 2023-11-30 15:53:21,141: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128556 effective words) took 6.8s, 459887 effective words/s', 'datetime': '2023-11-30T15:53:21.141407', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:21,141: collecting all words and their counts
INFO - 2023-11-30 15:53:21,142: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:21,173: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:21,173: Updating model with new vocabulary
INFO - 2023-11-30 15:53:21,185: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:21.185744', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:21,201: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:21,202: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:53:21,202: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156052.710303482 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:53:21.202436', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:21,226: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:21,226: updating layer weights
INFO - 2023-11-30 15:53:21,227: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:21.227296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:21,227: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:21,227: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:21.227578', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:21,558: EPOCH 0: training on 191080 raw words (156075 effective words) took 0.3s, 475433 effective words/s
INFO - 2023-11-30 15:53:21,896: EPOCH 1: training on 191080 raw words (156113 effective words) took 0.3s, 465065 effective words/s
INFO - 2023-11-30 15:53:22,222: EPOCH 2: training on 191080 raw words (156129 effective words) took 0.3s, 482199 effective words/s
INFO - 2023-11-30 15:53:22,553: EPOCH 3: training on 191080 raw words (156070 effective words) took 0.3s, 475590 effective words/s
INFO - 2023-11-30 15:53:22,888: EPOCH 4: training on 191080 raw words (156169 effective words) took 0.3s, 469284 effective words/s
INFO - 2023-11-30 15:53:23,246: EPOCH 5: training on 191080 raw words (155852 effective words) took 0.4s, 438620 effective words/s
INFO - 2023-11-30 15:53:23,572: EPOCH 6: training on 191080 raw words (156055 effective words) took 0.3s, 483243 effective words/s
INFO - 2023-11-30 15:53:23,901: EPOCH 7: training on 191080 raw words (155980 effective words) took 0.3s, 478920 effective words/s
INFO - 2023-11-30 15:53:24,290: EPOCH 8: training on 191080 raw words (156094 effective words) took 0.3s, 495929 effective words/s
INFO - 2023-11-30 15:53:24,614: EPOCH 9: training on 191080 raw words (155933 effective words) took 0.3s, 485013 effective words/s
INFO - 2023-11-30 15:53:24,937: EPOCH 10: training on 191080 raw words (156093 effective words) took 0.3s, 486700 effective words/s
INFO - 2023-11-30 15:53:25,277: EPOCH 11: training on 191080 raw words (156252 effective words) took 0.3s, 462979 effective words/s
INFO - 2023-11-30 15:53:25,623: EPOCH 12: training on 191080 raw words (155896 effective words) took 0.3s, 453487 effective words/s
INFO - 2023-11-30 15:53:25,974: EPOCH 13: training on 191080 raw words (155993 effective words) took 0.3s, 447944 effective words/s
INFO - 2023-11-30 15:53:26,333: EPOCH 14: training on 191080 raw words (156012 effective words) took 0.4s, 437550 effective words/s
INFO - 2023-11-30 15:53:26,662: EPOCH 15: training on 191080 raw words (156144 effective words) took 0.3s, 477278 effective words/s
INFO - 2023-11-30 15:53:26,985: EPOCH 16: training on 191080 raw words (156054 effective words) took 0.3s, 487093 effective words/s
INFO - 2023-11-30 15:53:27,314: EPOCH 17: training on 191080 raw words (156013 effective words) took 0.3s, 510955 effective words/s
INFO - 2023-11-30 15:53:27,664: EPOCH 18: training on 191080 raw words (156134 effective words) took 0.3s, 450199 effective words/s
INFO - 2023-11-30 15:53:28,013: EPOCH 19: training on 191080 raw words (156183 effective words) took 0.3s, 450165 effective words/s
INFO - 2023-11-30 15:53:28,013: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121244 effective words) took 6.8s, 459944 effective words/s', 'datetime': '2023-11-30T15:53:28.013874', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:28,014: collecting all words and their counts
INFO - 2023-11-30 15:53:28,014: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:28,046: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:28,046: Updating model with new vocabulary
INFO - 2023-11-30 15:53:28,062: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:28.062234', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:28,082: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:28,082: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:53:28,082: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156069.3348985977 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:53:28.082699', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:28,108: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:28,108: updating layer weights
INFO - 2023-11-30 15:53:28,109: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:28.109133', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:28,109: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:28,109: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:28.109403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:28,553: EPOCH 0: training on 191080 raw words (155963 effective words) took 0.4s, 353269 effective words/s
INFO - 2023-11-30 15:53:29,106: EPOCH 1: training on 191080 raw words (155919 effective words) took 0.5s, 284070 effective words/s
INFO - 2023-11-30 15:53:29,567: EPOCH 2: training on 191080 raw words (155950 effective words) took 0.5s, 340892 effective words/s
INFO - 2023-11-30 15:53:30,124: EPOCH 3: training on 191080 raw words (155891 effective words) took 0.6s, 281617 effective words/s
INFO - 2023-11-30 15:53:30,657: EPOCH 4: training on 191080 raw words (155970 effective words) took 0.5s, 318490 effective words/s
INFO - 2023-11-30 15:53:31,251: EPOCH 5: training on 191080 raw words (156115 effective words) took 0.6s, 264350 effective words/s
INFO - 2023-11-30 15:53:31,765: EPOCH 6: training on 191080 raw words (155983 effective words) took 0.5s, 305816 effective words/s
INFO - 2023-11-30 15:53:32,344: EPOCH 7: training on 191080 raw words (155855 effective words) took 0.6s, 271182 effective words/s
INFO - 2023-11-30 15:53:33,081: EPOCH 8: training on 191080 raw words (156145 effective words) took 0.7s, 213111 effective words/s
INFO - 2023-11-30 15:53:33,832: EPOCH 9: training on 191080 raw words (155943 effective words) took 0.7s, 208547 effective words/s
INFO - 2023-11-30 15:53:34,584: EPOCH 10: training on 191080 raw words (156086 effective words) took 0.7s, 208838 effective words/s
INFO - 2023-11-30 15:53:35,371: EPOCH 11: training on 191080 raw words (156109 effective words) took 0.8s, 204175 effective words/s
INFO - 2023-11-30 15:53:36,100: EPOCH 12: training on 191080 raw words (156292 effective words) took 0.7s, 215578 effective words/s
INFO - 2023-11-30 15:53:36,840: EPOCH 13: training on 191080 raw words (156207 effective words) took 0.7s, 212420 effective words/s
INFO - 2023-11-30 15:53:37,432: EPOCH 14: training on 191080 raw words (156067 effective words) took 0.6s, 265466 effective words/s
INFO - 2023-11-30 15:53:37,881: EPOCH 15: training on 191080 raw words (156024 effective words) took 0.4s, 349384 effective words/s
INFO - 2023-11-30 15:53:38,386: EPOCH 16: training on 191080 raw words (156304 effective words) took 0.5s, 324822 effective words/s
INFO - 2023-11-30 15:53:38,807: EPOCH 17: training on 191080 raw words (156129 effective words) took 0.4s, 373607 effective words/s
INFO - 2023-11-30 15:53:39,324: EPOCH 18: training on 191080 raw words (156093 effective words) took 0.5s, 304135 effective words/s
INFO - 2023-11-30 15:53:39,808: EPOCH 19: training on 191080 raw words (156059 effective words) took 0.5s, 324345 effective words/s
INFO - 2023-11-30 15:53:39,808: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121104 effective words) took 11.7s, 266780 effective words/s', 'datetime': '2023-11-30T15:53:39.808715', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:39,808: collecting all words and their counts
INFO - 2023-11-30 15:53:39,809: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:39,840: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:39,840: Updating model with new vocabulary
INFO - 2023-11-30 15:53:39,854: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:39.854585', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:39,870: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:39,870: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:53:39,871: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156138.06471701083 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:53:39.871131', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:39,895: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:39,895: updating layer weights
INFO - 2023-11-30 15:53:39,895: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:39.895815', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:39,896: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:39,896: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:39.896228', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:40,228: EPOCH 0: training on 191080 raw words (156227 effective words) took 0.3s, 474957 effective words/s
INFO - 2023-11-30 15:53:40,563: EPOCH 1: training on 191080 raw words (156179 effective words) took 0.3s, 469363 effective words/s
INFO - 2023-11-30 15:53:40,903: EPOCH 2: training on 191080 raw words (156036 effective words) took 0.3s, 462381 effective words/s
INFO - 2023-11-30 15:53:41,264: EPOCH 3: training on 191080 raw words (156125 effective words) took 0.4s, 436213 effective words/s
INFO - 2023-11-30 15:53:41,591: EPOCH 4: training on 191080 raw words (156373 effective words) took 0.3s, 482475 effective words/s
INFO - 2023-11-30 15:53:41,923: EPOCH 5: training on 191080 raw words (156129 effective words) took 0.3s, 472950 effective words/s
INFO - 2023-11-30 15:53:42,259: EPOCH 6: training on 191080 raw words (156214 effective words) took 0.3s, 467586 effective words/s
INFO - 2023-11-30 15:53:42,586: EPOCH 7: training on 191080 raw words (156039 effective words) took 0.3s, 482067 effective words/s
INFO - 2023-11-30 15:53:42,910: EPOCH 8: training on 191080 raw words (156102 effective words) took 0.3s, 485240 effective words/s
INFO - 2023-11-30 15:53:43,237: EPOCH 9: training on 191080 raw words (156151 effective words) took 0.3s, 481868 effective words/s
INFO - 2023-11-30 15:53:43,564: EPOCH 10: training on 191080 raw words (156250 effective words) took 0.3s, 480690 effective words/s
INFO - 2023-11-30 15:53:43,877: EPOCH 11: training on 191080 raw words (156127 effective words) took 0.3s, 503110 effective words/s
INFO - 2023-11-30 15:53:44,202: EPOCH 12: training on 191080 raw words (155935 effective words) took 0.3s, 483034 effective words/s
INFO - 2023-11-30 15:53:44,558: EPOCH 13: training on 191080 raw words (156283 effective words) took 0.4s, 442434 effective words/s
INFO - 2023-11-30 15:53:44,912: EPOCH 14: training on 191080 raw words (156246 effective words) took 0.4s, 444581 effective words/s
INFO - 2023-11-30 15:53:45,269: EPOCH 15: training on 191080 raw words (156163 effective words) took 0.4s, 441640 effective words/s
INFO - 2023-11-30 15:53:45,619: EPOCH 16: training on 191080 raw words (156227 effective words) took 0.3s, 449083 effective words/s
INFO - 2023-11-30 15:53:45,951: EPOCH 17: training on 191080 raw words (156273 effective words) took 0.3s, 474319 effective words/s
INFO - 2023-11-30 15:53:46,288: EPOCH 18: training on 191080 raw words (156125 effective words) took 0.3s, 466739 effective words/s
INFO - 2023-11-30 15:53:46,622: EPOCH 19: training on 191080 raw words (156240 effective words) took 0.3s, 470995 effective words/s
INFO - 2023-11-30 15:53:46,623: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123444 effective words) took 6.7s, 464326 effective words/s', 'datetime': '2023-11-30T15:53:46.623237', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:46,623: collecting all words and their counts
INFO - 2023-11-30 15:53:46,624: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:46,660: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:46,660: Updating model with new vocabulary
INFO - 2023-11-30 15:53:46,678: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:46.678024', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:46,701: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:46,701: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:53:46,701: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156251.92015506228 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:53:46.701561', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:46,727: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:46,727: updating layer weights
INFO - 2023-11-30 15:53:46,728: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:46.728194', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:46,728: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:46,728: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:46.728734', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:47,074: EPOCH 0: training on 191080 raw words (156280 effective words) took 0.3s, 456131 effective words/s
INFO - 2023-11-30 15:53:47,468: EPOCH 1: training on 191080 raw words (156358 effective words) took 0.4s, 399525 effective words/s
INFO - 2023-11-30 15:53:47,880: EPOCH 2: training on 191080 raw words (156246 effective words) took 0.4s, 381910 effective words/s
INFO - 2023-11-30 15:53:48,238: EPOCH 3: training on 191080 raw words (156237 effective words) took 0.4s, 440405 effective words/s
INFO - 2023-11-30 15:53:48,590: EPOCH 4: training on 191080 raw words (156394 effective words) took 0.3s, 447285 effective words/s
INFO - 2023-11-30 15:53:48,968: EPOCH 5: training on 191080 raw words (156255 effective words) took 0.4s, 417502 effective words/s
INFO - 2023-11-30 15:53:49,443: EPOCH 6: training on 191080 raw words (156291 effective words) took 0.5s, 330114 effective words/s
INFO - 2023-11-30 15:53:49,778: EPOCH 7: training on 191080 raw words (156276 effective words) took 0.3s, 470649 effective words/s
INFO - 2023-11-30 15:53:50,119: EPOCH 8: training on 191080 raw words (156267 effective words) took 0.3s, 461867 effective words/s
INFO - 2023-11-30 15:53:50,457: EPOCH 9: training on 191080 raw words (156217 effective words) took 0.3s, 467139 effective words/s
INFO - 2023-11-30 15:53:50,793: EPOCH 10: training on 191080 raw words (156373 effective words) took 0.3s, 469318 effective words/s
INFO - 2023-11-30 15:53:51,136: EPOCH 11: training on 191080 raw words (156141 effective words) took 0.3s, 457687 effective words/s
INFO - 2023-11-30 15:53:51,484: EPOCH 12: training on 191080 raw words (156558 effective words) took 0.3s, 453380 effective words/s
INFO - 2023-11-30 15:53:51,856: EPOCH 13: training on 191080 raw words (156201 effective words) took 0.4s, 423551 effective words/s
INFO - 2023-11-30 15:53:52,242: EPOCH 14: training on 191080 raw words (156345 effective words) took 0.4s, 407355 effective words/s
INFO - 2023-11-30 15:53:52,669: EPOCH 15: training on 191080 raw words (156220 effective words) took 0.4s, 368355 effective words/s
INFO - 2023-11-30 15:53:53,112: EPOCH 16: training on 191080 raw words (156233 effective words) took 0.4s, 355147 effective words/s
INFO - 2023-11-30 15:53:53,558: EPOCH 17: training on 191080 raw words (156201 effective words) took 0.4s, 352817 effective words/s
INFO - 2023-11-30 15:53:54,017: EPOCH 18: training on 191080 raw words (156190 effective words) took 0.5s, 342328 effective words/s
INFO - 2023-11-30 15:53:54,492: EPOCH 19: training on 191080 raw words (156175 effective words) took 0.5s, 331841 effective words/s
INFO - 2023-11-30 15:53:54,492: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125458 effective words) took 7.8s, 402582 effective words/s', 'datetime': '2023-11-30T15:53:54.492517', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:54,492: collecting all words and their counts
INFO - 2023-11-30 15:53:54,493: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:53:54,534: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:53:54,534: Updating model with new vocabulary
INFO - 2023-11-30 15:53:54,552: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:53:54.552132', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:54,572: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:53:54,573: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:53:54,573: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156198.86717427295 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:53:54.573442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:53:54,605: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:53:54,605: updating layer weights
INFO - 2023-11-30 15:53:54,606: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:53:54.605986', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:53:54,606: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:53:54,606: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:53:54.606515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:53:55,034: EPOCH 0: training on 191080 raw words (156118 effective words) took 0.4s, 367521 effective words/s
INFO - 2023-11-30 15:53:55,471: EPOCH 1: training on 191080 raw words (156211 effective words) took 0.4s, 360530 effective words/s
INFO - 2023-11-30 15:53:55,933: EPOCH 2: training on 191080 raw words (156185 effective words) took 0.5s, 339956 effective words/s
INFO - 2023-11-30 15:53:56,382: EPOCH 3: training on 191080 raw words (156050 effective words) took 0.4s, 350155 effective words/s
INFO - 2023-11-30 15:53:56,873: EPOCH 4: training on 191080 raw words (156146 effective words) took 0.5s, 320358 effective words/s
INFO - 2023-11-30 15:53:57,411: EPOCH 5: training on 191080 raw words (156143 effective words) took 0.5s, 292236 effective words/s
INFO - 2023-11-30 15:53:57,901: EPOCH 6: training on 191080 raw words (156119 effective words) took 0.5s, 321334 effective words/s
INFO - 2023-11-30 15:53:58,459: EPOCH 7: training on 191080 raw words (156189 effective words) took 0.6s, 281674 effective words/s
INFO - 2023-11-30 15:53:59,025: EPOCH 8: training on 191080 raw words (156224 effective words) took 0.6s, 277792 effective words/s
INFO - 2023-11-30 15:53:59,553: EPOCH 9: training on 191080 raw words (156170 effective words) took 0.5s, 297581 effective words/s
INFO - 2023-11-30 15:54:00,104: EPOCH 10: training on 191080 raw words (156410 effective words) took 0.5s, 285610 effective words/s
INFO - 2023-11-30 15:54:00,604: EPOCH 11: training on 191080 raw words (156230 effective words) took 0.5s, 314823 effective words/s
INFO - 2023-11-30 15:54:01,119: EPOCH 12: training on 191080 raw words (156358 effective words) took 0.5s, 306173 effective words/s
INFO - 2023-11-30 15:54:01,579: EPOCH 13: training on 191080 raw words (156046 effective words) took 0.5s, 342190 effective words/s
INFO - 2023-11-30 15:54:01,930: EPOCH 14: training on 191080 raw words (156169 effective words) took 0.3s, 448065 effective words/s
INFO - 2023-11-30 15:54:02,331: EPOCH 15: training on 191080 raw words (156093 effective words) took 0.4s, 392939 effective words/s
INFO - 2023-11-30 15:54:02,746: EPOCH 16: training on 191080 raw words (156198 effective words) took 0.4s, 379411 effective words/s
INFO - 2023-11-30 15:54:03,088: EPOCH 17: training on 191080 raw words (156284 effective words) took 0.3s, 460203 effective words/s
INFO - 2023-11-30 15:54:03,420: EPOCH 18: training on 191080 raw words (156098 effective words) took 0.3s, 474253 effective words/s
INFO - 2023-11-30 15:54:03,753: EPOCH 19: training on 191080 raw words (156464 effective words) took 0.3s, 473894 effective words/s
INFO - 2023-11-30 15:54:03,753: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123905 effective words) took 9.1s, 341534 effective words/s', 'datetime': '2023-11-30T15:54:03.753395', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:03,753: collecting all words and their counts
INFO - 2023-11-30 15:54:03,753: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:03,786: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:03,786: Updating model with new vocabulary
INFO - 2023-11-30 15:54:03,800: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:03.800433', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:03,817: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:03,817: sample=0.001 downsamples 34 most-common words
INFO - 2023-11-30 15:54:03,817: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156152.25566916083 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:54:03.817824', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:03,841: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:03,842: updating layer weights
INFO - 2023-11-30 15:54:03,842: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:03.842608', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:03,842: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:03,842: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:03.842907', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:04,186: EPOCH 0: training on 191080 raw words (156077 effective words) took 0.3s, 457445 effective words/s
INFO - 2023-11-30 15:54:04,544: EPOCH 1: training on 191080 raw words (155951 effective words) took 0.4s, 439169 effective words/s
INFO - 2023-11-30 15:54:04,895: EPOCH 2: training on 191080 raw words (156162 effective words) took 0.3s, 448201 effective words/s
INFO - 2023-11-30 15:54:05,243: EPOCH 3: training on 191080 raw words (156236 effective words) took 0.3s, 452439 effective words/s
INFO - 2023-11-30 15:54:05,596: EPOCH 4: training on 191080 raw words (156432 effective words) took 0.4s, 446754 effective words/s
INFO - 2023-11-30 15:54:05,942: EPOCH 5: training on 191080 raw words (156140 effective words) took 0.3s, 453806 effective words/s
INFO - 2023-11-30 15:54:06,289: EPOCH 6: training on 191080 raw words (156053 effective words) took 0.3s, 453071 effective words/s
INFO - 2023-11-30 15:54:06,639: EPOCH 7: training on 191080 raw words (156155 effective words) took 0.3s, 449775 effective words/s
INFO - 2023-11-30 15:54:06,991: EPOCH 8: training on 191080 raw words (156191 effective words) took 0.3s, 447845 effective words/s
INFO - 2023-11-30 15:54:07,348: EPOCH 9: training on 191080 raw words (155952 effective words) took 0.4s, 440243 effective words/s
INFO - 2023-11-30 15:54:07,692: EPOCH 10: training on 191080 raw words (156185 effective words) took 0.3s, 457207 effective words/s
INFO - 2023-11-30 15:54:08,048: EPOCH 11: training on 191080 raw words (156368 effective words) took 0.4s, 442619 effective words/s
INFO - 2023-11-30 15:54:08,383: EPOCH 12: training on 191080 raw words (156177 effective words) took 0.3s, 470148 effective words/s
INFO - 2023-11-30 15:54:08,715: EPOCH 13: training on 191080 raw words (156028 effective words) took 0.3s, 474108 effective words/s
INFO - 2023-11-30 15:54:09,048: EPOCH 14: training on 191080 raw words (156043 effective words) took 0.3s, 472076 effective words/s
INFO - 2023-11-30 15:54:09,384: EPOCH 15: training on 191080 raw words (156081 effective words) took 0.3s, 467821 effective words/s
INFO - 2023-11-30 15:54:09,723: EPOCH 16: training on 191080 raw words (156215 effective words) took 0.3s, 464020 effective words/s
INFO - 2023-11-30 15:54:10,055: EPOCH 17: training on 191080 raw words (156075 effective words) took 0.3s, 473076 effective words/s
INFO - 2023-11-30 15:54:10,400: EPOCH 18: training on 191080 raw words (156070 effective words) took 0.3s, 456282 effective words/s
INFO - 2023-11-30 15:54:10,730: EPOCH 19: training on 191080 raw words (156177 effective words) took 0.3s, 476361 effective words/s
INFO - 2023-11-30 15:54:10,731: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122768 effective words) took 6.9s, 453365 effective words/s', 'datetime': '2023-11-30T15:54:10.731023', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:10,731: collecting all words and their counts
INFO - 2023-11-30 15:54:10,731: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:10,761: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:10,761: Updating model with new vocabulary
INFO - 2023-11-30 15:54:10,773: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:10.773826', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:10,789: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:10,789: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:54:10,789: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156024.5051132628 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:54:10.789761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:10,814: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:10,814: updating layer weights
INFO - 2023-11-30 15:54:10,814: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:10.814927', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:10,815: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:10,815: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:10.815186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:11,134: EPOCH 0: training on 191080 raw words (156146 effective words) took 0.3s, 492112 effective words/s
INFO - 2023-11-30 15:54:11,460: EPOCH 1: training on 191080 raw words (155929 effective words) took 0.3s, 481780 effective words/s
INFO - 2023-11-30 15:54:11,781: EPOCH 2: training on 191080 raw words (155918 effective words) took 0.3s, 489086 effective words/s
INFO - 2023-11-30 15:54:12,107: EPOCH 3: training on 191080 raw words (156054 effective words) took 0.3s, 482654 effective words/s
INFO - 2023-11-30 15:54:12,492: EPOCH 4: training on 191080 raw words (155910 effective words) took 0.4s, 407968 effective words/s
INFO - 2023-11-30 15:54:12,806: EPOCH 5: training on 191080 raw words (156029 effective words) took 0.3s, 500867 effective words/s
INFO - 2023-11-30 15:54:13,127: EPOCH 6: training on 191080 raw words (156115 effective words) took 0.3s, 489725 effective words/s
INFO - 2023-11-30 15:54:13,447: EPOCH 7: training on 191080 raw words (156015 effective words) took 0.3s, 491679 effective words/s
INFO - 2023-11-30 15:54:13,771: EPOCH 8: training on 191080 raw words (155803 effective words) took 0.3s, 484761 effective words/s
INFO - 2023-11-30 15:54:14,090: EPOCH 9: training on 191080 raw words (156118 effective words) took 0.3s, 493166 effective words/s
INFO - 2023-11-30 15:54:14,411: EPOCH 10: training on 191080 raw words (156259 effective words) took 0.3s, 490699 effective words/s
INFO - 2023-11-30 15:54:14,728: EPOCH 11: training on 191080 raw words (155894 effective words) took 0.3s, 495513 effective words/s
INFO - 2023-11-30 15:54:15,043: EPOCH 12: training on 191080 raw words (156077 effective words) took 0.3s, 499311 effective words/s
INFO - 2023-11-30 15:54:15,363: EPOCH 13: training on 191080 raw words (156035 effective words) took 0.3s, 491776 effective words/s
INFO - 2023-11-30 15:54:15,694: EPOCH 14: training on 191080 raw words (156224 effective words) took 0.3s, 475516 effective words/s
INFO - 2023-11-30 15:54:16,014: EPOCH 15: training on 191080 raw words (156044 effective words) took 0.3s, 491332 effective words/s
INFO - 2023-11-30 15:54:16,335: EPOCH 16: training on 191080 raw words (155983 effective words) took 0.3s, 489160 effective words/s
INFO - 2023-11-30 15:54:16,659: EPOCH 17: training on 191080 raw words (156006 effective words) took 0.3s, 485280 effective words/s
INFO - 2023-11-30 15:54:17,085: EPOCH 18: training on 191080 raw words (155945 effective words) took 0.4s, 368549 effective words/s
INFO - 2023-11-30 15:54:17,509: EPOCH 19: training on 191080 raw words (155936 effective words) took 0.4s, 370315 effective words/s
INFO - 2023-11-30 15:54:17,509: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120440 effective words) took 6.7s, 466124 effective words/s', 'datetime': '2023-11-30T15:54:17.509758', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:17,509: collecting all words and their counts
INFO - 2023-11-30 15:54:17,510: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:17,552: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:17,552: Updating model with new vocabulary
INFO - 2023-11-30 15:54:17,569: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:17.569087', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:17,590: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:17,591: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:54:17,591: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156283.678511668 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:54:17.591247', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:17,626: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:17,626: updating layer weights
INFO - 2023-11-30 15:54:17,627: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:17.627003', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:17,627: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:17,627: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:17.627410', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:18,078: EPOCH 0: training on 191080 raw words (156079 effective words) took 0.4s, 348506 effective words/s
INFO - 2023-11-30 15:54:18,534: EPOCH 1: training on 191080 raw words (156380 effective words) took 0.5s, 345885 effective words/s
INFO - 2023-11-30 15:54:18,985: EPOCH 2: training on 191080 raw words (156262 effective words) took 0.4s, 348831 effective words/s
INFO - 2023-11-30 15:54:19,431: EPOCH 3: training on 191080 raw words (156318 effective words) took 0.4s, 352513 effective words/s
INFO - 2023-11-30 15:54:19,892: EPOCH 4: training on 191080 raw words (156260 effective words) took 0.5s, 341228 effective words/s
INFO - 2023-11-30 15:54:20,382: EPOCH 5: training on 191080 raw words (156241 effective words) took 0.5s, 321501 effective words/s
INFO - 2023-11-30 15:54:20,865: EPOCH 6: training on 191080 raw words (156358 effective words) took 0.5s, 326316 effective words/s
INFO - 2023-11-30 15:54:21,342: EPOCH 7: training on 191080 raw words (156180 effective words) took 0.5s, 329359 effective words/s
INFO - 2023-11-30 15:54:21,818: EPOCH 8: training on 191080 raw words (156319 effective words) took 0.5s, 331093 effective words/s
INFO - 2023-11-30 15:54:22,300: EPOCH 9: training on 191080 raw words (156190 effective words) took 0.5s, 343273 effective words/s
INFO - 2023-11-30 15:54:22,793: EPOCH 10: training on 191080 raw words (156366 effective words) took 0.5s, 319198 effective words/s
INFO - 2023-11-30 15:54:23,321: EPOCH 11: training on 191080 raw words (156282 effective words) took 0.5s, 297916 effective words/s
INFO - 2023-11-30 15:54:23,834: EPOCH 12: training on 191080 raw words (156275 effective words) took 0.5s, 307082 effective words/s
INFO - 2023-11-30 15:54:24,350: EPOCH 13: training on 191080 raw words (156227 effective words) took 0.5s, 304718 effective words/s
INFO - 2023-11-30 15:54:24,866: EPOCH 14: training on 191080 raw words (156413 effective words) took 0.5s, 305049 effective words/s
INFO - 2023-11-30 15:54:25,397: EPOCH 15: training on 191080 raw words (156138 effective words) took 0.5s, 296182 effective words/s
INFO - 2023-11-30 15:54:25,842: EPOCH 16: training on 191080 raw words (156321 effective words) took 0.4s, 353845 effective words/s
INFO - 2023-11-30 15:54:26,178: EPOCH 17: training on 191080 raw words (156320 effective words) took 0.3s, 469589 effective words/s
INFO - 2023-11-30 15:54:26,514: EPOCH 18: training on 191080 raw words (156321 effective words) took 0.3s, 468669 effective words/s
INFO - 2023-11-30 15:54:26,847: EPOCH 19: training on 191080 raw words (156232 effective words) took 0.3s, 472301 effective words/s
INFO - 2023-11-30 15:54:26,847: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125482 effective words) took 9.2s, 338983 effective words/s', 'datetime': '2023-11-30T15:54:26.847743', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:26,847: collecting all words and their counts
INFO - 2023-11-30 15:54:26,848: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:26,876: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:26,877: Updating model with new vocabulary
INFO - 2023-11-30 15:54:26,889: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:26.889094', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:26,904: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:26,904: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:54:26,905: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156175.70486326088 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:54:26.905023', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:26,928: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:26,929: updating layer weights
INFO - 2023-11-30 15:54:26,929: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:26.929508', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:26,929: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:26,929: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:26.929783', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:27,247: EPOCH 0: training on 191080 raw words (156093 effective words) took 0.3s, 495061 effective words/s
INFO - 2023-11-30 15:54:27,615: EPOCH 1: training on 191080 raw words (156058 effective words) took 0.4s, 426549 effective words/s
INFO - 2023-11-30 15:54:27,986: EPOCH 2: training on 191080 raw words (156293 effective words) took 0.4s, 424561 effective words/s
INFO - 2023-11-30 15:54:28,362: EPOCH 3: training on 191080 raw words (156196 effective words) took 0.4s, 418783 effective words/s
INFO - 2023-11-30 15:54:28,727: EPOCH 4: training on 191080 raw words (155991 effective words) took 0.4s, 430833 effective words/s
INFO - 2023-11-30 15:54:29,073: EPOCH 5: training on 191080 raw words (156129 effective words) took 0.3s, 455722 effective words/s
INFO - 2023-11-30 15:54:29,421: EPOCH 6: training on 191080 raw words (156198 effective words) took 0.3s, 451434 effective words/s
INFO - 2023-11-30 15:54:29,764: EPOCH 7: training on 191080 raw words (156251 effective words) took 0.3s, 459132 effective words/s
INFO - 2023-11-30 15:54:30,099: EPOCH 8: training on 191080 raw words (156215 effective words) took 0.3s, 470047 effective words/s
INFO - 2023-11-30 15:54:30,458: EPOCH 9: training on 191080 raw words (156356 effective words) took 0.4s, 439219 effective words/s
INFO - 2023-11-30 15:54:30,794: EPOCH 10: training on 191080 raw words (156411 effective words) took 0.3s, 468334 effective words/s
INFO - 2023-11-30 15:54:31,161: EPOCH 11: training on 191080 raw words (156126 effective words) took 0.3s, 455928 effective words/s
INFO - 2023-11-30 15:54:31,505: EPOCH 12: training on 191080 raw words (156224 effective words) took 0.3s, 457761 effective words/s
INFO - 2023-11-30 15:54:31,858: EPOCH 13: training on 191080 raw words (156355 effective words) took 0.4s, 445794 effective words/s
INFO - 2023-11-30 15:54:32,198: EPOCH 14: training on 191080 raw words (156324 effective words) took 0.3s, 463774 effective words/s
INFO - 2023-11-30 15:54:32,538: EPOCH 15: training on 191080 raw words (156156 effective words) took 0.3s, 462329 effective words/s
INFO - 2023-11-30 15:54:32,872: EPOCH 16: training on 191080 raw words (156029 effective words) took 0.3s, 471919 effective words/s
INFO - 2023-11-30 15:54:33,218: EPOCH 17: training on 191080 raw words (156161 effective words) took 0.3s, 455578 effective words/s
INFO - 2023-11-30 15:54:33,561: EPOCH 18: training on 191080 raw words (156233 effective words) took 0.3s, 458705 effective words/s
INFO - 2023-11-30 15:54:33,918: EPOCH 19: training on 191080 raw words (156166 effective words) took 0.4s, 441134 effective words/s
INFO - 2023-11-30 15:54:33,918: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123965 effective words) took 7.0s, 447020 effective words/s', 'datetime': '2023-11-30T15:54:33.918335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:33,918: collecting all words and their counts
INFO - 2023-11-30 15:54:33,918: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:33,953: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:33,953: Updating model with new vocabulary
INFO - 2023-11-30 15:54:33,967: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:33.967050', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:33,985: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:33,985: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:54:33,985: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156216.09174037777 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:54:33.985865', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:34,016: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:34,017: updating layer weights
INFO - 2023-11-30 15:54:34,017: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:34.017598', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:34,017: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:34,017: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:34.017871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:34,368: EPOCH 0: training on 191080 raw words (156231 effective words) took 0.3s, 449080 effective words/s
INFO - 2023-11-30 15:54:34,723: EPOCH 1: training on 191080 raw words (156351 effective words) took 0.4s, 443553 effective words/s
INFO - 2023-11-30 15:54:35,140: EPOCH 2: training on 191080 raw words (156264 effective words) took 0.4s, 376768 effective words/s
INFO - 2023-11-30 15:54:35,506: EPOCH 3: training on 191080 raw words (156239 effective words) took 0.4s, 429811 effective words/s
INFO - 2023-11-30 15:54:35,856: EPOCH 4: training on 191080 raw words (156104 effective words) took 0.3s, 449236 effective words/s
INFO - 2023-11-30 15:54:36,233: EPOCH 5: training on 191080 raw words (156190 effective words) took 0.4s, 417914 effective words/s
INFO - 2023-11-30 15:54:36,594: EPOCH 6: training on 191080 raw words (156384 effective words) took 0.4s, 436030 effective words/s
INFO - 2023-11-30 15:54:36,945: EPOCH 7: training on 191080 raw words (156307 effective words) took 0.3s, 448627 effective words/s
INFO - 2023-11-30 15:54:37,300: EPOCH 8: training on 191080 raw words (156582 effective words) took 0.3s, 469783 effective words/s
INFO - 2023-11-30 15:54:37,667: EPOCH 9: training on 191080 raw words (156435 effective words) took 0.4s, 429280 effective words/s
INFO - 2023-11-30 15:54:38,014: EPOCH 10: training on 191080 raw words (156116 effective words) took 0.3s, 453276 effective words/s
INFO - 2023-11-30 15:54:38,378: EPOCH 11: training on 191080 raw words (156331 effective words) took 0.4s, 431955 effective words/s
INFO - 2023-11-30 15:54:38,732: EPOCH 12: training on 191080 raw words (156318 effective words) took 0.4s, 445722 effective words/s
INFO - 2023-11-30 15:54:39,081: EPOCH 13: training on 191080 raw words (156224 effective words) took 0.3s, 450883 effective words/s
INFO - 2023-11-30 15:54:39,456: EPOCH 14: training on 191080 raw words (156390 effective words) took 0.4s, 420250 effective words/s
INFO - 2023-11-30 15:54:39,808: EPOCH 15: training on 191080 raw words (156245 effective words) took 0.4s, 445911 effective words/s
INFO - 2023-11-30 15:54:40,159: EPOCH 16: training on 191080 raw words (156269 effective words) took 0.3s, 449596 effective words/s
INFO - 2023-11-30 15:54:40,514: EPOCH 17: training on 191080 raw words (156275 effective words) took 0.4s, 443044 effective words/s
INFO - 2023-11-30 15:54:40,906: EPOCH 18: training on 191080 raw words (156262 effective words) took 0.4s, 401226 effective words/s
INFO - 2023-11-30 15:54:41,396: EPOCH 19: training on 191080 raw words (156211 effective words) took 0.5s, 321320 effective words/s
INFO - 2023-11-30 15:54:41,396: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125728 effective words) took 7.4s, 423615 effective words/s', 'datetime': '2023-11-30T15:54:41.396720', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:41,396: collecting all words and their counts
INFO - 2023-11-30 15:54:41,397: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:41,440: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:41,441: Updating model with new vocabulary
INFO - 2023-11-30 15:54:41,464: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:41.464110', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:41,486: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:41,486: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:54:41,487: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156265.6941945012 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:54:41.487105', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:41,523: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:41,524: updating layer weights
INFO - 2023-11-30 15:54:41,524: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:41.524522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:41,524: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:41,524: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:41.524917', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:42,003: EPOCH 0: training on 191080 raw words (156282 effective words) took 0.5s, 329166 effective words/s
INFO - 2023-11-30 15:54:42,461: EPOCH 1: training on 191080 raw words (156189 effective words) took 0.5s, 343296 effective words/s
INFO - 2023-11-30 15:54:42,932: EPOCH 2: training on 191080 raw words (156295 effective words) took 0.4s, 354810 effective words/s
INFO - 2023-11-30 15:54:43,386: EPOCH 3: training on 191080 raw words (156241 effective words) took 0.5s, 346135 effective words/s
INFO - 2023-11-30 15:54:43,850: EPOCH 4: training on 191080 raw words (156251 effective words) took 0.5s, 340061 effective words/s
INFO - 2023-11-30 15:54:44,342: EPOCH 5: training on 191080 raw words (156235 effective words) took 0.5s, 319233 effective words/s
INFO - 2023-11-30 15:54:44,835: EPOCH 6: training on 191080 raw words (156206 effective words) took 0.5s, 318934 effective words/s
INFO - 2023-11-30 15:54:45,333: EPOCH 7: training on 191080 raw words (156337 effective words) took 0.5s, 316283 effective words/s
INFO - 2023-11-30 15:54:45,840: EPOCH 8: training on 191080 raw words (156396 effective words) took 0.5s, 311203 effective words/s
INFO - 2023-11-30 15:54:46,336: EPOCH 9: training on 191080 raw words (156316 effective words) took 0.5s, 317805 effective words/s
INFO - 2023-11-30 15:54:46,842: EPOCH 10: training on 191080 raw words (156248 effective words) took 0.5s, 310659 effective words/s
INFO - 2023-11-30 15:54:47,354: EPOCH 11: training on 191080 raw words (156252 effective words) took 0.5s, 307141 effective words/s
INFO - 2023-11-30 15:54:47,912: EPOCH 12: training on 191080 raw words (156062 effective words) took 0.6s, 281780 effective words/s
INFO - 2023-11-30 15:54:48,456: EPOCH 13: training on 191080 raw words (156288 effective words) took 0.5s, 289640 effective words/s
INFO - 2023-11-30 15:54:49,034: EPOCH 14: training on 191080 raw words (156345 effective words) took 0.6s, 272321 effective words/s
INFO - 2023-11-30 15:54:49,626: EPOCH 15: training on 191080 raw words (156256 effective words) took 0.6s, 265798 effective words/s
INFO - 2023-11-30 15:54:50,061: EPOCH 16: training on 191080 raw words (156118 effective words) took 0.4s, 362325 effective words/s
INFO - 2023-11-30 15:54:50,417: EPOCH 17: training on 191080 raw words (156258 effective words) took 0.4s, 442485 effective words/s
INFO - 2023-11-30 15:54:50,805: EPOCH 18: training on 191080 raw words (156293 effective words) took 0.4s, 406319 effective words/s
INFO - 2023-11-30 15:54:51,166: EPOCH 19: training on 191080 raw words (156419 effective words) took 0.4s, 437661 effective words/s
INFO - 2023-11-30 15:54:51,166: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125287 effective words) took 9.6s, 324147 effective words/s', 'datetime': '2023-11-30T15:54:51.166732', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:51,167: collecting all words and their counts
INFO - 2023-11-30 15:54:51,167: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:51,204: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:51,205: Updating model with new vocabulary
INFO - 2023-11-30 15:54:51,220: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:51.220178', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:51,238: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:51,238: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:54:51,238: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156125.05852158758 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:54:51.238631', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:51,265: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:51,265: updating layer weights
INFO - 2023-11-30 15:54:51,265: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:51.265741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:51,265: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:51,265: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:51.265971', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:51,615: EPOCH 0: training on 191080 raw words (156294 effective words) took 0.3s, 451180 effective words/s
INFO - 2023-11-30 15:54:51,966: EPOCH 1: training on 191080 raw words (156163 effective words) took 0.3s, 446965 effective words/s
INFO - 2023-11-30 15:54:52,349: EPOCH 2: training on 191080 raw words (156283 effective words) took 0.4s, 410643 effective words/s
INFO - 2023-11-30 15:54:52,721: EPOCH 3: training on 191080 raw words (156147 effective words) took 0.4s, 422513 effective words/s
INFO - 2023-11-30 15:54:53,080: EPOCH 4: training on 191080 raw words (156010 effective words) took 0.4s, 438699 effective words/s
INFO - 2023-11-30 15:54:53,412: EPOCH 5: training on 191080 raw words (156038 effective words) took 0.3s, 473987 effective words/s
INFO - 2023-11-30 15:54:53,763: EPOCH 6: training on 191080 raw words (156155 effective words) took 0.3s, 448311 effective words/s
INFO - 2023-11-30 15:54:54,132: EPOCH 7: training on 191080 raw words (156152 effective words) took 0.4s, 426314 effective words/s
INFO - 2023-11-30 15:54:54,513: EPOCH 8: training on 191080 raw words (156235 effective words) took 0.4s, 412291 effective words/s
INFO - 2023-11-30 15:54:54,932: EPOCH 9: training on 191080 raw words (156328 effective words) took 0.4s, 376206 effective words/s
INFO - 2023-11-30 15:54:55,340: EPOCH 10: training on 191080 raw words (156166 effective words) took 0.4s, 385836 effective words/s
INFO - 2023-11-30 15:54:55,724: EPOCH 11: training on 191080 raw words (156007 effective words) took 0.4s, 409315 effective words/s
INFO - 2023-11-30 15:54:56,164: EPOCH 12: training on 191080 raw words (156192 effective words) took 0.4s, 357106 effective words/s
INFO - 2023-11-30 15:54:56,554: EPOCH 13: training on 191080 raw words (155990 effective words) took 0.4s, 403325 effective words/s
INFO - 2023-11-30 15:54:57,059: EPOCH 14: training on 191080 raw words (156170 effective words) took 0.5s, 311200 effective words/s
INFO - 2023-11-30 15:54:57,553: EPOCH 15: training on 191080 raw words (156301 effective words) took 0.5s, 319203 effective words/s
INFO - 2023-11-30 15:54:57,940: EPOCH 16: training on 191080 raw words (156177 effective words) took 0.4s, 406385 effective words/s
INFO - 2023-11-30 15:54:58,339: EPOCH 17: training on 191080 raw words (156056 effective words) took 0.4s, 393549 effective words/s
INFO - 2023-11-30 15:54:58,756: EPOCH 18: training on 191080 raw words (155965 effective words) took 0.4s, 377079 effective words/s
INFO - 2023-11-30 15:54:59,180: EPOCH 19: training on 191080 raw words (156098 effective words) took 0.4s, 370097 effective words/s
INFO - 2023-11-30 15:54:59,180: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122927 effective words) took 7.9s, 394571 effective words/s', 'datetime': '2023-11-30T15:54:59.180847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:59,181: collecting all words and their counts
INFO - 2023-11-30 15:54:59,181: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:54:59,214: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:54:59,215: Updating model with new vocabulary
INFO - 2023-11-30 15:54:59,228: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:54:59.228085', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:59,244: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:54:59,244: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:54:59,245: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156300.499481122 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:54:59.244958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:54:59,270: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:54:59,270: updating layer weights
INFO - 2023-11-30 15:54:59,271: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:54:59.271212', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:54:59,271: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:54:59,271: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:54:59.271560', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:54:59,650: EPOCH 0: training on 191080 raw words (156472 effective words) took 0.4s, 415941 effective words/s
INFO - 2023-11-30 15:54:59,999: EPOCH 1: training on 191080 raw words (156237 effective words) took 0.3s, 451978 effective words/s
INFO - 2023-11-30 15:55:00,344: EPOCH 2: training on 191080 raw words (156121 effective words) took 0.3s, 456313 effective words/s
INFO - 2023-11-30 15:55:00,716: EPOCH 3: training on 191080 raw words (156469 effective words) took 0.4s, 424363 effective words/s
INFO - 2023-11-30 15:55:01,064: EPOCH 4: training on 191080 raw words (156308 effective words) took 0.3s, 451956 effective words/s
INFO - 2023-11-30 15:55:01,392: EPOCH 5: training on 191080 raw words (156247 effective words) took 0.3s, 507879 effective words/s
INFO - 2023-11-30 15:55:01,718: EPOCH 6: training on 191080 raw words (156318 effective words) took 0.3s, 483886 effective words/s
INFO - 2023-11-30 15:55:02,043: EPOCH 7: training on 191080 raw words (156219 effective words) took 0.3s, 485139 effective words/s
INFO - 2023-11-30 15:55:02,366: EPOCH 8: training on 191080 raw words (156316 effective words) took 0.3s, 486884 effective words/s
INFO - 2023-11-30 15:55:02,692: EPOCH 9: training on 191080 raw words (156402 effective words) took 0.3s, 483255 effective words/s
INFO - 2023-11-30 15:55:03,020: EPOCH 10: training on 191080 raw words (156232 effective words) took 0.3s, 480144 effective words/s
INFO - 2023-11-30 15:55:03,345: EPOCH 11: training on 191080 raw words (156402 effective words) took 0.3s, 484746 effective words/s
INFO - 2023-11-30 15:55:03,671: EPOCH 12: training on 191080 raw words (156454 effective words) took 0.3s, 484411 effective words/s
INFO - 2023-11-30 15:55:03,989: EPOCH 13: training on 191080 raw words (156151 effective words) took 0.3s, 493905 effective words/s
INFO - 2023-11-30 15:55:04,314: EPOCH 14: training on 191080 raw words (156173 effective words) took 0.3s, 484029 effective words/s
INFO - 2023-11-30 15:55:04,639: EPOCH 15: training on 191080 raw words (156310 effective words) took 0.3s, 484552 effective words/s
INFO - 2023-11-30 15:55:04,979: EPOCH 16: training on 191080 raw words (156191 effective words) took 0.3s, 463156 effective words/s
INFO - 2023-11-30 15:55:05,422: EPOCH 17: training on 191080 raw words (156130 effective words) took 0.4s, 354194 effective words/s
INFO - 2023-11-30 15:55:05,897: EPOCH 18: training on 191080 raw words (156076 effective words) took 0.5s, 330827 effective words/s
INFO - 2023-11-30 15:55:06,366: EPOCH 19: training on 191080 raw words (156443 effective words) took 0.5s, 336571 effective words/s
INFO - 2023-11-30 15:55:06,366: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125671 effective words) took 7.1s, 440560 effective words/s', 'datetime': '2023-11-30T15:55:06.366507', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:06,366: collecting all words and their counts
INFO - 2023-11-30 15:55:06,367: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:06,412: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:06,412: Updating model with new vocabulary
INFO - 2023-11-30 15:55:06,432: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:06.432697', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:06,459: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:06,459: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:55:06,459: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156074.30976427242 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:55:06.459687', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:06,495: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:06,495: updating layer weights
INFO - 2023-11-30 15:55:06,496: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:06.496153', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:06,496: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:06,496: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:06.496498', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:06,994: EPOCH 0: training on 191080 raw words (156151 effective words) took 0.5s, 316553 effective words/s
INFO - 2023-11-30 15:55:07,522: EPOCH 1: training on 191080 raw words (156186 effective words) took 0.5s, 297473 effective words/s
INFO - 2023-11-30 15:55:08,014: EPOCH 2: training on 191080 raw words (156181 effective words) took 0.5s, 320851 effective words/s
INFO - 2023-11-30 15:55:08,521: EPOCH 3: training on 191080 raw words (156132 effective words) took 0.5s, 309983 effective words/s
INFO - 2023-11-30 15:55:09,037: EPOCH 4: training on 191080 raw words (155928 effective words) took 0.5s, 304743 effective words/s
INFO - 2023-11-30 15:55:09,535: EPOCH 5: training on 191080 raw words (156064 effective words) took 0.5s, 316025 effective words/s
INFO - 2023-11-30 15:55:10,028: EPOCH 6: training on 191080 raw words (155965 effective words) took 0.5s, 318583 effective words/s
INFO - 2023-11-30 15:55:10,533: EPOCH 7: training on 191080 raw words (156032 effective words) took 0.5s, 311307 effective words/s
INFO - 2023-11-30 15:55:11,049: EPOCH 8: training on 191080 raw words (156165 effective words) took 0.5s, 305314 effective words/s
INFO - 2023-11-30 15:55:11,581: EPOCH 9: training on 191080 raw words (155907 effective words) took 0.5s, 294591 effective words/s
INFO - 2023-11-30 15:55:12,106: EPOCH 10: training on 191080 raw words (156152 effective words) took 0.5s, 299879 effective words/s
INFO - 2023-11-30 15:55:12,619: EPOCH 11: training on 191080 raw words (156272 effective words) took 0.5s, 306824 effective words/s
INFO - 2023-11-30 15:55:13,142: EPOCH 12: training on 191080 raw words (156107 effective words) took 0.5s, 300250 effective words/s
INFO - 2023-11-30 15:55:13,662: EPOCH 13: training on 191080 raw words (156100 effective words) took 0.5s, 302795 effective words/s
INFO - 2023-11-30 15:55:14,139: EPOCH 14: training on 191080 raw words (156118 effective words) took 0.5s, 329667 effective words/s
INFO - 2023-11-30 15:55:14,468: EPOCH 15: training on 191080 raw words (155977 effective words) took 0.3s, 477847 effective words/s
INFO - 2023-11-30 15:55:14,795: EPOCH 16: training on 191080 raw words (156090 effective words) took 0.3s, 480869 effective words/s
INFO - 2023-11-30 15:55:15,138: EPOCH 17: training on 191080 raw words (156073 effective words) took 0.3s, 458220 effective words/s
INFO - 2023-11-30 15:55:15,463: EPOCH 18: training on 191080 raw words (156082 effective words) took 0.3s, 484294 effective words/s
INFO - 2023-11-30 15:55:15,801: EPOCH 19: training on 191080 raw words (155956 effective words) took 0.3s, 463612 effective words/s
INFO - 2023-11-30 15:55:15,802: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121638 effective words) took 9.3s, 335461 effective words/s', 'datetime': '2023-11-30T15:55:15.802195', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:15,802: collecting all words and their counts
INFO - 2023-11-30 15:55:15,802: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:15,830: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:15,830: Updating model with new vocabulary
INFO - 2023-11-30 15:55:15,842: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:15.842388', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:15,857: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:15,858: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:55:15,858: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156321.8722527941 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:55:15.858152', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:15,881: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:15,882: updating layer weights
INFO - 2023-11-30 15:55:15,882: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:15.882536', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:15,882: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:15,882: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:15.882817', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:16,207: EPOCH 0: training on 191080 raw words (156324 effective words) took 0.3s, 485553 effective words/s
INFO - 2023-11-30 15:55:16,527: EPOCH 1: training on 191080 raw words (156326 effective words) took 0.3s, 492312 effective words/s
INFO - 2023-11-30 15:55:16,905: EPOCH 2: training on 191080 raw words (156220 effective words) took 0.4s, 415746 effective words/s
INFO - 2023-11-30 15:55:17,229: EPOCH 3: training on 191080 raw words (156364 effective words) took 0.3s, 485999 effective words/s
INFO - 2023-11-30 15:55:17,549: EPOCH 4: training on 191080 raw words (156469 effective words) took 0.3s, 492764 effective words/s
INFO - 2023-11-30 15:55:17,868: EPOCH 5: training on 191080 raw words (156243 effective words) took 0.3s, 493433 effective words/s
INFO - 2023-11-30 15:55:18,189: EPOCH 6: training on 191080 raw words (156356 effective words) took 0.3s, 490966 effective words/s
INFO - 2023-11-30 15:55:18,520: EPOCH 7: training on 191080 raw words (156399 effective words) took 0.3s, 476206 effective words/s
INFO - 2023-11-30 15:55:18,843: EPOCH 8: training on 191080 raw words (156336 effective words) took 0.3s, 486915 effective words/s
INFO - 2023-11-30 15:55:19,166: EPOCH 9: training on 191080 raw words (156291 effective words) took 0.3s, 488295 effective words/s
INFO - 2023-11-30 15:55:19,503: EPOCH 10: training on 191080 raw words (156240 effective words) took 0.3s, 465936 effective words/s
INFO - 2023-11-30 15:55:19,825: EPOCH 11: training on 191080 raw words (156155 effective words) took 0.3s, 489140 effective words/s
INFO - 2023-11-30 15:55:20,152: EPOCH 12: training on 191080 raw words (156431 effective words) took 0.3s, 481905 effective words/s
INFO - 2023-11-30 15:55:20,476: EPOCH 13: training on 191080 raw words (156323 effective words) took 0.3s, 487669 effective words/s
INFO - 2023-11-30 15:55:20,805: EPOCH 14: training on 191080 raw words (156392 effective words) took 0.3s, 479210 effective words/s
INFO - 2023-11-30 15:55:21,131: EPOCH 15: training on 191080 raw words (156264 effective words) took 0.3s, 482280 effective words/s
INFO - 2023-11-30 15:55:21,456: EPOCH 16: training on 191080 raw words (156420 effective words) took 0.3s, 484980 effective words/s
INFO - 2023-11-30 15:55:21,781: EPOCH 17: training on 191080 raw words (156385 effective words) took 0.3s, 484728 effective words/s
INFO - 2023-11-30 15:55:22,117: EPOCH 18: training on 191080 raw words (156258 effective words) took 0.3s, 468392 effective words/s
INFO - 2023-11-30 15:55:22,440: EPOCH 19: training on 191080 raw words (156454 effective words) took 0.3s, 487627 effective words/s
INFO - 2023-11-30 15:55:22,441: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126650 effective words) took 6.6s, 476751 effective words/s', 'datetime': '2023-11-30T15:55:22.441216', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:22,441: collecting all words and their counts
INFO - 2023-11-30 15:55:22,441: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:22,472: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:22,473: Updating model with new vocabulary
INFO - 2023-11-30 15:55:22,486: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:22.486207', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:22,502: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:22,503: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:55:22,503: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 155900.4879879348 word corpus (81.6%% of prior 191080)', 'datetime': '2023-11-30T15:55:22.503234', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:22,526: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:22,527: updating layer weights
INFO - 2023-11-30 15:55:22,527: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:22.527486', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:22,527: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:22,527: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:22.527770', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:22,872: EPOCH 0: training on 191080 raw words (155903 effective words) took 0.3s, 454959 effective words/s
INFO - 2023-11-30 15:55:23,217: EPOCH 1: training on 191080 raw words (155918 effective words) took 0.3s, 455300 effective words/s
INFO - 2023-11-30 15:55:23,567: EPOCH 2: training on 191080 raw words (155766 effective words) took 0.3s, 448330 effective words/s
INFO - 2023-11-30 15:55:23,900: EPOCH 3: training on 191080 raw words (155840 effective words) took 0.3s, 470531 effective words/s
INFO - 2023-11-30 15:55:24,278: EPOCH 4: training on 191080 raw words (155940 effective words) took 0.4s, 416014 effective words/s
INFO - 2023-11-30 15:55:24,657: EPOCH 5: training on 191080 raw words (155717 effective words) took 0.4s, 413812 effective words/s
INFO - 2023-11-30 15:55:25,018: EPOCH 6: training on 191080 raw words (155811 effective words) took 0.4s, 435317 effective words/s
INFO - 2023-11-30 15:55:25,359: EPOCH 7: training on 191080 raw words (156015 effective words) took 0.3s, 462675 effective words/s
INFO - 2023-11-30 15:55:25,692: EPOCH 8: training on 191080 raw words (155975 effective words) took 0.3s, 471098 effective words/s
INFO - 2023-11-30 15:55:26,026: EPOCH 9: training on 191080 raw words (155663 effective words) took 0.3s, 469176 effective words/s
INFO - 2023-11-30 15:55:26,361: EPOCH 10: training on 191080 raw words (155790 effective words) took 0.3s, 470914 effective words/s
INFO - 2023-11-30 15:55:26,714: EPOCH 11: training on 191080 raw words (155812 effective words) took 0.3s, 445186 effective words/s
INFO - 2023-11-30 15:55:27,077: EPOCH 12: training on 191080 raw words (155828 effective words) took 0.4s, 431817 effective words/s
INFO - 2023-11-30 15:55:27,464: EPOCH 13: training on 191080 raw words (155784 effective words) took 0.4s, 405811 effective words/s
INFO - 2023-11-30 15:55:27,818: EPOCH 14: training on 191080 raw words (155903 effective words) took 0.4s, 442127 effective words/s
INFO - 2023-11-30 15:55:28,165: EPOCH 15: training on 191080 raw words (156147 effective words) took 0.3s, 454816 effective words/s
INFO - 2023-11-30 15:55:28,508: EPOCH 16: training on 191080 raw words (155869 effective words) took 0.3s, 457866 effective words/s
INFO - 2023-11-30 15:55:28,858: EPOCH 17: training on 191080 raw words (155956 effective words) took 0.3s, 448328 effective words/s
INFO - 2023-11-30 15:55:29,244: EPOCH 18: training on 191080 raw words (156096 effective words) took 0.4s, 409389 effective words/s
INFO - 2023-11-30 15:55:29,713: EPOCH 19: training on 191080 raw words (156039 effective words) took 0.5s, 335140 effective words/s
INFO - 2023-11-30 15:55:29,713: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3117772 effective words) took 7.2s, 433894 effective words/s', 'datetime': '2023-11-30T15:55:29.713478', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:29,713: collecting all words and their counts
INFO - 2023-11-30 15:55:29,714: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:29,756: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:29,757: Updating model with new vocabulary
INFO - 2023-11-30 15:55:29,774: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:29.774288', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:29,795: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:29,795: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:55:29,796: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156227.9965330544 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:55:29.796239', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:29,829: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:29,829: updating layer weights
INFO - 2023-11-30 15:55:29,830: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:29.830273', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:29,830: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:29,830: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:29.830587', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:30,260: EPOCH 0: training on 191080 raw words (156384 effective words) took 0.4s, 366563 effective words/s
INFO - 2023-11-30 15:55:30,701: EPOCH 1: training on 191080 raw words (156241 effective words) took 0.4s, 357280 effective words/s
INFO - 2023-11-30 15:55:31,180: EPOCH 2: training on 191080 raw words (156285 effective words) took 0.5s, 328708 effective words/s
INFO - 2023-11-30 15:55:31,730: EPOCH 3: training on 191080 raw words (156333 effective words) took 0.5s, 286229 effective words/s
INFO - 2023-11-30 15:55:32,338: EPOCH 4: training on 191080 raw words (156299 effective words) took 0.6s, 258241 effective words/s
INFO - 2023-11-30 15:55:33,180: EPOCH 5: training on 191080 raw words (156307 effective words) took 0.8s, 186516 effective words/s
INFO - 2023-11-30 15:55:34,096: EPOCH 6: training on 191080 raw words (156137 effective words) took 0.9s, 171099 effective words/s
INFO - 2023-11-30 15:55:34,797: EPOCH 7: training on 191080 raw words (156347 effective words) took 0.7s, 224310 effective words/s
INFO - 2023-11-30 15:55:35,570: EPOCH 8: training on 191080 raw words (156035 effective words) took 0.8s, 202791 effective words/s
INFO - 2023-11-30 15:55:36,270: EPOCH 9: training on 191080 raw words (156320 effective words) took 0.7s, 224459 effective words/s
INFO - 2023-11-30 15:55:36,913: EPOCH 10: training on 191080 raw words (156094 effective words) took 0.6s, 244641 effective words/s
INFO - 2023-11-30 15:55:37,582: EPOCH 11: training on 191080 raw words (156350 effective words) took 0.7s, 234713 effective words/s
INFO - 2023-11-30 15:55:38,233: EPOCH 12: training on 191080 raw words (156332 effective words) took 0.6s, 241889 effective words/s
INFO - 2023-11-30 15:55:38,663: EPOCH 13: training on 191080 raw words (156252 effective words) took 0.4s, 365780 effective words/s
INFO - 2023-11-30 15:55:39,095: EPOCH 14: training on 191080 raw words (156224 effective words) took 0.4s, 364300 effective words/s
INFO - 2023-11-30 15:55:39,543: EPOCH 15: training on 191080 raw words (156205 effective words) took 0.4s, 351050 effective words/s
INFO - 2023-11-30 15:55:39,971: EPOCH 16: training on 191080 raw words (156100 effective words) took 0.4s, 367268 effective words/s
INFO - 2023-11-30 15:55:40,415: EPOCH 17: training on 191080 raw words (156392 effective words) took 0.4s, 354402 effective words/s
INFO - 2023-11-30 15:55:40,757: EPOCH 18: training on 191080 raw words (156200 effective words) took 0.3s, 460051 effective words/s
INFO - 2023-11-30 15:55:41,106: EPOCH 19: training on 191080 raw words (156073 effective words) took 0.3s, 451734 effective words/s
INFO - 2023-11-30 15:55:41,106: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3124910 effective words) took 11.3s, 277140 effective words/s', 'datetime': '2023-11-30T15:55:41.106338', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:41,106: collecting all words and their counts
INFO - 2023-11-30 15:55:41,106: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:41,139: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:41,139: Updating model with new vocabulary
INFO - 2023-11-30 15:55:41,151: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:41.151837', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:41,167: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:41,167: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:55:41,167: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156474.13097727596 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:55:41.167660', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:41,192: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:41,192: updating layer weights
INFO - 2023-11-30 15:55:41,192: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:41.192898', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:41,193: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:41,193: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:41.193433', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:41,526: EPOCH 0: training on 191080 raw words (156349 effective words) took 0.3s, 473633 effective words/s
INFO - 2023-11-30 15:55:41,873: EPOCH 1: training on 191080 raw words (156326 effective words) took 0.3s, 454811 effective words/s
INFO - 2023-11-30 15:55:42,239: EPOCH 2: training on 191080 raw words (156443 effective words) took 0.4s, 430579 effective words/s
INFO - 2023-11-30 15:55:42,630: EPOCH 3: training on 191080 raw words (156573 effective words) took 0.4s, 403057 effective words/s
INFO - 2023-11-30 15:55:42,971: EPOCH 4: training on 191080 raw words (156416 effective words) took 0.3s, 489673 effective words/s
INFO - 2023-11-30 15:55:43,334: EPOCH 5: training on 191080 raw words (156411 effective words) took 0.4s, 433299 effective words/s
INFO - 2023-11-30 15:55:43,695: EPOCH 6: training on 191080 raw words (156405 effective words) took 0.4s, 437164 effective words/s
INFO - 2023-11-30 15:55:44,035: EPOCH 7: training on 191080 raw words (156555 effective words) took 0.3s, 463800 effective words/s
INFO - 2023-11-30 15:55:44,374: EPOCH 8: training on 191080 raw words (156420 effective words) took 0.3s, 467063 effective words/s
INFO - 2023-11-30 15:55:44,713: EPOCH 9: training on 191080 raw words (156553 effective words) took 0.3s, 466142 effective words/s
INFO - 2023-11-30 15:55:45,059: EPOCH 10: training on 191080 raw words (156250 effective words) took 0.3s, 454105 effective words/s
INFO - 2023-11-30 15:55:45,404: EPOCH 11: training on 191080 raw words (156452 effective words) took 0.3s, 456721 effective words/s
INFO - 2023-11-30 15:55:45,744: EPOCH 12: training on 191080 raw words (156392 effective words) took 0.3s, 462441 effective words/s
INFO - 2023-11-30 15:55:46,082: EPOCH 13: training on 191080 raw words (156496 effective words) took 0.3s, 467112 effective words/s
INFO - 2023-11-30 15:55:46,420: EPOCH 14: training on 191080 raw words (156628 effective words) took 0.3s, 467717 effective words/s
INFO - 2023-11-30 15:55:46,765: EPOCH 15: training on 191080 raw words (156520 effective words) took 0.3s, 457446 effective words/s
INFO - 2023-11-30 15:55:47,108: EPOCH 16: training on 191080 raw words (156405 effective words) took 0.3s, 458853 effective words/s
INFO - 2023-11-30 15:55:47,445: EPOCH 17: training on 191080 raw words (156294 effective words) took 0.3s, 467443 effective words/s
INFO - 2023-11-30 15:55:47,784: EPOCH 18: training on 191080 raw words (156460 effective words) took 0.3s, 464802 effective words/s
INFO - 2023-11-30 15:55:48,138: EPOCH 19: training on 191080 raw words (156476 effective words) took 0.4s, 445529 effective words/s
INFO - 2023-11-30 15:55:48,138: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128824 effective words) took 6.9s, 450534 effective words/s', 'datetime': '2023-11-30T15:55:48.138297', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:48,138: collecting all words and their counts
INFO - 2023-11-30 15:55:48,138: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:48,169: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:48,169: Updating model with new vocabulary
INFO - 2023-11-30 15:55:48,183: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:48.183236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:48,200: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:48,200: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:55:48,201: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156145.12414053583 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:55:48.201074', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:48,225: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:48,225: updating layer weights
INFO - 2023-11-30 15:55:48,225: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:48.225729', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:48,225: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:48,226: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:48.226048', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:48,549: EPOCH 0: training on 191080 raw words (155880 effective words) took 0.3s, 487026 effective words/s
INFO - 2023-11-30 15:55:48,884: EPOCH 1: training on 191080 raw words (156048 effective words) took 0.3s, 469744 effective words/s
INFO - 2023-11-30 15:55:49,230: EPOCH 2: training on 191080 raw words (156117 effective words) took 0.3s, 454665 effective words/s
INFO - 2023-11-30 15:55:49,584: EPOCH 3: training on 191080 raw words (156232 effective words) took 0.4s, 445502 effective words/s
INFO - 2023-11-30 15:55:49,951: EPOCH 4: training on 191080 raw words (156298 effective words) took 0.4s, 428175 effective words/s
INFO - 2023-11-30 15:55:50,282: EPOCH 5: training on 191080 raw words (156252 effective words) took 0.3s, 476799 effective words/s
INFO - 2023-11-30 15:55:50,610: EPOCH 6: training on 191080 raw words (156130 effective words) took 0.3s, 478712 effective words/s
INFO - 2023-11-30 15:55:50,945: EPOCH 7: training on 191080 raw words (156170 effective words) took 0.3s, 468675 effective words/s
INFO - 2023-11-30 15:55:51,267: EPOCH 8: training on 191080 raw words (156060 effective words) took 0.3s, 489389 effective words/s
INFO - 2023-11-30 15:55:51,618: EPOCH 9: training on 191080 raw words (156063 effective words) took 0.3s, 447427 effective words/s
INFO - 2023-11-30 15:55:51,984: EPOCH 10: training on 191080 raw words (156205 effective words) took 0.4s, 430572 effective words/s
INFO - 2023-11-30 15:55:52,317: EPOCH 11: training on 191080 raw words (156019 effective words) took 0.3s, 471772 effective words/s
INFO - 2023-11-30 15:55:52,675: EPOCH 12: training on 191080 raw words (156243 effective words) took 0.4s, 439498 effective words/s
INFO - 2023-11-30 15:55:53,076: EPOCH 13: training on 191080 raw words (156004 effective words) took 0.4s, 392299 effective words/s
INFO - 2023-11-30 15:55:53,439: EPOCH 14: training on 191080 raw words (156192 effective words) took 0.4s, 434335 effective words/s
INFO - 2023-11-30 15:55:53,915: EPOCH 15: training on 191080 raw words (156161 effective words) took 0.5s, 329935 effective words/s
INFO - 2023-11-30 15:55:54,368: EPOCH 16: training on 191080 raw words (156220 effective words) took 0.4s, 347440 effective words/s
INFO - 2023-11-30 15:55:54,916: EPOCH 17: training on 191080 raw words (156007 effective words) took 0.5s, 286620 effective words/s
INFO - 2023-11-30 15:55:55,535: EPOCH 18: training on 191080 raw words (156163 effective words) took 0.6s, 255827 effective words/s
INFO - 2023-11-30 15:55:56,203: EPOCH 19: training on 191080 raw words (156364 effective words) took 0.7s, 235270 effective words/s
INFO - 2023-11-30 15:55:56,203: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122828 effective words) took 8.0s, 391453 effective words/s', 'datetime': '2023-11-30T15:55:56.203717', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:56,203: collecting all words and their counts
INFO - 2023-11-30 15:55:56,204: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:55:56,268: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:55:56,268: Updating model with new vocabulary
INFO - 2023-11-30 15:55:56,296: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:55:56.296460', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:56,332: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:55:56,333: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:55:56,333: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156210.19113775154 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:55:56.333439', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:55:56,390: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:55:56,390: updating layer weights
INFO - 2023-11-30 15:55:56,390: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:55:56.390920', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:55:56,391: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:55:56,391: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:55:56.391352', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:55:57,149: EPOCH 0: training on 191080 raw words (156103 effective words) took 0.8s, 207829 effective words/s
INFO - 2023-11-30 15:55:57,827: EPOCH 1: training on 191080 raw words (156266 effective words) took 0.7s, 231438 effective words/s
INFO - 2023-11-30 15:55:58,671: EPOCH 2: training on 191080 raw words (156189 effective words) took 0.8s, 186207 effective words/s
INFO - 2023-11-30 15:55:59,506: EPOCH 3: training on 191080 raw words (156248 effective words) took 0.8s, 188014 effective words/s
INFO - 2023-11-30 15:56:00,335: EPOCH 4: training on 191080 raw words (156313 effective words) took 0.8s, 189369 effective words/s
INFO - 2023-11-30 15:56:01,172: EPOCH 5: training on 191080 raw words (156120 effective words) took 0.8s, 187520 effective words/s
INFO - 2023-11-30 15:56:01,959: EPOCH 6: training on 191080 raw words (156022 effective words) took 0.8s, 199399 effective words/s
INFO - 2023-11-30 15:56:02,570: EPOCH 7: training on 191080 raw words (156221 effective words) took 0.6s, 257098 effective words/s
INFO - 2023-11-30 15:56:03,050: EPOCH 8: training on 191080 raw words (156011 effective words) took 0.5s, 326732 effective words/s
INFO - 2023-11-30 15:56:03,514: EPOCH 9: training on 191080 raw words (156232 effective words) took 0.5s, 339521 effective words/s
INFO - 2023-11-30 15:56:03,982: EPOCH 10: training on 191080 raw words (156277 effective words) took 0.5s, 336157 effective words/s
INFO - 2023-11-30 15:56:04,543: EPOCH 11: training on 191080 raw words (156121 effective words) took 0.6s, 279683 effective words/s
INFO - 2023-11-30 15:56:05,099: EPOCH 12: training on 191080 raw words (156113 effective words) took 0.6s, 282204 effective words/s
INFO - 2023-11-30 15:56:05,491: EPOCH 13: training on 191080 raw words (156219 effective words) took 0.4s, 401089 effective words/s
INFO - 2023-11-30 15:56:05,877: EPOCH 14: training on 191080 raw words (156319 effective words) took 0.4s, 408671 effective words/s
INFO - 2023-11-30 15:56:06,227: EPOCH 15: training on 191080 raw words (156141 effective words) took 0.3s, 449248 effective words/s
INFO - 2023-11-30 15:56:06,572: EPOCH 16: training on 191080 raw words (156117 effective words) took 0.3s, 456076 effective words/s
INFO - 2023-11-30 15:56:06,969: EPOCH 17: training on 191080 raw words (156333 effective words) took 0.4s, 396390 effective words/s
INFO - 2023-11-30 15:56:07,319: EPOCH 18: training on 191080 raw words (156262 effective words) took 0.3s, 449881 effective words/s
INFO - 2023-11-30 15:56:07,666: EPOCH 19: training on 191080 raw words (156217 effective words) took 0.3s, 452752 effective words/s
INFO - 2023-11-30 15:56:07,666: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123844 effective words) took 11.3s, 277053 effective words/s', 'datetime': '2023-11-30T15:56:07.666852', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:07,666: collecting all words and their counts
INFO - 2023-11-30 15:56:07,667: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:07,696: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:07,696: Updating model with new vocabulary
INFO - 2023-11-30 15:56:07,710: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:07.710694', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:07,727: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:07,727: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:56:07,728: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156106.50816507917 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:56:07.728199', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:07,751: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:07,751: updating layer weights
INFO - 2023-11-30 15:56:07,752: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:07.752129', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:07,752: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:07,752: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:07.752314', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:08,088: EPOCH 0: training on 191080 raw words (156072 effective words) took 0.3s, 467903 effective words/s
INFO - 2023-11-30 15:56:08,425: EPOCH 1: training on 191080 raw words (156249 effective words) took 0.3s, 467246 effective words/s
INFO - 2023-11-30 15:56:08,767: EPOCH 2: training on 191080 raw words (156119 effective words) took 0.3s, 460100 effective words/s
INFO - 2023-11-30 15:56:09,104: EPOCH 3: training on 191080 raw words (156075 effective words) took 0.3s, 466989 effective words/s
INFO - 2023-11-30 15:56:09,444: EPOCH 4: training on 191080 raw words (156007 effective words) took 0.3s, 460934 effective words/s
INFO - 2023-11-30 15:56:09,785: EPOCH 5: training on 191080 raw words (156238 effective words) took 0.3s, 461552 effective words/s
INFO - 2023-11-30 15:56:10,138: EPOCH 6: training on 191080 raw words (156110 effective words) took 0.4s, 446015 effective words/s
INFO - 2023-11-30 15:56:10,480: EPOCH 7: training on 191080 raw words (156226 effective words) took 0.3s, 459219 effective words/s
INFO - 2023-11-30 15:56:10,834: EPOCH 8: training on 191080 raw words (156173 effective words) took 0.4s, 445970 effective words/s
INFO - 2023-11-30 15:56:11,171: EPOCH 9: training on 191080 raw words (156097 effective words) took 0.3s, 466005 effective words/s
INFO - 2023-11-30 15:56:11,506: EPOCH 10: training on 191080 raw words (156048 effective words) took 0.3s, 469295 effective words/s
INFO - 2023-11-30 15:56:11,854: EPOCH 11: training on 191080 raw words (156073 effective words) took 0.3s, 453071 effective words/s
INFO - 2023-11-30 15:56:12,199: EPOCH 12: training on 191080 raw words (155947 effective words) took 0.3s, 454758 effective words/s
INFO - 2023-11-30 15:56:12,537: EPOCH 13: training on 191080 raw words (156100 effective words) took 0.3s, 466064 effective words/s
INFO - 2023-11-30 15:56:12,884: EPOCH 14: training on 191080 raw words (155920 effective words) took 0.3s, 452876 effective words/s
INFO - 2023-11-30 15:56:13,228: EPOCH 15: training on 191080 raw words (156063 effective words) took 0.3s, 456481 effective words/s
INFO - 2023-11-30 15:56:13,573: EPOCH 16: training on 191080 raw words (156057 effective words) took 0.3s, 455942 effective words/s
INFO - 2023-11-30 15:56:13,917: EPOCH 17: training on 191080 raw words (156085 effective words) took 0.3s, 457606 effective words/s
INFO - 2023-11-30 15:56:14,262: EPOCH 18: training on 191080 raw words (155881 effective words) took 0.3s, 454772 effective words/s
INFO - 2023-11-30 15:56:14,608: EPOCH 19: training on 191080 raw words (156050 effective words) took 0.3s, 455273 effective words/s
INFO - 2023-11-30 15:56:14,608: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121590 effective words) took 6.9s, 455280 effective words/s', 'datetime': '2023-11-30T15:56:14.608851', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:14,609: collecting all words and their counts
INFO - 2023-11-30 15:56:14,609: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:14,644: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:14,644: Updating model with new vocabulary
INFO - 2023-11-30 15:56:14,658: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:14.658524', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:14,676: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:14,676: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:56:14,676: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156365.336425236 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:56:14.676543', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:14,704: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:14,704: updating layer weights
INFO - 2023-11-30 15:56:14,704: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:14.704667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:14,704: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:14,704: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:14.704917', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:15,078: EPOCH 0: training on 191080 raw words (156314 effective words) took 0.4s, 421756 effective words/s
INFO - 2023-11-30 15:56:15,466: EPOCH 1: training on 191080 raw words (156279 effective words) took 0.4s, 405803 effective words/s
INFO - 2023-11-30 15:56:15,855: EPOCH 2: training on 191080 raw words (156288 effective words) took 0.4s, 403938 effective words/s
INFO - 2023-11-30 15:56:16,212: EPOCH 3: training on 191080 raw words (156492 effective words) took 0.4s, 441368 effective words/s
INFO - 2023-11-30 15:56:16,564: EPOCH 4: training on 191080 raw words (156518 effective words) took 0.3s, 447566 effective words/s
INFO - 2023-11-30 15:56:16,963: EPOCH 5: training on 191080 raw words (156419 effective words) took 0.4s, 395718 effective words/s
INFO - 2023-11-30 15:56:17,369: EPOCH 6: training on 191080 raw words (156406 effective words) took 0.4s, 387600 effective words/s
INFO - 2023-11-30 15:56:17,767: EPOCH 7: training on 191080 raw words (156516 effective words) took 0.4s, 395139 effective words/s
INFO - 2023-11-30 15:56:18,323: EPOCH 8: training on 191080 raw words (156300 effective words) took 0.6s, 282622 effective words/s
INFO - 2023-11-30 15:56:18,786: EPOCH 9: training on 191080 raw words (156454 effective words) took 0.5s, 340424 effective words/s
INFO - 2023-11-30 15:56:19,269: EPOCH 10: training on 191080 raw words (156571 effective words) took 0.5s, 326332 effective words/s
INFO - 2023-11-30 15:56:19,761: EPOCH 11: training on 191080 raw words (156542 effective words) took 0.5s, 320577 effective words/s
INFO - 2023-11-30 15:56:20,254: EPOCH 12: training on 191080 raw words (156456 effective words) took 0.5s, 319855 effective words/s
INFO - 2023-11-30 15:56:20,722: EPOCH 13: training on 191080 raw words (156363 effective words) took 0.5s, 336610 effective words/s
INFO - 2023-11-30 15:56:21,215: EPOCH 14: training on 191080 raw words (156400 effective words) took 0.5s, 319311 effective words/s
INFO - 2023-11-30 15:56:21,733: EPOCH 15: training on 191080 raw words (156515 effective words) took 0.5s, 304449 effective words/s
INFO - 2023-11-30 15:56:22,258: EPOCH 16: training on 191080 raw words (156326 effective words) took 0.5s, 299536 effective words/s
INFO - 2023-11-30 15:56:22,770: EPOCH 17: training on 191080 raw words (156143 effective words) took 0.5s, 307202 effective words/s
INFO - 2023-11-30 15:56:23,289: EPOCH 18: training on 191080 raw words (156544 effective words) took 0.5s, 304034 effective words/s
INFO - 2023-11-30 15:56:23,841: EPOCH 19: training on 191080 raw words (156379 effective words) took 0.5s, 284555 effective words/s
INFO - 2023-11-30 15:56:23,842: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128225 effective words) took 9.1s, 342368 effective words/s', 'datetime': '2023-11-30T15:56:23.842056', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:23,842: collecting all words and their counts
INFO - 2023-11-30 15:56:23,842: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:23,896: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:23,897: Updating model with new vocabulary
INFO - 2023-11-30 15:56:23,918: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:23.918651', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:23,949: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:23,949: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:56:23,950: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156353.36390979204 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:56:23.950001', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:24,001: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:24,001: updating layer weights
INFO - 2023-11-30 15:56:24,002: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:24.002254', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:24,002: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:24,003: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:24.003184', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:24,574: EPOCH 0: training on 191080 raw words (156380 effective words) took 0.6s, 275903 effective words/s
INFO - 2023-11-30 15:56:25,106: EPOCH 1: training on 191080 raw words (156388 effective words) took 0.5s, 296195 effective words/s
INFO - 2023-11-30 15:56:25,629: EPOCH 2: training on 191080 raw words (156305 effective words) took 0.5s, 301274 effective words/s
INFO - 2023-11-30 15:56:26,155: EPOCH 3: training on 191080 raw words (156477 effective words) took 0.5s, 299350 effective words/s
INFO - 2023-11-30 15:56:26,684: EPOCH 4: training on 191080 raw words (156412 effective words) took 0.5s, 297675 effective words/s
INFO - 2023-11-30 15:56:27,026: EPOCH 5: training on 191080 raw words (156370 effective words) took 0.3s, 460406 effective words/s
INFO - 2023-11-30 15:56:27,364: EPOCH 6: training on 191080 raw words (156393 effective words) took 0.3s, 467442 effective words/s
INFO - 2023-11-30 15:56:27,706: EPOCH 7: training on 191080 raw words (156566 effective words) took 0.3s, 461433 effective words/s
INFO - 2023-11-30 15:56:28,054: EPOCH 8: training on 191080 raw words (156225 effective words) took 0.3s, 453109 effective words/s
INFO - 2023-11-30 15:56:28,400: EPOCH 9: training on 191080 raw words (156501 effective words) took 0.3s, 455556 effective words/s
INFO - 2023-11-30 15:56:28,740: EPOCH 10: training on 191080 raw words (156318 effective words) took 0.3s, 463714 effective words/s
INFO - 2023-11-30 15:56:29,093: EPOCH 11: training on 191080 raw words (156338 effective words) took 0.3s, 446737 effective words/s
INFO - 2023-11-30 15:56:29,436: EPOCH 12: training on 191080 raw words (156322 effective words) took 0.3s, 460868 effective words/s
INFO - 2023-11-30 15:56:29,779: EPOCH 13: training on 191080 raw words (156283 effective words) took 0.3s, 458597 effective words/s
INFO - 2023-11-30 15:56:30,122: EPOCH 14: training on 191080 raw words (156291 effective words) took 0.3s, 458594 effective words/s
INFO - 2023-11-30 15:56:30,460: EPOCH 15: training on 191080 raw words (156523 effective words) took 0.3s, 467440 effective words/s
INFO - 2023-11-30 15:56:30,806: EPOCH 16: training on 191080 raw words (156467 effective words) took 0.3s, 454999 effective words/s
INFO - 2023-11-30 15:56:31,130: EPOCH 17: training on 191080 raw words (156431 effective words) took 0.3s, 486792 effective words/s
INFO - 2023-11-30 15:56:31,477: EPOCH 18: training on 191080 raw words (156221 effective words) took 0.3s, 454122 effective words/s
INFO - 2023-11-30 15:56:31,816: EPOCH 19: training on 191080 raw words (156521 effective words) took 0.3s, 465707 effective words/s
INFO - 2023-11-30 15:56:31,816: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127732 effective words) took 7.8s, 400312 effective words/s', 'datetime': '2023-11-30T15:56:31.816681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:31,816: collecting all words and their counts
INFO - 2023-11-30 15:56:31,817: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:31,856: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:31,857: Updating model with new vocabulary
INFO - 2023-11-30 15:56:31,870: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:31.870941', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:31,889: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:31,889: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:56:31,889: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156398.0530271518 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:56:31.889438', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:31,914: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:31,914: updating layer weights
INFO - 2023-11-30 15:56:31,914: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:31.914827', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:31,914: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:31,915: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:31.915134', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:32,253: EPOCH 0: training on 191080 raw words (156427 effective words) took 0.3s, 465185 effective words/s
INFO - 2023-11-30 15:56:32,624: EPOCH 1: training on 191080 raw words (156285 effective words) took 0.4s, 424361 effective words/s
INFO - 2023-11-30 15:56:33,001: EPOCH 2: training on 191080 raw words (156461 effective words) took 0.4s, 418328 effective words/s
INFO - 2023-11-30 15:56:33,372: EPOCH 3: training on 191080 raw words (156391 effective words) took 0.4s, 424016 effective words/s
INFO - 2023-11-30 15:56:33,728: EPOCH 4: training on 191080 raw words (156355 effective words) took 0.4s, 443607 effective words/s
INFO - 2023-11-30 15:56:34,109: EPOCH 5: training on 191080 raw words (156250 effective words) took 0.4s, 412655 effective words/s
INFO - 2023-11-30 15:56:34,467: EPOCH 6: training on 191080 raw words (156222 effective words) took 0.4s, 440264 effective words/s
INFO - 2023-11-30 15:56:34,851: EPOCH 7: training on 191080 raw words (156494 effective words) took 0.4s, 410375 effective words/s
INFO - 2023-11-30 15:56:35,211: EPOCH 8: training on 191080 raw words (156626 effective words) took 0.4s, 438236 effective words/s
INFO - 2023-11-30 15:56:35,574: EPOCH 9: training on 191080 raw words (156324 effective words) took 0.4s, 433236 effective words/s
INFO - 2023-11-30 15:56:35,943: EPOCH 10: training on 191080 raw words (156353 effective words) took 0.4s, 427653 effective words/s
INFO - 2023-11-30 15:56:36,317: EPOCH 11: training on 191080 raw words (156495 effective words) took 0.4s, 421784 effective words/s
INFO - 2023-11-30 15:56:36,691: EPOCH 12: training on 191080 raw words (156399 effective words) took 0.4s, 420080 effective words/s
INFO - 2023-11-30 15:56:37,077: EPOCH 13: training on 191080 raw words (156480 effective words) took 0.4s, 408323 effective words/s
INFO - 2023-11-30 15:56:37,462: EPOCH 14: training on 191080 raw words (156099 effective words) took 0.4s, 408197 effective words/s
INFO - 2023-11-30 15:56:37,836: EPOCH 15: training on 191080 raw words (156263 effective words) took 0.4s, 421000 effective words/s
INFO - 2023-11-30 15:56:38,198: EPOCH 16: training on 191080 raw words (156522 effective words) took 0.4s, 436271 effective words/s
INFO - 2023-11-30 15:56:38,558: EPOCH 17: training on 191080 raw words (156302 effective words) took 0.4s, 436565 effective words/s
INFO - 2023-11-30 15:56:38,915: EPOCH 18: training on 191080 raw words (156432 effective words) took 0.4s, 441267 effective words/s
INFO - 2023-11-30 15:56:39,270: EPOCH 19: training on 191080 raw words (156571 effective words) took 0.4s, 443824 effective words/s
INFO - 2023-11-30 15:56:39,270: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127751 effective words) took 7.4s, 425225 effective words/s', 'datetime': '2023-11-30T15:56:39.270798', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:39,271: collecting all words and their counts
INFO - 2023-11-30 15:56:39,271: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:39,302: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:39,302: Updating model with new vocabulary
INFO - 2023-11-30 15:56:39,316: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:39.316482', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:39,333: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:39,334: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:56:39,334: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156319.21322414672 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:56:39.334283', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:39,367: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:39,367: updating layer weights
INFO - 2023-11-30 15:56:39,367: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:39.367842', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:39,368: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:39,368: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:39.368138', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:39,700: EPOCH 0: training on 191080 raw words (156300 effective words) took 0.3s, 507926 effective words/s
INFO - 2023-11-30 15:56:40,046: EPOCH 1: training on 191080 raw words (156339 effective words) took 0.3s, 455562 effective words/s
INFO - 2023-11-30 15:56:40,443: EPOCH 2: training on 191080 raw words (156221 effective words) took 0.4s, 395684 effective words/s
INFO - 2023-11-30 15:56:40,780: EPOCH 3: training on 191080 raw words (156082 effective words) took 0.3s, 467053 effective words/s
INFO - 2023-11-30 15:56:41,156: EPOCH 4: training on 191080 raw words (156358 effective words) took 0.4s, 418811 effective words/s
INFO - 2023-11-30 15:56:41,556: EPOCH 5: training on 191080 raw words (156374 effective words) took 0.4s, 393969 effective words/s
INFO - 2023-11-30 15:56:41,916: EPOCH 6: training on 191080 raw words (156394 effective words) took 0.4s, 436987 effective words/s
INFO - 2023-11-30 15:56:42,370: EPOCH 7: training on 191080 raw words (156275 effective words) took 0.5s, 346739 effective words/s
INFO - 2023-11-30 15:56:42,796: EPOCH 8: training on 191080 raw words (156469 effective words) took 0.4s, 369515 effective words/s
INFO - 2023-11-30 15:56:43,241: EPOCH 9: training on 191080 raw words (156461 effective words) took 0.4s, 354513 effective words/s
INFO - 2023-11-30 15:56:43,673: EPOCH 10: training on 191080 raw words (156286 effective words) took 0.4s, 364422 effective words/s
INFO - 2023-11-30 15:56:44,162: EPOCH 11: training on 191080 raw words (156326 effective words) took 0.5s, 321761 effective words/s
INFO - 2023-11-30 15:56:44,639: EPOCH 12: training on 191080 raw words (156375 effective words) took 0.5s, 330101 effective words/s
INFO - 2023-11-30 15:56:45,090: EPOCH 13: training on 191080 raw words (156199 effective words) took 0.4s, 348596 effective words/s
INFO - 2023-11-30 15:56:45,548: EPOCH 14: training on 191080 raw words (156284 effective words) took 0.5s, 344419 effective words/s
INFO - 2023-11-30 15:56:46,005: EPOCH 15: training on 191080 raw words (156479 effective words) took 0.5s, 344635 effective words/s
INFO - 2023-11-30 15:56:46,463: EPOCH 16: training on 191080 raw words (156555 effective words) took 0.5s, 344408 effective words/s
INFO - 2023-11-30 15:56:46,917: EPOCH 17: training on 191080 raw words (156504 effective words) took 0.5s, 347309 effective words/s
INFO - 2023-11-30 15:56:47,374: EPOCH 18: training on 191080 raw words (156396 effective words) took 0.5s, 344914 effective words/s
INFO - 2023-11-30 15:56:47,832: EPOCH 19: training on 191080 raw words (156535 effective words) took 0.5s, 344774 effective words/s
INFO - 2023-11-30 15:56:47,832: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127212 effective words) took 8.5s, 369467 effective words/s', 'datetime': '2023-11-30T15:56:47.832418', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:47,832: collecting all words and their counts
INFO - 2023-11-30 15:56:47,833: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:47,880: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:47,880: Updating model with new vocabulary
INFO - 2023-11-30 15:56:47,900: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:47.900319', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:47,935: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:47,935: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:56:47,935: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156437.1018629943 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:56:47.935756', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:47,975: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:47,975: updating layer weights
INFO - 2023-11-30 15:56:47,976: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:47.976086', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:47,976: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:47,976: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:47.976452', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:48,496: EPOCH 0: training on 191080 raw words (156319 effective words) took 0.5s, 302724 effective words/s
INFO - 2023-11-30 15:56:49,029: EPOCH 1: training on 191080 raw words (156238 effective words) took 0.5s, 295223 effective words/s
INFO - 2023-11-30 15:56:49,614: EPOCH 2: training on 191080 raw words (156543 effective words) took 0.6s, 273784 effective words/s
INFO - 2023-11-30 15:56:50,156: EPOCH 3: training on 191080 raw words (156434 effective words) took 0.5s, 290531 effective words/s
INFO - 2023-11-30 15:56:50,675: EPOCH 4: training on 191080 raw words (156601 effective words) took 0.5s, 303759 effective words/s
INFO - 2023-11-30 15:56:51,069: EPOCH 5: training on 191080 raw words (156456 effective words) took 0.4s, 401790 effective words/s
INFO - 2023-11-30 15:56:51,402: EPOCH 6: training on 191080 raw words (156576 effective words) took 0.3s, 473375 effective words/s
INFO - 2023-11-30 15:56:51,745: EPOCH 7: training on 191080 raw words (156414 effective words) took 0.3s, 459343 effective words/s
INFO - 2023-11-30 15:56:52,076: EPOCH 8: training on 191080 raw words (156429 effective words) took 0.3s, 475951 effective words/s
INFO - 2023-11-30 15:56:52,425: EPOCH 9: training on 191080 raw words (156603 effective words) took 0.3s, 451884 effective words/s
INFO - 2023-11-30 15:56:52,758: EPOCH 10: training on 191080 raw words (156341 effective words) took 0.3s, 472103 effective words/s
INFO - 2023-11-30 15:56:53,092: EPOCH 11: training on 191080 raw words (156221 effective words) took 0.3s, 472109 effective words/s
INFO - 2023-11-30 15:56:53,445: EPOCH 12: training on 191080 raw words (156449 effective words) took 0.4s, 445440 effective words/s
INFO - 2023-11-30 15:56:53,791: EPOCH 13: training on 191080 raw words (156540 effective words) took 0.3s, 455506 effective words/s
INFO - 2023-11-30 15:56:54,160: EPOCH 14: training on 191080 raw words (156333 effective words) took 0.4s, 427915 effective words/s
INFO - 2023-11-30 15:56:54,511: EPOCH 15: training on 191080 raw words (156432 effective words) took 0.3s, 448259 effective words/s
INFO - 2023-11-30 15:56:54,850: EPOCH 16: training on 191080 raw words (156522 effective words) took 0.3s, 466300 effective words/s
INFO - 2023-11-30 15:56:55,238: EPOCH 17: training on 191080 raw words (156478 effective words) took 0.4s, 405270 effective words/s
INFO - 2023-11-30 15:56:55,588: EPOCH 18: training on 191080 raw words (156334 effective words) took 0.3s, 450821 effective words/s
INFO - 2023-11-30 15:56:55,924: EPOCH 19: training on 191080 raw words (156144 effective words) took 0.3s, 467723 effective words/s
INFO - 2023-11-30 15:56:55,924: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128407 effective words) took 7.9s, 393599 effective words/s', 'datetime': '2023-11-30T15:56:55.924820', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:55,925: collecting all words and their counts
INFO - 2023-11-30 15:56:55,925: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:56:55,966: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:56:55,966: Updating model with new vocabulary
INFO - 2023-11-30 15:56:55,980: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:56:55.980558', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:55,996: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:56:55,996: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:56:55,996: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156049.83568981095 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:56:55.996747', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:56:56,024: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:56:56,024: updating layer weights
INFO - 2023-11-30 15:56:56,025: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:56:56.024997', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:56:56,025: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:56:56,025: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:56:56.025447', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:56:56,368: EPOCH 0: training on 191080 raw words (156114 effective words) took 0.3s, 460070 effective words/s
INFO - 2023-11-30 15:56:56,894: EPOCH 1: training on 191080 raw words (155984 effective words) took 0.5s, 298122 effective words/s
INFO - 2023-11-30 15:56:57,391: EPOCH 2: training on 191080 raw words (156235 effective words) took 0.5s, 316396 effective words/s
INFO - 2023-11-30 15:56:57,950: EPOCH 3: training on 191080 raw words (156048 effective words) took 0.6s, 280725 effective words/s
INFO - 2023-11-30 15:56:58,458: EPOCH 4: training on 191080 raw words (155837 effective words) took 0.5s, 308650 effective words/s
INFO - 2023-11-30 15:56:58,934: EPOCH 5: training on 191080 raw words (156102 effective words) took 0.5s, 329278 effective words/s
INFO - 2023-11-30 15:56:59,360: EPOCH 6: training on 191080 raw words (156232 effective words) took 0.4s, 369503 effective words/s
INFO - 2023-11-30 15:56:59,781: EPOCH 7: training on 191080 raw words (156166 effective words) took 0.4s, 373463 effective words/s
INFO - 2023-11-30 15:57:00,196: EPOCH 8: training on 191080 raw words (156015 effective words) took 0.4s, 378753 effective words/s
INFO - 2023-11-30 15:57:00,609: EPOCH 9: training on 191080 raw words (156266 effective words) took 0.4s, 381196 effective words/s
INFO - 2023-11-30 15:57:01,062: EPOCH 10: training on 191080 raw words (155923 effective words) took 0.4s, 346868 effective words/s
INFO - 2023-11-30 15:57:01,525: EPOCH 11: training on 191080 raw words (155773 effective words) took 0.5s, 338700 effective words/s
INFO - 2023-11-30 15:57:01,947: EPOCH 12: training on 191080 raw words (156072 effective words) took 0.4s, 372323 effective words/s
INFO - 2023-11-30 15:57:02,356: EPOCH 13: training on 191080 raw words (156105 effective words) took 0.4s, 384231 effective words/s
INFO - 2023-11-30 15:57:02,810: EPOCH 14: training on 191080 raw words (155907 effective words) took 0.5s, 345174 effective words/s
INFO - 2023-11-30 15:57:03,243: EPOCH 15: training on 191080 raw words (156111 effective words) took 0.4s, 363069 effective words/s
INFO - 2023-11-30 15:57:03,607: EPOCH 16: training on 191080 raw words (156020 effective words) took 0.4s, 432038 effective words/s
INFO - 2023-11-30 15:57:03,966: EPOCH 17: training on 191080 raw words (156115 effective words) took 0.4s, 439022 effective words/s
INFO - 2023-11-30 15:57:04,292: EPOCH 18: training on 191080 raw words (156092 effective words) took 0.3s, 483012 effective words/s
INFO - 2023-11-30 15:57:04,610: EPOCH 19: training on 191080 raw words (156119 effective words) took 0.3s, 494027 effective words/s
INFO - 2023-11-30 15:57:04,611: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121236 effective words) took 8.6s, 363549 effective words/s', 'datetime': '2023-11-30T15:57:04.611137', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:04,611: collecting all words and their counts
INFO - 2023-11-30 15:57:04,611: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:04,642: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:04,642: Updating model with new vocabulary
INFO - 2023-11-30 15:57:04,655: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:04.655775', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:04,671: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:04,671: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:57:04,671: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156058.88293185417 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:57:04.671921', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:04,696: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:04,696: updating layer weights
INFO - 2023-11-30 15:57:04,697: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:04.697077', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:04,697: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:04,697: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:04.697337', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:05,063: EPOCH 0: training on 191080 raw words (155987 effective words) took 0.4s, 429590 effective words/s
INFO - 2023-11-30 15:57:05,400: EPOCH 1: training on 191080 raw words (156133 effective words) took 0.3s, 467304 effective words/s
INFO - 2023-11-30 15:57:05,747: EPOCH 2: training on 191080 raw words (155908 effective words) took 0.3s, 452316 effective words/s
INFO - 2023-11-30 15:57:06,119: EPOCH 3: training on 191080 raw words (156148 effective words) took 0.4s, 423027 effective words/s
INFO - 2023-11-30 15:57:06,583: EPOCH 4: training on 191080 raw words (156067 effective words) took 0.5s, 339642 effective words/s
INFO - 2023-11-30 15:57:07,045: EPOCH 5: training on 191080 raw words (156174 effective words) took 0.5s, 340656 effective words/s
INFO - 2023-11-30 15:57:07,495: EPOCH 6: training on 191080 raw words (155998 effective words) took 0.4s, 348690 effective words/s
INFO - 2023-11-30 15:57:07,940: EPOCH 7: training on 191080 raw words (155965 effective words) took 0.4s, 352757 effective words/s
INFO - 2023-11-30 15:57:08,396: EPOCH 8: training on 191080 raw words (155787 effective words) took 0.5s, 343907 effective words/s
INFO - 2023-11-30 15:57:08,842: EPOCH 9: training on 191080 raw words (155953 effective words) took 0.4s, 352455 effective words/s
INFO - 2023-11-30 15:57:09,315: EPOCH 10: training on 191080 raw words (156120 effective words) took 0.4s, 347857 effective words/s
INFO - 2023-11-30 15:57:09,791: EPOCH 11: training on 191080 raw words (155993 effective words) took 0.5s, 329544 effective words/s
INFO - 2023-11-30 15:57:10,272: EPOCH 12: training on 191080 raw words (156121 effective words) took 0.5s, 326863 effective words/s
INFO - 2023-11-30 15:57:10,747: EPOCH 13: training on 191080 raw words (155995 effective words) took 0.5s, 330955 effective words/s
INFO - 2023-11-30 15:57:11,233: EPOCH 14: training on 191080 raw words (156042 effective words) took 0.5s, 322977 effective words/s
INFO - 2023-11-30 15:57:11,706: EPOCH 15: training on 191080 raw words (155974 effective words) took 0.5s, 332230 effective words/s
INFO - 2023-11-30 15:57:12,200: EPOCH 16: training on 191080 raw words (156127 effective words) took 0.5s, 317337 effective words/s
INFO - 2023-11-30 15:57:12,727: EPOCH 17: training on 191080 raw words (155960 effective words) took 0.5s, 298371 effective words/s
INFO - 2023-11-30 15:57:13,238: EPOCH 18: training on 191080 raw words (156245 effective words) took 0.5s, 307466 effective words/s
INFO - 2023-11-30 15:57:13,748: EPOCH 19: training on 191080 raw words (156124 effective words) took 0.5s, 308816 effective words/s
INFO - 2023-11-30 15:57:13,748: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120821 effective words) took 9.1s, 344809 effective words/s', 'datetime': '2023-11-30T15:57:13.748327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:13,748: collecting all words and their counts
INFO - 2023-11-30 15:57:13,748: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:13,795: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:13,795: Updating model with new vocabulary
INFO - 2023-11-30 15:57:13,816: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:13.816374', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:13,841: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:13,842: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:57:13,842: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156190.73525089794 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:57:13.842525', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:13,879: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:13,880: updating layer weights
INFO - 2023-11-30 15:57:13,880: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:13.880595', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:13,880: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:13,881: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:13.881016', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:14,387: EPOCH 0: training on 191080 raw words (156162 effective words) took 0.5s, 310941 effective words/s
INFO - 2023-11-30 15:57:14,888: EPOCH 1: training on 191080 raw words (156385 effective words) took 0.5s, 314409 effective words/s
INFO - 2023-11-30 15:57:15,253: EPOCH 2: training on 191080 raw words (156252 effective words) took 0.4s, 432361 effective words/s
INFO - 2023-11-30 15:57:15,598: EPOCH 3: training on 191080 raw words (156251 effective words) took 0.3s, 456260 effective words/s
INFO - 2023-11-30 15:57:15,919: EPOCH 4: training on 191080 raw words (155968 effective words) took 0.3s, 488932 effective words/s
INFO - 2023-11-30 15:57:16,244: EPOCH 5: training on 191080 raw words (156117 effective words) took 0.3s, 483979 effective words/s
INFO - 2023-11-30 15:57:16,572: EPOCH 6: training on 191080 raw words (155960 effective words) took 0.3s, 479537 effective words/s
INFO - 2023-11-30 15:57:16,900: EPOCH 7: training on 191080 raw words (156258 effective words) took 0.3s, 479868 effective words/s
INFO - 2023-11-30 15:57:17,226: EPOCH 8: training on 191080 raw words (156084 effective words) took 0.3s, 482620 effective words/s
INFO - 2023-11-30 15:57:17,553: EPOCH 9: training on 191080 raw words (156255 effective words) took 0.3s, 482045 effective words/s
INFO - 2023-11-30 15:57:17,874: EPOCH 10: training on 191080 raw words (156237 effective words) took 0.3s, 490009 effective words/s
INFO - 2023-11-30 15:57:18,196: EPOCH 11: training on 191080 raw words (156227 effective words) took 0.3s, 488095 effective words/s
INFO - 2023-11-30 15:57:18,511: EPOCH 12: training on 191080 raw words (156355 effective words) took 0.3s, 500121 effective words/s
INFO - 2023-11-30 15:57:18,835: EPOCH 13: training on 191080 raw words (156112 effective words) took 0.3s, 486829 effective words/s
INFO - 2023-11-30 15:57:19,162: EPOCH 14: training on 191080 raw words (156238 effective words) took 0.3s, 481763 effective words/s
INFO - 2023-11-30 15:57:19,489: EPOCH 15: training on 191080 raw words (156143 effective words) took 0.3s, 481603 effective words/s
INFO - 2023-11-30 15:57:19,801: EPOCH 16: training on 191080 raw words (156201 effective words) took 0.3s, 504750 effective words/s
INFO - 2023-11-30 15:57:20,130: EPOCH 17: training on 191080 raw words (156123 effective words) took 0.3s, 478033 effective words/s
INFO - 2023-11-30 15:57:20,469: EPOCH 18: training on 191080 raw words (156489 effective words) took 0.3s, 464683 effective words/s
INFO - 2023-11-30 15:57:20,789: EPOCH 19: training on 191080 raw words (156147 effective words) took 0.3s, 491884 effective words/s
INFO - 2023-11-30 15:57:20,789: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123964 effective words) took 6.9s, 452182 effective words/s', 'datetime': '2023-11-30T15:57:20.789866', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:20,790: collecting all words and their counts
INFO - 2023-11-30 15:57:20,790: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:20,821: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:20,821: Updating model with new vocabulary
INFO - 2023-11-30 15:57:20,835: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:20.835101', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:20,850: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:20,851: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:57:20,851: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156132.70967449987 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:57:20.851609', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:20,877: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:20,877: updating layer weights
INFO - 2023-11-30 15:57:20,877: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:20.877913', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:20,878: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:20,878: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:20.878279', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:21,214: EPOCH 0: training on 191080 raw words (156230 effective words) took 0.3s, 467181 effective words/s
INFO - 2023-11-30 15:57:21,549: EPOCH 1: training on 191080 raw words (156172 effective words) took 0.3s, 470110 effective words/s
INFO - 2023-11-30 15:57:21,940: EPOCH 2: training on 191080 raw words (156179 effective words) took 0.4s, 401974 effective words/s
INFO - 2023-11-30 15:57:22,281: EPOCH 3: training on 191080 raw words (156004 effective words) took 0.3s, 460143 effective words/s
INFO - 2023-11-30 15:57:22,616: EPOCH 4: training on 191080 raw words (156171 effective words) took 0.3s, 469910 effective words/s
INFO - 2023-11-30 15:57:22,969: EPOCH 5: training on 191080 raw words (156225 effective words) took 0.4s, 445918 effective words/s
INFO - 2023-11-30 15:57:23,320: EPOCH 6: training on 191080 raw words (155951 effective words) took 0.3s, 448402 effective words/s
INFO - 2023-11-30 15:57:23,652: EPOCH 7: training on 191080 raw words (156206 effective words) took 0.3s, 473550 effective words/s
INFO - 2023-11-30 15:57:23,987: EPOCH 8: training on 191080 raw words (155897 effective words) took 0.3s, 467684 effective words/s
INFO - 2023-11-30 15:57:24,325: EPOCH 9: training on 191080 raw words (156054 effective words) took 0.3s, 466197 effective words/s
INFO - 2023-11-30 15:57:24,695: EPOCH 10: training on 191080 raw words (155965 effective words) took 0.4s, 424024 effective words/s
INFO - 2023-11-30 15:57:25,040: EPOCH 11: training on 191080 raw words (156062 effective words) took 0.3s, 456036 effective words/s
INFO - 2023-11-30 15:57:25,381: EPOCH 12: training on 191080 raw words (155972 effective words) took 0.3s, 460129 effective words/s
INFO - 2023-11-30 15:57:25,722: EPOCH 13: training on 191080 raw words (156074 effective words) took 0.3s, 461007 effective words/s
INFO - 2023-11-30 15:57:26,054: EPOCH 14: training on 191080 raw words (156066 effective words) took 0.3s, 475473 effective words/s
INFO - 2023-11-30 15:57:26,403: EPOCH 15: training on 191080 raw words (156275 effective words) took 0.3s, 449606 effective words/s
INFO - 2023-11-30 15:57:26,744: EPOCH 16: training on 191080 raw words (156034 effective words) took 0.3s, 461256 effective words/s
INFO - 2023-11-30 15:57:27,089: EPOCH 17: training on 191080 raw words (156067 effective words) took 0.3s, 456906 effective words/s
INFO - 2023-11-30 15:57:27,464: EPOCH 18: training on 191080 raw words (156085 effective words) took 0.4s, 417965 effective words/s
INFO - 2023-11-30 15:57:27,835: EPOCH 19: training on 191080 raw words (156171 effective words) took 0.4s, 424718 effective words/s
INFO - 2023-11-30 15:57:27,835: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121860 effective words) took 7.0s, 448724 effective words/s', 'datetime': '2023-11-30T15:57:27.835607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:27,835: collecting all words and their counts
INFO - 2023-11-30 15:57:27,836: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:27,871: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:27,871: Updating model with new vocabulary
INFO - 2023-11-30 15:57:27,886: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:27.886208', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:27,903: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:27,904: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:57:27,904: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156233.72987351177 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:57:27.904283', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:27,930: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:27,930: updating layer weights
INFO - 2023-11-30 15:57:27,930: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:27.930776', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:27,931: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:27,931: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:27.931245', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:28,269: EPOCH 0: training on 191080 raw words (155909 effective words) took 0.3s, 464417 effective words/s
INFO - 2023-11-30 15:57:28,598: EPOCH 1: training on 191080 raw words (156131 effective words) took 0.3s, 478026 effective words/s
INFO - 2023-11-30 15:57:28,959: EPOCH 2: training on 191080 raw words (156364 effective words) took 0.4s, 436695 effective words/s
INFO - 2023-11-30 15:57:29,334: EPOCH 3: training on 191080 raw words (156207 effective words) took 0.4s, 419575 effective words/s
INFO - 2023-11-30 15:57:29,788: EPOCH 4: training on 191080 raw words (156129 effective words) took 0.5s, 345971 effective words/s
INFO - 2023-11-30 15:57:30,115: EPOCH 5: training on 191080 raw words (156135 effective words) took 0.3s, 481795 effective words/s
INFO - 2023-11-30 15:57:30,506: EPOCH 6: training on 191080 raw words (155888 effective words) took 0.4s, 400601 effective words/s
INFO - 2023-11-30 15:57:30,920: EPOCH 7: training on 191080 raw words (156302 effective words) took 0.4s, 380793 effective words/s
INFO - 2023-11-30 15:57:31,342: EPOCH 8: training on 191080 raw words (156305 effective words) took 0.4s, 372914 effective words/s
INFO - 2023-11-30 15:57:31,770: EPOCH 9: training on 191080 raw words (156073 effective words) took 0.4s, 368595 effective words/s
INFO - 2023-11-30 15:57:32,180: EPOCH 10: training on 191080 raw words (156341 effective words) took 0.4s, 384147 effective words/s
INFO - 2023-11-30 15:57:32,609: EPOCH 11: training on 191080 raw words (156098 effective words) took 0.4s, 366186 effective words/s
INFO - 2023-11-30 15:57:33,044: EPOCH 12: training on 191080 raw words (156253 effective words) took 0.4s, 361621 effective words/s
INFO - 2023-11-30 15:57:33,495: EPOCH 13: training on 191080 raw words (156111 effective words) took 0.4s, 348832 effective words/s
INFO - 2023-11-30 15:57:33,916: EPOCH 14: training on 191080 raw words (156343 effective words) took 0.4s, 374382 effective words/s
INFO - 2023-11-30 15:57:34,246: EPOCH 15: training on 191080 raw words (156235 effective words) took 0.3s, 478279 effective words/s
INFO - 2023-11-30 15:57:34,592: EPOCH 16: training on 191080 raw words (156196 effective words) took 0.3s, 456006 effective words/s
INFO - 2023-11-30 15:57:34,927: EPOCH 17: training on 191080 raw words (156338 effective words) took 0.3s, 469423 effective words/s
INFO - 2023-11-30 15:57:35,446: EPOCH 18: training on 191080 raw words (156282 effective words) took 0.5s, 302519 effective words/s
INFO - 2023-11-30 15:57:35,902: EPOCH 19: training on 191080 raw words (156291 effective words) took 0.5s, 344894 effective words/s
INFO - 2023-11-30 15:57:35,904: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123931 effective words) took 8.0s, 391860 effective words/s', 'datetime': '2023-11-30T15:57:35.903429', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:35,904: collecting all words and their counts
INFO - 2023-11-30 15:57:35,904: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:35,951: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:35,952: Updating model with new vocabulary
INFO - 2023-11-30 15:57:35,969: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:35.969316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:35,998: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:35,998: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:57:35,998: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 155916.2718207253 word corpus (81.6%% of prior 191080)', 'datetime': '2023-11-30T15:57:35.998607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:36,034: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:36,035: updating layer weights
INFO - 2023-11-30 15:57:36,035: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:36.035611', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:36,035: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:36,035: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:36.035859', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:36,652: EPOCH 0: training on 191080 raw words (155892 effective words) took 0.6s, 254290 effective words/s
INFO - 2023-11-30 15:57:37,178: EPOCH 1: training on 191080 raw words (155826 effective words) took 0.5s, 298761 effective words/s
INFO - 2023-11-30 15:57:37,704: EPOCH 2: training on 191080 raw words (155830 effective words) took 0.5s, 297931 effective words/s
INFO - 2023-11-30 15:57:38,297: EPOCH 3: training on 191080 raw words (155779 effective words) took 0.6s, 264921 effective words/s
INFO - 2023-11-30 15:57:38,841: EPOCH 4: training on 191080 raw words (155974 effective words) took 0.5s, 288588 effective words/s
INFO - 2023-11-30 15:57:39,309: EPOCH 5: training on 191080 raw words (155944 effective words) took 0.5s, 335783 effective words/s
INFO - 2023-11-30 15:57:39,669: EPOCH 6: training on 191080 raw words (155746 effective words) took 0.4s, 434954 effective words/s
INFO - 2023-11-30 15:57:40,032: EPOCH 7: training on 191080 raw words (155808 effective words) took 0.4s, 432653 effective words/s
INFO - 2023-11-30 15:57:40,402: EPOCH 8: training on 191080 raw words (156013 effective words) took 0.4s, 425230 effective words/s
INFO - 2023-11-30 15:57:40,750: EPOCH 9: training on 191080 raw words (155928 effective words) took 0.3s, 451486 effective words/s
INFO - 2023-11-30 15:57:41,099: EPOCH 10: training on 191080 raw words (155872 effective words) took 0.3s, 450666 effective words/s
INFO - 2023-11-30 15:57:41,501: EPOCH 11: training on 191080 raw words (155904 effective words) took 0.4s, 390235 effective words/s
INFO - 2023-11-30 15:57:41,858: EPOCH 12: training on 191080 raw words (155749 effective words) took 0.4s, 440627 effective words/s
INFO - 2023-11-30 15:57:42,209: EPOCH 13: training on 191080 raw words (155981 effective words) took 0.3s, 447088 effective words/s
INFO - 2023-11-30 15:57:42,560: EPOCH 14: training on 191080 raw words (155844 effective words) took 0.3s, 446218 effective words/s
INFO - 2023-11-30 15:57:42,926: EPOCH 15: training on 191080 raw words (155827 effective words) took 0.4s, 429531 effective words/s
INFO - 2023-11-30 15:57:43,280: EPOCH 16: training on 191080 raw words (155948 effective words) took 0.4s, 442734 effective words/s
INFO - 2023-11-30 15:57:43,631: EPOCH 17: training on 191080 raw words (155925 effective words) took 0.3s, 447795 effective words/s
INFO - 2023-11-30 15:57:43,985: EPOCH 18: training on 191080 raw words (155761 effective words) took 0.4s, 443642 effective words/s
INFO - 2023-11-30 15:57:44,344: EPOCH 19: training on 191080 raw words (155894 effective words) took 0.4s, 437449 effective words/s
INFO - 2023-11-30 15:57:44,344: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3117445 effective words) took 8.3s, 375218 effective words/s', 'datetime': '2023-11-30T15:57:44.344328', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:44,344: collecting all words and their counts
INFO - 2023-11-30 15:57:44,344: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:44,376: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:44,377: Updating model with new vocabulary
INFO - 2023-11-30 15:57:44,390: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:44.390469', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:44,407: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:44,407: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:57:44,408: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156181.7276112947 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:57:44.408276', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:44,432: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:44,432: updating layer weights
INFO - 2023-11-30 15:57:44,432: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:44.432924', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:44,433: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:44,433: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:44.433393', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:44,776: EPOCH 0: training on 191080 raw words (156169 effective words) took 0.3s, 459309 effective words/s
INFO - 2023-11-30 15:57:45,112: EPOCH 1: training on 191080 raw words (156216 effective words) took 0.3s, 468135 effective words/s
INFO - 2023-11-30 15:57:45,444: EPOCH 2: training on 191080 raw words (155933 effective words) took 0.3s, 473209 effective words/s
INFO - 2023-11-30 15:57:45,779: EPOCH 3: training on 191080 raw words (155990 effective words) took 0.3s, 469193 effective words/s
INFO - 2023-11-30 15:57:46,167: EPOCH 4: training on 191080 raw words (156181 effective words) took 0.4s, 405570 effective words/s
INFO - 2023-11-30 15:57:46,524: EPOCH 5: training on 191080 raw words (156298 effective words) took 0.4s, 440910 effective words/s
INFO - 2023-11-30 15:57:46,878: EPOCH 6: training on 191080 raw words (156046 effective words) took 0.4s, 442919 effective words/s
INFO - 2023-11-30 15:57:47,230: EPOCH 7: training on 191080 raw words (156197 effective words) took 0.3s, 447835 effective words/s
INFO - 2023-11-30 15:57:47,601: EPOCH 8: training on 191080 raw words (156386 effective words) took 0.4s, 426063 effective words/s
INFO - 2023-11-30 15:57:47,951: EPOCH 9: training on 191080 raw words (156046 effective words) took 0.3s, 449887 effective words/s
INFO - 2023-11-30 15:57:48,309: EPOCH 10: training on 191080 raw words (156151 effective words) took 0.4s, 439054 effective words/s
INFO - 2023-11-30 15:57:48,651: EPOCH 11: training on 191080 raw words (156149 effective words) took 0.3s, 460163 effective words/s
INFO - 2023-11-30 15:57:48,997: EPOCH 12: training on 191080 raw words (156138 effective words) took 0.3s, 454259 effective words/s
INFO - 2023-11-30 15:57:49,331: EPOCH 13: training on 191080 raw words (156291 effective words) took 0.3s, 471139 effective words/s
INFO - 2023-11-30 15:57:49,667: EPOCH 14: training on 191080 raw words (156237 effective words) took 0.3s, 469095 effective words/s
INFO - 2023-11-30 15:57:50,013: EPOCH 15: training on 191080 raw words (156173 effective words) took 0.3s, 454201 effective words/s
INFO - 2023-11-30 15:57:50,351: EPOCH 16: training on 191080 raw words (155968 effective words) took 0.3s, 465160 effective words/s
INFO - 2023-11-30 15:57:50,698: EPOCH 17: training on 191080 raw words (156047 effective words) took 0.3s, 453903 effective words/s
INFO - 2023-11-30 15:57:51,040: EPOCH 18: training on 191080 raw words (156260 effective words) took 0.3s, 460018 effective words/s
INFO - 2023-11-30 15:57:51,385: EPOCH 19: training on 191080 raw words (156311 effective words) took 0.3s, 457040 effective words/s
INFO - 2023-11-30 15:57:51,385: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123187 effective words) took 7.0s, 449266 effective words/s', 'datetime': '2023-11-30T15:57:51.385401', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:51,385: collecting all words and their counts
INFO - 2023-11-30 15:57:51,385: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:57:51,419: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:57:51,419: Updating model with new vocabulary
INFO - 2023-11-30 15:57:51,434: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:57:51.434664', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:51,452: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:57:51,452: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:57:51,452: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156424.13405304548 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:57:51.452616', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:57:51,477: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:57:51,477: updating layer weights
INFO - 2023-11-30 15:57:51,478: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:57:51.478591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:57:51,478: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:57:51,479: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:57:51.478999', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:57:51,847: EPOCH 0: training on 191080 raw words (156345 effective words) took 0.4s, 428129 effective words/s
INFO - 2023-11-30 15:57:52,278: EPOCH 1: training on 191080 raw words (156419 effective words) took 0.4s, 365879 effective words/s
INFO - 2023-11-30 15:57:52,639: EPOCH 2: training on 191080 raw words (156382 effective words) took 0.4s, 436188 effective words/s
INFO - 2023-11-30 15:57:53,023: EPOCH 3: training on 191080 raw words (156429 effective words) took 0.4s, 409952 effective words/s
INFO - 2023-11-30 15:57:53,434: EPOCH 4: training on 191080 raw words (156397 effective words) took 0.4s, 383631 effective words/s
INFO - 2023-11-30 15:57:53,823: EPOCH 5: training on 191080 raw words (156408 effective words) took 0.4s, 405252 effective words/s
INFO - 2023-11-30 15:57:54,191: EPOCH 6: training on 191080 raw words (156379 effective words) took 0.4s, 428233 effective words/s
INFO - 2023-11-30 15:57:54,618: EPOCH 7: training on 191080 raw words (156348 effective words) took 0.4s, 368421 effective words/s
INFO - 2023-11-30 15:57:55,090: EPOCH 8: training on 191080 raw words (156452 effective words) took 0.5s, 333570 effective words/s
INFO - 2023-11-30 15:57:55,561: EPOCH 9: training on 191080 raw words (156286 effective words) took 0.5s, 334063 effective words/s
INFO - 2023-11-30 15:57:56,030: EPOCH 10: training on 191080 raw words (156384 effective words) took 0.5s, 335789 effective words/s
INFO - 2023-11-30 15:57:56,475: EPOCH 11: training on 191080 raw words (156489 effective words) took 0.4s, 354383 effective words/s
INFO - 2023-11-30 15:57:56,932: EPOCH 12: training on 191080 raw words (156534 effective words) took 0.5s, 344624 effective words/s
INFO - 2023-11-30 15:57:57,421: EPOCH 13: training on 191080 raw words (156566 effective words) took 0.5s, 322746 effective words/s
INFO - 2023-11-30 15:57:57,918: EPOCH 14: training on 191080 raw words (156491 effective words) took 0.5s, 317205 effective words/s
INFO - 2023-11-30 15:57:58,428: EPOCH 15: training on 191080 raw words (156492 effective words) took 0.5s, 308955 effective words/s
INFO - 2023-11-30 15:57:58,910: EPOCH 16: training on 191080 raw words (156471 effective words) took 0.5s, 326617 effective words/s
INFO - 2023-11-30 15:57:59,411: EPOCH 17: training on 191080 raw words (156446 effective words) took 0.5s, 314452 effective words/s
INFO - 2023-11-30 15:57:59,906: EPOCH 18: training on 191080 raw words (156538 effective words) took 0.5s, 318741 effective words/s
INFO - 2023-11-30 15:58:00,421: EPOCH 19: training on 191080 raw words (156364 effective words) took 0.5s, 305805 effective words/s
INFO - 2023-11-30 15:58:00,421: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128620 effective words) took 8.9s, 349870 effective words/s', 'datetime': '2023-11-30T15:58:00.421425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:00,421: collecting all words and their counts
INFO - 2023-11-30 15:58:00,422: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:00,474: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:00,475: Updating model with new vocabulary
INFO - 2023-11-30 15:58:00,501: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:00.501818', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:00,527: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:00,527: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:58:00,528: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156274.5505238074 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:58:00.528021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:00,570: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:00,570: updating layer weights
INFO - 2023-11-30 15:58:00,571: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:00.571191', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:00,571: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:00,571: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:00.571616', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:01,114: EPOCH 0: training on 191080 raw words (156201 effective words) took 0.5s, 289810 effective words/s
INFO - 2023-11-30 15:58:01,615: EPOCH 1: training on 191080 raw words (156311 effective words) took 0.5s, 314524 effective words/s
INFO - 2023-11-30 15:58:02,183: EPOCH 2: training on 191080 raw words (156353 effective words) took 0.6s, 277222 effective words/s
INFO - 2023-11-30 15:58:02,720: EPOCH 3: training on 191080 raw words (156404 effective words) took 0.5s, 307316 effective words/s
INFO - 2023-11-30 15:58:03,234: EPOCH 4: training on 191080 raw words (156265 effective words) took 0.5s, 306491 effective words/s
INFO - 2023-11-30 15:58:03,830: EPOCH 5: training on 191080 raw words (156322 effective words) took 0.6s, 264006 effective words/s
INFO - 2023-11-30 15:58:04,275: EPOCH 6: training on 191080 raw words (156300 effective words) took 0.4s, 354647 effective words/s
INFO - 2023-11-30 15:58:04,866: EPOCH 7: training on 191080 raw words (156275 effective words) took 0.6s, 266736 effective words/s
INFO - 2023-11-30 15:58:05,358: EPOCH 8: training on 191080 raw words (156372 effective words) took 0.5s, 321301 effective words/s
INFO - 2023-11-30 15:58:05,804: EPOCH 9: training on 191080 raw words (156211 effective words) took 0.4s, 353599 effective words/s
INFO - 2023-11-30 15:58:06,292: EPOCH 10: training on 191080 raw words (156217 effective words) took 0.5s, 322104 effective words/s
INFO - 2023-11-30 15:58:06,663: EPOCH 11: training on 191080 raw words (156152 effective words) took 0.4s, 424507 effective words/s
INFO - 2023-11-30 15:58:07,045: EPOCH 12: training on 191080 raw words (156241 effective words) took 0.4s, 411867 effective words/s
INFO - 2023-11-30 15:58:07,418: EPOCH 13: training on 191080 raw words (156264 effective words) took 0.4s, 423085 effective words/s
INFO - 2023-11-30 15:58:07,787: EPOCH 14: training on 191080 raw words (156195 effective words) took 0.4s, 427617 effective words/s
INFO - 2023-11-30 15:58:08,150: EPOCH 15: training on 191080 raw words (156292 effective words) took 0.4s, 433822 effective words/s
INFO - 2023-11-30 15:58:08,535: EPOCH 16: training on 191080 raw words (156240 effective words) took 0.4s, 408597 effective words/s
INFO - 2023-11-30 15:58:08,929: EPOCH 17: training on 191080 raw words (156140 effective words) took 0.4s, 399510 effective words/s
INFO - 2023-11-30 15:58:09,296: EPOCH 18: training on 191080 raw words (156295 effective words) took 0.4s, 429783 effective words/s
INFO - 2023-11-30 15:58:09,627: EPOCH 19: training on 191080 raw words (156469 effective words) took 0.3s, 475169 effective words/s
INFO - 2023-11-30 15:58:09,628: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125519 effective words) took 9.1s, 345119 effective words/s', 'datetime': '2023-11-30T15:58:09.628170', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:09,628: collecting all words and their counts
INFO - 2023-11-30 15:58:09,628: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:09,658: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:09,659: Updating model with new vocabulary
INFO - 2023-11-30 15:58:09,672: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:09.672850', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:09,688: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:09,689: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:58:09,689: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156445.40190491886 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:58:09.689173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:09,712: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:09,712: updating layer weights
INFO - 2023-11-30 15:58:09,712: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:09.712640', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:09,712: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:09,712: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:09.712952', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:10,051: EPOCH 0: training on 191080 raw words (156524 effective words) took 0.3s, 493908 effective words/s
INFO - 2023-11-30 15:58:10,414: EPOCH 1: training on 191080 raw words (156492 effective words) took 0.4s, 435885 effective words/s
INFO - 2023-11-30 15:58:10,783: EPOCH 2: training on 191080 raw words (156420 effective words) took 0.4s, 429101 effective words/s
INFO - 2023-11-30 15:58:11,149: EPOCH 3: training on 191080 raw words (156360 effective words) took 0.4s, 430405 effective words/s
INFO - 2023-11-30 15:58:11,518: EPOCH 4: training on 191080 raw words (156474 effective words) took 0.4s, 427612 effective words/s
INFO - 2023-11-30 15:58:11,854: EPOCH 5: training on 191080 raw words (156523 effective words) took 0.3s, 469387 effective words/s
INFO - 2023-11-30 15:58:12,207: EPOCH 6: training on 191080 raw words (156399 effective words) took 0.4s, 445714 effective words/s
INFO - 2023-11-30 15:58:12,551: EPOCH 7: training on 191080 raw words (156453 effective words) took 0.3s, 458718 effective words/s
INFO - 2023-11-30 15:58:12,884: EPOCH 8: training on 191080 raw words (156317 effective words) took 0.3s, 472769 effective words/s
INFO - 2023-11-30 15:58:13,226: EPOCH 9: training on 191080 raw words (156479 effective words) took 0.3s, 461197 effective words/s
INFO - 2023-11-30 15:58:13,579: EPOCH 10: training on 191080 raw words (156558 effective words) took 0.4s, 445416 effective words/s
INFO - 2023-11-30 15:58:13,923: EPOCH 11: training on 191080 raw words (156368 effective words) took 0.3s, 459221 effective words/s
INFO - 2023-11-30 15:58:14,258: EPOCH 12: training on 191080 raw words (156394 effective words) took 0.3s, 469781 effective words/s
INFO - 2023-11-30 15:58:14,633: EPOCH 13: training on 191080 raw words (156399 effective words) took 0.4s, 419644 effective words/s
INFO - 2023-11-30 15:58:14,976: EPOCH 14: training on 191080 raw words (156482 effective words) took 0.3s, 460522 effective words/s
INFO - 2023-11-30 15:58:15,318: EPOCH 15: training on 191080 raw words (156606 effective words) took 0.3s, 460440 effective words/s
INFO - 2023-11-30 15:58:15,651: EPOCH 16: training on 191080 raw words (156593 effective words) took 0.3s, 474227 effective words/s
INFO - 2023-11-30 15:58:15,998: EPOCH 17: training on 191080 raw words (156493 effective words) took 0.3s, 455006 effective words/s
INFO - 2023-11-30 15:58:16,340: EPOCH 18: training on 191080 raw words (156610 effective words) took 0.3s, 461047 effective words/s
INFO - 2023-11-30 15:58:16,691: EPOCH 19: training on 191080 raw words (156326 effective words) took 0.3s, 448351 effective words/s
INFO - 2023-11-30 15:58:16,692: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3129270 effective words) took 7.0s, 448385 effective words/s', 'datetime': '2023-11-30T15:58:16.692074', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:16,692: collecting all words and their counts
INFO - 2023-11-30 15:58:16,692: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:16,723: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:16,723: Updating model with new vocabulary
INFO - 2023-11-30 15:58:16,736: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:16.736832', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:16,777: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:16,778: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:58:16,778: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156055.06770644934 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:58:16.778344', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:16,802: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:16,802: updating layer weights
INFO - 2023-11-30 15:58:16,802: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:16.802569', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:16,802: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:16,802: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:16.802776', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:17,148: EPOCH 0: training on 191080 raw words (155926 effective words) took 0.3s, 454175 effective words/s
INFO - 2023-11-30 15:58:17,469: EPOCH 1: training on 191080 raw words (155910 effective words) took 0.3s, 490066 effective words/s
INFO - 2023-11-30 15:58:17,828: EPOCH 2: training on 191080 raw words (155949 effective words) took 0.4s, 437656 effective words/s
INFO - 2023-11-30 15:58:18,181: EPOCH 3: training on 191080 raw words (156056 effective words) took 0.4s, 445155 effective words/s
INFO - 2023-11-30 15:58:18,554: EPOCH 4: training on 191080 raw words (156021 effective words) took 0.4s, 422104 effective words/s
INFO - 2023-11-30 15:58:18,894: EPOCH 5: training on 191080 raw words (155930 effective words) took 0.3s, 463242 effective words/s
INFO - 2023-11-30 15:58:19,301: EPOCH 6: training on 191080 raw words (155943 effective words) took 0.4s, 386565 effective words/s
INFO - 2023-11-30 15:58:19,711: EPOCH 7: training on 191080 raw words (156093 effective words) took 0.4s, 383956 effective words/s
INFO - 2023-11-30 15:58:20,167: EPOCH 8: training on 191080 raw words (156149 effective words) took 0.5s, 345265 effective words/s
INFO - 2023-11-30 15:58:20,590: EPOCH 9: training on 191080 raw words (155974 effective words) took 0.4s, 371874 effective words/s
INFO - 2023-11-30 15:58:20,989: EPOCH 10: training on 191080 raw words (155989 effective words) took 0.4s, 394344 effective words/s
INFO - 2023-11-30 15:58:21,440: EPOCH 11: training on 191080 raw words (156013 effective words) took 0.4s, 348176 effective words/s
INFO - 2023-11-30 15:58:21,921: EPOCH 12: training on 191080 raw words (156088 effective words) took 0.5s, 326730 effective words/s
INFO - 2023-11-30 15:58:22,391: EPOCH 13: training on 191080 raw words (155882 effective words) took 0.5s, 333614 effective words/s
INFO - 2023-11-30 15:58:22,900: EPOCH 14: training on 191080 raw words (156084 effective words) took 0.5s, 308727 effective words/s
INFO - 2023-11-30 15:58:23,376: EPOCH 15: training on 191080 raw words (155979 effective words) took 0.5s, 330193 effective words/s
INFO - 2023-11-30 15:58:23,786: EPOCH 16: training on 191080 raw words (156152 effective words) took 0.4s, 383367 effective words/s
INFO - 2023-11-30 15:58:24,198: EPOCH 17: training on 191080 raw words (156091 effective words) took 0.4s, 381777 effective words/s
INFO - 2023-11-30 15:58:24,615: EPOCH 18: training on 191080 raw words (156027 effective words) took 0.4s, 377561 effective words/s
INFO - 2023-11-30 15:58:25,040: EPOCH 19: training on 191080 raw words (156108 effective words) took 0.4s, 370245 effective words/s
INFO - 2023-11-30 15:58:25,040: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3120364 effective words) took 8.2s, 378797 effective words/s', 'datetime': '2023-11-30T15:58:25.040447', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:25,040: collecting all words and their counts
INFO - 2023-11-30 15:58:25,041: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:25,080: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:25,080: Updating model with new vocabulary
INFO - 2023-11-30 15:58:25,098: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:25.098112', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:25,120: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:25,120: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:58:25,121: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 155802.69695029536 word corpus (81.5%% of prior 191080)', 'datetime': '2023-11-30T15:58:25.121145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:25,154: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:25,155: updating layer weights
INFO - 2023-11-30 15:58:25,155: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:25.155579', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:25,155: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:25,155: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:25.155943', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:25,615: EPOCH 0: training on 191080 raw words (155830 effective words) took 0.5s, 341297 effective words/s
INFO - 2023-11-30 15:58:26,067: EPOCH 1: training on 191080 raw words (155509 effective words) took 0.4s, 347061 effective words/s
INFO - 2023-11-30 15:58:26,526: EPOCH 2: training on 191080 raw words (155751 effective words) took 0.5s, 341694 effective words/s
INFO - 2023-11-30 15:58:26,971: EPOCH 3: training on 191080 raw words (155623 effective words) took 0.4s, 352063 effective words/s
INFO - 2023-11-30 15:58:27,421: EPOCH 4: training on 191080 raw words (155906 effective words) took 0.4s, 349332 effective words/s
INFO - 2023-11-30 15:58:27,780: EPOCH 5: training on 191080 raw words (155842 effective words) took 0.4s, 437653 effective words/s
INFO - 2023-11-30 15:58:28,110: EPOCH 6: training on 191080 raw words (155585 effective words) took 0.3s, 474285 effective words/s
INFO - 2023-11-30 15:58:28,450: EPOCH 7: training on 191080 raw words (155735 effective words) took 0.3s, 461842 effective words/s
INFO - 2023-11-30 15:58:28,787: EPOCH 8: training on 191080 raw words (155879 effective words) took 0.3s, 466372 effective words/s
INFO - 2023-11-30 15:58:29,129: EPOCH 9: training on 191080 raw words (156066 effective words) took 0.3s, 459014 effective words/s
INFO - 2023-11-30 15:58:29,463: EPOCH 10: training on 191080 raw words (155638 effective words) took 0.3s, 469956 effective words/s
INFO - 2023-11-30 15:58:29,793: EPOCH 11: training on 191080 raw words (155849 effective words) took 0.3s, 475996 effective words/s
INFO - 2023-11-30 15:58:30,125: EPOCH 12: training on 191080 raw words (155849 effective words) took 0.3s, 471183 effective words/s
INFO - 2023-11-30 15:58:30,453: EPOCH 13: training on 191080 raw words (155641 effective words) took 0.3s, 477379 effective words/s
INFO - 2023-11-30 15:58:30,785: EPOCH 14: training on 191080 raw words (155908 effective words) took 0.3s, 473996 effective words/s
INFO - 2023-11-30 15:58:31,118: EPOCH 15: training on 191080 raw words (155992 effective words) took 0.3s, 471154 effective words/s
INFO - 2023-11-30 15:58:31,457: EPOCH 16: training on 191080 raw words (156031 effective words) took 0.3s, 463976 effective words/s
INFO - 2023-11-30 15:58:31,793: EPOCH 17: training on 191080 raw words (155848 effective words) took 0.3s, 467164 effective words/s
INFO - 2023-11-30 15:58:32,130: EPOCH 18: training on 191080 raw words (155788 effective words) took 0.3s, 465034 effective words/s
INFO - 2023-11-30 15:58:32,459: EPOCH 19: training on 191080 raw words (155825 effective words) took 0.3s, 477357 effective words/s
INFO - 2023-11-30 15:58:32,459: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3116095 effective words) took 7.3s, 426656 effective words/s', 'datetime': '2023-11-30T15:58:32.459638', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:32,459: collecting all words and their counts
INFO - 2023-11-30 15:58:32,460: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:32,489: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:32,489: Updating model with new vocabulary
INFO - 2023-11-30 15:58:32,502: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:32.501973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:32,517: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:32,518: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:58:32,518: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156124.5333523475 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:58:32.518169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:32,542: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:32,542: updating layer weights
INFO - 2023-11-30 15:58:32,543: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:32.543058', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:32,543: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:32,543: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:32.543337', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:32,857: EPOCH 0: training on 191080 raw words (156033 effective words) took 0.3s, 499780 effective words/s
INFO - 2023-11-30 15:58:33,178: EPOCH 1: training on 191080 raw words (156214 effective words) took 0.3s, 490432 effective words/s
INFO - 2023-11-30 15:58:33,495: EPOCH 2: training on 191080 raw words (156136 effective words) took 0.3s, 498217 effective words/s
INFO - 2023-11-30 15:58:33,815: EPOCH 3: training on 191080 raw words (156057 effective words) took 0.3s, 496882 effective words/s
INFO - 2023-11-30 15:58:34,133: EPOCH 4: training on 191080 raw words (156195 effective words) took 0.3s, 495781 effective words/s
INFO - 2023-11-30 15:58:34,449: EPOCH 5: training on 191080 raw words (156177 effective words) took 0.3s, 497749 effective words/s
INFO - 2023-11-30 15:58:34,773: EPOCH 6: training on 191080 raw words (156094 effective words) took 0.3s, 486742 effective words/s
INFO - 2023-11-30 15:58:35,094: EPOCH 7: training on 191080 raw words (155877 effective words) took 0.3s, 489867 effective words/s
INFO - 2023-11-30 15:58:35,463: EPOCH 8: training on 191080 raw words (155921 effective words) took 0.4s, 424539 effective words/s
INFO - 2023-11-30 15:58:35,836: EPOCH 9: training on 191080 raw words (156137 effective words) took 0.4s, 422677 effective words/s
INFO - 2023-11-30 15:58:36,218: EPOCH 10: training on 191080 raw words (156233 effective words) took 0.4s, 411902 effective words/s
INFO - 2023-11-30 15:58:36,558: EPOCH 11: training on 191080 raw words (156101 effective words) took 0.3s, 463590 effective words/s
INFO - 2023-11-30 15:58:36,875: EPOCH 12: training on 191080 raw words (156060 effective words) took 0.3s, 495276 effective words/s
INFO - 2023-11-30 15:58:37,193: EPOCH 13: training on 191080 raw words (156082 effective words) took 0.3s, 494597 effective words/s
INFO - 2023-11-30 15:58:37,523: EPOCH 14: training on 191080 raw words (156178 effective words) took 0.3s, 476694 effective words/s
INFO - 2023-11-30 15:58:37,837: EPOCH 15: training on 191080 raw words (156164 effective words) took 0.3s, 501026 effective words/s
INFO - 2023-11-30 15:58:38,157: EPOCH 16: training on 191080 raw words (155944 effective words) took 0.3s, 521386 effective words/s
INFO - 2023-11-30 15:58:38,477: EPOCH 17: training on 191080 raw words (156066 effective words) took 0.3s, 492020 effective words/s
INFO - 2023-11-30 15:58:38,792: EPOCH 18: training on 191080 raw words (156113 effective words) took 0.3s, 500765 effective words/s
INFO - 2023-11-30 15:58:39,110: EPOCH 19: training on 191080 raw words (155949 effective words) took 0.3s, 493662 effective words/s
INFO - 2023-11-30 15:58:39,111: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121731 effective words) took 6.6s, 475315 effective words/s', 'datetime': '2023-11-30T15:58:39.111202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:39,111: collecting all words and their counts
INFO - 2023-11-30 15:58:39,111: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:39,141: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:39,141: Updating model with new vocabulary
INFO - 2023-11-30 15:58:39,154: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:39.154233', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:39,170: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:39,171: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:58:39,171: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156179.7948577388 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:58:39.171332', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:39,196: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:39,196: updating layer weights
INFO - 2023-11-30 15:58:39,196: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:39.196871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:39,197: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:39,197: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:39.197158', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:39,533: EPOCH 0: training on 191080 raw words (156196 effective words) took 0.3s, 467845 effective words/s
INFO - 2023-11-30 15:58:39,863: EPOCH 1: training on 191080 raw words (156045 effective words) took 0.3s, 476452 effective words/s
INFO - 2023-11-30 15:58:40,259: EPOCH 2: training on 191080 raw words (156332 effective words) took 0.4s, 398391 effective words/s
INFO - 2023-11-30 15:58:40,596: EPOCH 3: training on 191080 raw words (156289 effective words) took 0.3s, 466774 effective words/s
INFO - 2023-11-30 15:58:40,931: EPOCH 4: training on 191080 raw words (156294 effective words) took 0.3s, 469286 effective words/s
INFO - 2023-11-30 15:58:41,267: EPOCH 5: training on 191080 raw words (156175 effective words) took 0.3s, 469945 effective words/s
INFO - 2023-11-30 15:58:41,605: EPOCH 6: training on 191080 raw words (156181 effective words) took 0.3s, 464675 effective words/s
INFO - 2023-11-30 15:58:41,942: EPOCH 7: training on 191080 raw words (156184 effective words) took 0.3s, 467227 effective words/s
INFO - 2023-11-30 15:58:42,283: EPOCH 8: training on 191080 raw words (156302 effective words) took 0.3s, 462247 effective words/s
INFO - 2023-11-30 15:58:42,624: EPOCH 9: training on 191080 raw words (156155 effective words) took 0.3s, 460462 effective words/s
INFO - 2023-11-30 15:58:42,969: EPOCH 10: training on 191080 raw words (156073 effective words) took 0.3s, 482063 effective words/s
INFO - 2023-11-30 15:58:43,317: EPOCH 11: training on 191080 raw words (156176 effective words) took 0.3s, 451360 effective words/s
INFO - 2023-11-30 15:58:43,655: EPOCH 12: training on 191080 raw words (156274 effective words) took 0.3s, 465913 effective words/s
INFO - 2023-11-30 15:58:43,995: EPOCH 13: training on 191080 raw words (156109 effective words) took 0.3s, 462957 effective words/s
INFO - 2023-11-30 15:58:44,334: EPOCH 14: training on 191080 raw words (156189 effective words) took 0.3s, 464352 effective words/s
INFO - 2023-11-30 15:58:44,680: EPOCH 15: training on 191080 raw words (156125 effective words) took 0.3s, 454887 effective words/s
INFO - 2023-11-30 15:58:45,016: EPOCH 16: training on 191080 raw words (156186 effective words) took 0.3s, 468037 effective words/s
INFO - 2023-11-30 15:58:45,355: EPOCH 17: training on 191080 raw words (156223 effective words) took 0.3s, 464406 effective words/s
INFO - 2023-11-30 15:58:45,699: EPOCH 18: training on 191080 raw words (156010 effective words) took 0.3s, 456489 effective words/s
INFO - 2023-11-30 15:58:46,168: EPOCH 19: training on 191080 raw words (156006 effective words) took 0.5s, 335278 effective words/s
INFO - 2023-11-30 15:58:46,168: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123524 effective words) took 7.0s, 448036 effective words/s', 'datetime': '2023-11-30T15:58:46.168886', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:46,169: collecting all words and their counts
INFO - 2023-11-30 15:58:46,169: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:46,219: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:46,219: Updating model with new vocabulary
INFO - 2023-11-30 15:58:46,237: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:46.237798', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:46,260: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:46,261: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:58:46,261: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156376.44735035035 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:58:46.261212', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:46,296: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:46,296: updating layer weights
INFO - 2023-11-30 15:58:46,296: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:46.296846', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:46,297: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:46,297: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:46.297340', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:46,764: EPOCH 0: training on 191080 raw words (156324 effective words) took 0.5s, 337338 effective words/s
INFO - 2023-11-30 15:58:47,230: EPOCH 1: training on 191080 raw words (156414 effective words) took 0.5s, 338339 effective words/s
INFO - 2023-11-30 15:58:47,675: EPOCH 2: training on 191080 raw words (156408 effective words) took 0.4s, 353694 effective words/s
INFO - 2023-11-30 15:58:48,168: EPOCH 3: training on 191080 raw words (156206 effective words) took 0.5s, 319375 effective words/s
INFO - 2023-11-30 15:58:48,633: EPOCH 4: training on 191080 raw words (156420 effective words) took 0.5s, 339136 effective words/s
INFO - 2023-11-30 15:58:49,167: EPOCH 5: training on 191080 raw words (156496 effective words) took 0.5s, 294599 effective words/s
INFO - 2023-11-30 15:58:49,779: EPOCH 6: training on 191080 raw words (156367 effective words) took 0.6s, 257830 effective words/s
INFO - 2023-11-30 15:58:50,312: EPOCH 7: training on 191080 raw words (156437 effective words) took 0.5s, 296119 effective words/s
INFO - 2023-11-30 15:58:50,816: EPOCH 8: training on 191080 raw words (156417 effective words) took 0.5s, 312711 effective words/s
INFO - 2023-11-30 15:58:51,355: EPOCH 9: training on 191080 raw words (156285 effective words) took 0.5s, 292022 effective words/s
INFO - 2023-11-30 15:58:51,868: EPOCH 10: training on 191080 raw words (156467 effective words) took 0.5s, 307863 effective words/s
INFO - 2023-11-30 15:58:52,334: EPOCH 11: training on 191080 raw words (156398 effective words) took 0.5s, 337943 effective words/s
INFO - 2023-11-30 15:58:52,819: EPOCH 12: training on 191080 raw words (156505 effective words) took 0.5s, 324426 effective words/s
INFO - 2023-11-30 15:58:53,265: EPOCH 13: training on 191080 raw words (156303 effective words) took 0.4s, 353388 effective words/s
INFO - 2023-11-30 15:58:53,706: EPOCH 14: training on 191080 raw words (156309 effective words) took 0.4s, 357468 effective words/s
INFO - 2023-11-30 15:58:54,146: EPOCH 15: training on 191080 raw words (156360 effective words) took 0.4s, 357399 effective words/s
INFO - 2023-11-30 15:58:54,590: EPOCH 16: training on 191080 raw words (156476 effective words) took 0.4s, 355238 effective words/s
INFO - 2023-11-30 15:58:55,023: EPOCH 17: training on 191080 raw words (156412 effective words) took 0.4s, 363353 effective words/s
INFO - 2023-11-30 15:58:55,454: EPOCH 18: training on 191080 raw words (156278 effective words) took 0.4s, 365767 effective words/s
INFO - 2023-11-30 15:58:55,885: EPOCH 19: training on 191080 raw words (156396 effective words) took 0.4s, 365364 effective words/s
INFO - 2023-11-30 15:58:55,885: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127678 effective words) took 9.6s, 326208 effective words/s', 'datetime': '2023-11-30T15:58:55.885532', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:55,885: collecting all words and their counts
INFO - 2023-11-30 15:58:55,886: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:58:55,931: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:58:55,931: Updating model with new vocabulary
INFO - 2023-11-30 15:58:55,948: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:58:55.948473', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:55,970: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:58:55,970: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:58:55,970: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156299.1940368326 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:58:55.970701', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:58:56,004: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:58:56,004: updating layer weights
INFO - 2023-11-30 15:58:56,005: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:58:56.005052', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:58:56,005: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:58:56,005: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:58:56.005400', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:58:56,454: EPOCH 0: training on 191080 raw words (156543 effective words) took 0.4s, 351795 effective words/s
INFO - 2023-11-30 15:58:56,908: EPOCH 1: training on 191080 raw words (156367 effective words) took 0.5s, 346978 effective words/s
INFO - 2023-11-30 15:58:57,357: EPOCH 2: training on 191080 raw words (156360 effective words) took 0.4s, 350463 effective words/s
INFO - 2023-11-30 15:58:57,805: EPOCH 3: training on 191080 raw words (156311 effective words) took 0.4s, 350949 effective words/s
INFO - 2023-11-30 15:58:58,240: EPOCH 4: training on 191080 raw words (156415 effective words) took 0.4s, 362905 effective words/s
INFO - 2023-11-30 15:58:58,677: EPOCH 5: training on 191080 raw words (156479 effective words) took 0.4s, 359969 effective words/s
INFO - 2023-11-30 15:58:59,176: EPOCH 6: training on 191080 raw words (156213 effective words) took 0.5s, 315806 effective words/s
INFO - 2023-11-30 15:58:59,612: EPOCH 7: training on 191080 raw words (156371 effective words) took 0.4s, 360955 effective words/s
INFO - 2023-11-30 15:59:00,046: EPOCH 8: training on 191080 raw words (156393 effective words) took 0.4s, 363117 effective words/s
INFO - 2023-11-30 15:59:00,492: EPOCH 9: training on 191080 raw words (156315 effective words) took 0.4s, 352970 effective words/s
INFO - 2023-11-30 15:59:00,917: EPOCH 10: training on 191080 raw words (156293 effective words) took 0.4s, 370077 effective words/s
INFO - 2023-11-30 15:59:01,266: EPOCH 11: training on 191080 raw words (156198 effective words) took 0.3s, 450818 effective words/s
INFO - 2023-11-30 15:59:01,604: EPOCH 12: training on 191080 raw words (156308 effective words) took 0.3s, 465753 effective words/s
INFO - 2023-11-30 15:59:01,941: EPOCH 13: training on 191080 raw words (156227 effective words) took 0.3s, 467188 effective words/s
INFO - 2023-11-30 15:59:02,276: EPOCH 14: training on 191080 raw words (156353 effective words) took 0.3s, 469688 effective words/s
INFO - 2023-11-30 15:59:02,610: EPOCH 15: training on 191080 raw words (156289 effective words) took 0.3s, 470565 effective words/s
INFO - 2023-11-30 15:59:02,943: EPOCH 16: training on 191080 raw words (156340 effective words) took 0.3s, 472723 effective words/s
INFO - 2023-11-30 15:59:03,275: EPOCH 17: training on 191080 raw words (156390 effective words) took 0.3s, 473746 effective words/s
INFO - 2023-11-30 15:59:03,613: EPOCH 18: training on 191080 raw words (156287 effective words) took 0.3s, 466561 effective words/s
INFO - 2023-11-30 15:59:03,955: EPOCH 19: training on 191080 raw words (156324 effective words) took 0.3s, 459840 effective words/s
INFO - 2023-11-30 15:59:03,955: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126776 effective words) took 8.0s, 393294 effective words/s', 'datetime': '2023-11-30T15:59:03.955817', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:03,956: collecting all words and their counts
INFO - 2023-11-30 15:59:03,956: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:03,990: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:03,991: Updating model with new vocabulary
INFO - 2023-11-30 15:59:04,005: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:04.005039', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:04,027: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:04,027: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:59:04,027: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156466.1817779063 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T15:59:04.027718', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:04,056: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:04,056: updating layer weights
INFO - 2023-11-30 15:59:04,057: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:04.057135', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:04,057: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:04,057: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:04.057512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:04,427: EPOCH 0: training on 191080 raw words (156422 effective words) took 0.4s, 425311 effective words/s
INFO - 2023-11-30 15:59:04,828: EPOCH 1: training on 191080 raw words (156465 effective words) took 0.4s, 393393 effective words/s
INFO - 2023-11-30 15:59:05,156: EPOCH 2: training on 191080 raw words (156346 effective words) took 0.3s, 480709 effective words/s
INFO - 2023-11-30 15:59:05,492: EPOCH 3: training on 191080 raw words (156238 effective words) took 0.3s, 468128 effective words/s
INFO - 2023-11-30 15:59:05,819: EPOCH 4: training on 191080 raw words (156557 effective words) took 0.3s, 482822 effective words/s
INFO - 2023-11-30 15:59:06,146: EPOCH 5: training on 191080 raw words (156480 effective words) took 0.3s, 481293 effective words/s
INFO - 2023-11-30 15:59:06,468: EPOCH 6: training on 191080 raw words (156516 effective words) took 0.3s, 489650 effective words/s
INFO - 2023-11-30 15:59:06,791: EPOCH 7: training on 191080 raw words (156617 effective words) took 0.3s, 489958 effective words/s
INFO - 2023-11-30 15:59:07,167: EPOCH 8: training on 191080 raw words (156379 effective words) took 0.4s, 417727 effective words/s
INFO - 2023-11-30 15:59:07,490: EPOCH 9: training on 191080 raw words (156709 effective words) took 0.3s, 488822 effective words/s
INFO - 2023-11-30 15:59:07,819: EPOCH 10: training on 191080 raw words (156445 effective words) took 0.3s, 478673 effective words/s
INFO - 2023-11-30 15:59:08,139: EPOCH 11: training on 191080 raw words (156396 effective words) took 0.3s, 492447 effective words/s
INFO - 2023-11-30 15:59:08,469: EPOCH 12: training on 191080 raw words (156576 effective words) took 0.3s, 478149 effective words/s
INFO - 2023-11-30 15:59:08,794: EPOCH 13: training on 191080 raw words (156412 effective words) took 0.3s, 485660 effective words/s
INFO - 2023-11-30 15:59:09,119: EPOCH 14: training on 191080 raw words (156415 effective words) took 0.3s, 485260 effective words/s
INFO - 2023-11-30 15:59:09,437: EPOCH 15: training on 191080 raw words (156232 effective words) took 0.3s, 496507 effective words/s
INFO - 2023-11-30 15:59:09,757: EPOCH 16: training on 191080 raw words (156415 effective words) took 0.3s, 492638 effective words/s
INFO - 2023-11-30 15:59:10,077: EPOCH 17: training on 191080 raw words (156356 effective words) took 0.3s, 492984 effective words/s
INFO - 2023-11-30 15:59:10,399: EPOCH 18: training on 191080 raw words (156399 effective words) took 0.3s, 490051 effective words/s
INFO - 2023-11-30 15:59:10,731: EPOCH 19: training on 191080 raw words (156405 effective words) took 0.3s, 475264 effective words/s
INFO - 2023-11-30 15:59:10,731: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3128780 effective words) took 6.7s, 468790 effective words/s', 'datetime': '2023-11-30T15:59:10.731861', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:10,732: collecting all words and their counts
INFO - 2023-11-30 15:59:10,732: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:10,762: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:10,762: Updating model with new vocabulary
INFO - 2023-11-30 15:59:10,776: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:10.776302', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:10,792: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:10,792: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:59:10,792: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156292.03740066156 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:59:10.792568', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:10,816: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:10,816: updating layer weights
INFO - 2023-11-30 15:59:10,817: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:10.817326', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:10,817: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:10,817: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:10.817580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:11,151: EPOCH 0: training on 191080 raw words (156364 effective words) took 0.3s, 471287 effective words/s
INFO - 2023-11-30 15:59:11,486: EPOCH 1: training on 191080 raw words (156187 effective words) took 0.3s, 470783 effective words/s
INFO - 2023-11-30 15:59:11,823: EPOCH 2: training on 191080 raw words (156253 effective words) took 0.3s, 466580 effective words/s
INFO - 2023-11-30 15:59:12,157: EPOCH 3: training on 191080 raw words (156120 effective words) took 0.3s, 471520 effective words/s
INFO - 2023-11-30 15:59:12,499: EPOCH 4: training on 191080 raw words (156205 effective words) took 0.3s, 459932 effective words/s
INFO - 2023-11-30 15:59:12,840: EPOCH 5: training on 191080 raw words (156218 effective words) took 0.3s, 461123 effective words/s
INFO - 2023-11-30 15:59:13,173: EPOCH 6: training on 191080 raw words (156264 effective words) took 0.3s, 473241 effective words/s
INFO - 2023-11-30 15:59:13,513: EPOCH 7: training on 191080 raw words (156300 effective words) took 0.3s, 462616 effective words/s
INFO - 2023-11-30 15:59:13,849: EPOCH 8: training on 191080 raw words (156193 effective words) took 0.3s, 468359 effective words/s
INFO - 2023-11-30 15:59:14,183: EPOCH 9: training on 191080 raw words (156286 effective words) took 0.3s, 470433 effective words/s
INFO - 2023-11-30 15:59:14,574: EPOCH 10: training on 191080 raw words (156344 effective words) took 0.4s, 402226 effective words/s
INFO - 2023-11-30 15:59:14,916: EPOCH 11: training on 191080 raw words (156128 effective words) took 0.3s, 459926 effective words/s
INFO - 2023-11-30 15:59:15,257: EPOCH 12: training on 191080 raw words (156366 effective words) took 0.3s, 462225 effective words/s
INFO - 2023-11-30 15:59:15,682: EPOCH 13: training on 191080 raw words (156490 effective words) took 0.4s, 369407 effective words/s
INFO - 2023-11-30 15:59:16,139: EPOCH 14: training on 191080 raw words (156376 effective words) took 0.5s, 345298 effective words/s
INFO - 2023-11-30 15:59:16,613: EPOCH 15: training on 191080 raw words (156500 effective words) took 0.5s, 332798 effective words/s
INFO - 2023-11-30 15:59:17,033: EPOCH 16: training on 191080 raw words (156135 effective words) took 0.4s, 374834 effective words/s
INFO - 2023-11-30 15:59:17,453: EPOCH 17: training on 191080 raw words (156526 effective words) took 0.4s, 375371 effective words/s
INFO - 2023-11-30 15:59:17,873: EPOCH 18: training on 191080 raw words (156218 effective words) took 0.4s, 375108 effective words/s
INFO - 2023-11-30 15:59:18,309: EPOCH 19: training on 191080 raw words (156390 effective words) took 0.4s, 374455 effective words/s
INFO - 2023-11-30 15:59:18,310: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125863 effective words) took 7.5s, 417205 effective words/s', 'datetime': '2023-11-30T15:59:18.310117', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:18,310: collecting all words and their counts
INFO - 2023-11-30 15:59:18,310: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:18,351: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:18,351: Updating model with new vocabulary
INFO - 2023-11-30 15:59:18,372: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:18.372437', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:18,394: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:18,395: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:59:18,395: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156098.21189692654 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:59:18.395498', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:18,425: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:18,425: updating layer weights
INFO - 2023-11-30 15:59:18,426: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:18.426213', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:18,426: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:18,426: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:18.426672', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:18,842: EPOCH 0: training on 191080 raw words (156076 effective words) took 0.4s, 399410 effective words/s
INFO - 2023-11-30 15:59:19,248: EPOCH 1: training on 191080 raw words (156031 effective words) took 0.4s, 386718 effective words/s
INFO - 2023-11-30 15:59:19,655: EPOCH 2: training on 191080 raw words (156058 effective words) took 0.4s, 386787 effective words/s
INFO - 2023-11-30 15:59:20,085: EPOCH 3: training on 191080 raw words (155998 effective words) took 0.4s, 365679 effective words/s
INFO - 2023-11-30 15:59:20,582: EPOCH 4: training on 191080 raw words (155998 effective words) took 0.5s, 315743 effective words/s
INFO - 2023-11-30 15:59:21,093: EPOCH 5: training on 191080 raw words (156056 effective words) took 0.5s, 307629 effective words/s
INFO - 2023-11-30 15:59:21,623: EPOCH 6: training on 191080 raw words (156216 effective words) took 0.5s, 297283 effective words/s
INFO - 2023-11-30 15:59:22,159: EPOCH 7: training on 191080 raw words (156279 effective words) took 0.5s, 293622 effective words/s
INFO - 2023-11-30 15:59:22,621: EPOCH 8: training on 191080 raw words (156140 effective words) took 0.5s, 340784 effective words/s
INFO - 2023-11-30 15:59:23,050: EPOCH 9: training on 191080 raw words (156115 effective words) took 0.4s, 366882 effective words/s
INFO - 2023-11-30 15:59:23,480: EPOCH 10: training on 191080 raw words (156071 effective words) took 0.4s, 365878 effective words/s
INFO - 2023-11-30 15:59:23,939: EPOCH 11: training on 191080 raw words (156201 effective words) took 0.5s, 342881 effective words/s
INFO - 2023-11-30 15:59:24,419: EPOCH 12: training on 191080 raw words (156263 effective words) took 0.5s, 328409 effective words/s
INFO - 2023-11-30 15:59:24,737: EPOCH 13: training on 191080 raw words (156237 effective words) took 0.3s, 498657 effective words/s
INFO - 2023-11-30 15:59:25,056: EPOCH 14: training on 191080 raw words (156175 effective words) took 0.3s, 493869 effective words/s
INFO - 2023-11-30 15:59:25,371: EPOCH 15: training on 191080 raw words (156053 effective words) took 0.3s, 498761 effective words/s
INFO - 2023-11-30 15:59:25,687: EPOCH 16: training on 191080 raw words (155928 effective words) took 0.3s, 496572 effective words/s
INFO - 2023-11-30 15:59:26,015: EPOCH 17: training on 191080 raw words (156057 effective words) took 0.3s, 479523 effective words/s
INFO - 2023-11-30 15:59:26,331: EPOCH 18: training on 191080 raw words (156037 effective words) took 0.3s, 497846 effective words/s
INFO - 2023-11-30 15:59:26,659: EPOCH 19: training on 191080 raw words (156228 effective words) took 0.3s, 479267 effective words/s
INFO - 2023-11-30 15:59:26,659: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122217 effective words) took 8.2s, 379231 effective words/s', 'datetime': '2023-11-30T15:59:26.659931', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:26,660: collecting all words and their counts
INFO - 2023-11-30 15:59:26,660: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:26,693: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:26,693: Updating model with new vocabulary
INFO - 2023-11-30 15:59:26,707: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:26.707837', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:26,726: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:26,726: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:59:26,727: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156372.64663138235 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:59:26.727034', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:26,760: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:26,760: updating layer weights
INFO - 2023-11-30 15:59:26,760: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:26.760907', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:26,761: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:26,761: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:26.761206', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:27,137: EPOCH 0: training on 191080 raw words (156588 effective words) took 0.4s, 441626 effective words/s
INFO - 2023-11-30 15:59:27,498: EPOCH 1: training on 191080 raw words (156366 effective words) took 0.4s, 436740 effective words/s
INFO - 2023-11-30 15:59:27,863: EPOCH 2: training on 191080 raw words (156329 effective words) took 0.4s, 430970 effective words/s
INFO - 2023-11-30 15:59:28,253: EPOCH 3: training on 191080 raw words (156293 effective words) took 0.4s, 403818 effective words/s
INFO - 2023-11-30 15:59:28,666: EPOCH 4: training on 191080 raw words (156332 effective words) took 0.4s, 381552 effective words/s
INFO - 2023-11-30 15:59:29,117: EPOCH 5: training on 191080 raw words (156572 effective words) took 0.4s, 349154 effective words/s
INFO - 2023-11-30 15:59:29,557: EPOCH 6: training on 191080 raw words (156381 effective words) took 0.4s, 358447 effective words/s
INFO - 2023-11-30 15:59:29,919: EPOCH 7: training on 191080 raw words (156296 effective words) took 0.4s, 435362 effective words/s
INFO - 2023-11-30 15:59:30,288: EPOCH 8: training on 191080 raw words (156357 effective words) took 0.4s, 426698 effective words/s
INFO - 2023-11-30 15:59:30,692: EPOCH 9: training on 191080 raw words (156367 effective words) took 0.4s, 390792 effective words/s
INFO - 2023-11-30 15:59:31,092: EPOCH 10: training on 191080 raw words (156466 effective words) took 0.4s, 394150 effective words/s
INFO - 2023-11-30 15:59:31,458: EPOCH 11: training on 191080 raw words (156288 effective words) took 0.4s, 431047 effective words/s
INFO - 2023-11-30 15:59:31,814: EPOCH 12: training on 191080 raw words (156204 effective words) took 0.4s, 441762 effective words/s
INFO - 2023-11-30 15:59:32,162: EPOCH 13: training on 191080 raw words (156383 effective words) took 0.3s, 452779 effective words/s
INFO - 2023-11-30 15:59:32,552: EPOCH 14: training on 191080 raw words (156307 effective words) took 0.4s, 403685 effective words/s
INFO - 2023-11-30 15:59:32,886: EPOCH 15: training on 191080 raw words (156347 effective words) took 0.3s, 471811 effective words/s
INFO - 2023-11-30 15:59:33,215: EPOCH 16: training on 191080 raw words (156526 effective words) took 0.3s, 479125 effective words/s
INFO - 2023-11-30 15:59:33,586: EPOCH 17: training on 191080 raw words (156303 effective words) took 0.4s, 423727 effective words/s
INFO - 2023-11-30 15:59:33,973: EPOCH 18: training on 191080 raw words (156074 effective words) took 0.4s, 406990 effective words/s
INFO - 2023-11-30 15:59:34,321: EPOCH 19: training on 191080 raw words (156199 effective words) took 0.3s, 460524 effective words/s
INFO - 2023-11-30 15:59:34,321: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126978 effective words) took 7.6s, 413612 effective words/s', 'datetime': '2023-11-30T15:59:34.321514', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:34,321: collecting all words and their counts
INFO - 2023-11-30 15:59:34,321: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:34,351: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:34,351: Updating model with new vocabulary
INFO - 2023-11-30 15:59:34,364: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:34.364652', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:34,380: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:34,380: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:59:34,380: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156094.26976232103 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:59:34.380801', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:34,404: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:34,404: updating layer weights
INFO - 2023-11-30 15:59:34,405: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:34.405302', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:34,405: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:34,405: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:34.405594', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:34,719: EPOCH 0: training on 191080 raw words (156209 effective words) took 0.3s, 513752 effective words/s
INFO - 2023-11-30 15:59:35,040: EPOCH 1: training on 191080 raw words (156071 effective words) took 0.3s, 489925 effective words/s
INFO - 2023-11-30 15:59:35,372: EPOCH 2: training on 191080 raw words (156005 effective words) took 0.3s, 474960 effective words/s
INFO - 2023-11-30 15:59:35,714: EPOCH 3: training on 191080 raw words (156097 effective words) took 0.3s, 459487 effective words/s
INFO - 2023-11-30 15:59:36,058: EPOCH 4: training on 191080 raw words (156109 effective words) took 0.3s, 457469 effective words/s
INFO - 2023-11-30 15:59:36,410: EPOCH 5: training on 191080 raw words (155968 effective words) took 0.3s, 447049 effective words/s
INFO - 2023-11-30 15:59:36,781: EPOCH 6: training on 191080 raw words (156118 effective words) took 0.4s, 423840 effective words/s
INFO - 2023-11-30 15:59:37,115: EPOCH 7: training on 191080 raw words (156176 effective words) took 0.3s, 471826 effective words/s
INFO - 2023-11-30 15:59:37,433: EPOCH 8: training on 191080 raw words (156125 effective words) took 0.3s, 494212 effective words/s
INFO - 2023-11-30 15:59:37,752: EPOCH 9: training on 191080 raw words (156254 effective words) took 0.3s, 494391 effective words/s
INFO - 2023-11-30 15:59:38,071: EPOCH 10: training on 191080 raw words (156234 effective words) took 0.3s, 494059 effective words/s
INFO - 2023-11-30 15:59:38,401: EPOCH 11: training on 191080 raw words (156106 effective words) took 0.3s, 476340 effective words/s
INFO - 2023-11-30 15:59:38,724: EPOCH 12: training on 191080 raw words (156152 effective words) took 0.3s, 487610 effective words/s
INFO - 2023-11-30 15:59:39,041: EPOCH 13: training on 191080 raw words (156098 effective words) took 0.3s, 495665 effective words/s
INFO - 2023-11-30 15:59:39,373: EPOCH 14: training on 191080 raw words (156223 effective words) took 0.3s, 476092 effective words/s
INFO - 2023-11-30 15:59:39,701: EPOCH 15: training on 191080 raw words (156101 effective words) took 0.3s, 479498 effective words/s
INFO - 2023-11-30 15:59:40,082: EPOCH 16: training on 191080 raw words (156114 effective words) took 0.4s, 412993 effective words/s
INFO - 2023-11-30 15:59:40,409: EPOCH 17: training on 191080 raw words (156200 effective words) took 0.3s, 481388 effective words/s
INFO - 2023-11-30 15:59:40,730: EPOCH 18: training on 191080 raw words (156097 effective words) took 0.3s, 489424 effective words/s
INFO - 2023-11-30 15:59:41,077: EPOCH 19: training on 191080 raw words (156085 effective words) took 0.3s, 452560 effective words/s
INFO - 2023-11-30 15:59:41,078: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3122542 effective words) took 6.7s, 467981 effective words/s', 'datetime': '2023-11-30T15:59:41.078182', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:41,078: collecting all words and their counts
INFO - 2023-11-30 15:59:41,078: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:41,129: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:41,130: Updating model with new vocabulary
INFO - 2023-11-30 15:59:41,154: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:41.154791', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:41,182: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:41,182: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:59:41,182: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 155916.98583552236 word corpus (81.6%% of prior 191080)', 'datetime': '2023-11-30T15:59:41.182904', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:41,226: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:41,226: updating layer weights
INFO - 2023-11-30 15:59:41,227: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:41.227203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:41,227: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:41,227: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:41.227558', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:41,716: EPOCH 0: training on 191080 raw words (155871 effective words) took 0.5s, 321319 effective words/s
INFO - 2023-11-30 15:59:42,192: EPOCH 1: training on 191080 raw words (155870 effective words) took 0.5s, 329582 effective words/s
INFO - 2023-11-30 15:59:42,676: EPOCH 2: training on 191080 raw words (155893 effective words) took 0.5s, 324001 effective words/s
INFO - 2023-11-30 15:59:43,169: EPOCH 3: training on 191080 raw words (155891 effective words) took 0.5s, 318941 effective words/s
INFO - 2023-11-30 15:59:43,689: EPOCH 4: training on 191080 raw words (155889 effective words) took 0.5s, 302223 effective words/s
INFO - 2023-11-30 15:59:44,181: EPOCH 5: training on 191080 raw words (156066 effective words) took 0.5s, 339754 effective words/s
INFO - 2023-11-30 15:59:44,699: EPOCH 6: training on 191080 raw words (156151 effective words) took 0.5s, 303995 effective words/s
INFO - 2023-11-30 15:59:45,195: EPOCH 7: training on 191080 raw words (155849 effective words) took 0.5s, 316041 effective words/s
INFO - 2023-11-30 15:59:45,747: EPOCH 8: training on 191080 raw words (155899 effective words) took 0.5s, 284499 effective words/s
INFO - 2023-11-30 15:59:46,268: EPOCH 9: training on 191080 raw words (155840 effective words) took 0.5s, 301615 effective words/s
INFO - 2023-11-30 15:59:46,780: EPOCH 10: training on 191080 raw words (155924 effective words) took 0.5s, 307613 effective words/s
INFO - 2023-11-30 15:59:47,294: EPOCH 11: training on 191080 raw words (155774 effective words) took 0.5s, 304538 effective words/s
INFO - 2023-11-30 15:59:47,805: EPOCH 12: training on 191080 raw words (155921 effective words) took 0.5s, 307614 effective words/s
INFO - 2023-11-30 15:59:48,279: EPOCH 13: training on 191080 raw words (155818 effective words) took 0.5s, 331561 effective words/s
INFO - 2023-11-30 15:59:48,695: EPOCH 14: training on 191080 raw words (155859 effective words) took 0.4s, 376504 effective words/s
INFO - 2023-11-30 15:59:49,112: EPOCH 15: training on 191080 raw words (155932 effective words) took 0.4s, 377283 effective words/s
INFO - 2023-11-30 15:59:49,529: EPOCH 16: training on 191080 raw words (155814 effective words) took 0.4s, 376251 effective words/s
INFO - 2023-11-30 15:59:49,943: EPOCH 17: training on 191080 raw words (155802 effective words) took 0.4s, 378901 effective words/s
INFO - 2023-11-30 15:59:50,396: EPOCH 18: training on 191080 raw words (155892 effective words) took 0.5s, 346138 effective words/s
INFO - 2023-11-30 15:59:50,785: EPOCH 19: training on 191080 raw words (155879 effective words) took 0.4s, 404170 effective words/s
INFO - 2023-11-30 15:59:50,786: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3117834 effective words) took 9.6s, 326189 effective words/s', 'datetime': '2023-11-30T15:59:50.786120', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:50,786: collecting all words and their counts
INFO - 2023-11-30 15:59:50,786: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:50,828: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:50,828: Updating model with new vocabulary
INFO - 2023-11-30 15:59:50,845: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:50.845854', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:50,866: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:50,866: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:59:50,866: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156257.87281449803 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T15:59:50.866886', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:50,902: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:50,902: updating layer weights
INFO - 2023-11-30 15:59:50,903: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:50.903280', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:50,903: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:50,903: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:50.903750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:51,317: EPOCH 0: training on 191080 raw words (156304 effective words) took 0.4s, 381100 effective words/s
INFO - 2023-11-30 15:59:51,685: EPOCH 1: training on 191080 raw words (156277 effective words) took 0.4s, 428239 effective words/s
INFO - 2023-11-30 15:59:52,032: EPOCH 2: training on 191080 raw words (156278 effective words) took 0.3s, 453596 effective words/s
INFO - 2023-11-30 15:59:52,394: EPOCH 3: training on 191080 raw words (156415 effective words) took 0.4s, 435474 effective words/s
INFO - 2023-11-30 15:59:52,720: EPOCH 4: training on 191080 raw words (156307 effective words) took 0.3s, 481792 effective words/s
INFO - 2023-11-30 15:59:53,038: EPOCH 5: training on 191080 raw words (156211 effective words) took 0.3s, 495673 effective words/s
INFO - 2023-11-30 15:59:53,365: EPOCH 6: training on 191080 raw words (156200 effective words) took 0.3s, 482333 effective words/s
INFO - 2023-11-30 15:59:53,689: EPOCH 7: training on 191080 raw words (156234 effective words) took 0.3s, 485807 effective words/s
INFO - 2023-11-30 15:59:54,045: EPOCH 8: training on 191080 raw words (156114 effective words) took 0.4s, 441674 effective words/s
INFO - 2023-11-30 15:59:54,370: EPOCH 9: training on 191080 raw words (156181 effective words) took 0.3s, 486563 effective words/s
INFO - 2023-11-30 15:59:54,689: EPOCH 10: training on 191080 raw words (156325 effective words) took 0.3s, 492813 effective words/s
INFO - 2023-11-30 15:59:55,042: EPOCH 11: training on 191080 raw words (156183 effective words) took 0.4s, 445789 effective words/s
INFO - 2023-11-30 15:59:55,362: EPOCH 12: training on 191080 raw words (156238 effective words) took 0.3s, 493059 effective words/s
INFO - 2023-11-30 15:59:55,683: EPOCH 13: training on 191080 raw words (156343 effective words) took 0.3s, 490411 effective words/s
INFO - 2023-11-30 15:59:56,006: EPOCH 14: training on 191080 raw words (156230 effective words) took 0.3s, 487879 effective words/s
INFO - 2023-11-30 15:59:56,328: EPOCH 15: training on 191080 raw words (156178 effective words) took 0.3s, 488859 effective words/s
INFO - 2023-11-30 15:59:56,650: EPOCH 16: training on 191080 raw words (156162 effective words) took 0.3s, 488600 effective words/s
INFO - 2023-11-30 15:59:56,978: EPOCH 17: training on 191080 raw words (156355 effective words) took 0.3s, 481636 effective words/s
INFO - 2023-11-30 15:59:57,333: EPOCH 18: training on 191080 raw words (156193 effective words) took 0.4s, 443214 effective words/s
INFO - 2023-11-30 15:59:57,688: EPOCH 19: training on 191080 raw words (156332 effective words) took 0.4s, 444152 effective words/s
INFO - 2023-11-30 15:59:57,688: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125060 effective words) took 6.8s, 460612 effective words/s', 'datetime': '2023-11-30T15:59:57.688552', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:57,688: collecting all words and their counts
INFO - 2023-11-30 15:59:57,689: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:59:57,722: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:59:57,722: Updating model with new vocabulary
INFO - 2023-11-30 15:59:57,737: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:59:57.737692', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:57,759: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:59:57,759: sample=0.001 downsamples 34 most-common words
INFO - 2023-11-30 15:59:57,760: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156164.63560623556 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T15:59:57.760034', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:59:57,786: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:59:57,786: updating layer weights
INFO - 2023-11-30 15:59:57,787: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:59:57.787242', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:59:57,787: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:59:57,787: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:59:57.787603', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:59:58,181: EPOCH 0: training on 191080 raw words (156197 effective words) took 0.4s, 399599 effective words/s
INFO - 2023-11-30 15:59:58,516: EPOCH 1: training on 191080 raw words (155972 effective words) took 0.3s, 468265 effective words/s
INFO - 2023-11-30 15:59:58,900: EPOCH 2: training on 191080 raw words (156319 effective words) took 0.4s, 409896 effective words/s
INFO - 2023-11-30 15:59:59,274: EPOCH 3: training on 191080 raw words (156183 effective words) took 0.4s, 420766 effective words/s
INFO - 2023-11-30 15:59:59,612: EPOCH 4: training on 191080 raw words (156107 effective words) took 0.3s, 464357 effective words/s
INFO - 2023-11-30 15:59:59,954: EPOCH 5: training on 191080 raw words (156288 effective words) took 0.3s, 460338 effective words/s
INFO - 2023-11-30 16:00:00,290: EPOCH 6: training on 191080 raw words (156219 effective words) took 0.3s, 473920 effective words/s
INFO - 2023-11-30 16:00:00,648: EPOCH 7: training on 191080 raw words (156238 effective words) took 0.4s, 438937 effective words/s
INFO - 2023-11-30 16:00:01,043: EPOCH 8: training on 191080 raw words (156220 effective words) took 0.4s, 398394 effective words/s
INFO - 2023-11-30 16:00:01,409: EPOCH 9: training on 191080 raw words (156196 effective words) took 0.4s, 429984 effective words/s
INFO - 2023-11-30 16:00:01,740: EPOCH 10: training on 191080 raw words (156023 effective words) took 0.3s, 474395 effective words/s
INFO - 2023-11-30 16:00:02,072: EPOCH 11: training on 191080 raw words (156154 effective words) took 0.3s, 474505 effective words/s
INFO - 2023-11-30 16:00:02,402: EPOCH 12: training on 191080 raw words (156183 effective words) took 0.3s, 476014 effective words/s
INFO - 2023-11-30 16:00:02,737: EPOCH 13: training on 191080 raw words (156227 effective words) took 0.3s, 470280 effective words/s
INFO - 2023-11-30 16:00:03,073: EPOCH 14: training on 191080 raw words (156173 effective words) took 0.3s, 468599 effective words/s
INFO - 2023-11-30 16:00:03,451: EPOCH 15: training on 191080 raw words (156037 effective words) took 0.4s, 415169 effective words/s
INFO - 2023-11-30 16:00:03,866: EPOCH 16: training on 191080 raw words (156108 effective words) took 0.4s, 379338 effective words/s
INFO - 2023-11-30 16:00:04,316: EPOCH 17: training on 191080 raw words (156054 effective words) took 0.4s, 348705 effective words/s
INFO - 2023-11-30 16:00:04,732: EPOCH 18: training on 191080 raw words (156080 effective words) took 0.4s, 378536 effective words/s
INFO - 2023-11-30 16:00:05,180: EPOCH 19: training on 191080 raw words (156314 effective words) took 0.4s, 351220 effective words/s
INFO - 2023-11-30 16:00:05,181: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3123292 effective words) took 7.4s, 422449 effective words/s', 'datetime': '2023-11-30T16:00:05.181050', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:05,181: collecting all words and their counts
INFO - 2023-11-30 16:00:05,181: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:05,228: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:05,228: Updating model with new vocabulary
INFO - 2023-11-30 16:00:05,247: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:05.247249', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:05,275: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:05,276: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:00:05,276: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156352.95862344516 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T16:00:05.276346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:05,317: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:05,317: updating layer weights
INFO - 2023-11-30 16:00:05,318: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:05.318387', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:05,318: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:05,318: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:05.318902', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:05,792: EPOCH 0: training on 191080 raw words (156348 effective words) took 0.5s, 335344 effective words/s
INFO - 2023-11-30 16:00:06,263: EPOCH 1: training on 191080 raw words (156260 effective words) took 0.5s, 334159 effective words/s
INFO - 2023-11-30 16:00:06,760: EPOCH 2: training on 191080 raw words (156254 effective words) took 0.5s, 317573 effective words/s
INFO - 2023-11-30 16:00:07,178: EPOCH 3: training on 191080 raw words (156319 effective words) took 0.4s, 376146 effective words/s
INFO - 2023-11-30 16:00:07,604: EPOCH 4: training on 191080 raw words (156103 effective words) took 0.4s, 370172 effective words/s
INFO - 2023-11-30 16:00:08,035: EPOCH 5: training on 191080 raw words (156435 effective words) took 0.4s, 364951 effective words/s
INFO - 2023-11-30 16:00:08,479: EPOCH 6: training on 191080 raw words (156391 effective words) took 0.4s, 354661 effective words/s
INFO - 2023-11-30 16:00:08,911: EPOCH 7: training on 191080 raw words (156580 effective words) took 0.4s, 366111 effective words/s
INFO - 2023-11-30 16:00:09,437: EPOCH 8: training on 191080 raw words (156440 effective words) took 0.5s, 299586 effective words/s
INFO - 2023-11-30 16:00:09,962: EPOCH 9: training on 191080 raw words (156280 effective words) took 0.5s, 299539 effective words/s
INFO - 2023-11-30 16:00:10,454: EPOCH 10: training on 191080 raw words (156568 effective words) took 0.5s, 320366 effective words/s
INFO - 2023-11-30 16:00:10,990: EPOCH 11: training on 191080 raw words (156340 effective words) took 0.5s, 293596 effective words/s
INFO - 2023-11-30 16:00:11,571: EPOCH 12: training on 191080 raw words (156402 effective words) took 0.6s, 272022 effective words/s
INFO - 2023-11-30 16:00:12,035: EPOCH 13: training on 191080 raw words (156395 effective words) took 0.5s, 340105 effective words/s
INFO - 2023-11-30 16:00:12,467: EPOCH 14: training on 191080 raw words (156426 effective words) took 0.4s, 364906 effective words/s
INFO - 2023-11-30 16:00:12,825: EPOCH 15: training on 191080 raw words (156179 effective words) took 0.4s, 438960 effective words/s
INFO - 2023-11-30 16:00:13,155: EPOCH 16: training on 191080 raw words (156325 effective words) took 0.3s, 477696 effective words/s
INFO - 2023-11-30 16:00:13,521: EPOCH 17: training on 191080 raw words (156322 effective words) took 0.4s, 430294 effective words/s
INFO - 2023-11-30 16:00:13,859: EPOCH 18: training on 191080 raw words (156386 effective words) took 0.3s, 467480 effective words/s
INFO - 2023-11-30 16:00:14,198: EPOCH 19: training on 191080 raw words (156406 effective words) took 0.3s, 464938 effective words/s
INFO - 2023-11-30 16:00:14,198: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127159 effective words) took 8.9s, 352186 effective words/s', 'datetime': '2023-11-30T16:00:14.198397', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:14,198: collecting all words and their counts
INFO - 2023-11-30 16:00:14,198: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:14,229: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:14,230: Updating model with new vocabulary
INFO - 2023-11-30 16:00:14,243: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:14.243542', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:14,260: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:14,260: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:00:14,261: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156225.86631664145 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T16:00:14.260980', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:14,284: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:14,284: updating layer weights
INFO - 2023-11-30 16:00:14,284: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:14.284916', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:14,285: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:14,285: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:14.285240', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:14,611: EPOCH 0: training on 191080 raw words (156129 effective words) took 0.3s, 482394 effective words/s
INFO - 2023-11-30 16:00:14,973: EPOCH 1: training on 191080 raw words (156111 effective words) took 0.4s, 434066 effective words/s
INFO - 2023-11-30 16:00:15,315: EPOCH 2: training on 191080 raw words (156130 effective words) took 0.3s, 459024 effective words/s
INFO - 2023-11-30 16:00:15,683: EPOCH 3: training on 191080 raw words (155919 effective words) took 0.4s, 427832 effective words/s
INFO - 2023-11-30 16:00:16,078: EPOCH 4: training on 191080 raw words (156230 effective words) took 0.4s, 397898 effective words/s
INFO - 2023-11-30 16:00:16,419: EPOCH 5: training on 191080 raw words (156321 effective words) took 0.3s, 461606 effective words/s
INFO - 2023-11-30 16:00:16,752: EPOCH 6: training on 191080 raw words (156143 effective words) took 0.3s, 472853 effective words/s
INFO - 2023-11-30 16:00:17,099: EPOCH 7: training on 191080 raw words (156303 effective words) took 0.3s, 453348 effective words/s
INFO - 2023-11-30 16:00:17,434: EPOCH 8: training on 191080 raw words (156475 effective words) took 0.3s, 471567 effective words/s
INFO - 2023-11-30 16:00:17,771: EPOCH 9: training on 191080 raw words (156186 effective words) took 0.3s, 467482 effective words/s
INFO - 2023-11-30 16:00:18,103: EPOCH 10: training on 191080 raw words (156032 effective words) took 0.3s, 471994 effective words/s
INFO - 2023-11-30 16:00:18,437: EPOCH 11: training on 191080 raw words (156019 effective words) took 0.3s, 470348 effective words/s
INFO - 2023-11-30 16:00:18,778: EPOCH 12: training on 191080 raw words (156405 effective words) took 0.3s, 462824 effective words/s
INFO - 2023-11-30 16:00:19,117: EPOCH 13: training on 191080 raw words (156216 effective words) took 0.3s, 464150 effective words/s
INFO - 2023-11-30 16:00:19,453: EPOCH 14: training on 191080 raw words (156355 effective words) took 0.3s, 467926 effective words/s
INFO - 2023-11-30 16:00:19,792: EPOCH 15: training on 191080 raw words (156096 effective words) took 0.3s, 464759 effective words/s
INFO - 2023-11-30 16:00:20,131: EPOCH 16: training on 191080 raw words (156263 effective words) took 0.3s, 464034 effective words/s
INFO - 2023-11-30 16:00:20,469: EPOCH 17: training on 191080 raw words (156294 effective words) took 0.3s, 467036 effective words/s
INFO - 2023-11-30 16:00:20,795: EPOCH 18: training on 191080 raw words (156181 effective words) took 0.3s, 482747 effective words/s
INFO - 2023-11-30 16:00:21,128: EPOCH 19: training on 191080 raw words (156460 effective words) took 0.3s, 473218 effective words/s
INFO - 2023-11-30 16:00:21,128: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3124268 effective words) took 6.8s, 456569 effective words/s', 'datetime': '2023-11-30T16:00:21.128305', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:21,128: collecting all words and their counts
INFO - 2023-11-30 16:00:21,128: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:21,159: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:21,160: Updating model with new vocabulary
INFO - 2023-11-30 16:00:21,172: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:21.172482', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:21,188: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:21,189: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:00:21,189: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156407.42643584235 word corpus (81.9%% of prior 191080)', 'datetime': '2023-11-30T16:00:21.189239', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:21,212: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:21,212: updating layer weights
INFO - 2023-11-30 16:00:21,213: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:21.213275', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:21,213: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:21,213: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:21.213652', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:21,532: EPOCH 0: training on 191080 raw words (156383 effective words) took 0.3s, 494015 effective words/s
INFO - 2023-11-30 16:00:21,856: EPOCH 1: training on 191080 raw words (156382 effective words) took 0.3s, 486909 effective words/s
INFO - 2023-11-30 16:00:22,190: EPOCH 2: training on 191080 raw words (156414 effective words) took 0.3s, 471902 effective words/s
INFO - 2023-11-30 16:00:22,516: EPOCH 3: training on 191080 raw words (156302 effective words) took 0.3s, 483759 effective words/s
INFO - 2023-11-30 16:00:22,837: EPOCH 4: training on 191080 raw words (156455 effective words) took 0.3s, 490397 effective words/s
INFO - 2023-11-30 16:00:23,175: EPOCH 5: training on 191080 raw words (156330 effective words) took 0.3s, 467100 effective words/s
INFO - 2023-11-30 16:00:23,569: EPOCH 6: training on 191080 raw words (156325 effective words) took 0.4s, 398868 effective words/s
INFO - 2023-11-30 16:00:23,894: EPOCH 7: training on 191080 raw words (156445 effective words) took 0.3s, 484588 effective words/s
INFO - 2023-11-30 16:00:24,222: EPOCH 8: training on 191080 raw words (156465 effective words) took 0.3s, 482094 effective words/s
INFO - 2023-11-30 16:00:24,549: EPOCH 9: training on 191080 raw words (156556 effective words) took 0.3s, 481962 effective words/s
INFO - 2023-11-30 16:00:24,876: EPOCH 10: training on 191080 raw words (156238 effective words) took 0.3s, 480760 effective words/s
INFO - 2023-11-30 16:00:25,197: EPOCH 11: training on 191080 raw words (156258 effective words) took 0.3s, 489930 effective words/s
INFO - 2023-11-30 16:00:25,518: EPOCH 12: training on 191080 raw words (156406 effective words) took 0.3s, 492273 effective words/s
INFO - 2023-11-30 16:00:25,843: EPOCH 13: training on 191080 raw words (156423 effective words) took 0.3s, 484543 effective words/s
INFO - 2023-11-30 16:00:26,205: EPOCH 14: training on 191080 raw words (156370 effective words) took 0.4s, 434186 effective words/s
INFO - 2023-11-30 16:00:26,535: EPOCH 15: training on 191080 raw words (156351 effective words) took 0.3s, 478001 effective words/s
INFO - 2023-11-30 16:00:26,852: EPOCH 16: training on 191080 raw words (156390 effective words) took 0.3s, 496321 effective words/s
INFO - 2023-11-30 16:00:27,182: EPOCH 17: training on 191080 raw words (156466 effective words) took 0.3s, 477616 effective words/s
INFO - 2023-11-30 16:00:27,518: EPOCH 18: training on 191080 raw words (156262 effective words) took 0.3s, 469289 effective words/s
INFO - 2023-11-30 16:00:27,945: EPOCH 19: training on 191080 raw words (156433 effective words) took 0.4s, 368883 effective words/s
INFO - 2023-11-30 16:00:27,945: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3127654 effective words) took 6.7s, 464624 effective words/s', 'datetime': '2023-11-30T16:00:27.945414', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:27,945: collecting all words and their counts
INFO - 2023-11-30 16:00:27,945: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:27,988: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:27,988: Updating model with new vocabulary
INFO - 2023-11-30 16:00:28,004: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:28.004648', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:28,025: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:28,026: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:00:28,026: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156336.65556766785 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T16:00:28.026143', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:28,058: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:28,058: updating layer weights
INFO - 2023-11-30 16:00:28,059: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:28.059355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:28,059: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:28,059: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:28.059677', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:28,510: EPOCH 0: training on 191080 raw words (156444 effective words) took 0.4s, 357260 effective words/s
INFO - 2023-11-30 16:00:28,962: EPOCH 1: training on 191080 raw words (156348 effective words) took 0.4s, 348703 effective words/s
INFO - 2023-11-30 16:00:29,406: EPOCH 2: training on 191080 raw words (156263 effective words) took 0.4s, 354542 effective words/s
INFO - 2023-11-30 16:00:29,849: EPOCH 3: training on 191080 raw words (156434 effective words) took 0.4s, 355719 effective words/s
INFO - 2023-11-30 16:00:30,302: EPOCH 4: training on 191080 raw words (156483 effective words) took 0.4s, 347859 effective words/s
INFO - 2023-11-30 16:00:30,769: EPOCH 5: training on 191080 raw words (156469 effective words) took 0.5s, 337486 effective words/s
INFO - 2023-11-30 16:00:31,322: EPOCH 6: training on 191080 raw words (156268 effective words) took 0.5s, 284354 effective words/s
INFO - 2023-11-30 16:00:31,817: EPOCH 7: training on 191080 raw words (156500 effective words) took 0.5s, 318933 effective words/s
INFO - 2023-11-30 16:00:32,364: EPOCH 8: training on 191080 raw words (156417 effective words) took 0.5s, 287538 effective words/s
INFO - 2023-11-30 16:00:32,848: EPOCH 9: training on 191080 raw words (156340 effective words) took 0.5s, 324757 effective words/s
INFO - 2023-11-30 16:00:33,319: EPOCH 10: training on 191080 raw words (156243 effective words) took 0.5s, 333990 effective words/s
INFO - 2023-11-30 16:00:33,833: EPOCH 11: training on 191080 raw words (156335 effective words) took 0.5s, 325310 effective words/s
INFO - 2023-11-30 16:00:34,359: EPOCH 12: training on 191080 raw words (156201 effective words) took 0.5s, 299157 effective words/s
INFO - 2023-11-30 16:00:34,874: EPOCH 13: training on 191080 raw words (156272 effective words) took 0.5s, 305529 effective words/s
INFO - 2023-11-30 16:00:35,390: EPOCH 14: training on 191080 raw words (156398 effective words) took 0.5s, 304868 effective words/s
INFO - 2023-11-30 16:00:35,918: EPOCH 15: training on 191080 raw words (156240 effective words) took 0.5s, 297979 effective words/s
INFO - 2023-11-30 16:00:36,432: EPOCH 16: training on 191080 raw words (156262 effective words) took 0.5s, 305920 effective words/s
INFO - 2023-11-30 16:00:36,840: EPOCH 17: training on 191080 raw words (156231 effective words) took 0.4s, 386790 effective words/s
INFO - 2023-11-30 16:00:37,263: EPOCH 18: training on 191080 raw words (156304 effective words) took 0.4s, 372300 effective words/s
INFO - 2023-11-30 16:00:37,760: EPOCH 19: training on 191080 raw words (156232 effective words) took 0.5s, 316564 effective words/s
INFO - 2023-11-30 16:00:37,760: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3126684 effective words) took 9.7s, 322320 effective words/s', 'datetime': '2023-11-30T16:00:37.760441', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:37,760: collecting all words and their counts
INFO - 2023-11-30 16:00:37,761: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:37,803: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:37,803: Updating model with new vocabulary
INFO - 2023-11-30 16:00:37,820: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:37.820911', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:37,844: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:37,844: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:00:37,844: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156118.77685273663 word corpus (81.7%% of prior 191080)', 'datetime': '2023-11-30T16:00:37.844761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:37,879: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:37,879: updating layer weights
INFO - 2023-11-30 16:00:37,880: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:37.879989', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:37,880: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:37,880: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:37.880376', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:38,315: EPOCH 0: training on 191080 raw words (156069 effective words) took 0.4s, 360510 effective words/s
INFO - 2023-11-30 16:00:38,714: EPOCH 1: training on 191080 raw words (156044 effective words) took 0.4s, 394749 effective words/s
INFO - 2023-11-30 16:00:39,128: EPOCH 2: training on 191080 raw words (155991 effective words) took 0.4s, 380403 effective words/s
INFO - 2023-11-30 16:00:39,519: EPOCH 3: training on 191080 raw words (156249 effective words) took 0.4s, 402707 effective words/s
INFO - 2023-11-30 16:00:40,000: EPOCH 4: training on 191080 raw words (156038 effective words) took 0.5s, 327311 effective words/s
INFO - 2023-11-30 16:00:40,322: EPOCH 5: training on 191080 raw words (156110 effective words) took 0.3s, 490193 effective words/s
INFO - 2023-11-30 16:00:40,688: EPOCH 6: training on 191080 raw words (155990 effective words) took 0.4s, 429427 effective words/s
INFO - 2023-11-30 16:00:41,011: EPOCH 7: training on 191080 raw words (156159 effective words) took 0.3s, 487378 effective words/s
INFO - 2023-11-30 16:00:41,337: EPOCH 8: training on 191080 raw words (155969 effective words) took 0.3s, 482379 effective words/s
INFO - 2023-11-30 16:00:41,661: EPOCH 9: training on 191080 raw words (156154 effective words) took 0.3s, 485567 effective words/s
INFO - 2023-11-30 16:00:42,032: EPOCH 10: training on 191080 raw words (156056 effective words) took 0.4s, 422615 effective words/s
INFO - 2023-11-30 16:00:42,366: EPOCH 11: training on 191080 raw words (156003 effective words) took 0.3s, 470313 effective words/s
INFO - 2023-11-30 16:00:42,726: EPOCH 12: training on 191080 raw words (156191 effective words) took 0.4s, 438851 effective words/s
INFO - 2023-11-30 16:00:43,044: EPOCH 13: training on 191080 raw words (156095 effective words) took 0.3s, 495565 effective words/s
INFO - 2023-11-30 16:00:43,366: EPOCH 14: training on 191080 raw words (155962 effective words) took 0.3s, 487229 effective words/s
INFO - 2023-11-30 16:00:43,686: EPOCH 15: training on 191080 raw words (156195 effective words) took 0.3s, 491792 effective words/s
INFO - 2023-11-30 16:00:44,009: EPOCH 16: training on 191080 raw words (156137 effective words) took 0.3s, 488968 effective words/s
INFO - 2023-11-30 16:00:44,338: EPOCH 17: training on 191080 raw words (156067 effective words) took 0.3s, 478396 effective words/s
INFO - 2023-11-30 16:00:44,651: EPOCH 18: training on 191080 raw words (156065 effective words) took 0.3s, 502290 effective words/s
INFO - 2023-11-30 16:00:44,983: EPOCH 19: training on 191080 raw words (156106 effective words) took 0.3s, 472890 effective words/s
INFO - 2023-11-30 16:00:44,983: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3121650 effective words) took 7.1s, 439471 effective words/s', 'datetime': '2023-11-30T16:00:44.983717', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:44,983: collecting all words and their counts
INFO - 2023-11-30 16:00:44,984: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:00:45,013: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:00:45,014: Updating model with new vocabulary
INFO - 2023-11-30 16:00:45,027: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:00:45.027082', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:45,043: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:00:45,043: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:00:45,043: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 156262.5994598242 word corpus (81.8%% of prior 191080)', 'datetime': '2023-11-30T16:00:45.043556', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:00:45,068: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:00:45,069: updating layer weights
INFO - 2023-11-30 16:00:45,069: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:00:45.069448', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:00:45,069: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:00:45,069: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:00:45.069739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:45,459: EPOCH 0: training on 191080 raw words (156312 effective words) took 0.4s, 403364 effective words/s
INFO - 2023-11-30 16:00:45,826: EPOCH 1: training on 191080 raw words (156214 effective words) took 0.4s, 429371 effective words/s
INFO - 2023-11-30 16:00:46,161: EPOCH 2: training on 191080 raw words (156274 effective words) took 0.3s, 469859 effective words/s
INFO - 2023-11-30 16:00:46,498: EPOCH 3: training on 191080 raw words (156196 effective words) took 0.3s, 467528 effective words/s
INFO - 2023-11-30 16:00:46,837: EPOCH 4: training on 191080 raw words (156276 effective words) took 0.3s, 463092 effective words/s
INFO - 2023-11-30 16:00:47,172: EPOCH 5: training on 191080 raw words (156238 effective words) took 0.3s, 471530 effective words/s
INFO - 2023-11-30 16:00:47,523: EPOCH 6: training on 191080 raw words (156235 effective words) took 0.3s, 470558 effective words/s
INFO - 2023-11-30 16:00:47,891: EPOCH 7: training on 191080 raw words (156415 effective words) took 0.4s, 427611 effective words/s
INFO - 2023-11-30 16:00:48,238: EPOCH 8: training on 191080 raw words (156133 effective words) took 0.3s, 453823 effective words/s
INFO - 2023-11-30 16:00:48,595: EPOCH 9: training on 191080 raw words (156492 effective words) took 0.4s, 441724 effective words/s
INFO - 2023-11-30 16:00:48,935: EPOCH 10: training on 191080 raw words (156127 effective words) took 0.3s, 462142 effective words/s
INFO - 2023-11-30 16:00:49,269: EPOCH 11: training on 191080 raw words (156223 effective words) took 0.3s, 471980 effective words/s
INFO - 2023-11-30 16:00:49,664: EPOCH 12: training on 191080 raw words (156194 effective words) took 0.4s, 398471 effective words/s
INFO - 2023-11-30 16:00:50,000: EPOCH 13: training on 191080 raw words (156234 effective words) took 0.3s, 468938 effective words/s
INFO - 2023-11-30 16:00:50,331: EPOCH 14: training on 191080 raw words (156224 effective words) took 0.3s, 476058 effective words/s
INFO - 2023-11-30 16:00:50,662: EPOCH 15: training on 191080 raw words (156244 effective words) took 0.3s, 475563 effective words/s
INFO - 2023-11-30 16:00:51,007: EPOCH 16: training on 191080 raw words (156313 effective words) took 0.3s, 455840 effective words/s
INFO - 2023-11-30 16:00:51,341: EPOCH 17: training on 191080 raw words (156186 effective words) took 0.3s, 470877 effective words/s
INFO - 2023-11-30 16:00:51,699: EPOCH 18: training on 191080 raw words (156397 effective words) took 0.4s, 440405 effective words/s
INFO - 2023-11-30 16:00:52,117: EPOCH 19: training on 191080 raw words (156265 effective words) took 0.4s, 376611 effective words/s
INFO - 2023-11-30 16:00:52,117: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (3125192 effective words) took 7.0s, 443436 effective words/s', 'datetime': '2023-11-30T16:00:52.117563', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:00:52,121: storing 4777x128 projection weights into POS.txt
