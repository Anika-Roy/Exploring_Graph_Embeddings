INFO - 2023-11-30 16:44:41,948: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-30T16:44:41.908480', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-30 16:44:41,948: collecting all words and their counts
INFO - 2023-11-30 16:44:41,949: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:44:41,978: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:44:41,978: Creating a fresh vocabulary
INFO - 2023-11-30 16:44:41,989: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 4777 unique words (100.00% of original 4777, drops 0)', 'datetime': '2023-11-30T16:44:41.989619', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:41,990: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 191080 word corpus (100.00% of original 191080, drops 0)', 'datetime': '2023-11-30T16:44:41.990164', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:42,064: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:44:42,064: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:44:42,064: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135595.2371352002 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:44:42.064934', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:42,130: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:44:42,130: resetting layer weights
INFO - 2023-11-30 16:44:42,536: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-30T16:44:42.535983', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-30 16:44:42,536: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:44:42.536274', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:44:42,884: EPOCH 0: training on 191080 raw words (135671 effective words) took 0.3s, 393458 effective words/s
INFO - 2023-11-30 16:44:43,364: EPOCH 1: training on 191080 raw words (135617 effective words) took 0.5s, 284504 effective words/s
INFO - 2023-11-30 16:44:43,654: EPOCH 2: training on 191080 raw words (135520 effective words) took 0.3s, 472420 effective words/s
INFO - 2023-11-30 16:44:44,486: EPOCH 3: training on 191080 raw words (135610 effective words) took 0.8s, 163412 effective words/s
INFO - 2023-11-30 16:44:44,774: EPOCH 4: training on 191080 raw words (135701 effective words) took 0.3s, 504890 effective words/s
INFO - 2023-11-30 16:44:45,060: EPOCH 5: training on 191080 raw words (135512 effective words) took 0.3s, 478314 effective words/s
INFO - 2023-11-30 16:44:45,629: EPOCH 6: training on 191080 raw words (135601 effective words) took 0.6s, 239300 effective words/s
INFO - 2023-11-30 16:44:45,915: EPOCH 7: training on 191080 raw words (135739 effective words) took 0.3s, 479702 effective words/s
INFO - 2023-11-30 16:44:47,524: EPOCH 8 - PROGRESS: at 10.47% examples, 8777 words/s, in_qsize 18, out_qsize 0
INFO - 2023-11-30 16:44:47,687: EPOCH 8: training on 191080 raw words (135467 effective words) took 1.8s, 76549 effective words/s
INFO - 2023-11-30 16:44:47,979: EPOCH 9: training on 191080 raw words (135464 effective words) took 0.3s, 468520 effective words/s
INFO - 2023-11-30 16:44:48,331: EPOCH 10: training on 191080 raw words (135657 effective words) took 0.3s, 388886 effective words/s
INFO - 2023-11-30 16:44:48,632: EPOCH 11: training on 191080 raw words (135566 effective words) took 0.3s, 454894 effective words/s
INFO - 2023-11-30 16:44:48,934: EPOCH 12: training on 191080 raw words (135618 effective words) took 0.3s, 453501 effective words/s
INFO - 2023-11-30 16:44:49,210: EPOCH 13: training on 191080 raw words (135568 effective words) took 0.3s, 495679 effective words/s
INFO - 2023-11-30 16:44:49,497: EPOCH 14: training on 191080 raw words (135684 effective words) took 0.3s, 476629 effective words/s
INFO - 2023-11-30 16:44:50,046: EPOCH 15: training on 191080 raw words (135548 effective words) took 0.3s, 515192 effective words/s
INFO - 2023-11-30 16:44:50,359: EPOCH 16: training on 191080 raw words (135710 effective words) took 0.3s, 436191 effective words/s
INFO - 2023-11-30 16:44:50,653: EPOCH 17: training on 191080 raw words (135522 effective words) took 0.3s, 464919 effective words/s
INFO - 2023-11-30 16:44:50,930: EPOCH 18: training on 191080 raw words (135563 effective words) took 0.3s, 493123 effective words/s
INFO - 2023-11-30 16:44:51,477: EPOCH 19: training on 191080 raw words (135729 effective words) took 0.5s, 249450 effective words/s
INFO - 2023-11-30 16:44:51,477: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712067 effective words) took 8.9s, 303316 effective words/s', 'datetime': '2023-11-30T16:44:51.477827', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:44:51,478: collecting all words and their counts
INFO - 2023-11-30 16:44:51,478: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:44:51,509: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:44:51,509: Updating model with new vocabulary
INFO - 2023-11-30 16:44:51,522: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:44:51.522028', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:51,541: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:44:51,541: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:44:51,541: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135251.2645775455 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:44:51.541739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:51,564: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:44:51,564: updating layer weights
INFO - 2023-11-30 16:44:51,565: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:44:51.565951', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:44:51,566: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:44:51,566: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:44:51.566229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:44:51,856: EPOCH 0: training on 191080 raw words (135358 effective words) took 0.3s, 470636 effective words/s
INFO - 2023-11-30 16:44:52,180: EPOCH 1: training on 191080 raw words (135472 effective words) took 0.3s, 421600 effective words/s
INFO - 2023-11-30 16:44:52,473: EPOCH 2: training on 191080 raw words (135300 effective words) took 0.3s, 465593 effective words/s
INFO - 2023-11-30 16:44:52,763: EPOCH 3: training on 191080 raw words (135426 effective words) took 0.3s, 470202 effective words/s
INFO - 2023-11-30 16:44:53,054: EPOCH 4: training on 191080 raw words (135358 effective words) took 0.3s, 470236 effective words/s
INFO - 2023-11-30 16:44:53,342: EPOCH 5: training on 191080 raw words (135140 effective words) took 0.3s, 472722 effective words/s
INFO - 2023-11-30 16:44:53,624: EPOCH 6: training on 191080 raw words (135295 effective words) took 0.3s, 483864 effective words/s
INFO - 2023-11-30 16:44:53,915: EPOCH 7: training on 191080 raw words (135287 effective words) took 0.3s, 468401 effective words/s
INFO - 2023-11-30 16:44:54,203: EPOCH 8: training on 191080 raw words (135358 effective words) took 0.3s, 476477 effective words/s
INFO - 2023-11-30 16:44:54,508: EPOCH 9: training on 191080 raw words (135391 effective words) took 0.3s, 447663 effective words/s
INFO - 2023-11-30 16:44:54,812: EPOCH 10: training on 191080 raw words (135312 effective words) took 0.3s, 448574 effective words/s
INFO - 2023-11-30 16:44:55,109: EPOCH 11: training on 191080 raw words (135275 effective words) took 0.3s, 497373 effective words/s
INFO - 2023-11-30 16:44:55,394: EPOCH 12: training on 191080 raw words (135221 effective words) took 0.3s, 479229 effective words/s
INFO - 2023-11-30 16:44:55,686: EPOCH 13: training on 191080 raw words (135235 effective words) took 0.3s, 467337 effective words/s
INFO - 2023-11-30 16:44:55,975: EPOCH 14: training on 191080 raw words (135102 effective words) took 0.3s, 470943 effective words/s
INFO - 2023-11-30 16:44:56,264: EPOCH 15: training on 191080 raw words (135315 effective words) took 0.3s, 473100 effective words/s
INFO - 2023-11-30 16:44:56,564: EPOCH 16: training on 191080 raw words (135198 effective words) took 0.3s, 454042 effective words/s
INFO - 2023-11-30 16:44:56,863: EPOCH 17: training on 191080 raw words (135425 effective words) took 0.3s, 457976 effective words/s
INFO - 2023-11-30 16:44:57,149: EPOCH 18: training on 191080 raw words (135331 effective words) took 0.3s, 476992 effective words/s
INFO - 2023-11-30 16:44:57,443: EPOCH 19: training on 191080 raw words (135196 effective words) took 0.3s, 463235 effective words/s
INFO - 2023-11-30 16:44:57,444: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2705995 effective words) took 5.9s, 460373 effective words/s', 'datetime': '2023-11-30T16:44:57.444218', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:44:57,444: collecting all words and their counts
INFO - 2023-11-30 16:44:57,444: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:44:57,485: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:44:57,485: Updating model with new vocabulary
INFO - 2023-11-30 16:44:57,500: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:44:57.500324', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:57,520: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:44:57,520: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:44:57,520: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135243.64933508745 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:44:57.520829', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:44:57,552: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:44:57,553: updating layer weights
INFO - 2023-11-30 16:44:57,553: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:44:57.553778', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:44:57,554: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:44:57,554: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:44:57.554260', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:44:57,857: EPOCH 0: training on 191080 raw words (135226 effective words) took 0.3s, 450029 effective words/s
INFO - 2023-11-30 16:44:58,140: EPOCH 1: training on 191080 raw words (135080 effective words) took 0.3s, 483774 effective words/s
INFO - 2023-11-30 16:44:58,416: EPOCH 2: training on 191080 raw words (135414 effective words) took 0.3s, 494146 effective words/s
INFO - 2023-11-30 16:44:58,699: EPOCH 3: training on 191080 raw words (135169 effective words) took 0.3s, 522921 effective words/s
INFO - 2023-11-30 16:44:58,995: EPOCH 4: training on 191080 raw words (135330 effective words) took 0.3s, 461412 effective words/s
INFO - 2023-11-30 16:44:59,271: EPOCH 5: training on 191080 raw words (134990 effective words) took 0.3s, 497898 effective words/s
INFO - 2023-11-30 16:44:59,552: EPOCH 6: training on 191080 raw words (135299 effective words) took 0.3s, 486147 effective words/s
INFO - 2023-11-30 16:44:59,829: EPOCH 7: training on 191080 raw words (135250 effective words) took 0.3s, 493952 effective words/s
INFO - 2023-11-30 16:45:00,159: EPOCH 8: training on 191080 raw words (135230 effective words) took 0.3s, 412805 effective words/s
INFO - 2023-11-30 16:45:00,437: EPOCH 9: training on 191080 raw words (135356 effective words) took 0.3s, 491981 effective words/s
INFO - 2023-11-30 16:45:00,734: EPOCH 10: training on 191080 raw words (135346 effective words) took 0.3s, 459252 effective words/s
INFO - 2023-11-30 16:45:01,083: EPOCH 11: training on 191080 raw words (135409 effective words) took 0.3s, 391321 effective words/s
INFO - 2023-11-30 16:45:01,433: EPOCH 12: training on 191080 raw words (135132 effective words) took 0.3s, 390079 effective words/s
INFO - 2023-11-30 16:45:01,780: EPOCH 13: training on 191080 raw words (135185 effective words) took 0.3s, 420859 effective words/s
INFO - 2023-11-30 16:45:02,124: EPOCH 14: training on 191080 raw words (135080 effective words) took 0.3s, 395661 effective words/s
INFO - 2023-11-30 16:45:02,473: EPOCH 15: training on 191080 raw words (135225 effective words) took 0.3s, 391535 effective words/s
INFO - 2023-11-30 16:45:02,828: EPOCH 16: training on 191080 raw words (135402 effective words) took 0.4s, 385192 effective words/s
INFO - 2023-11-30 16:45:03,200: EPOCH 17: training on 191080 raw words (135284 effective words) took 0.4s, 366450 effective words/s
INFO - 2023-11-30 16:45:03,577: EPOCH 18: training on 191080 raw words (135507 effective words) took 0.4s, 362036 effective words/s
INFO - 2023-11-30 16:45:03,938: EPOCH 19: training on 191080 raw words (135232 effective words) took 0.4s, 378398 effective words/s
INFO - 2023-11-30 16:45:03,938: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2705146 effective words) took 6.4s, 423712 effective words/s', 'datetime': '2023-11-30T16:45:03.938858', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:03,939: collecting all words and their counts
INFO - 2023-11-30 16:45:03,939: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:03,994: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:03,994: Updating model with new vocabulary
INFO - 2023-11-30 16:45:04,018: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:04.018585', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:04,054: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:04,054: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:04,055: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135621.1939075896 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:45:04.055054', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:04,091: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:04,091: updating layer weights
INFO - 2023-11-30 16:45:04,091: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:04.091907', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:04,092: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:04,092: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:04.092587', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:04,475: EPOCH 0: training on 191080 raw words (135516 effective words) took 0.4s, 357834 effective words/s
INFO - 2023-11-30 16:45:04,859: EPOCH 1: training on 191080 raw words (135612 effective words) took 0.4s, 356126 effective words/s
INFO - 2023-11-30 16:45:05,240: EPOCH 2: training on 191080 raw words (135540 effective words) took 0.4s, 358460 effective words/s
INFO - 2023-11-30 16:45:05,635: EPOCH 3: training on 191080 raw words (135757 effective words) took 0.4s, 369977 effective words/s
INFO - 2023-11-30 16:45:06,014: EPOCH 4: training on 191080 raw words (135886 effective words) took 0.4s, 361751 effective words/s
INFO - 2023-11-30 16:45:06,403: EPOCH 5: training on 191080 raw words (135704 effective words) took 0.4s, 352080 effective words/s
INFO - 2023-11-30 16:45:06,828: EPOCH 6: training on 191080 raw words (135641 effective words) took 0.4s, 322271 effective words/s
INFO - 2023-11-30 16:45:07,221: EPOCH 7: training on 191080 raw words (135700 effective words) took 0.4s, 367033 effective words/s
INFO - 2023-11-30 16:45:07,618: EPOCH 8: training on 191080 raw words (135441 effective words) took 0.4s, 343275 effective words/s
INFO - 2023-11-30 16:45:08,050: EPOCH 9: training on 191080 raw words (135637 effective words) took 0.4s, 316647 effective words/s
INFO - 2023-11-30 16:45:08,447: EPOCH 10: training on 191080 raw words (135368 effective words) took 0.4s, 343988 effective words/s
INFO - 2023-11-30 16:45:08,838: EPOCH 11: training on 191080 raw words (135805 effective words) took 0.4s, 350362 effective words/s
INFO - 2023-11-30 16:45:09,238: EPOCH 12: training on 191080 raw words (135475 effective words) took 0.4s, 342295 effective words/s
INFO - 2023-11-30 16:45:09,669: EPOCH 13: training on 191080 raw words (135623 effective words) took 0.4s, 316452 effective words/s
INFO - 2023-11-30 16:45:10,020: EPOCH 14: training on 191080 raw words (135378 effective words) took 0.3s, 390581 effective words/s
INFO - 2023-11-30 16:45:10,369: EPOCH 15: training on 191080 raw words (135659 effective words) took 0.3s, 391328 effective words/s
INFO - 2023-11-30 16:45:10,709: EPOCH 16: training on 191080 raw words (135456 effective words) took 0.3s, 401977 effective words/s
INFO - 2023-11-30 16:45:11,064: EPOCH 17: training on 191080 raw words (135338 effective words) took 0.4s, 385579 effective words/s
INFO - 2023-11-30 16:45:11,417: EPOCH 18: training on 191080 raw words (135704 effective words) took 0.4s, 386837 effective words/s
INFO - 2023-11-30 16:45:11,785: EPOCH 19: training on 191080 raw words (135433 effective words) took 0.4s, 371985 effective words/s
INFO - 2023-11-30 16:45:11,785: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711673 effective words) took 7.7s, 352494 effective words/s', 'datetime': '2023-11-30T16:45:11.785716', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:11,785: collecting all words and their counts
INFO - 2023-11-30 16:45:11,786: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:11,835: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:11,835: Updating model with new vocabulary
INFO - 2023-11-30 16:45:11,851: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:11.851383', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:11,872: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:11,872: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:11,872: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135504.13926066319 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:45:11.872474', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:11,909: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:11,910: updating layer weights
INFO - 2023-11-30 16:45:11,910: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:11.910448', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:11,910: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:11,910: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:11.910794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:12,262: EPOCH 0: training on 191080 raw words (135485 effective words) took 0.3s, 389399 effective words/s
INFO - 2023-11-30 16:45:12,616: EPOCH 1: training on 191080 raw words (135382 effective words) took 0.4s, 385838 effective words/s
INFO - 2023-11-30 16:45:12,947: EPOCH 2: training on 191080 raw words (135543 effective words) took 0.3s, 414803 effective words/s
INFO - 2023-11-30 16:45:13,283: EPOCH 3: training on 191080 raw words (135756 effective words) took 0.3s, 407825 effective words/s
INFO - 2023-11-30 16:45:13,619: EPOCH 4: training on 191080 raw words (135444 effective words) took 0.3s, 442623 effective words/s
INFO - 2023-11-30 16:45:14,070: EPOCH 5: training on 191080 raw words (135332 effective words) took 0.4s, 301514 effective words/s
INFO - 2023-11-30 16:45:14,425: EPOCH 6: training on 191080 raw words (135417 effective words) took 0.4s, 385504 effective words/s
INFO - 2023-11-30 16:45:14,793: EPOCH 7: training on 191080 raw words (135338 effective words) took 0.4s, 371233 effective words/s
INFO - 2023-11-30 16:45:15,201: EPOCH 8: training on 191080 raw words (135489 effective words) took 0.4s, 334454 effective words/s
INFO - 2023-11-30 16:45:15,553: EPOCH 9: training on 191080 raw words (135386 effective words) took 0.3s, 388930 effective words/s
INFO - 2023-11-30 16:45:15,899: EPOCH 10: training on 191080 raw words (135435 effective words) took 0.3s, 395102 effective words/s
INFO - 2023-11-30 16:45:16,237: EPOCH 11: training on 191080 raw words (135400 effective words) took 0.3s, 405552 effective words/s
INFO - 2023-11-30 16:45:16,567: EPOCH 12: training on 191080 raw words (135469 effective words) took 0.3s, 448280 effective words/s
INFO - 2023-11-30 16:45:16,909: EPOCH 13: training on 191080 raw words (135607 effective words) took 0.3s, 398963 effective words/s
INFO - 2023-11-30 16:45:17,247: EPOCH 14: training on 191080 raw words (135438 effective words) took 0.3s, 404864 effective words/s
INFO - 2023-11-30 16:45:17,572: EPOCH 15: training on 191080 raw words (135362 effective words) took 0.3s, 421063 effective words/s
INFO - 2023-11-30 16:45:17,914: EPOCH 16: training on 191080 raw words (135378 effective words) took 0.3s, 399554 effective words/s
INFO - 2023-11-30 16:45:18,251: EPOCH 17: training on 191080 raw words (135311 effective words) took 0.3s, 405222 effective words/s
INFO - 2023-11-30 16:45:18,600: EPOCH 18: training on 191080 raw words (135445 effective words) took 0.3s, 401307 effective words/s
INFO - 2023-11-30 16:45:18,947: EPOCH 19: training on 191080 raw words (135501 effective words) took 0.3s, 393830 effective words/s
INFO - 2023-11-30 16:45:18,947: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708918 effective words) took 7.0s, 384967 effective words/s', 'datetime': '2023-11-30T16:45:18.947810', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:18,948: collecting all words and their counts
INFO - 2023-11-30 16:45:18,948: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:18,988: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:18,989: Updating model with new vocabulary
INFO - 2023-11-30 16:45:19,003: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:19.003901', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:19,024: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:19,024: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:19,024: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135278.69516143273 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:45:19.024546', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:19,055: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:19,055: updating layer weights
INFO - 2023-11-30 16:45:19,055: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:19.055902', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:19,056: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:19,056: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:19.056233', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:19,427: EPOCH 0: training on 191080 raw words (135380 effective words) took 0.3s, 392689 effective words/s
INFO - 2023-11-30 16:45:19,768: EPOCH 1: training on 191080 raw words (135498 effective words) took 0.3s, 401930 effective words/s
INFO - 2023-11-30 16:45:20,110: EPOCH 2: training on 191080 raw words (135302 effective words) took 0.3s, 398989 effective words/s
INFO - 2023-11-30 16:45:20,455: EPOCH 3: training on 191080 raw words (135250 effective words) took 0.3s, 395520 effective words/s
INFO - 2023-11-30 16:45:20,801: EPOCH 4: training on 191080 raw words (135228 effective words) took 0.3s, 393949 effective words/s
INFO - 2023-11-30 16:45:21,148: EPOCH 5: training on 191080 raw words (135321 effective words) took 0.3s, 423443 effective words/s
INFO - 2023-11-30 16:45:21,505: EPOCH 6: training on 191080 raw words (135390 effective words) took 0.4s, 382990 effective words/s
INFO - 2023-11-30 16:45:21,856: EPOCH 7: training on 191080 raw words (135229 effective words) took 0.3s, 389025 effective words/s
INFO - 2023-11-30 16:45:22,209: EPOCH 8: training on 191080 raw words (135198 effective words) took 0.3s, 386945 effective words/s
INFO - 2023-11-30 16:45:22,550: EPOCH 9: training on 191080 raw words (135506 effective words) took 0.3s, 401313 effective words/s
INFO - 2023-11-30 16:45:22,895: EPOCH 10: training on 191080 raw words (135170 effective words) took 0.3s, 395121 effective words/s
INFO - 2023-11-30 16:45:23,255: EPOCH 11: training on 191080 raw words (135358 effective words) took 0.4s, 379655 effective words/s
INFO - 2023-11-30 16:45:23,597: EPOCH 12: training on 191080 raw words (135218 effective words) took 0.3s, 399215 effective words/s
INFO - 2023-11-30 16:45:23,940: EPOCH 13: training on 191080 raw words (135299 effective words) took 0.3s, 397484 effective words/s
INFO - 2023-11-30 16:45:24,275: EPOCH 14: training on 191080 raw words (135282 effective words) took 0.3s, 407685 effective words/s
INFO - 2023-11-30 16:45:24,684: EPOCH 15: training on 191080 raw words (135481 effective words) took 0.4s, 333531 effective words/s
INFO - 2023-11-30 16:45:25,027: EPOCH 16: training on 191080 raw words (135203 effective words) took 0.3s, 397782 effective words/s
INFO - 2023-11-30 16:45:25,375: EPOCH 17: training on 191080 raw words (135488 effective words) took 0.3s, 393096 effective words/s
INFO - 2023-11-30 16:45:25,715: EPOCH 18: training on 191080 raw words (135306 effective words) took 0.3s, 402059 effective words/s
INFO - 2023-11-30 16:45:26,051: EPOCH 19: training on 191080 raw words (135099 effective words) took 0.3s, 406346 effective words/s
INFO - 2023-11-30 16:45:26,051: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2706206 effective words) took 7.0s, 386873 effective words/s', 'datetime': '2023-11-30T16:45:26.051465', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:26,051: collecting all words and their counts
INFO - 2023-11-30 16:45:26,051: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:26,094: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:26,094: Updating model with new vocabulary
INFO - 2023-11-30 16:45:26,121: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:26.121325', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:26,159: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:26,159: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:26,159: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135590.34005055358 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:45:26.159829', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:26,192: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:26,192: updating layer weights
INFO - 2023-11-30 16:45:26,192: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:26.192681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:26,192: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:26,193: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:26.193049', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:26,625: EPOCH 0: training on 191080 raw words (135549 effective words) took 0.4s, 316387 effective words/s
INFO - 2023-11-30 16:45:26,955: EPOCH 1: training on 191080 raw words (135738 effective words) took 0.3s, 423962 effective words/s
INFO - 2023-11-30 16:45:27,290: EPOCH 2: training on 191080 raw words (135715 effective words) took 0.3s, 407529 effective words/s
INFO - 2023-11-30 16:45:27,657: EPOCH 3: training on 191080 raw words (135559 effective words) took 0.4s, 372995 effective words/s
INFO - 2023-11-30 16:45:28,026: EPOCH 4: training on 191080 raw words (135729 effective words) took 0.4s, 371597 effective words/s
INFO - 2023-11-30 16:45:28,377: EPOCH 5: training on 191080 raw words (135611 effective words) took 0.3s, 390416 effective words/s
INFO - 2023-11-30 16:45:28,712: EPOCH 6: training on 191080 raw words (135521 effective words) took 0.3s, 409449 effective words/s
INFO - 2023-11-30 16:45:29,037: EPOCH 7: training on 191080 raw words (135721 effective words) took 0.3s, 421779 effective words/s
INFO - 2023-11-30 16:45:29,432: EPOCH 8: training on 191080 raw words (135322 effective words) took 0.4s, 345087 effective words/s
INFO - 2023-11-30 16:45:29,791: EPOCH 9: training on 191080 raw words (135531 effective words) took 0.4s, 380771 effective words/s
INFO - 2023-11-30 16:45:30,118: EPOCH 10: training on 191080 raw words (135927 effective words) took 0.3s, 419324 effective words/s
INFO - 2023-11-30 16:45:30,473: EPOCH 11: training on 191080 raw words (135733 effective words) took 0.4s, 385838 effective words/s
INFO - 2023-11-30 16:45:30,807: EPOCH 12: training on 191080 raw words (135568 effective words) took 0.3s, 409648 effective words/s
INFO - 2023-11-30 16:45:31,140: EPOCH 13: training on 191080 raw words (135455 effective words) took 0.3s, 410463 effective words/s
INFO - 2023-11-30 16:45:31,470: EPOCH 14: training on 191080 raw words (135629 effective words) took 0.3s, 416105 effective words/s
INFO - 2023-11-30 16:45:31,796: EPOCH 15: training on 191080 raw words (135443 effective words) took 0.3s, 420161 effective words/s
INFO - 2023-11-30 16:45:32,124: EPOCH 16: training on 191080 raw words (135638 effective words) took 0.3s, 417898 effective words/s
INFO - 2023-11-30 16:45:32,451: EPOCH 17: training on 191080 raw words (135507 effective words) took 0.3s, 418616 effective words/s
INFO - 2023-11-30 16:45:32,783: EPOCH 18: training on 191080 raw words (135553 effective words) took 0.3s, 413543 effective words/s
INFO - 2023-11-30 16:45:33,127: EPOCH 19: training on 191080 raw words (135522 effective words) took 0.3s, 397612 effective words/s
INFO - 2023-11-30 16:45:33,127: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711971 effective words) took 6.9s, 391083 effective words/s', 'datetime': '2023-11-30T16:45:33.127743', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:33,127: collecting all words and their counts
INFO - 2023-11-30 16:45:33,128: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:33,166: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:33,166: Updating model with new vocabulary
INFO - 2023-11-30 16:45:33,181: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:33.181844', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:33,200: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:33,201: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:33,201: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135542.38419709844 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:45:33.201145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:33,232: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:33,232: updating layer weights
INFO - 2023-11-30 16:45:33,232: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:33.232812', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:33,232: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:33,233: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:33.233117', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:33,592: EPOCH 0: training on 191080 raw words (135712 effective words) took 0.4s, 380746 effective words/s
INFO - 2023-11-30 16:45:33,933: EPOCH 1: training on 191080 raw words (135726 effective words) took 0.3s, 400941 effective words/s
INFO - 2023-11-30 16:45:34,283: EPOCH 2: training on 191080 raw words (135603 effective words) took 0.3s, 390505 effective words/s
INFO - 2023-11-30 16:45:34,616: EPOCH 3: training on 191080 raw words (135495 effective words) took 0.3s, 411030 effective words/s
INFO - 2023-11-30 16:45:35,019: EPOCH 4: training on 191080 raw words (135495 effective words) took 0.4s, 338490 effective words/s
INFO - 2023-11-30 16:45:35,598: EPOCH 5: training on 191080 raw words (135606 effective words) took 0.4s, 356496 effective words/s
INFO - 2023-11-30 16:45:35,943: EPOCH 6: training on 191080 raw words (135468 effective words) took 0.3s, 395843 effective words/s
INFO - 2023-11-30 16:45:36,301: EPOCH 7: training on 191080 raw words (135773 effective words) took 0.4s, 382472 effective words/s
INFO - 2023-11-30 16:45:36,678: EPOCH 8: training on 191080 raw words (135752 effective words) took 0.4s, 363969 effective words/s
INFO - 2023-11-30 16:45:37,013: EPOCH 9: training on 191080 raw words (135693 effective words) took 0.3s, 409641 effective words/s
INFO - 2023-11-30 16:45:37,352: EPOCH 10: training on 191080 raw words (135519 effective words) took 0.3s, 402601 effective words/s
INFO - 2023-11-30 16:45:37,698: EPOCH 11: training on 191080 raw words (135413 effective words) took 0.3s, 395769 effective words/s
INFO - 2023-11-30 16:45:38,065: EPOCH 12: training on 191080 raw words (135625 effective words) took 0.3s, 387779 effective words/s
INFO - 2023-11-30 16:45:38,432: EPOCH 13: training on 191080 raw words (135676 effective words) took 0.4s, 373552 effective words/s
INFO - 2023-11-30 16:45:38,770: EPOCH 14: training on 191080 raw words (135602 effective words) took 0.3s, 405258 effective words/s
INFO - 2023-11-30 16:45:39,106: EPOCH 15: training on 191080 raw words (135554 effective words) took 0.3s, 406188 effective words/s
INFO - 2023-11-30 16:45:39,460: EPOCH 16: training on 191080 raw words (135506 effective words) took 0.3s, 414753 effective words/s
INFO - 2023-11-30 16:45:39,810: EPOCH 17: training on 191080 raw words (135600 effective words) took 0.3s, 390906 effective words/s
INFO - 2023-11-30 16:45:40,157: EPOCH 18: training on 191080 raw words (135520 effective words) took 0.3s, 394731 effective words/s
INFO - 2023-11-30 16:45:40,503: EPOCH 19: training on 191080 raw words (135459 effective words) took 0.3s, 394485 effective words/s
INFO - 2023-11-30 16:45:40,504: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711797 effective words) took 7.3s, 372977 effective words/s', 'datetime': '2023-11-30T16:45:40.503983', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:40,504: collecting all words and their counts
INFO - 2023-11-30 16:45:40,504: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:40,540: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:40,540: Updating model with new vocabulary
INFO - 2023-11-30 16:45:40,555: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:40.555677', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:40,575: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:40,575: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:40,575: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135706.51875879586 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:45:40.575410', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:40,611: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:40,611: updating layer weights
INFO - 2023-11-30 16:45:40,612: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:40.612188', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:40,612: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:40,612: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:40.612603', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:40,986: EPOCH 0: training on 191080 raw words (135528 effective words) took 0.4s, 365304 effective words/s
INFO - 2023-11-30 16:45:41,318: EPOCH 1: training on 191080 raw words (135840 effective words) took 0.3s, 413650 effective words/s
INFO - 2023-11-30 16:45:41,659: EPOCH 2: training on 191080 raw words (135490 effective words) took 0.3s, 400713 effective words/s
INFO - 2023-11-30 16:45:41,989: EPOCH 3: training on 191080 raw words (135599 effective words) took 0.3s, 414953 effective words/s
INFO - 2023-11-30 16:45:42,342: EPOCH 4: training on 191080 raw words (135722 effective words) took 0.3s, 388406 effective words/s
INFO - 2023-11-30 16:45:42,694: EPOCH 5: training on 191080 raw words (135507 effective words) took 0.3s, 388524 effective words/s
INFO - 2023-11-30 16:45:43,039: EPOCH 6: training on 191080 raw words (135599 effective words) took 0.3s, 396804 effective words/s
INFO - 2023-11-30 16:45:43,399: EPOCH 7: training on 191080 raw words (135511 effective words) took 0.4s, 379296 effective words/s
INFO - 2023-11-30 16:45:43,786: EPOCH 8: training on 191080 raw words (135706 effective words) took 0.4s, 353481 effective words/s
INFO - 2023-11-30 16:45:44,133: EPOCH 9: training on 191080 raw words (135616 effective words) took 0.3s, 425470 effective words/s
INFO - 2023-11-30 16:45:44,464: EPOCH 10: training on 191080 raw words (135509 effective words) took 0.3s, 413491 effective words/s
INFO - 2023-11-30 16:45:44,813: EPOCH 11: training on 191080 raw words (135783 effective words) took 0.3s, 392722 effective words/s
INFO - 2023-11-30 16:45:45,141: EPOCH 12: training on 191080 raw words (135694 effective words) took 0.3s, 450974 effective words/s
INFO - 2023-11-30 16:45:45,509: EPOCH 13: training on 191080 raw words (135701 effective words) took 0.4s, 371697 effective words/s
INFO - 2023-11-30 16:45:45,854: EPOCH 14: training on 191080 raw words (135696 effective words) took 0.3s, 417734 effective words/s
INFO - 2023-11-30 16:45:46,183: EPOCH 15: training on 191080 raw words (135345 effective words) took 0.3s, 415756 effective words/s
INFO - 2023-11-30 16:45:46,511: EPOCH 16: training on 191080 raw words (135576 effective words) took 0.3s, 416178 effective words/s
INFO - 2023-11-30 16:45:46,839: EPOCH 17: training on 191080 raw words (135684 effective words) took 0.3s, 451805 effective words/s
INFO - 2023-11-30 16:45:47,157: EPOCH 18: training on 191080 raw words (135684 effective words) took 0.3s, 442715 effective words/s
INFO - 2023-11-30 16:45:47,495: EPOCH 19: training on 191080 raw words (135618 effective words) took 0.3s, 404559 effective words/s
INFO - 2023-11-30 16:45:47,495: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712408 effective words) took 6.9s, 394077 effective words/s', 'datetime': '2023-11-30T16:45:47.495743', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:47,495: collecting all words and their counts
INFO - 2023-11-30 16:45:47,496: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:47,540: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:47,540: Updating model with new vocabulary
INFO - 2023-11-30 16:45:47,556: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:47.556837', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:47,587: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:47,587: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:47,587: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135612.29015709588 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:45:47.587641', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:47,626: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:47,627: updating layer weights
INFO - 2023-11-30 16:45:47,627: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:47.627415', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:47,627: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:47,627: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:47.627749', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:47,971: EPOCH 0: training on 191080 raw words (135734 effective words) took 0.3s, 398696 effective words/s
INFO - 2023-11-30 16:45:48,320: EPOCH 1: training on 191080 raw words (135484 effective words) took 0.3s, 391730 effective words/s
INFO - 2023-11-30 16:45:48,694: EPOCH 2: training on 191080 raw words (135517 effective words) took 0.4s, 364868 effective words/s
INFO - 2023-11-30 16:45:49,049: EPOCH 3: training on 191080 raw words (135436 effective words) took 0.4s, 385605 effective words/s
INFO - 2023-11-30 16:45:49,386: EPOCH 4: training on 191080 raw words (135453 effective words) took 0.3s, 404563 effective words/s
INFO - 2023-11-30 16:45:49,742: EPOCH 5: training on 191080 raw words (135675 effective words) took 0.3s, 417546 effective words/s
INFO - 2023-11-30 16:45:50,080: EPOCH 6: training on 191080 raw words (135497 effective words) took 0.3s, 405233 effective words/s
INFO - 2023-11-30 16:45:50,433: EPOCH 7: training on 191080 raw words (135745 effective words) took 0.4s, 387039 effective words/s
INFO - 2023-11-30 16:45:50,787: EPOCH 8: training on 191080 raw words (135774 effective words) took 0.4s, 387890 effective words/s
INFO - 2023-11-30 16:45:51,132: EPOCH 9: training on 191080 raw words (135610 effective words) took 0.3s, 395710 effective words/s
INFO - 2023-11-30 16:45:51,490: EPOCH 10: training on 191080 raw words (135344 effective words) took 0.4s, 382066 effective words/s
INFO - 2023-11-30 16:45:51,856: EPOCH 11: training on 191080 raw words (135830 effective words) took 0.4s, 373755 effective words/s
INFO - 2023-11-30 16:45:52,204: EPOCH 12: training on 191080 raw words (135449 effective words) took 0.3s, 392961 effective words/s
INFO - 2023-11-30 16:45:52,549: EPOCH 13: training on 191080 raw words (135809 effective words) took 0.3s, 398149 effective words/s
INFO - 2023-11-30 16:45:52,893: EPOCH 14: training on 191080 raw words (135548 effective words) took 0.3s, 397683 effective words/s
INFO - 2023-11-30 16:45:53,248: EPOCH 15: training on 191080 raw words (135832 effective words) took 0.4s, 385926 effective words/s
INFO - 2023-11-30 16:45:53,604: EPOCH 16: training on 191080 raw words (135620 effective words) took 0.4s, 385063 effective words/s
INFO - 2023-11-30 16:45:53,980: EPOCH 17: training on 191080 raw words (135499 effective words) took 0.4s, 363556 effective words/s
INFO - 2023-11-30 16:45:54,397: EPOCH 18: training on 191080 raw words (135657 effective words) took 0.4s, 330906 effective words/s
INFO - 2023-11-30 16:45:54,771: EPOCH 19: training on 191080 raw words (135482 effective words) took 0.4s, 366083 effective words/s
INFO - 2023-11-30 16:45:54,771: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711995 effective words) took 7.1s, 379653 effective words/s', 'datetime': '2023-11-30T16:45:54.771277', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:54,771: collecting all words and their counts
INFO - 2023-11-30 16:45:54,771: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:45:54,819: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:45:54,820: Updating model with new vocabulary
INFO - 2023-11-30 16:45:54,846: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:45:54.846001', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:54,866: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:45:54,866: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:45:54,866: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135627.6772575532 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:45:54.866907', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:45:54,900: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:45:54,900: updating layer weights
INFO - 2023-11-30 16:45:54,901: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:45:54.901285', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:45:54,901: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:45:54,901: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:45:54.901615', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:45:55,248: EPOCH 0: training on 191080 raw words (135670 effective words) took 0.3s, 400422 effective words/s
INFO - 2023-11-30 16:45:55,570: EPOCH 1: training on 191080 raw words (135672 effective words) took 0.3s, 425233 effective words/s
INFO - 2023-11-30 16:45:55,901: EPOCH 2: training on 191080 raw words (135701 effective words) took 0.3s, 413102 effective words/s
INFO - 2023-11-30 16:45:56,229: EPOCH 3: training on 191080 raw words (135588 effective words) took 0.3s, 446146 effective words/s
INFO - 2023-11-30 16:45:56,566: EPOCH 4: training on 191080 raw words (135526 effective words) took 0.3s, 406946 effective words/s
INFO - 2023-11-30 16:45:56,896: EPOCH 5: training on 191080 raw words (135384 effective words) took 0.3s, 413926 effective words/s
INFO - 2023-11-30 16:45:57,258: EPOCH 6: training on 191080 raw words (135715 effective words) took 0.4s, 378022 effective words/s
INFO - 2023-11-30 16:45:57,603: EPOCH 7: training on 191080 raw words (135592 effective words) took 0.3s, 396530 effective words/s
INFO - 2023-11-30 16:45:57,931: EPOCH 8: training on 191080 raw words (135427 effective words) took 0.3s, 416743 effective words/s
INFO - 2023-11-30 16:45:58,250: EPOCH 9: training on 191080 raw words (135626 effective words) took 0.3s, 430013 effective words/s
INFO - 2023-11-30 16:45:58,576: EPOCH 10: training on 191080 raw words (135621 effective words) took 0.3s, 419277 effective words/s
INFO - 2023-11-30 16:45:58,942: EPOCH 11: training on 191080 raw words (135831 effective words) took 0.4s, 374254 effective words/s
INFO - 2023-11-30 16:45:59,271: EPOCH 12: training on 191080 raw words (135587 effective words) took 0.3s, 416672 effective words/s
INFO - 2023-11-30 16:45:59,619: EPOCH 13: training on 191080 raw words (135548 effective words) took 0.3s, 393059 effective words/s
INFO - 2023-11-30 16:45:59,949: EPOCH 14: training on 191080 raw words (135624 effective words) took 0.3s, 435405 effective words/s
INFO - 2023-11-30 16:46:00,278: EPOCH 15: training on 191080 raw words (135604 effective words) took 0.3s, 416084 effective words/s
INFO - 2023-11-30 16:46:00,631: EPOCH 16: training on 191080 raw words (135683 effective words) took 0.3s, 387770 effective words/s
INFO - 2023-11-30 16:46:00,963: EPOCH 17: training on 191080 raw words (135788 effective words) took 0.3s, 412166 effective words/s
INFO - 2023-11-30 16:46:01,295: EPOCH 18: training on 191080 raw words (135491 effective words) took 0.3s, 412671 effective words/s
INFO - 2023-11-30 16:46:01,641: EPOCH 19: training on 191080 raw words (135544 effective words) took 0.3s, 402870 effective words/s
INFO - 2023-11-30 16:46:01,641: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712222 effective words) took 6.7s, 402415 effective words/s', 'datetime': '2023-11-30T16:46:01.641638', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:01,641: collecting all words and their counts
INFO - 2023-11-30 16:46:01,642: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:01,688: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:01,688: Updating model with new vocabulary
INFO - 2023-11-30 16:46:01,707: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:01.707617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:01,741: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:01,741: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:01,742: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135451.24276812596 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:01.742254', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:01,779: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:01,779: updating layer weights
INFO - 2023-11-30 16:46:01,780: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:01.780135', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:01,780: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:01,781: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:01.781123', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:02,142: EPOCH 0: training on 191080 raw words (135529 effective words) took 0.4s, 379389 effective words/s
INFO - 2023-11-30 16:46:02,496: EPOCH 1: training on 191080 raw words (135396 effective words) took 0.4s, 386101 effective words/s
INFO - 2023-11-30 16:46:02,850: EPOCH 2: training on 191080 raw words (135409 effective words) took 0.4s, 386075 effective words/s
INFO - 2023-11-30 16:46:03,200: EPOCH 3: training on 191080 raw words (135623 effective words) took 0.3s, 392713 effective words/s
INFO - 2023-11-30 16:46:03,568: EPOCH 4: training on 191080 raw words (135287 effective words) took 0.4s, 371525 effective words/s
INFO - 2023-11-30 16:46:03,928: EPOCH 5: training on 191080 raw words (135641 effective words) took 0.4s, 380623 effective words/s
INFO - 2023-11-30 16:46:04,332: EPOCH 6: training on 191080 raw words (135336 effective words) took 0.3s, 407263 effective words/s
INFO - 2023-11-30 16:46:04,718: EPOCH 7: training on 191080 raw words (135504 effective words) took 0.4s, 353585 effective words/s
INFO - 2023-11-30 16:46:05,184: EPOCH 8: training on 191080 raw words (135535 effective words) took 0.5s, 293681 effective words/s
INFO - 2023-11-30 16:46:05,719: EPOCH 9: training on 191080 raw words (135427 effective words) took 0.5s, 255245 effective words/s
INFO - 2023-11-30 16:46:06,096: EPOCH 10: training on 191080 raw words (135275 effective words) took 0.4s, 375192 effective words/s
INFO - 2023-11-30 16:46:06,555: EPOCH 11: training on 191080 raw words (135330 effective words) took 0.5s, 297383 effective words/s
INFO - 2023-11-30 16:46:06,980: EPOCH 12: training on 191080 raw words (135470 effective words) took 0.4s, 321207 effective words/s
INFO - 2023-11-30 16:46:07,356: EPOCH 13: training on 191080 raw words (135587 effective words) took 0.4s, 363885 effective words/s
INFO - 2023-11-30 16:46:07,701: EPOCH 14: training on 191080 raw words (135443 effective words) took 0.3s, 396381 effective words/s
INFO - 2023-11-30 16:46:08,059: EPOCH 15: training on 191080 raw words (135375 effective words) took 0.4s, 382306 effective words/s
INFO - 2023-11-30 16:46:08,384: EPOCH 16: training on 191080 raw words (135344 effective words) took 0.3s, 419307 effective words/s
INFO - 2023-11-30 16:46:08,693: EPOCH 17: training on 191080 raw words (135289 effective words) took 0.3s, 442936 effective words/s
INFO - 2023-11-30 16:46:09,027: EPOCH 18: training on 191080 raw words (135443 effective words) took 0.3s, 408323 effective words/s
INFO - 2023-11-30 16:46:09,351: EPOCH 19: training on 191080 raw words (135536 effective words) took 0.3s, 423457 effective words/s
INFO - 2023-11-30 16:46:09,351: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708779 effective words) took 7.6s, 357827 effective words/s', 'datetime': '2023-11-30T16:46:09.351591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:09,351: collecting all words and their counts
INFO - 2023-11-30 16:46:09,352: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:09,393: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:09,393: Updating model with new vocabulary
INFO - 2023-11-30 16:46:09,408: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:09.408169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:09,432: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:09,432: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:46:09,432: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135365.0627575411 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:46:09.432685', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:09,473: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:09,473: updating layer weights
INFO - 2023-11-30 16:46:09,473: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:09.473962', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:09,474: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:09,474: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:09.474221', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:09,784: EPOCH 0: training on 191080 raw words (135526 effective words) took 0.3s, 439926 effective words/s
INFO - 2023-11-30 16:46:10,064: EPOCH 1: training on 191080 raw words (135533 effective words) took 0.3s, 524195 effective words/s
INFO - 2023-11-30 16:46:10,346: EPOCH 2: training on 191080 raw words (135366 effective words) took 0.3s, 485076 effective words/s
INFO - 2023-11-30 16:46:10,626: EPOCH 3: training on 191080 raw words (135234 effective words) took 0.3s, 519751 effective words/s
INFO - 2023-11-30 16:46:10,913: EPOCH 4: training on 191080 raw words (135481 effective words) took 0.3s, 476226 effective words/s
INFO - 2023-11-30 16:46:11,190: EPOCH 5: training on 191080 raw words (135353 effective words) took 0.3s, 493680 effective words/s
INFO - 2023-11-30 16:46:11,481: EPOCH 6: training on 191080 raw words (135576 effective words) took 0.3s, 469612 effective words/s
INFO - 2023-11-30 16:46:11,786: EPOCH 7: training on 191080 raw words (135346 effective words) took 0.3s, 448615 effective words/s
INFO - 2023-11-30 16:46:12,066: EPOCH 8: training on 191080 raw words (135412 effective words) took 0.3s, 487467 effective words/s
INFO - 2023-11-30 16:46:12,344: EPOCH 9: training on 191080 raw words (135469 effective words) took 0.3s, 492831 effective words/s
INFO - 2023-11-30 16:46:12,659: EPOCH 10: training on 191080 raw words (135321 effective words) took 0.3s, 432547 effective words/s
INFO - 2023-11-30 16:46:12,937: EPOCH 11: training on 191080 raw words (135445 effective words) took 0.3s, 492989 effective words/s
INFO - 2023-11-30 16:46:13,215: EPOCH 12: training on 191080 raw words (135393 effective words) took 0.3s, 491371 effective words/s
INFO - 2023-11-30 16:46:13,489: EPOCH 13: training on 191080 raw words (135247 effective words) took 0.3s, 498004 effective words/s
INFO - 2023-11-30 16:46:13,764: EPOCH 14: training on 191080 raw words (135331 effective words) took 0.3s, 496434 effective words/s
INFO - 2023-11-30 16:46:14,044: EPOCH 15: training on 191080 raw words (135187 effective words) took 0.3s, 487121 effective words/s
INFO - 2023-11-30 16:46:14,317: EPOCH 16: training on 191080 raw words (135385 effective words) took 0.3s, 499654 effective words/s
INFO - 2023-11-30 16:46:14,602: EPOCH 17: training on 191080 raw words (135337 effective words) took 0.3s, 479390 effective words/s
INFO - 2023-11-30 16:46:14,880: EPOCH 18: training on 191080 raw words (135483 effective words) took 0.3s, 491281 effective words/s
INFO - 2023-11-30 16:46:15,158: EPOCH 19: training on 191080 raw words (135218 effective words) took 0.3s, 491286 effective words/s
INFO - 2023-11-30 16:46:15,158: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2707643 effective words) took 5.7s, 476336 effective words/s', 'datetime': '2023-11-30T16:46:15.158723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:15,158: collecting all words and their counts
INFO - 2023-11-30 16:46:15,159: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:15,187: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:15,188: Updating model with new vocabulary
INFO - 2023-11-30 16:46:15,201: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:15.201705', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:15,220: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:15,220: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:15,220: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135566.11794415783 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:15.220779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:15,260: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:15,260: updating layer weights
INFO - 2023-11-30 16:46:15,261: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:15.261261', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:15,261: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:15,261: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:15.261553', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:15,564: EPOCH 0: training on 191080 raw words (135545 effective words) took 0.3s, 450942 effective words/s
INFO - 2023-11-30 16:46:15,867: EPOCH 1: training on 191080 raw words (135456 effective words) took 0.3s, 451743 effective words/s
INFO - 2023-11-30 16:46:16,151: EPOCH 2: training on 191080 raw words (135406 effective words) took 0.3s, 480141 effective words/s
INFO - 2023-11-30 16:46:16,441: EPOCH 3: training on 191080 raw words (135422 effective words) took 0.3s, 470673 effective words/s
INFO - 2023-11-30 16:46:16,740: EPOCH 4: training on 191080 raw words (135784 effective words) took 0.3s, 458249 effective words/s
INFO - 2023-11-30 16:46:17,030: EPOCH 5: training on 191080 raw words (135706 effective words) took 0.3s, 472913 effective words/s
INFO - 2023-11-30 16:46:17,324: EPOCH 6: training on 191080 raw words (135718 effective words) took 0.3s, 466087 effective words/s
INFO - 2023-11-30 16:46:17,621: EPOCH 7: training on 191080 raw words (135799 effective words) took 0.3s, 460656 effective words/s
INFO - 2023-11-30 16:46:17,910: EPOCH 8: training on 191080 raw words (135548 effective words) took 0.3s, 473825 effective words/s
INFO - 2023-11-30 16:46:18,226: EPOCH 9: training on 191080 raw words (135368 effective words) took 0.3s, 431323 effective words/s
INFO - 2023-11-30 16:46:18,526: EPOCH 10: training on 191080 raw words (135552 effective words) took 0.3s, 455810 effective words/s
INFO - 2023-11-30 16:46:18,822: EPOCH 11: training on 191080 raw words (135633 effective words) took 0.3s, 461410 effective words/s
INFO - 2023-11-30 16:46:19,110: EPOCH 12: training on 191080 raw words (135495 effective words) took 0.3s, 474432 effective words/s
INFO - 2023-11-30 16:46:19,404: EPOCH 13: training on 191080 raw words (135666 effective words) took 0.3s, 466382 effective words/s
INFO - 2023-11-30 16:46:19,679: EPOCH 14: training on 191080 raw words (135560 effective words) took 0.3s, 496613 effective words/s
INFO - 2023-11-30 16:46:19,958: EPOCH 15: training on 191080 raw words (135681 effective words) took 0.3s, 491852 effective words/s
INFO - 2023-11-30 16:46:20,247: EPOCH 16: training on 191080 raw words (135471 effective words) took 0.3s, 472990 effective words/s
INFO - 2023-11-30 16:46:20,521: EPOCH 17: training on 191080 raw words (135618 effective words) took 0.3s, 499676 effective words/s
INFO - 2023-11-30 16:46:20,848: EPOCH 18: training on 191080 raw words (135609 effective words) took 0.3s, 418310 effective words/s
INFO - 2023-11-30 16:46:21,142: EPOCH 19: training on 191080 raw words (135495 effective words) took 0.3s, 464842 effective words/s
INFO - 2023-11-30 16:46:21,142: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711532 effective words) took 5.9s, 461071 effective words/s', 'datetime': '2023-11-30T16:46:21.142627', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:21,142: collecting all words and their counts
INFO - 2023-11-30 16:46:21,143: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:21,174: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:21,174: Updating model with new vocabulary
INFO - 2023-11-30 16:46:21,186: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:21.186864', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:21,202: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:21,202: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:21,202: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135701.07541491563 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:46:21.202485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:21,225: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:21,225: updating layer weights
INFO - 2023-11-30 16:46:21,225: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:21.225955', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:21,226: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:21,226: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:21.226236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:21,648: EPOCH 0: training on 191080 raw words (135959 effective words) took 0.4s, 324173 effective words/s
INFO - 2023-11-30 16:46:22,032: EPOCH 1: training on 191080 raw words (135630 effective words) took 0.4s, 356197 effective words/s
INFO - 2023-11-30 16:46:22,413: EPOCH 2: training on 191080 raw words (135669 effective words) took 0.4s, 359274 effective words/s
INFO - 2023-11-30 16:46:22,808: EPOCH 3: training on 191080 raw words (135719 effective words) took 0.4s, 346341 effective words/s
INFO - 2023-11-30 16:46:23,428: EPOCH 4: training on 191080 raw words (135755 effective words) took 0.6s, 221092 effective words/s
INFO - 2023-11-30 16:46:23,925: EPOCH 5: training on 191080 raw words (135653 effective words) took 0.5s, 275904 effective words/s
INFO - 2023-11-30 16:46:24,380: EPOCH 6: training on 191080 raw words (135801 effective words) took 0.4s, 302145 effective words/s
INFO - 2023-11-30 16:46:24,811: EPOCH 7: training on 191080 raw words (135983 effective words) took 0.4s, 318941 effective words/s
INFO - 2023-11-30 16:46:25,217: EPOCH 8: training on 191080 raw words (135685 effective words) took 0.4s, 337279 effective words/s
INFO - 2023-11-30 16:46:25,639: EPOCH 9: training on 191080 raw words (135628 effective words) took 0.4s, 347479 effective words/s
INFO - 2023-11-30 16:46:26,034: EPOCH 10: training on 191080 raw words (135779 effective words) took 0.4s, 346795 effective words/s
INFO - 2023-11-30 16:46:26,443: EPOCH 11: training on 191080 raw words (135815 effective words) took 0.4s, 335031 effective words/s
INFO - 2023-11-30 16:46:26,848: EPOCH 12: training on 191080 raw words (135741 effective words) took 0.4s, 337914 effective words/s
INFO - 2023-11-30 16:46:27,276: EPOCH 13: training on 191080 raw words (135689 effective words) took 0.4s, 319914 effective words/s
INFO - 2023-11-30 16:46:27,754: EPOCH 14: training on 191080 raw words (135757 effective words) took 0.5s, 286097 effective words/s
INFO - 2023-11-30 16:46:28,183: EPOCH 15: training on 191080 raw words (135758 effective words) took 0.4s, 319850 effective words/s
INFO - 2023-11-30 16:46:28,608: EPOCH 16: training on 191080 raw words (135588 effective words) took 0.4s, 321550 effective words/s
INFO - 2023-11-30 16:46:29,037: EPOCH 17: training on 191080 raw words (135753 effective words) took 0.4s, 319184 effective words/s
INFO - 2023-11-30 16:46:29,462: EPOCH 18: training on 191080 raw words (135636 effective words) took 0.4s, 322294 effective words/s
INFO - 2023-11-30 16:46:29,892: EPOCH 19: training on 191080 raw words (135601 effective words) took 0.4s, 317516 effective words/s
INFO - 2023-11-30 16:46:29,893: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2714599 effective words) took 8.7s, 313219 effective words/s', 'datetime': '2023-11-30T16:46:29.893153', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:29,893: collecting all words and their counts
INFO - 2023-11-30 16:46:29,893: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:29,946: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:29,946: Updating model with new vocabulary
INFO - 2023-11-30 16:46:29,975: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:29.975432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:30,017: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:30,017: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:30,018: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135445.3498779913 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:30.018092', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:30,070: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:30,070: updating layer weights
INFO - 2023-11-30 16:46:30,071: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:30.071387', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:30,071: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:30,071: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:30.071750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:30,494: EPOCH 0: training on 191080 raw words (135497 effective words) took 0.4s, 322890 effective words/s
INFO - 2023-11-30 16:46:30,891: EPOCH 1: training on 191080 raw words (135552 effective words) took 0.4s, 344170 effective words/s
INFO - 2023-11-30 16:46:31,270: EPOCH 2: training on 191080 raw words (135533 effective words) took 0.4s, 361095 effective words/s
INFO - 2023-11-30 16:46:31,674: EPOCH 3: training on 191080 raw words (135328 effective words) took 0.4s, 337498 effective words/s
INFO - 2023-11-30 16:46:32,258: EPOCH 4: training on 191080 raw words (135635 effective words) took 0.6s, 233456 effective words/s
INFO - 2023-11-30 16:46:32,778: EPOCH 5: training on 191080 raw words (135304 effective words) took 0.5s, 262946 effective words/s
INFO - 2023-11-30 16:46:33,204: EPOCH 6: training on 191080 raw words (135378 effective words) took 0.4s, 321031 effective words/s
INFO - 2023-11-30 16:46:33,649: EPOCH 7: training on 191080 raw words (135632 effective words) took 0.4s, 307508 effective words/s
INFO - 2023-11-30 16:46:34,018: EPOCH 8: training on 191080 raw words (135365 effective words) took 0.4s, 370447 effective words/s
INFO - 2023-11-30 16:46:34,410: EPOCH 9: training on 191080 raw words (135513 effective words) took 0.4s, 348876 effective words/s
INFO - 2023-11-30 16:46:34,789: EPOCH 10: training on 191080 raw words (135377 effective words) took 0.4s, 359993 effective words/s
INFO - 2023-11-30 16:46:35,175: EPOCH 11: training on 191080 raw words (135451 effective words) took 0.4s, 354254 effective words/s
INFO - 2023-11-30 16:46:35,560: EPOCH 12: training on 191080 raw words (135522 effective words) took 0.4s, 354604 effective words/s
INFO - 2023-11-30 16:46:35,989: EPOCH 13: training on 191080 raw words (135463 effective words) took 0.4s, 318450 effective words/s
INFO - 2023-11-30 16:46:36,352: EPOCH 14: training on 191080 raw words (135444 effective words) took 0.4s, 376202 effective words/s
INFO - 2023-11-30 16:46:36,683: EPOCH 15: training on 191080 raw words (135493 effective words) took 0.3s, 413263 effective words/s
INFO - 2023-11-30 16:46:37,000: EPOCH 16: training on 191080 raw words (135662 effective words) took 0.3s, 451873 effective words/s
INFO - 2023-11-30 16:46:37,293: EPOCH 17: training on 191080 raw words (135436 effective words) took 0.3s, 467099 effective words/s
INFO - 2023-11-30 16:46:37,590: EPOCH 18: training on 191080 raw words (135497 effective words) took 0.3s, 460304 effective words/s
INFO - 2023-11-30 16:46:37,888: EPOCH 19: training on 191080 raw words (135435 effective words) took 0.3s, 459204 effective words/s
INFO - 2023-11-30 16:46:37,888: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709517 effective words) took 7.8s, 346647 effective words/s', 'datetime': '2023-11-30T16:46:37.888298', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:37,888: collecting all words and their counts
INFO - 2023-11-30 16:46:37,888: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:37,920: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:37,920: Updating model with new vocabulary
INFO - 2023-11-30 16:46:37,933: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:37.932973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:37,952: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:37,952: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:37,952: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135469.6158644919 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:37.952500', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:37,990: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:37,990: updating layer weights
INFO - 2023-11-30 16:46:37,991: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:37.991199', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:37,991: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:37,991: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:37.991693', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:38,289: EPOCH 0: training on 191080 raw words (135547 effective words) took 0.3s, 459373 effective words/s
INFO - 2023-11-30 16:46:38,580: EPOCH 1: training on 191080 raw words (135494 effective words) took 0.3s, 469821 effective words/s
INFO - 2023-11-30 16:46:38,866: EPOCH 2: training on 191080 raw words (135589 effective words) took 0.3s, 478747 effective words/s
INFO - 2023-11-30 16:46:39,144: EPOCH 3: training on 191080 raw words (135589 effective words) took 0.3s, 492789 effective words/s
INFO - 2023-11-30 16:46:39,427: EPOCH 4: training on 191080 raw words (135311 effective words) took 0.3s, 482390 effective words/s
INFO - 2023-11-30 16:46:39,728: EPOCH 5: training on 191080 raw words (135350 effective words) took 0.3s, 454477 effective words/s
INFO - 2023-11-30 16:46:40,005: EPOCH 6: training on 191080 raw words (135393 effective words) took 0.3s, 492325 effective words/s
INFO - 2023-11-30 16:46:40,300: EPOCH 7: training on 191080 raw words (135655 effective words) took 0.3s, 463579 effective words/s
INFO - 2023-11-30 16:46:40,586: EPOCH 8: training on 191080 raw words (135455 effective words) took 0.3s, 479506 effective words/s
INFO - 2023-11-30 16:46:40,865: EPOCH 9: training on 191080 raw words (135554 effective words) took 0.3s, 490434 effective words/s
INFO - 2023-11-30 16:46:41,142: EPOCH 10: training on 191080 raw words (135703 effective words) took 0.3s, 493269 effective words/s
INFO - 2023-11-30 16:46:41,421: EPOCH 11: training on 191080 raw words (135596 effective words) took 0.3s, 490841 effective words/s
INFO - 2023-11-30 16:46:41,696: EPOCH 12: training on 191080 raw words (135451 effective words) took 0.3s, 497244 effective words/s
INFO - 2023-11-30 16:46:41,972: EPOCH 13: training on 191080 raw words (135442 effective words) took 0.3s, 495208 effective words/s
INFO - 2023-11-30 16:46:42,246: EPOCH 14: training on 191080 raw words (135494 effective words) took 0.3s, 498818 effective words/s
INFO - 2023-11-30 16:46:42,539: EPOCH 15: training on 191080 raw words (135385 effective words) took 0.3s, 467253 effective words/s
INFO - 2023-11-30 16:46:42,821: EPOCH 16: training on 191080 raw words (135376 effective words) took 0.3s, 482969 effective words/s
INFO - 2023-11-30 16:46:43,090: EPOCH 17: training on 191080 raw words (135540 effective words) took 0.3s, 509056 effective words/s
INFO - 2023-11-30 16:46:43,357: EPOCH 18: training on 191080 raw words (135424 effective words) took 0.3s, 510488 effective words/s
INFO - 2023-11-30 16:46:43,637: EPOCH 19: training on 191080 raw words (135594 effective words) took 0.3s, 490188 effective words/s
INFO - 2023-11-30 16:46:43,637: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709942 effective words) took 5.6s, 480019 effective words/s', 'datetime': '2023-11-30T16:46:43.637384', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:43,637: collecting all words and their counts
INFO - 2023-11-30 16:46:43,637: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:43,665: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:43,666: Updating model with new vocabulary
INFO - 2023-11-30 16:46:43,677: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:43.677873', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:43,700: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:43,700: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:46:43,700: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135381.91188524422 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:43.700892', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:43,740: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:43,740: updating layer weights
INFO - 2023-11-30 16:46:43,740: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:43.740839', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:43,741: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:43,741: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:43.741141', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:44,087: EPOCH 0: training on 191080 raw words (135632 effective words) took 0.3s, 394134 effective words/s
INFO - 2023-11-30 16:46:44,387: EPOCH 1: training on 191080 raw words (135443 effective words) took 0.3s, 455341 effective words/s
INFO - 2023-11-30 16:46:44,717: EPOCH 2: training on 191080 raw words (135419 effective words) took 0.3s, 413925 effective words/s
INFO - 2023-11-30 16:46:45,009: EPOCH 3: training on 191080 raw words (135609 effective words) took 0.3s, 482705 effective words/s
INFO - 2023-11-30 16:46:45,303: EPOCH 4: training on 191080 raw words (135466 effective words) took 0.3s, 464375 effective words/s
INFO - 2023-11-30 16:46:45,619: EPOCH 5: training on 191080 raw words (135202 effective words) took 0.3s, 431372 effective words/s
INFO - 2023-11-30 16:46:45,913: EPOCH 6: training on 191080 raw words (135435 effective words) took 0.3s, 464574 effective words/s
INFO - 2023-11-30 16:46:46,198: EPOCH 7: training on 191080 raw words (135193 effective words) took 0.3s, 478358 effective words/s
INFO - 2023-11-30 16:46:46,522: EPOCH 8: training on 191080 raw words (135482 effective words) took 0.3s, 421951 effective words/s
INFO - 2023-11-30 16:46:46,849: EPOCH 9: training on 191080 raw words (135476 effective words) took 0.3s, 416967 effective words/s
INFO - 2023-11-30 16:46:47,182: EPOCH 10: training on 191080 raw words (135462 effective words) took 0.3s, 411616 effective words/s
INFO - 2023-11-30 16:46:47,477: EPOCH 11: training on 191080 raw words (135434 effective words) took 0.3s, 463294 effective words/s
INFO - 2023-11-30 16:46:47,775: EPOCH 12: training on 191080 raw words (135521 effective words) took 0.3s, 457966 effective words/s
INFO - 2023-11-30 16:46:48,112: EPOCH 13: training on 191080 raw words (135405 effective words) took 0.3s, 405953 effective words/s
INFO - 2023-11-30 16:46:48,461: EPOCH 14: training on 191080 raw words (135469 effective words) took 0.3s, 392378 effective words/s
INFO - 2023-11-30 16:46:48,762: EPOCH 15: training on 191080 raw words (135528 effective words) took 0.3s, 453986 effective words/s
INFO - 2023-11-30 16:46:49,080: EPOCH 16: training on 191080 raw words (135227 effective words) took 0.3s, 429480 effective words/s
INFO - 2023-11-30 16:46:49,366: EPOCH 17: training on 191080 raw words (135391 effective words) took 0.3s, 476063 effective words/s
INFO - 2023-11-30 16:46:49,673: EPOCH 18: training on 191080 raw words (135291 effective words) took 0.3s, 445357 effective words/s
INFO - 2023-11-30 16:46:49,984: EPOCH 19: training on 191080 raw words (135258 effective words) took 0.3s, 438827 effective words/s
INFO - 2023-11-30 16:46:49,984: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708343 effective words) took 6.2s, 433789 effective words/s', 'datetime': '2023-11-30T16:46:49.984716', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:49,984: collecting all words and their counts
INFO - 2023-11-30 16:46:49,985: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:50,015: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:50,015: Updating model with new vocabulary
INFO - 2023-11-30 16:46:50,028: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:50.028580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:50,044: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:50,045: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:50,045: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135293.6687299468 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:46:50.045301', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:50,070: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:50,070: updating layer weights
INFO - 2023-11-30 16:46:50,071: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:50.070995', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:50,071: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:50,071: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:50.071454', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:50,358: EPOCH 0: training on 191080 raw words (135430 effective words) took 0.3s, 476826 effective words/s
INFO - 2023-11-30 16:46:50,655: EPOCH 1: training on 191080 raw words (135255 effective words) took 0.3s, 458888 effective words/s
INFO - 2023-11-30 16:46:50,950: EPOCH 2: training on 191080 raw words (135491 effective words) took 0.3s, 464397 effective words/s
INFO - 2023-11-30 16:46:51,247: EPOCH 3: training on 191080 raw words (135328 effective words) took 0.3s, 459740 effective words/s
INFO - 2023-11-30 16:46:51,598: EPOCH 4: training on 191080 raw words (135477 effective words) took 0.3s, 388619 effective words/s
INFO - 2023-11-30 16:46:51,942: EPOCH 5: training on 191080 raw words (135339 effective words) took 0.3s, 396415 effective words/s
INFO - 2023-11-30 16:46:52,249: EPOCH 6: training on 191080 raw words (135301 effective words) took 0.3s, 446182 effective words/s
INFO - 2023-11-30 16:46:52,536: EPOCH 7: training on 191080 raw words (135286 effective words) took 0.3s, 474914 effective words/s
INFO - 2023-11-30 16:46:52,822: EPOCH 8: training on 191080 raw words (135210 effective words) took 0.3s, 477152 effective words/s
INFO - 2023-11-30 16:46:53,108: EPOCH 9: training on 191080 raw words (135095 effective words) took 0.3s, 475837 effective words/s
INFO - 2023-11-30 16:46:53,504: EPOCH 10: training on 191080 raw words (135252 effective words) took 0.4s, 345326 effective words/s
INFO - 2023-11-30 16:46:53,946: EPOCH 11: training on 191080 raw words (135227 effective words) took 0.4s, 308774 effective words/s
INFO - 2023-11-30 16:46:54,360: EPOCH 12: training on 191080 raw words (135217 effective words) took 0.4s, 329180 effective words/s
INFO - 2023-11-30 16:46:54,930: EPOCH 13: training on 191080 raw words (135284 effective words) took 0.6s, 239485 effective words/s
INFO - 2023-11-30 16:46:55,435: EPOCH 14: training on 191080 raw words (135455 effective words) took 0.5s, 270050 effective words/s
INFO - 2023-11-30 16:46:55,975: EPOCH 15: training on 191080 raw words (135051 effective words) took 0.5s, 252484 effective words/s
INFO - 2023-11-30 16:46:56,513: EPOCH 16: training on 191080 raw words (135285 effective words) took 0.5s, 253383 effective words/s
INFO - 2023-11-30 16:46:57,042: EPOCH 17: training on 191080 raw words (135271 effective words) took 0.5s, 257465 effective words/s
INFO - 2023-11-30 16:46:57,650: EPOCH 18: training on 191080 raw words (135483 effective words) took 0.6s, 224798 effective words/s
INFO - 2023-11-30 16:46:58,106: EPOCH 19: training on 191080 raw words (135375 effective words) took 0.5s, 300658 effective words/s
INFO - 2023-11-30 16:46:58,106: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2706112 effective words) took 8.0s, 336792 effective words/s', 'datetime': '2023-11-30T16:46:58.106581', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:58,106: collecting all words and their counts
INFO - 2023-11-30 16:46:58,107: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:46:58,173: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:46:58,174: Updating model with new vocabulary
INFO - 2023-11-30 16:46:58,207: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:46:58.207933', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:58,234: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:46:58,234: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:46:58,235: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135466.06623217434 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:46:58.235186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:46:58,284: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:46:58,284: updating layer weights
INFO - 2023-11-30 16:46:58,285: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:46:58.285297', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:46:58,285: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:46:58,285: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:46:58.285671', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:46:58,818: EPOCH 0: training on 191080 raw words (135617 effective words) took 0.5s, 256638 effective words/s
INFO - 2023-11-30 16:46:59,419: EPOCH 1: training on 191080 raw words (135370 effective words) took 0.6s, 226906 effective words/s
INFO - 2023-11-30 16:46:59,921: EPOCH 2: training on 191080 raw words (135638 effective words) took 0.5s, 272052 effective words/s
INFO - 2023-11-30 16:47:00,501: EPOCH 3: training on 191080 raw words (135457 effective words) took 0.6s, 235433 effective words/s
INFO - 2023-11-30 16:47:01,137: EPOCH 4: training on 191080 raw words (135371 effective words) took 0.6s, 215135 effective words/s
INFO - 2023-11-30 16:47:01,770: EPOCH 5: training on 191080 raw words (135606 effective words) took 0.6s, 216155 effective words/s
INFO - 2023-11-30 16:47:02,458: EPOCH 6: training on 191080 raw words (135533 effective words) took 0.7s, 198380 effective words/s
INFO - 2023-11-30 16:47:02,897: EPOCH 7: training on 191080 raw words (135426 effective words) took 0.4s, 311880 effective words/s
INFO - 2023-11-30 16:47:03,316: EPOCH 8: training on 191080 raw words (135426 effective words) took 0.4s, 325037 effective words/s
INFO - 2023-11-30 16:47:03,701: EPOCH 9: training on 191080 raw words (135472 effective words) took 0.4s, 354887 effective words/s
INFO - 2023-11-30 16:47:04,034: EPOCH 10: training on 191080 raw words (135483 effective words) took 0.3s, 410408 effective words/s
INFO - 2023-11-30 16:47:04,440: EPOCH 11: training on 191080 raw words (135348 effective words) took 0.4s, 336248 effective words/s
INFO - 2023-11-30 16:47:04,785: EPOCH 12: training on 191080 raw words (135596 effective words) took 0.3s, 396120 effective words/s
INFO - 2023-11-30 16:47:05,111: EPOCH 13: training on 191080 raw words (135595 effective words) took 0.3s, 418798 effective words/s
INFO - 2023-11-30 16:47:05,490: EPOCH 14: training on 191080 raw words (135523 effective words) took 0.4s, 360806 effective words/s
INFO - 2023-11-30 16:47:05,869: EPOCH 15: training on 191080 raw words (135392 effective words) took 0.4s, 360380 effective words/s
INFO - 2023-11-30 16:47:06,199: EPOCH 16: training on 191080 raw words (135456 effective words) took 0.3s, 419143 effective words/s
INFO - 2023-11-30 16:47:06,559: EPOCH 17: training on 191080 raw words (135421 effective words) took 0.4s, 379156 effective words/s
INFO - 2023-11-30 16:47:06,931: EPOCH 18: training on 191080 raw words (135336 effective words) took 0.4s, 367544 effective words/s
INFO - 2023-11-30 16:47:07,283: EPOCH 19: training on 191080 raw words (135436 effective words) took 0.3s, 388182 effective words/s
INFO - 2023-11-30 16:47:07,283: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709502 effective words) took 9.0s, 301132 effective words/s', 'datetime': '2023-11-30T16:47:07.283588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:07,283: collecting all words and their counts
INFO - 2023-11-30 16:47:07,284: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:07,313: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:07,313: Updating model with new vocabulary
INFO - 2023-11-30 16:47:07,326: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:07.326767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:07,343: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:07,343: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:07,344: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135559.57648485128 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:47:07.344164', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:07,368: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:07,368: updating layer weights
INFO - 2023-11-30 16:47:07,368: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:07.368749', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:07,368: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:07,368: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:07.368975', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:07,662: EPOCH 0: training on 191080 raw words (135520 effective words) took 0.3s, 467171 effective words/s
INFO - 2023-11-30 16:47:07,956: EPOCH 1: training on 191080 raw words (135760 effective words) took 0.3s, 465841 effective words/s
INFO - 2023-11-30 16:47:08,248: EPOCH 2: training on 191080 raw words (135705 effective words) took 0.3s, 468854 effective words/s
INFO - 2023-11-30 16:47:08,545: EPOCH 3: training on 191080 raw words (135594 effective words) took 0.3s, 460834 effective words/s
INFO - 2023-11-30 16:47:08,830: EPOCH 4: training on 191080 raw words (135476 effective words) took 0.3s, 478278 effective words/s
INFO - 2023-11-30 16:47:09,144: EPOCH 5: training on 191080 raw words (135689 effective words) took 0.3s, 436146 effective words/s
INFO - 2023-11-30 16:47:09,527: EPOCH 6: training on 191080 raw words (135487 effective words) took 0.4s, 355641 effective words/s
INFO - 2023-11-30 16:47:09,828: EPOCH 7: training on 191080 raw words (135524 effective words) took 0.3s, 455436 effective words/s
INFO - 2023-11-30 16:47:10,134: EPOCH 8: training on 191080 raw words (135680 effective words) took 0.3s, 447474 effective words/s
INFO - 2023-11-30 16:47:10,441: EPOCH 9: training on 191080 raw words (135530 effective words) took 0.3s, 444550 effective words/s
INFO - 2023-11-30 16:47:10,732: EPOCH 10: training on 191080 raw words (135323 effective words) took 0.3s, 468545 effective words/s
INFO - 2023-11-30 16:47:11,043: EPOCH 11: training on 191080 raw words (135437 effective words) took 0.3s, 439252 effective words/s
INFO - 2023-11-30 16:47:11,393: EPOCH 12: training on 191080 raw words (135590 effective words) took 0.3s, 390146 effective words/s
INFO - 2023-11-30 16:47:11,729: EPOCH 13: training on 191080 raw words (135638 effective words) took 0.3s, 408281 effective words/s
INFO - 2023-11-30 16:47:12,106: EPOCH 14: training on 191080 raw words (135550 effective words) took 0.4s, 362010 effective words/s
INFO - 2023-11-30 16:47:12,429: EPOCH 15: training on 191080 raw words (135699 effective words) took 0.3s, 424342 effective words/s
INFO - 2023-11-30 16:47:12,783: EPOCH 16: training on 191080 raw words (135543 effective words) took 0.4s, 386161 effective words/s
INFO - 2023-11-30 16:47:13,058: EPOCH 17: training on 191080 raw words (135517 effective words) took 0.3s, 497637 effective words/s
INFO - 2023-11-30 16:47:13,359: EPOCH 18: training on 191080 raw words (135391 effective words) took 0.3s, 454688 effective words/s
INFO - 2023-11-30 16:47:13,644: EPOCH 19: training on 191080 raw words (135480 effective words) took 0.3s, 478775 effective words/s
INFO - 2023-11-30 16:47:13,645: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711133 effective words) took 6.3s, 431986 effective words/s', 'datetime': '2023-11-30T16:47:13.645100', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:13,645: collecting all words and their counts
INFO - 2023-11-30 16:47:13,645: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:13,681: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:13,681: Updating model with new vocabulary
INFO - 2023-11-30 16:47:13,694: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:13.694908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:13,710: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:13,711: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:47:13,711: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135523.4631968682 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:47:13.711401', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:13,747: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:13,748: updating layer weights
INFO - 2023-11-30 16:47:13,748: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:13.748580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:13,748: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:13,748: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:13.748856', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:14,061: EPOCH 0: training on 191080 raw words (135542 effective words) took 0.3s, 462815 effective words/s
INFO - 2023-11-30 16:47:14,436: EPOCH 1: training on 191080 raw words (135686 effective words) took 0.4s, 364636 effective words/s
INFO - 2023-11-30 16:47:14,780: EPOCH 2: training on 191080 raw words (135450 effective words) took 0.3s, 404617 effective words/s
INFO - 2023-11-30 16:47:15,136: EPOCH 3: training on 191080 raw words (135524 effective words) took 0.4s, 383895 effective words/s
INFO - 2023-11-30 16:47:15,573: EPOCH 4: training on 191080 raw words (135484 effective words) took 0.4s, 312578 effective words/s
INFO - 2023-11-30 16:47:16,004: EPOCH 5: training on 191080 raw words (135586 effective words) took 0.4s, 316765 effective words/s
INFO - 2023-11-30 16:47:16,436: EPOCH 6: training on 191080 raw words (135477 effective words) took 0.4s, 316649 effective words/s
INFO - 2023-11-30 16:47:16,781: EPOCH 7: training on 191080 raw words (135440 effective words) took 0.3s, 395617 effective words/s
INFO - 2023-11-30 16:47:17,179: EPOCH 8: training on 191080 raw words (135271 effective words) took 0.4s, 341852 effective words/s
INFO - 2023-11-30 16:47:17,513: EPOCH 9: training on 191080 raw words (135611 effective words) took 0.3s, 409860 effective words/s
INFO - 2023-11-30 16:47:17,913: EPOCH 10: training on 191080 raw words (135513 effective words) took 0.4s, 341164 effective words/s
INFO - 2023-11-30 16:47:18,303: EPOCH 11: training on 191080 raw words (135453 effective words) took 0.4s, 350126 effective words/s
INFO - 2023-11-30 16:47:18,760: EPOCH 12: training on 191080 raw words (135521 effective words) took 0.5s, 298718 effective words/s
INFO - 2023-11-30 16:47:19,132: EPOCH 13: training on 191080 raw words (135600 effective words) took 0.4s, 368006 effective words/s
INFO - 2023-11-30 16:47:19,508: EPOCH 14: training on 191080 raw words (135617 effective words) took 0.4s, 363822 effective words/s
INFO - 2023-11-30 16:47:19,899: EPOCH 15: training on 191080 raw words (135516 effective words) took 0.4s, 348348 effective words/s
INFO - 2023-11-30 16:47:20,270: EPOCH 16: training on 191080 raw words (135286 effective words) took 0.4s, 383917 effective words/s
INFO - 2023-11-30 16:47:20,637: EPOCH 17: training on 191080 raw words (135676 effective words) took 0.4s, 372883 effective words/s
INFO - 2023-11-30 16:47:21,006: EPOCH 18: training on 191080 raw words (135379 effective words) took 0.4s, 369872 effective words/s
INFO - 2023-11-30 16:47:21,380: EPOCH 19: training on 191080 raw words (135449 effective words) took 0.4s, 386970 effective words/s
INFO - 2023-11-30 16:47:21,380: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710081 effective words) took 7.6s, 355115 effective words/s', 'datetime': '2023-11-30T16:47:21.380555', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:21,380: collecting all words and their counts
INFO - 2023-11-30 16:47:21,381: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:21,436: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:21,436: Updating model with new vocabulary
INFO - 2023-11-30 16:47:21,463: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:21.463893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:21,487: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:21,487: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:21,488: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135746.79181770913 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:47:21.488122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:21,529: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:21,529: updating layer weights
INFO - 2023-11-30 16:47:21,530: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:21.530548', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:21,530: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:21,530: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:21.530921', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:21,897: EPOCH 0: training on 191080 raw words (135722 effective words) took 0.4s, 374795 effective words/s
INFO - 2023-11-30 16:47:22,259: EPOCH 1: training on 191080 raw words (135604 effective words) took 0.4s, 377674 effective words/s
INFO - 2023-11-30 16:47:22,620: EPOCH 2: training on 191080 raw words (135623 effective words) took 0.4s, 378074 effective words/s
INFO - 2023-11-30 16:47:22,988: EPOCH 3: training on 191080 raw words (135818 effective words) took 0.4s, 373161 effective words/s
INFO - 2023-11-30 16:47:23,361: EPOCH 4: training on 191080 raw words (135619 effective words) took 0.4s, 366315 effective words/s
INFO - 2023-11-30 16:47:23,734: EPOCH 5: training on 191080 raw words (135667 effective words) took 0.4s, 367038 effective words/s
INFO - 2023-11-30 16:47:24,119: EPOCH 6: training on 191080 raw words (135887 effective words) took 0.4s, 356275 effective words/s
INFO - 2023-11-30 16:47:24,575: EPOCH 7: training on 191080 raw words (135708 effective words) took 0.5s, 299735 effective words/s
INFO - 2023-11-30 16:47:24,985: EPOCH 8: training on 191080 raw words (135857 effective words) took 0.4s, 334755 effective words/s
INFO - 2023-11-30 16:47:25,397: EPOCH 9: training on 191080 raw words (135789 effective words) took 0.4s, 332573 effective words/s
INFO - 2023-11-30 16:47:25,857: EPOCH 10: training on 191080 raw words (135812 effective words) took 0.5s, 297401 effective words/s
INFO - 2023-11-30 16:47:26,262: EPOCH 11: training on 191080 raw words (135788 effective words) took 0.4s, 337884 effective words/s
INFO - 2023-11-30 16:47:26,694: EPOCH 12: training on 191080 raw words (135579 effective words) took 0.4s, 317201 effective words/s
INFO - 2023-11-30 16:47:26,984: EPOCH 13: training on 191080 raw words (135749 effective words) took 0.3s, 471791 effective words/s
INFO - 2023-11-30 16:47:27,341: EPOCH 14: training on 191080 raw words (135878 effective words) took 0.4s, 384342 effective words/s
INFO - 2023-11-30 16:47:27,647: EPOCH 15: training on 191080 raw words (135697 effective words) took 0.3s, 447808 effective words/s
INFO - 2023-11-30 16:47:27,957: EPOCH 16: training on 191080 raw words (135781 effective words) took 0.3s, 442096 effective words/s
INFO - 2023-11-30 16:47:28,258: EPOCH 17: training on 191080 raw words (135829 effective words) took 0.3s, 454741 effective words/s
INFO - 2023-11-30 16:47:28,545: EPOCH 18: training on 191080 raw words (135865 effective words) took 0.3s, 477688 effective words/s
INFO - 2023-11-30 16:47:28,864: EPOCH 19: training on 191080 raw words (135679 effective words) took 0.3s, 428459 effective words/s
INFO - 2023-11-30 16:47:28,864: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2714951 effective words) took 7.3s, 370210 effective words/s', 'datetime': '2023-11-30T16:47:28.864626', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:28,864: collecting all words and their counts
INFO - 2023-11-30 16:47:28,865: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:28,895: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:28,895: Updating model with new vocabulary
INFO - 2023-11-30 16:47:28,908: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:28.908505', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:28,925: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:28,925: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:28,926: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135577.3032687389 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:47:28.926024', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:28,951: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:28,951: updating layer weights
INFO - 2023-11-30 16:47:28,951: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:28.951725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:28,951: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:28,952: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:28.952040', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:29,262: EPOCH 0: training on 191080 raw words (135713 effective words) took 0.3s, 440977 effective words/s
INFO - 2023-11-30 16:47:29,582: EPOCH 1: training on 191080 raw words (135577 effective words) took 0.3s, 427011 effective words/s
INFO - 2023-11-30 16:47:29,901: EPOCH 2: training on 191080 raw words (135711 effective words) took 0.3s, 429953 effective words/s
INFO - 2023-11-30 16:47:30,215: EPOCH 3: training on 191080 raw words (135588 effective words) took 0.3s, 437447 effective words/s
INFO - 2023-11-30 16:47:30,529: EPOCH 4: training on 191080 raw words (135735 effective words) took 0.3s, 434761 effective words/s
INFO - 2023-11-30 16:47:30,825: EPOCH 5: training on 191080 raw words (135368 effective words) took 0.3s, 461161 effective words/s
INFO - 2023-11-30 16:47:31,147: EPOCH 6: training on 191080 raw words (135377 effective words) took 0.3s, 424983 effective words/s
INFO - 2023-11-30 16:47:31,440: EPOCH 7: training on 191080 raw words (135665 effective words) took 0.3s, 467573 effective words/s
INFO - 2023-11-30 16:47:31,772: EPOCH 8: training on 191080 raw words (135496 effective words) took 0.3s, 410786 effective words/s
INFO - 2023-11-30 16:47:32,072: EPOCH 9: training on 191080 raw words (135677 effective words) took 0.3s, 457591 effective words/s
INFO - 2023-11-30 16:47:32,369: EPOCH 10: training on 191080 raw words (135778 effective words) took 0.3s, 461792 effective words/s
INFO - 2023-11-30 16:47:32,680: EPOCH 11: training on 191080 raw words (135542 effective words) took 0.3s, 438660 effective words/s
INFO - 2023-11-30 16:47:33,139: EPOCH 12: training on 191080 raw words (135603 effective words) took 0.5s, 297942 effective words/s
INFO - 2023-11-30 16:47:33,477: EPOCH 13: training on 191080 raw words (135451 effective words) took 0.3s, 403425 effective words/s
INFO - 2023-11-30 16:47:33,799: EPOCH 14: training on 191080 raw words (135561 effective words) took 0.3s, 425853 effective words/s
INFO - 2023-11-30 16:47:34,107: EPOCH 15: training on 191080 raw words (135577 effective words) took 0.3s, 444060 effective words/s
INFO - 2023-11-30 16:47:34,459: EPOCH 16: training on 191080 raw words (135788 effective words) took 0.3s, 388465 effective words/s
INFO - 2023-11-30 16:47:34,794: EPOCH 17: training on 191080 raw words (135482 effective words) took 0.3s, 408201 effective words/s
INFO - 2023-11-30 16:47:35,114: EPOCH 18: training on 191080 raw words (135633 effective words) took 0.3s, 426244 effective words/s
INFO - 2023-11-30 16:47:35,506: EPOCH 19: training on 191080 raw words (135854 effective words) took 0.4s, 356093 effective words/s
INFO - 2023-11-30 16:47:35,506: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712176 effective words) took 6.6s, 413784 effective words/s', 'datetime': '2023-11-30T16:47:35.506808', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:35,506: collecting all words and their counts
INFO - 2023-11-30 16:47:35,507: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:35,534: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:35,535: Updating model with new vocabulary
INFO - 2023-11-30 16:47:35,550: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:35.550672', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:35,566: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:35,566: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:35,566: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135455.1175432277 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:47:35.566479', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:35,590: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:35,590: updating layer weights
INFO - 2023-11-30 16:47:35,590: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:35.590816', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:35,590: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:35,591: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:35.591068', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:35,909: EPOCH 0: training on 191080 raw words (135313 effective words) took 0.3s, 428974 effective words/s
INFO - 2023-11-30 16:47:36,241: EPOCH 1: training on 191080 raw words (135635 effective words) took 0.3s, 411765 effective words/s
INFO - 2023-11-30 16:47:36,615: EPOCH 2: training on 191080 raw words (135583 effective words) took 0.4s, 368275 effective words/s
INFO - 2023-11-30 16:47:36,991: EPOCH 3: training on 191080 raw words (135159 effective words) took 0.4s, 362457 effective words/s
INFO - 2023-11-30 16:47:37,418: EPOCH 4: training on 191080 raw words (135467 effective words) took 0.4s, 319906 effective words/s
INFO - 2023-11-30 16:47:37,762: EPOCH 5: training on 191080 raw words (135505 effective words) took 0.3s, 396176 effective words/s
INFO - 2023-11-30 16:47:38,114: EPOCH 6: training on 191080 raw words (135528 effective words) took 0.3s, 390470 effective words/s
INFO - 2023-11-30 16:47:38,462: EPOCH 7: training on 191080 raw words (135411 effective words) took 0.3s, 392765 effective words/s
INFO - 2023-11-30 16:47:38,850: EPOCH 8: training on 191080 raw words (135506 effective words) took 0.4s, 351518 effective words/s
INFO - 2023-11-30 16:47:39,261: EPOCH 9: training on 191080 raw words (135638 effective words) took 0.4s, 332325 effective words/s
INFO - 2023-11-30 16:47:39,669: EPOCH 10: training on 191080 raw words (135457 effective words) took 0.4s, 334508 effective words/s
INFO - 2023-11-30 16:47:39,972: EPOCH 11: training on 191080 raw words (135403 effective words) took 0.3s, 451710 effective words/s
INFO - 2023-11-30 16:47:40,265: EPOCH 12: training on 191080 raw words (135568 effective words) took 0.3s, 467938 effective words/s
INFO - 2023-11-30 16:47:40,574: EPOCH 13: training on 191080 raw words (135550 effective words) took 0.3s, 442354 effective words/s
INFO - 2023-11-30 16:47:40,930: EPOCH 14: training on 191080 raw words (135263 effective words) took 0.4s, 382732 effective words/s
INFO - 2023-11-30 16:47:41,238: EPOCH 15: training on 191080 raw words (135574 effective words) took 0.3s, 443520 effective words/s
INFO - 2023-11-30 16:47:41,542: EPOCH 16: training on 191080 raw words (135254 effective words) took 0.3s, 449470 effective words/s
INFO - 2023-11-30 16:47:41,855: EPOCH 17: training on 191080 raw words (135551 effective words) took 0.3s, 437215 effective words/s
INFO - 2023-11-30 16:47:42,245: EPOCH 18: training on 191080 raw words (135454 effective words) took 0.4s, 350606 effective words/s
INFO - 2023-11-30 16:47:42,670: EPOCH 19: training on 191080 raw words (135531 effective words) took 0.4s, 321499 effective words/s
INFO - 2023-11-30 16:47:42,670: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709350 effective words) took 7.1s, 382720 effective words/s', 'datetime': '2023-11-30T16:47:42.670403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:42,670: collecting all words and their counts
INFO - 2023-11-30 16:47:42,671: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:42,718: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:42,719: Updating model with new vocabulary
INFO - 2023-11-30 16:47:42,737: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:42.737764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:42,762: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:42,762: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:42,763: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135521.27693611782 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:47:42.762957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:42,797: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:42,797: updating layer weights
INFO - 2023-11-30 16:47:42,798: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:42.798200', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:42,798: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:42,798: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:42.798675', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:43,206: EPOCH 0: training on 191080 raw words (135478 effective words) took 0.4s, 334876 effective words/s
INFO - 2023-11-30 16:47:43,636: EPOCH 1: training on 191080 raw words (135264 effective words) took 0.4s, 317174 effective words/s
INFO - 2023-11-30 16:47:44,055: EPOCH 2: training on 191080 raw words (135544 effective words) took 0.4s, 326136 effective words/s
INFO - 2023-11-30 16:47:44,476: EPOCH 3: training on 191080 raw words (135427 effective words) took 0.4s, 324948 effective words/s
INFO - 2023-11-30 16:47:44,909: EPOCH 4: training on 191080 raw words (135552 effective words) took 0.4s, 315454 effective words/s
INFO - 2023-11-30 16:47:45,381: EPOCH 5: training on 191080 raw words (135512 effective words) took 0.5s, 289516 effective words/s
INFO - 2023-11-30 16:47:45,849: EPOCH 6: training on 191080 raw words (135463 effective words) took 0.5s, 292080 effective words/s
INFO - 2023-11-30 16:47:46,257: EPOCH 7: training on 191080 raw words (135414 effective words) took 0.4s, 334412 effective words/s
INFO - 2023-11-30 16:47:46,727: EPOCH 8: training on 191080 raw words (135445 effective words) took 0.5s, 290218 effective words/s
INFO - 2023-11-30 16:47:47,149: EPOCH 9: training on 191080 raw words (135484 effective words) took 0.4s, 324289 effective words/s
INFO - 2023-11-30 16:47:47,564: EPOCH 10: training on 191080 raw words (135534 effective words) took 0.4s, 329074 effective words/s
INFO - 2023-11-30 16:47:47,982: EPOCH 11: training on 191080 raw words (135393 effective words) took 0.4s, 327290 effective words/s
INFO - 2023-11-30 16:47:48,427: EPOCH 12: training on 191080 raw words (135407 effective words) took 0.4s, 306542 effective words/s
INFO - 2023-11-30 16:47:48,879: EPOCH 13: training on 191080 raw words (135639 effective words) took 0.4s, 303339 effective words/s
INFO - 2023-11-30 16:47:49,366: EPOCH 14: training on 191080 raw words (135477 effective words) took 0.5s, 280179 effective words/s
INFO - 2023-11-30 16:47:49,790: EPOCH 15: training on 191080 raw words (135609 effective words) took 0.4s, 322530 effective words/s
INFO - 2023-11-30 16:47:50,279: EPOCH 16: training on 191080 raw words (135417 effective words) took 0.4s, 328182 effective words/s
INFO - 2023-11-30 16:47:50,698: EPOCH 17: training on 191080 raw words (135422 effective words) took 0.4s, 325915 effective words/s
INFO - 2023-11-30 16:47:51,084: EPOCH 18: training on 191080 raw words (135633 effective words) took 0.4s, 355362 effective words/s
INFO - 2023-11-30 16:47:51,456: EPOCH 19: training on 191080 raw words (135522 effective words) took 0.4s, 367262 effective words/s
INFO - 2023-11-30 16:47:51,457: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709636 effective words) took 8.7s, 312956 effective words/s', 'datetime': '2023-11-30T16:47:51.457143', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:51,457: collecting all words and their counts
INFO - 2023-11-30 16:47:51,457: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:51,502: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:51,502: Updating model with new vocabulary
INFO - 2023-11-30 16:47:51,527: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:51.527713', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:51,550: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:51,550: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:51,551: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135710.4542983493 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:47:51.551157', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:51,585: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:51,585: updating layer weights
INFO - 2023-11-30 16:47:51,586: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:51.586245', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:51,586: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:51,586: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:51.586551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:51,924: EPOCH 0: training on 191080 raw words (135792 effective words) took 0.3s, 405120 effective words/s
INFO - 2023-11-30 16:47:52,260: EPOCH 1: training on 191080 raw words (135586 effective words) took 0.3s, 406432 effective words/s
INFO - 2023-11-30 16:47:52,639: EPOCH 2: training on 191080 raw words (135582 effective words) took 0.4s, 361008 effective words/s
INFO - 2023-11-30 16:47:52,979: EPOCH 3: training on 191080 raw words (135630 effective words) took 0.3s, 403224 effective words/s
INFO - 2023-11-30 16:47:53,304: EPOCH 4: training on 191080 raw words (135682 effective words) took 0.3s, 420668 effective words/s
INFO - 2023-11-30 16:47:53,644: EPOCH 5: training on 191080 raw words (135576 effective words) took 0.3s, 403165 effective words/s
INFO - 2023-11-30 16:47:53,982: EPOCH 6: training on 191080 raw words (135643 effective words) took 0.3s, 404886 effective words/s
INFO - 2023-11-30 16:47:54,316: EPOCH 7: training on 191080 raw words (135592 effective words) took 0.3s, 409912 effective words/s
INFO - 2023-11-30 16:47:54,676: EPOCH 8: training on 191080 raw words (135638 effective words) took 0.3s, 414527 effective words/s
INFO - 2023-11-30 16:47:55,017: EPOCH 9: training on 191080 raw words (135856 effective words) took 0.3s, 401550 effective words/s
INFO - 2023-11-30 16:47:55,370: EPOCH 10: training on 191080 raw words (135440 effective words) took 0.3s, 387957 effective words/s
INFO - 2023-11-30 16:47:55,712: EPOCH 11: training on 191080 raw words (135692 effective words) took 0.3s, 400345 effective words/s
INFO - 2023-11-30 16:47:56,042: EPOCH 12: training on 191080 raw words (135805 effective words) took 0.3s, 415808 effective words/s
INFO - 2023-11-30 16:47:56,382: EPOCH 13: training on 191080 raw words (135721 effective words) took 0.3s, 402837 effective words/s
INFO - 2023-11-30 16:47:56,717: EPOCH 14: training on 191080 raw words (135900 effective words) took 0.3s, 410721 effective words/s
INFO - 2023-11-30 16:47:57,050: EPOCH 15: training on 191080 raw words (135707 effective words) took 0.3s, 411474 effective words/s
INFO - 2023-11-30 16:47:57,389: EPOCH 16: training on 191080 raw words (135637 effective words) took 0.3s, 403974 effective words/s
INFO - 2023-11-30 16:47:57,757: EPOCH 17: training on 191080 raw words (135735 effective words) took 0.4s, 372795 effective words/s
INFO - 2023-11-30 16:47:58,132: EPOCH 18: training on 191080 raw words (135754 effective words) took 0.4s, 365088 effective words/s
INFO - 2023-11-30 16:47:58,461: EPOCH 19: training on 191080 raw words (135959 effective words) took 0.3s, 416873 effective words/s
INFO - 2023-11-30 16:47:58,462: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2713927 effective words) took 6.9s, 394727 effective words/s', 'datetime': '2023-11-30T16:47:58.462159', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:58,462: collecting all words and their counts
INFO - 2023-11-30 16:47:58,462: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:47:58,522: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:47:58,523: Updating model with new vocabulary
INFO - 2023-11-30 16:47:58,541: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:47:58.541594', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:58,563: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:47:58,564: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:47:58,564: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135534.82572675872 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:47:58.564368', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:47:58,600: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:47:58,600: updating layer weights
INFO - 2023-11-30 16:47:58,601: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:47:58.601221', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:47:58,601: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:47:58,601: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:47:58.601613', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:47:58,950: EPOCH 0: training on 191080 raw words (135544 effective words) took 0.3s, 392613 effective words/s
INFO - 2023-11-30 16:47:59,289: EPOCH 1: training on 191080 raw words (135433 effective words) took 0.3s, 403262 effective words/s
INFO - 2023-11-30 16:47:59,651: EPOCH 2: training on 191080 raw words (135492 effective words) took 0.4s, 377529 effective words/s
INFO - 2023-11-30 16:48:00,028: EPOCH 3: training on 191080 raw words (135694 effective words) took 0.4s, 363731 effective words/s
INFO - 2023-11-30 16:48:00,382: EPOCH 4: training on 191080 raw words (135558 effective words) took 0.3s, 416043 effective words/s
INFO - 2023-11-30 16:48:00,767: EPOCH 5: training on 191080 raw words (135893 effective words) took 0.4s, 356715 effective words/s
INFO - 2023-11-30 16:48:01,117: EPOCH 6: training on 191080 raw words (135465 effective words) took 0.3s, 391636 effective words/s
INFO - 2023-11-30 16:48:01,512: EPOCH 7: training on 191080 raw words (135608 effective words) took 0.4s, 345797 effective words/s
INFO - 2023-11-30 16:48:01,892: EPOCH 8: training on 191080 raw words (135661 effective words) took 0.3s, 389918 effective words/s
INFO - 2023-11-30 16:48:02,261: EPOCH 9: training on 191080 raw words (135655 effective words) took 0.4s, 371361 effective words/s
INFO - 2023-11-30 16:48:02,621: EPOCH 10: training on 191080 raw words (135524 effective words) took 0.4s, 380346 effective words/s
INFO - 2023-11-30 16:48:02,969: EPOCH 11: training on 191080 raw words (135449 effective words) took 0.3s, 391806 effective words/s
INFO - 2023-11-30 16:48:03,334: EPOCH 12: training on 191080 raw words (135599 effective words) took 0.4s, 374551 effective words/s
INFO - 2023-11-30 16:48:03,726: EPOCH 13: training on 191080 raw words (135477 effective words) took 0.4s, 349363 effective words/s
INFO - 2023-11-30 16:48:04,069: EPOCH 14: training on 191080 raw words (135495 effective words) took 0.3s, 398474 effective words/s
INFO - 2023-11-30 16:48:04,518: EPOCH 15: training on 191080 raw words (135415 effective words) took 0.4s, 304375 effective words/s
INFO - 2023-11-30 16:48:04,877: EPOCH 16: training on 191080 raw words (135616 effective words) took 0.4s, 382532 effective words/s
INFO - 2023-11-30 16:48:05,239: EPOCH 17: training on 191080 raw words (135643 effective words) took 0.4s, 377670 effective words/s
INFO - 2023-11-30 16:48:05,591: EPOCH 18: training on 191080 raw words (135727 effective words) took 0.3s, 389860 effective words/s
INFO - 2023-11-30 16:48:05,939: EPOCH 19: training on 191080 raw words (135682 effective words) took 0.3s, 394121 effective words/s
INFO - 2023-11-30 16:48:05,939: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711630 effective words) took 7.3s, 369558 effective words/s', 'datetime': '2023-11-30T16:48:05.939312', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:05,939: collecting all words and their counts
INFO - 2023-11-30 16:48:05,939: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:05,978: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:05,978: Updating model with new vocabulary
INFO - 2023-11-30 16:48:05,997: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:05.997620', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:06,024: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:06,024: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:06,024: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135563.8490188078 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:48:06.024821', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:06,078: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:06,078: updating layer weights
INFO - 2023-11-30 16:48:06,079: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:06.079294', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:06,079: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:06,079: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:06.079796', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:06,481: EPOCH 0: training on 191080 raw words (135646 effective words) took 0.4s, 346501 effective words/s
INFO - 2023-11-30 16:48:06,826: EPOCH 1: training on 191080 raw words (135804 effective words) took 0.3s, 396282 effective words/s
INFO - 2023-11-30 16:48:07,169: EPOCH 2: training on 191080 raw words (135551 effective words) took 0.3s, 398866 effective words/s
INFO - 2023-11-30 16:48:07,509: EPOCH 3: training on 191080 raw words (135641 effective words) took 0.3s, 403134 effective words/s
INFO - 2023-11-30 16:48:07,841: EPOCH 4: training on 191080 raw words (135414 effective words) took 0.3s, 411513 effective words/s
INFO - 2023-11-30 16:48:08,184: EPOCH 5: training on 191080 raw words (135404 effective words) took 0.3s, 398303 effective words/s
INFO - 2023-11-30 16:48:08,545: EPOCH 6: training on 191080 raw words (135636 effective words) took 0.4s, 380215 effective words/s
INFO - 2023-11-30 16:48:08,881: EPOCH 7: training on 191080 raw words (135387 effective words) took 0.3s, 406182 effective words/s
INFO - 2023-11-30 16:48:09,223: EPOCH 8: training on 191080 raw words (135510 effective words) took 0.3s, 399898 effective words/s
INFO - 2023-11-30 16:48:09,586: EPOCH 9: training on 191080 raw words (135631 effective words) took 0.4s, 377609 effective words/s
INFO - 2023-11-30 16:48:09,920: EPOCH 10: training on 191080 raw words (135416 effective words) took 0.3s, 409511 effective words/s
INFO - 2023-11-30 16:48:10,249: EPOCH 11: training on 191080 raw words (135363 effective words) took 0.3s, 415015 effective words/s
INFO - 2023-11-30 16:48:10,599: EPOCH 12: training on 191080 raw words (135580 effective words) took 0.3s, 390893 effective words/s
INFO - 2023-11-30 16:48:10,942: EPOCH 13: training on 191080 raw words (135806 effective words) took 0.3s, 400293 effective words/s
INFO - 2023-11-30 16:48:11,292: EPOCH 14: training on 191080 raw words (135383 effective words) took 0.3s, 390733 effective words/s
INFO - 2023-11-30 16:48:11,633: EPOCH 15: training on 191080 raw words (135512 effective words) took 0.3s, 401007 effective words/s
INFO - 2023-11-30 16:48:11,978: EPOCH 16: training on 191080 raw words (135609 effective words) took 0.3s, 397883 effective words/s
INFO - 2023-11-30 16:48:12,326: EPOCH 17: training on 191080 raw words (135476 effective words) took 0.3s, 392920 effective words/s
INFO - 2023-11-30 16:48:12,701: EPOCH 18: training on 191080 raw words (135560 effective words) took 0.4s, 369917 effective words/s
INFO - 2023-11-30 16:48:13,036: EPOCH 19: training on 191080 raw words (135642 effective words) took 0.3s, 408175 effective words/s
INFO - 2023-11-30 16:48:13,037: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710971 effective words) took 7.0s, 389658 effective words/s', 'datetime': '2023-11-30T16:48:13.037320', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:13,037: collecting all words and their counts
INFO - 2023-11-30 16:48:13,037: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:13,089: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:13,089: Updating model with new vocabulary
INFO - 2023-11-30 16:48:13,110: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:13.110103', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:13,131: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:13,132: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:13,132: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135580.04117515683 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:48:13.132365', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:13,164: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:13,164: updating layer weights
INFO - 2023-11-30 16:48:13,165: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:13.165238', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:13,165: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:13,165: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:13.165524', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:13,508: EPOCH 0: training on 191080 raw words (135662 effective words) took 0.3s, 399071 effective words/s
INFO - 2023-11-30 16:48:13,857: EPOCH 1: training on 191080 raw words (135621 effective words) took 0.3s, 391444 effective words/s
INFO - 2023-11-30 16:48:14,269: EPOCH 2: training on 191080 raw words (135609 effective words) took 0.4s, 332131 effective words/s
INFO - 2023-11-30 16:48:14,628: EPOCH 3: training on 191080 raw words (135651 effective words) took 0.4s, 380421 effective words/s
INFO - 2023-11-30 16:48:14,975: EPOCH 4: training on 191080 raw words (135786 effective words) took 0.3s, 394145 effective words/s
INFO - 2023-11-30 16:48:15,323: EPOCH 5: training on 191080 raw words (135469 effective words) took 0.3s, 393318 effective words/s
INFO - 2023-11-30 16:48:15,691: EPOCH 6: training on 191080 raw words (135576 effective words) took 0.4s, 371741 effective words/s
INFO - 2023-11-30 16:48:16,041: EPOCH 7: training on 191080 raw words (135589 effective words) took 0.3s, 391846 effective words/s
INFO - 2023-11-30 16:48:16,386: EPOCH 8: training on 191080 raw words (135689 effective words) took 0.3s, 397162 effective words/s
INFO - 2023-11-30 16:48:16,750: EPOCH 9: training on 191080 raw words (135575 effective words) took 0.4s, 376032 effective words/s
INFO - 2023-11-30 16:48:17,088: EPOCH 10: training on 191080 raw words (135523 effective words) took 0.3s, 404648 effective words/s
INFO - 2023-11-30 16:48:17,458: EPOCH 11: training on 191080 raw words (135598 effective words) took 0.4s, 369987 effective words/s
INFO - 2023-11-30 16:48:17,806: EPOCH 12: training on 191080 raw words (135701 effective words) took 0.3s, 393982 effective words/s
INFO - 2023-11-30 16:48:18,162: EPOCH 13: training on 191080 raw words (135787 effective words) took 0.4s, 384694 effective words/s
INFO - 2023-11-30 16:48:18,518: EPOCH 14: training on 191080 raw words (135531 effective words) took 0.3s, 413153 effective words/s
INFO - 2023-11-30 16:48:18,881: EPOCH 15: training on 191080 raw words (135551 effective words) took 0.4s, 376900 effective words/s
INFO - 2023-11-30 16:48:19,248: EPOCH 16: training on 191080 raw words (135397 effective words) took 0.4s, 372725 effective words/s
INFO - 2023-11-30 16:48:19,597: EPOCH 17: training on 191080 raw words (135609 effective words) took 0.3s, 392560 effective words/s
INFO - 2023-11-30 16:48:19,942: EPOCH 18: training on 191080 raw words (135677 effective words) took 0.3s, 397631 effective words/s
INFO - 2023-11-30 16:48:20,286: EPOCH 19: training on 191080 raw words (135550 effective words) took 0.3s, 397398 effective words/s
INFO - 2023-11-30 16:48:20,286: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712151 effective words) took 7.1s, 380865 effective words/s', 'datetime': '2023-11-30T16:48:20.286685', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:20,286: collecting all words and their counts
INFO - 2023-11-30 16:48:20,287: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:20,324: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:20,325: Updating model with new vocabulary
INFO - 2023-11-30 16:48:20,340: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:20.340250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:20,366: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:20,366: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:20,366: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135743.66518828008 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:48:20.366669', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:20,403: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:20,403: updating layer weights
INFO - 2023-11-30 16:48:20,404: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:20.404172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:20,404: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:20,404: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:20.404429', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:20,740: EPOCH 0: training on 191080 raw words (135739 effective words) took 0.3s, 407150 effective words/s
INFO - 2023-11-30 16:48:21,080: EPOCH 1: training on 191080 raw words (135636 effective words) took 0.3s, 402262 effective words/s
INFO - 2023-11-30 16:48:21,435: EPOCH 2: training on 191080 raw words (135810 effective words) took 0.4s, 386597 effective words/s
INFO - 2023-11-30 16:48:21,795: EPOCH 3: training on 191080 raw words (135753 effective words) took 0.4s, 380135 effective words/s
INFO - 2023-11-30 16:48:22,213: EPOCH 4: training on 191080 raw words (135889 effective words) took 0.4s, 328082 effective words/s
INFO - 2023-11-30 16:48:22,552: EPOCH 5: training on 191080 raw words (135962 effective words) took 0.3s, 404951 effective words/s
INFO - 2023-11-30 16:48:22,898: EPOCH 6: training on 191080 raw words (135781 effective words) took 0.3s, 396944 effective words/s
INFO - 2023-11-30 16:48:23,236: EPOCH 7: training on 191080 raw words (135822 effective words) took 0.3s, 405553 effective words/s
INFO - 2023-11-30 16:48:23,578: EPOCH 8: training on 191080 raw words (135756 effective words) took 0.3s, 410662 effective words/s
INFO - 2023-11-30 16:48:23,911: EPOCH 9: training on 191080 raw words (135846 effective words) took 0.3s, 412033 effective words/s
INFO - 2023-11-30 16:48:24,267: EPOCH 10: training on 191080 raw words (135696 effective words) took 0.4s, 384300 effective words/s
INFO - 2023-11-30 16:48:24,653: EPOCH 11: training on 191080 raw words (135724 effective words) took 0.4s, 353656 effective words/s
INFO - 2023-11-30 16:48:25,033: EPOCH 12: training on 191080 raw words (135553 effective words) took 0.4s, 361015 effective words/s
INFO - 2023-11-30 16:48:25,369: EPOCH 13: training on 191080 raw words (135843 effective words) took 0.3s, 408346 effective words/s
INFO - 2023-11-30 16:48:25,700: EPOCH 14: training on 191080 raw words (135716 effective words) took 0.3s, 413119 effective words/s
INFO - 2023-11-30 16:48:26,030: EPOCH 15: training on 191080 raw words (135651 effective words) took 0.3s, 414715 effective words/s
INFO - 2023-11-30 16:48:26,363: EPOCH 16: training on 191080 raw words (135659 effective words) took 0.3s, 411755 effective words/s
INFO - 2023-11-30 16:48:26,701: EPOCH 17: training on 191080 raw words (135799 effective words) took 0.3s, 405237 effective words/s
INFO - 2023-11-30 16:48:27,032: EPOCH 18: training on 191080 raw words (135786 effective words) took 0.3s, 414940 effective words/s
INFO - 2023-11-30 16:48:27,418: EPOCH 19: training on 191080 raw words (135724 effective words) took 0.4s, 354040 effective words/s
INFO - 2023-11-30 16:48:27,419: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2715145 effective words) took 7.0s, 387061 effective words/s', 'datetime': '2023-11-30T16:48:27.419332', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:27,419: collecting all words and their counts
INFO - 2023-11-30 16:48:27,420: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:27,469: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:27,469: Updating model with new vocabulary
INFO - 2023-11-30 16:48:27,487: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:27.487876', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:27,526: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:27,527: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:27,527: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135556.29629733347 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:48:27.527849', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:27,581: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:27,581: updating layer weights
INFO - 2023-11-30 16:48:27,582: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:27.581958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:27,582: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:27,582: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:27.582679', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:27,944: EPOCH 0: training on 191080 raw words (135540 effective words) took 0.4s, 378958 effective words/s
INFO - 2023-11-30 16:48:28,341: EPOCH 1: training on 191080 raw words (135615 effective words) took 0.4s, 344251 effective words/s
INFO - 2023-11-30 16:48:28,686: EPOCH 2: training on 191080 raw words (135322 effective words) took 0.3s, 396084 effective words/s
INFO - 2023-11-30 16:48:29,049: EPOCH 3: training on 191080 raw words (135470 effective words) took 0.4s, 377891 effective words/s
INFO - 2023-11-30 16:48:29,425: EPOCH 4: training on 191080 raw words (135619 effective words) took 0.4s, 363592 effective words/s
INFO - 2023-11-30 16:48:29,789: EPOCH 5: training on 191080 raw words (135350 effective words) took 0.4s, 375557 effective words/s
INFO - 2023-11-30 16:48:30,187: EPOCH 6: training on 191080 raw words (135729 effective words) took 0.4s, 343455 effective words/s
INFO - 2023-11-30 16:48:30,578: EPOCH 7: training on 191080 raw words (135747 effective words) took 0.4s, 350492 effective words/s
INFO - 2023-11-30 16:48:30,931: EPOCH 8: training on 191080 raw words (135599 effective words) took 0.3s, 387866 effective words/s
INFO - 2023-11-30 16:48:31,277: EPOCH 9: training on 191080 raw words (135828 effective words) took 0.3s, 396989 effective words/s
INFO - 2023-11-30 16:48:31,624: EPOCH 10: training on 191080 raw words (135612 effective words) took 0.3s, 394367 effective words/s
INFO - 2023-11-30 16:48:31,968: EPOCH 11: training on 191080 raw words (135565 effective words) took 0.3s, 397243 effective words/s
INFO - 2023-11-30 16:48:32,307: EPOCH 12: training on 191080 raw words (135610 effective words) took 0.3s, 431870 effective words/s
INFO - 2023-11-30 16:48:32,703: EPOCH 13: training on 191080 raw words (135366 effective words) took 0.4s, 344635 effective words/s
INFO - 2023-11-30 16:48:33,056: EPOCH 14: training on 191080 raw words (135507 effective words) took 0.4s, 386444 effective words/s
INFO - 2023-11-30 16:48:33,417: EPOCH 15: training on 191080 raw words (135587 effective words) took 0.4s, 379488 effective words/s
INFO - 2023-11-30 16:48:33,779: EPOCH 16: training on 191080 raw words (135492 effective words) took 0.4s, 377607 effective words/s
INFO - 2023-11-30 16:48:34,134: EPOCH 17: training on 191080 raw words (135683 effective words) took 0.4s, 385263 effective words/s
INFO - 2023-11-30 16:48:34,477: EPOCH 18: training on 191080 raw words (135499 effective words) took 0.3s, 398544 effective words/s
INFO - 2023-11-30 16:48:34,838: EPOCH 19: training on 191080 raw words (135476 effective words) took 0.4s, 379116 effective words/s
INFO - 2023-11-30 16:48:34,838: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711216 effective words) took 7.3s, 373679 effective words/s', 'datetime': '2023-11-30T16:48:34.838398', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:34,838: collecting all words and their counts
INFO - 2023-11-30 16:48:34,838: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:34,882: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:34,882: Updating model with new vocabulary
INFO - 2023-11-30 16:48:34,899: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:34.899622', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:34,923: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:34,923: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:34,923: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135843.5120419448 word corpus (71.1%% of prior 191080)', 'datetime': '2023-11-30T16:48:34.923893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:34,958: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:34,958: updating layer weights
INFO - 2023-11-30 16:48:34,959: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:34.959171', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:34,959: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:34,959: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:34.959485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:35,335: EPOCH 0: training on 191080 raw words (135744 effective words) took 0.4s, 363782 effective words/s
INFO - 2023-11-30 16:48:35,697: EPOCH 1: training on 191080 raw words (135923 effective words) took 0.4s, 380115 effective words/s
INFO - 2023-11-30 16:48:36,042: EPOCH 2: training on 191080 raw words (135985 effective words) took 0.3s, 397915 effective words/s
INFO - 2023-11-30 16:48:36,387: EPOCH 3: training on 191080 raw words (135808 effective words) took 0.3s, 398612 effective words/s
INFO - 2023-11-30 16:48:36,748: EPOCH 4: training on 191080 raw words (135726 effective words) took 0.4s, 378933 effective words/s
INFO - 2023-11-30 16:48:37,089: EPOCH 5: training on 191080 raw words (135681 effective words) took 0.3s, 401820 effective words/s
INFO - 2023-11-30 16:48:37,430: EPOCH 6: training on 191080 raw words (136002 effective words) took 0.3s, 401690 effective words/s
INFO - 2023-11-30 16:48:37,767: EPOCH 7: training on 191080 raw words (135978 effective words) took 0.3s, 407829 effective words/s
INFO - 2023-11-30 16:48:38,165: EPOCH 8: training on 191080 raw words (135858 effective words) took 0.4s, 343941 effective words/s
INFO - 2023-11-30 16:48:38,501: EPOCH 9: training on 191080 raw words (136031 effective words) took 0.3s, 441746 effective words/s
INFO - 2023-11-30 16:48:38,853: EPOCH 10: training on 191080 raw words (135828 effective words) took 0.3s, 389415 effective words/s
INFO - 2023-11-30 16:48:39,189: EPOCH 11: training on 191080 raw words (135614 effective words) took 0.3s, 406559 effective words/s
INFO - 2023-11-30 16:48:39,564: EPOCH 12: training on 191080 raw words (135785 effective words) took 0.4s, 385139 effective words/s
INFO - 2023-11-30 16:48:39,912: EPOCH 13: training on 191080 raw words (135825 effective words) took 0.3s, 394430 effective words/s
INFO - 2023-11-30 16:48:40,243: EPOCH 14: training on 191080 raw words (135874 effective words) took 0.3s, 414245 effective words/s
INFO - 2023-11-30 16:48:40,585: EPOCH 15: training on 191080 raw words (135865 effective words) took 0.3s, 401408 effective words/s
INFO - 2023-11-30 16:48:40,922: EPOCH 16: training on 191080 raw words (135920 effective words) took 0.3s, 407654 effective words/s
INFO - 2023-11-30 16:48:41,254: EPOCH 17: training on 191080 raw words (135830 effective words) took 0.3s, 413249 effective words/s
INFO - 2023-11-30 16:48:41,585: EPOCH 18: training on 191080 raw words (135867 effective words) took 0.3s, 413400 effective words/s
INFO - 2023-11-30 16:48:41,911: EPOCH 19: training on 191080 raw words (135579 effective words) took 0.3s, 420780 effective words/s
INFO - 2023-11-30 16:48:41,911: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2716723 effective words) took 7.0s, 390776 effective words/s', 'datetime': '2023-11-30T16:48:41.911778', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:41,912: collecting all words and their counts
INFO - 2023-11-30 16:48:41,912: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:41,953: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:41,953: Updating model with new vocabulary
INFO - 2023-11-30 16:48:41,969: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:41.969576', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:41,991: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:41,991: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:41,991: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135234.95738349968 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:48:41.991945', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:42,024: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:42,024: updating layer weights
INFO - 2023-11-30 16:48:42,025: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:42.025070', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:42,025: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:42,025: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:42.025742', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:42,422: EPOCH 0: training on 191080 raw words (135389 effective words) took 0.4s, 343584 effective words/s
INFO - 2023-11-30 16:48:42,805: EPOCH 1: training on 191080 raw words (135144 effective words) took 0.4s, 357228 effective words/s
INFO - 2023-11-30 16:48:43,156: EPOCH 2: training on 191080 raw words (135201 effective words) took 0.3s, 388528 effective words/s
INFO - 2023-11-30 16:48:43,519: EPOCH 3: training on 191080 raw words (135191 effective words) took 0.4s, 376187 effective words/s
INFO - 2023-11-30 16:48:43,862: EPOCH 4: training on 191080 raw words (135032 effective words) took 0.3s, 396599 effective words/s
INFO - 2023-11-30 16:48:44,209: EPOCH 5: training on 191080 raw words (135137 effective words) took 0.3s, 393574 effective words/s
INFO - 2023-11-30 16:48:44,551: EPOCH 6: training on 191080 raw words (135319 effective words) took 0.3s, 400016 effective words/s
INFO - 2023-11-30 16:48:44,928: EPOCH 7: training on 191080 raw words (135344 effective words) took 0.4s, 361309 effective words/s
INFO - 2023-11-30 16:48:45,320: EPOCH 8: training on 191080 raw words (135430 effective words) took 0.4s, 348616 effective words/s
INFO - 2023-11-30 16:48:45,716: EPOCH 9: training on 191080 raw words (135367 effective words) took 0.4s, 345206 effective words/s
INFO - 2023-11-30 16:48:46,075: EPOCH 10: training on 191080 raw words (135102 effective words) took 0.4s, 380333 effective words/s
INFO - 2023-11-30 16:48:46,529: EPOCH 11: training on 191080 raw words (135356 effective words) took 0.5s, 299982 effective words/s
INFO - 2023-11-30 16:48:46,899: EPOCH 12: training on 191080 raw words (135330 effective words) took 0.4s, 369122 effective words/s
INFO - 2023-11-30 16:48:47,251: EPOCH 13: training on 191080 raw words (135378 effective words) took 0.3s, 388699 effective words/s
INFO - 2023-11-30 16:48:47,602: EPOCH 14: training on 191080 raw words (135103 effective words) took 0.3s, 387876 effective words/s
INFO - 2023-11-30 16:48:47,953: EPOCH 15: training on 191080 raw words (135468 effective words) took 0.3s, 390052 effective words/s
INFO - 2023-11-30 16:48:48,299: EPOCH 16: training on 191080 raw words (135324 effective words) took 0.3s, 395305 effective words/s
INFO - 2023-11-30 16:48:48,675: EPOCH 17: training on 191080 raw words (135022 effective words) took 0.4s, 362269 effective words/s
INFO - 2023-11-30 16:48:49,030: EPOCH 18: training on 191080 raw words (135208 effective words) took 0.4s, 384008 effective words/s
INFO - 2023-11-30 16:48:49,425: EPOCH 19: training on 191080 raw words (135151 effective words) took 0.4s, 344600 effective words/s
INFO - 2023-11-30 16:48:49,426: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2704996 effective words) took 7.4s, 365532 effective words/s', 'datetime': '2023-11-30T16:48:49.426221', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:49,426: collecting all words and their counts
INFO - 2023-11-30 16:48:49,426: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:49,474: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:49,475: Updating model with new vocabulary
INFO - 2023-11-30 16:48:49,494: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:49.494343', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:49,521: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:49,521: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:49,521: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135530.42870235833 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:48:49.521891', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:49,561: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:49,561: updating layer weights
INFO - 2023-11-30 16:48:49,562: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:49.562327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:49,562: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:49,562: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:49.562660', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:49,942: EPOCH 0: training on 191080 raw words (135609 effective words) took 0.4s, 361431 effective words/s
INFO - 2023-11-30 16:48:50,274: EPOCH 1: training on 191080 raw words (135564 effective words) took 0.3s, 411742 effective words/s
INFO - 2023-11-30 16:48:50,614: EPOCH 2: training on 191080 raw words (135531 effective words) took 0.3s, 401643 effective words/s
INFO - 2023-11-30 16:48:50,971: EPOCH 3: training on 191080 raw words (135413 effective words) took 0.4s, 383691 effective words/s
INFO - 2023-11-30 16:48:51,306: EPOCH 4: training on 191080 raw words (135321 effective words) took 0.3s, 408142 effective words/s
INFO - 2023-11-30 16:48:51,670: EPOCH 5: training on 191080 raw words (135505 effective words) took 0.4s, 375717 effective words/s
INFO - 2023-11-30 16:48:52,014: EPOCH 6: training on 191080 raw words (135568 effective words) took 0.3s, 398333 effective words/s
INFO - 2023-11-30 16:48:52,354: EPOCH 7: training on 191080 raw words (135486 effective words) took 0.3s, 412856 effective words/s
INFO - 2023-11-30 16:48:52,705: EPOCH 8: training on 191080 raw words (135388 effective words) took 0.3s, 391587 effective words/s
INFO - 2023-11-30 16:48:53,049: EPOCH 9: training on 191080 raw words (135521 effective words) took 0.3s, 397545 effective words/s
INFO - 2023-11-30 16:48:53,380: EPOCH 10: training on 191080 raw words (135555 effective words) took 0.3s, 412833 effective words/s
INFO - 2023-11-30 16:48:53,699: EPOCH 11: training on 191080 raw words (135555 effective words) took 0.3s, 428922 effective words/s
INFO - 2023-11-30 16:48:54,038: EPOCH 12: training on 191080 raw words (135453 effective words) took 0.3s, 403542 effective words/s
INFO - 2023-11-30 16:48:54,367: EPOCH 13: training on 191080 raw words (135515 effective words) took 0.3s, 416737 effective words/s
INFO - 2023-11-30 16:48:54,726: EPOCH 14: training on 191080 raw words (135687 effective words) took 0.4s, 381064 effective words/s
INFO - 2023-11-30 16:48:55,060: EPOCH 15: training on 191080 raw words (135481 effective words) took 0.3s, 409825 effective words/s
INFO - 2023-11-30 16:48:55,387: EPOCH 16: training on 191080 raw words (135619 effective words) took 0.3s, 417578 effective words/s
INFO - 2023-11-30 16:48:55,777: EPOCH 17: training on 191080 raw words (135552 effective words) took 0.4s, 350621 effective words/s
INFO - 2023-11-30 16:48:56,107: EPOCH 18: training on 191080 raw words (135526 effective words) took 0.3s, 413719 effective words/s
INFO - 2023-11-30 16:48:56,443: EPOCH 19: training on 191080 raw words (135567 effective words) took 0.3s, 407201 effective words/s
INFO - 2023-11-30 16:48:56,444: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710416 effective words) took 6.9s, 393882 effective words/s', 'datetime': '2023-11-30T16:48:56.444141', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:56,444: collecting all words and their counts
INFO - 2023-11-30 16:48:56,444: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:48:56,491: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:48:56,491: Updating model with new vocabulary
INFO - 2023-11-30 16:48:56,509: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:48:56.509225', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:56,531: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:48:56,531: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:48:56,531: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135664.85799703022 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:48:56.531739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:48:56,581: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:48:56,582: updating layer weights
INFO - 2023-11-30 16:48:56,582: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:48:56.582570', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:48:56,582: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:48:56,583: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:48:56.583067', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:48:56,996: EPOCH 0: training on 191080 raw words (135682 effective words) took 0.4s, 331741 effective words/s
INFO - 2023-11-30 16:48:57,362: EPOCH 1: training on 191080 raw words (135570 effective words) took 0.4s, 373860 effective words/s
INFO - 2023-11-30 16:48:57,745: EPOCH 2: training on 191080 raw words (135317 effective words) took 0.4s, 356394 effective words/s
INFO - 2023-11-30 16:48:58,101: EPOCH 3: training on 191080 raw words (135637 effective words) took 0.4s, 384779 effective words/s
INFO - 2023-11-30 16:48:58,473: EPOCH 4: training on 191080 raw words (135765 effective words) took 0.4s, 368310 effective words/s
INFO - 2023-11-30 16:48:58,863: EPOCH 5: training on 191080 raw words (135662 effective words) took 0.4s, 350317 effective words/s
INFO - 2023-11-30 16:48:59,210: EPOCH 6: training on 191080 raw words (135653 effective words) took 0.3s, 395858 effective words/s
INFO - 2023-11-30 16:48:59,569: EPOCH 7: training on 191080 raw words (135472 effective words) took 0.4s, 379919 effective words/s
INFO - 2023-11-30 16:48:59,918: EPOCH 8: training on 191080 raw words (135562 effective words) took 0.3s, 392906 effective words/s
INFO - 2023-11-30 16:49:00,316: EPOCH 9: training on 191080 raw words (135816 effective words) took 0.4s, 343672 effective words/s
INFO - 2023-11-30 16:49:00,689: EPOCH 10: training on 191080 raw words (135793 effective words) took 0.4s, 367747 effective words/s
INFO - 2023-11-30 16:49:01,060: EPOCH 11: training on 191080 raw words (135678 effective words) took 0.4s, 369521 effective words/s
INFO - 2023-11-30 16:49:01,409: EPOCH 12: training on 191080 raw words (135691 effective words) took 0.3s, 392468 effective words/s
INFO - 2023-11-30 16:49:01,785: EPOCH 13: training on 191080 raw words (135767 effective words) took 0.4s, 364197 effective words/s
INFO - 2023-11-30 16:49:02,138: EPOCH 14: training on 191080 raw words (135729 effective words) took 0.4s, 387452 effective words/s
INFO - 2023-11-30 16:49:02,504: EPOCH 15: training on 191080 raw words (135572 effective words) took 0.4s, 373794 effective words/s
INFO - 2023-11-30 16:49:02,849: EPOCH 16: training on 191080 raw words (135865 effective words) took 0.3s, 397270 effective words/s
INFO - 2023-11-30 16:49:03,187: EPOCH 17: training on 191080 raw words (135646 effective words) took 0.3s, 406032 effective words/s
INFO - 2023-11-30 16:49:03,539: EPOCH 18: training on 191080 raw words (135500 effective words) took 0.3s, 388279 effective words/s
INFO - 2023-11-30 16:49:03,921: EPOCH 19: training on 191080 raw words (135622 effective words) took 0.4s, 357639 effective words/s
INFO - 2023-11-30 16:49:03,922: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712999 effective words) took 7.3s, 369679 effective words/s', 'datetime': '2023-11-30T16:49:03.922109', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:03,922: collecting all words and their counts
INFO - 2023-11-30 16:49:03,922: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:03,968: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:03,968: Updating model with new vocabulary
INFO - 2023-11-30 16:49:03,990: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:03.990130', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:04,019: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:04,019: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:04,020: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135773.5992204695 word corpus (71.1%% of prior 191080)', 'datetime': '2023-11-30T16:49:04.020094', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:04,057: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:04,058: updating layer weights
INFO - 2023-11-30 16:49:04,058: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:04.058665', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:04,059: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:04,059: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:04.059411', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:04,399: EPOCH 0: training on 191080 raw words (135716 effective words) took 0.3s, 404659 effective words/s
INFO - 2023-11-30 16:49:04,741: EPOCH 1: training on 191080 raw words (135750 effective words) took 0.3s, 402434 effective words/s
INFO - 2023-11-30 16:49:05,100: EPOCH 2: training on 191080 raw words (135878 effective words) took 0.4s, 381378 effective words/s
INFO - 2023-11-30 16:49:05,489: EPOCH 3: training on 191080 raw words (135597 effective words) took 0.4s, 351245 effective words/s
INFO - 2023-11-30 16:49:05,823: EPOCH 4: training on 191080 raw words (135700 effective words) took 0.3s, 410003 effective words/s
INFO - 2023-11-30 16:49:06,152: EPOCH 5: training on 191080 raw words (135806 effective words) took 0.3s, 416174 effective words/s
INFO - 2023-11-30 16:49:06,495: EPOCH 6: training on 191080 raw words (135678 effective words) took 0.3s, 399631 effective words/s
INFO - 2023-11-30 16:49:06,861: EPOCH 7: training on 191080 raw words (135981 effective words) took 0.4s, 375376 effective words/s
INFO - 2023-11-30 16:49:07,197: EPOCH 8: training on 191080 raw words (135689 effective words) took 0.3s, 408074 effective words/s
INFO - 2023-11-30 16:49:07,536: EPOCH 9: training on 191080 raw words (135992 effective words) took 0.3s, 405015 effective words/s
INFO - 2023-11-30 16:49:07,872: EPOCH 10: training on 191080 raw words (135859 effective words) took 0.3s, 407159 effective words/s
INFO - 2023-11-30 16:49:08,204: EPOCH 11: training on 191080 raw words (135929 effective words) took 0.3s, 414428 effective words/s
INFO - 2023-11-30 16:49:08,537: EPOCH 12: training on 191080 raw words (135792 effective words) took 0.3s, 411472 effective words/s
INFO - 2023-11-30 16:49:08,891: EPOCH 13: training on 191080 raw words (135670 effective words) took 0.4s, 386718 effective words/s
INFO - 2023-11-30 16:49:09,244: EPOCH 14: training on 191080 raw words (135965 effective words) took 0.4s, 387972 effective words/s
INFO - 2023-11-30 16:49:09,601: EPOCH 15: training on 191080 raw words (135802 effective words) took 0.4s, 383770 effective words/s
INFO - 2023-11-30 16:49:09,939: EPOCH 16: training on 191080 raw words (135848 effective words) took 0.3s, 406532 effective words/s
INFO - 2023-11-30 16:49:10,270: EPOCH 17: training on 191080 raw words (135602 effective words) took 0.3s, 413181 effective words/s
INFO - 2023-11-30 16:49:10,599: EPOCH 18: training on 191080 raw words (135807 effective words) took 0.3s, 417116 effective words/s
INFO - 2023-11-30 16:49:10,950: EPOCH 19: training on 191080 raw words (135899 effective words) took 0.3s, 390709 effective words/s
INFO - 2023-11-30 16:49:10,950: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2715960 effective words) took 6.9s, 394139 effective words/s', 'datetime': '2023-11-30T16:49:10.950567', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:10,950: collecting all words and their counts
INFO - 2023-11-30 16:49:10,951: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:10,988: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:10,988: Updating model with new vocabulary
INFO - 2023-11-30 16:49:11,005: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:11.005144', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:11,026: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:11,026: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:11,026: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135521.84719655348 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:49:11.026638', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:11,060: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:11,060: updating layer weights
INFO - 2023-11-30 16:49:11,061: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:11.061404', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:11,061: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:11,061: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:11.061807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:11,429: EPOCH 0: training on 191080 raw words (135512 effective words) took 0.4s, 370998 effective words/s
INFO - 2023-11-30 16:49:11,803: EPOCH 1: training on 191080 raw words (135670 effective words) took 0.4s, 366268 effective words/s
INFO - 2023-11-30 16:49:12,158: EPOCH 2: training on 191080 raw words (135616 effective words) took 0.4s, 384904 effective words/s
INFO - 2023-11-30 16:49:12,533: EPOCH 3: training on 191080 raw words (135556 effective words) took 0.4s, 364501 effective words/s
INFO - 2023-11-30 16:49:12,896: EPOCH 4: training on 191080 raw words (135615 effective words) took 0.4s, 377291 effective words/s
INFO - 2023-11-30 16:49:13,234: EPOCH 5: training on 191080 raw words (135645 effective words) took 0.3s, 404996 effective words/s
INFO - 2023-11-30 16:49:13,587: EPOCH 6: training on 191080 raw words (135377 effective words) took 0.4s, 386190 effective words/s
INFO - 2023-11-30 16:49:13,951: EPOCH 7: training on 191080 raw words (135470 effective words) took 0.4s, 376124 effective words/s
INFO - 2023-11-30 16:49:14,298: EPOCH 8: training on 191080 raw words (135544 effective words) took 0.3s, 393911 effective words/s
INFO - 2023-11-30 16:49:14,709: EPOCH 9: training on 191080 raw words (135628 effective words) took 0.4s, 332410 effective words/s
INFO - 2023-11-30 16:49:15,063: EPOCH 10: training on 191080 raw words (135482 effective words) took 0.4s, 386620 effective words/s
INFO - 2023-11-30 16:49:15,423: EPOCH 11: training on 191080 raw words (135380 effective words) took 0.4s, 380006 effective words/s
INFO - 2023-11-30 16:49:15,795: EPOCH 12: training on 191080 raw words (135519 effective words) took 0.4s, 367692 effective words/s
INFO - 2023-11-30 16:49:16,142: EPOCH 13: training on 191080 raw words (135554 effective words) took 0.3s, 394163 effective words/s
INFO - 2023-11-30 16:49:16,487: EPOCH 14: training on 191080 raw words (135518 effective words) took 0.3s, 397265 effective words/s
INFO - 2023-11-30 16:49:16,836: EPOCH 15: training on 191080 raw words (135416 effective words) took 0.3s, 390981 effective words/s
INFO - 2023-11-30 16:49:17,205: EPOCH 16: training on 191080 raw words (135578 effective words) took 0.4s, 371822 effective words/s
INFO - 2023-11-30 16:49:17,542: EPOCH 17: training on 191080 raw words (135535 effective words) took 0.3s, 405084 effective words/s
INFO - 2023-11-30 16:49:17,892: EPOCH 18: training on 191080 raw words (135408 effective words) took 0.3s, 391246 effective words/s
INFO - 2023-11-30 16:49:18,263: EPOCH 19: training on 191080 raw words (135544 effective words) took 0.4s, 368243 effective words/s
INFO - 2023-11-30 16:49:18,264: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710567 effective words) took 7.2s, 376361 effective words/s', 'datetime': '2023-11-30T16:49:18.264020', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:18,264: collecting all words and their counts
INFO - 2023-11-30 16:49:18,264: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:18,319: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:18,319: Updating model with new vocabulary
INFO - 2023-11-30 16:49:18,350: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:18.350660', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:18,388: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:18,388: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:18,388: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135649.0440751444 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:49:18.388814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:18,447: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:18,447: updating layer weights
INFO - 2023-11-30 16:49:18,448: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:18.447979', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:18,448: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:18,448: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:18.448644', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:18,792: EPOCH 0: training on 191080 raw words (135596 effective words) took 0.3s, 398281 effective words/s
INFO - 2023-11-30 16:49:19,121: EPOCH 1: training on 191080 raw words (135458 effective words) took 0.3s, 414962 effective words/s
INFO - 2023-11-30 16:49:19,469: EPOCH 2: training on 191080 raw words (135641 effective words) took 0.3s, 394085 effective words/s
INFO - 2023-11-30 16:49:19,855: EPOCH 3: training on 191080 raw words (135610 effective words) took 0.4s, 354430 effective words/s
INFO - 2023-11-30 16:49:20,187: EPOCH 4: training on 191080 raw words (135686 effective words) took 0.3s, 412611 effective words/s
INFO - 2023-11-30 16:49:20,520: EPOCH 5: training on 191080 raw words (135926 effective words) took 0.3s, 411650 effective words/s
INFO - 2023-11-30 16:49:20,867: EPOCH 6: training on 191080 raw words (135846 effective words) took 0.3s, 395273 effective words/s
INFO - 2023-11-30 16:49:21,212: EPOCH 7: training on 191080 raw words (135694 effective words) took 0.3s, 397512 effective words/s
INFO - 2023-11-30 16:49:21,574: EPOCH 8: training on 191080 raw words (135700 effective words) took 0.4s, 378211 effective words/s
INFO - 2023-11-30 16:49:21,915: EPOCH 9: training on 191080 raw words (135793 effective words) took 0.3s, 402045 effective words/s
INFO - 2023-11-30 16:49:22,255: EPOCH 10: training on 191080 raw words (135730 effective words) took 0.3s, 403652 effective words/s
INFO - 2023-11-30 16:49:22,607: EPOCH 11: training on 191080 raw words (135917 effective words) took 0.3s, 389803 effective words/s
INFO - 2023-11-30 16:49:22,950: EPOCH 12: training on 191080 raw words (135733 effective words) took 0.3s, 400188 effective words/s
INFO - 2023-11-30 16:49:23,301: EPOCH 13: training on 191080 raw words (135645 effective words) took 0.3s, 388807 effective words/s
INFO - 2023-11-30 16:49:23,641: EPOCH 14: training on 191080 raw words (135706 effective words) took 0.3s, 403994 effective words/s
INFO - 2023-11-30 16:49:24,086: EPOCH 15: training on 191080 raw words (135628 effective words) took 0.4s, 306706 effective words/s
INFO - 2023-11-30 16:49:24,443: EPOCH 16: training on 191080 raw words (135561 effective words) took 0.4s, 384265 effective words/s
INFO - 2023-11-30 16:49:24,824: EPOCH 17: training on 191080 raw words (135686 effective words) took 0.4s, 358376 effective words/s
INFO - 2023-11-30 16:49:25,168: EPOCH 18: training on 191080 raw words (135859 effective words) took 0.3s, 399643 effective words/s
INFO - 2023-11-30 16:49:25,499: EPOCH 19: training on 191080 raw words (135728 effective words) took 0.3s, 413592 effective words/s
INFO - 2023-11-30 16:49:25,499: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2714143 effective words) took 7.1s, 384945 effective words/s', 'datetime': '2023-11-30T16:49:25.499706', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:25,499: collecting all words and their counts
INFO - 2023-11-30 16:49:25,500: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:25,540: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:25,540: Updating model with new vocabulary
INFO - 2023-11-30 16:49:25,559: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:25.559081', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:25,594: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:25,594: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:25,594: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135145.69848163376 word corpus (70.7%% of prior 191080)', 'datetime': '2023-11-30T16:49:25.594481', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:25,643: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:25,643: updating layer weights
INFO - 2023-11-30 16:49:25,644: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:25.644360', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:25,644: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:25,644: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:25.644651', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:26,041: EPOCH 0: training on 191080 raw words (135338 effective words) took 0.4s, 350748 effective words/s
INFO - 2023-11-30 16:49:26,403: EPOCH 1: training on 191080 raw words (135009 effective words) took 0.4s, 385309 effective words/s
INFO - 2023-11-30 16:49:26,742: EPOCH 2: training on 191080 raw words (135190 effective words) took 0.3s, 402385 effective words/s
INFO - 2023-11-30 16:49:27,110: EPOCH 3: training on 191080 raw words (135155 effective words) took 0.4s, 370322 effective words/s
INFO - 2023-11-30 16:49:27,523: EPOCH 4: training on 191080 raw words (135261 effective words) took 0.4s, 329714 effective words/s
INFO - 2023-11-30 16:49:27,883: EPOCH 5: training on 191080 raw words (135220 effective words) took 0.4s, 378806 effective words/s
INFO - 2023-11-30 16:49:28,240: EPOCH 6: training on 191080 raw words (135040 effective words) took 0.4s, 381978 effective words/s
INFO - 2023-11-30 16:49:28,601: EPOCH 7: training on 191080 raw words (135203 effective words) took 0.4s, 377548 effective words/s
INFO - 2023-11-30 16:49:29,003: EPOCH 8: training on 191080 raw words (135067 effective words) took 0.4s, 337971 effective words/s
INFO - 2023-11-30 16:49:29,345: EPOCH 9: training on 191080 raw words (135112 effective words) took 0.3s, 398377 effective words/s
INFO - 2023-11-30 16:49:29,693: EPOCH 10: training on 191080 raw words (135187 effective words) took 0.3s, 392676 effective words/s
INFO - 2023-11-30 16:49:30,081: EPOCH 11: training on 191080 raw words (135219 effective words) took 0.4s, 351892 effective words/s
INFO - 2023-11-30 16:49:30,454: EPOCH 12: training on 191080 raw words (135226 effective words) took 0.4s, 374520 effective words/s
INFO - 2023-11-30 16:49:30,830: EPOCH 13: training on 191080 raw words (134914 effective words) took 0.4s, 362315 effective words/s
INFO - 2023-11-30 16:49:31,180: EPOCH 14: training on 191080 raw words (135376 effective words) took 0.3s, 390652 effective words/s
INFO - 2023-11-30 16:49:31,525: EPOCH 15: training on 191080 raw words (135238 effective words) took 0.3s, 396037 effective words/s
INFO - 2023-11-30 16:49:31,869: EPOCH 16: training on 191080 raw words (135287 effective words) took 0.3s, 395829 effective words/s
INFO - 2023-11-30 16:49:32,231: EPOCH 17: training on 191080 raw words (135166 effective words) took 0.4s, 377063 effective words/s
INFO - 2023-11-30 16:49:32,573: EPOCH 18: training on 191080 raw words (135025 effective words) took 0.3s, 398385 effective words/s
INFO - 2023-11-30 16:49:32,925: EPOCH 19: training on 191080 raw words (135275 effective words) took 0.3s, 388600 effective words/s
INFO - 2023-11-30 16:49:32,925: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2703508 effective words) took 7.3s, 371316 effective words/s', 'datetime': '2023-11-30T16:49:32.925762', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:32,925: collecting all words and their counts
INFO - 2023-11-30 16:49:32,926: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:32,978: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:32,978: Updating model with new vocabulary
INFO - 2023-11-30 16:49:33,004: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:33.004456', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:33,026: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:33,026: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 16:49:33,027: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135559.59352777575 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:49:33.027055', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:33,062: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:33,062: updating layer weights
INFO - 2023-11-30 16:49:33,063: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:33.062998', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:33,063: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:33,063: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:33.063329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:33,401: EPOCH 0: training on 191080 raw words (135601 effective words) took 0.3s, 404876 effective words/s
INFO - 2023-11-30 16:49:33,762: EPOCH 1: training on 191080 raw words (135562 effective words) took 0.3s, 387395 effective words/s
INFO - 2023-11-30 16:49:34,109: EPOCH 2: training on 191080 raw words (135591 effective words) took 0.3s, 394535 effective words/s
INFO - 2023-11-30 16:49:34,455: EPOCH 3: training on 191080 raw words (135592 effective words) took 0.3s, 395888 effective words/s
INFO - 2023-11-30 16:49:34,803: EPOCH 4: training on 191080 raw words (135453 effective words) took 0.3s, 392970 effective words/s
INFO - 2023-11-30 16:49:35,153: EPOCH 5: training on 191080 raw words (135577 effective words) took 0.3s, 390279 effective words/s
INFO - 2023-11-30 16:49:35,546: EPOCH 6: training on 191080 raw words (135574 effective words) took 0.4s, 354905 effective words/s
INFO - 2023-11-30 16:49:35,989: EPOCH 7: training on 191080 raw words (135560 effective words) took 0.4s, 308836 effective words/s
INFO - 2023-11-30 16:49:36,403: EPOCH 8: training on 191080 raw words (135615 effective words) took 0.4s, 329739 effective words/s
INFO - 2023-11-30 16:49:36,808: EPOCH 9: training on 191080 raw words (135555 effective words) took 0.4s, 338165 effective words/s
INFO - 2023-11-30 16:49:37,174: EPOCH 10: training on 191080 raw words (135625 effective words) took 0.4s, 373409 effective words/s
INFO - 2023-11-30 16:49:37,525: EPOCH 11: training on 191080 raw words (135500 effective words) took 0.3s, 389702 effective words/s
INFO - 2023-11-30 16:49:37,897: EPOCH 12: training on 191080 raw words (135681 effective words) took 0.4s, 369105 effective words/s
INFO - 2023-11-30 16:49:38,237: EPOCH 13: training on 191080 raw words (135464 effective words) took 0.3s, 402363 effective words/s
INFO - 2023-11-30 16:49:38,573: EPOCH 14: training on 191080 raw words (135658 effective words) took 0.3s, 406442 effective words/s
INFO - 2023-11-30 16:49:38,911: EPOCH 15: training on 191080 raw words (135648 effective words) took 0.3s, 406200 effective words/s
INFO - 2023-11-30 16:49:39,266: EPOCH 16: training on 191080 raw words (135570 effective words) took 0.4s, 385052 effective words/s
INFO - 2023-11-30 16:49:39,632: EPOCH 17: training on 191080 raw words (135502 effective words) took 0.4s, 374064 effective words/s
INFO - 2023-11-30 16:49:39,971: EPOCH 18: training on 191080 raw words (135563 effective words) took 0.3s, 404430 effective words/s
INFO - 2023-11-30 16:49:40,304: EPOCH 19: training on 191080 raw words (135561 effective words) took 0.3s, 410587 effective words/s
INFO - 2023-11-30 16:49:40,304: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711452 effective words) took 7.2s, 374444 effective words/s', 'datetime': '2023-11-30T16:49:40.304783', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:40,304: collecting all words and their counts
INFO - 2023-11-30 16:49:40,305: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:40,347: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:40,347: Updating model with new vocabulary
INFO - 2023-11-30 16:49:40,365: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:40.365040', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:40,387: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:40,387: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:40,387: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135562.9104393792 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:49:40.387896', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:40,424: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:40,424: updating layer weights
INFO - 2023-11-30 16:49:40,425: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:40.425514', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:40,425: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:40,426: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:40.426141', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:40,788: EPOCH 0: training on 191080 raw words (135671 effective words) took 0.3s, 410958 effective words/s
INFO - 2023-11-30 16:49:41,143: EPOCH 1: training on 191080 raw words (135684 effective words) took 0.4s, 385061 effective words/s
INFO - 2023-11-30 16:49:41,494: EPOCH 2: training on 191080 raw words (135757 effective words) took 0.3s, 390337 effective words/s
INFO - 2023-11-30 16:49:41,891: EPOCH 3: training on 191080 raw words (135750 effective words) took 0.4s, 344086 effective words/s
INFO - 2023-11-30 16:49:42,245: EPOCH 4: training on 191080 raw words (135647 effective words) took 0.4s, 387550 effective words/s
INFO - 2023-11-30 16:49:42,618: EPOCH 5: training on 191080 raw words (135662 effective words) took 0.4s, 367157 effective words/s
INFO - 2023-11-30 16:49:42,960: EPOCH 6: training on 191080 raw words (135591 effective words) took 0.3s, 399240 effective words/s
INFO - 2023-11-30 16:49:43,303: EPOCH 7: training on 191080 raw words (135532 effective words) took 0.3s, 399769 effective words/s
INFO - 2023-11-30 16:49:43,666: EPOCH 8: training on 191080 raw words (135516 effective words) took 0.3s, 398879 effective words/s
INFO - 2023-11-30 16:49:44,007: EPOCH 9: training on 191080 raw words (135592 effective words) took 0.3s, 400555 effective words/s
INFO - 2023-11-30 16:49:44,370: EPOCH 10: training on 191080 raw words (135479 effective words) took 0.4s, 377032 effective words/s
INFO - 2023-11-30 16:49:44,766: EPOCH 11: training on 191080 raw words (135755 effective words) took 0.4s, 352500 effective words/s
INFO - 2023-11-30 16:49:45,109: EPOCH 12: training on 191080 raw words (135534 effective words) took 0.3s, 399174 effective words/s
INFO - 2023-11-30 16:49:45,478: EPOCH 13: training on 191080 raw words (135673 effective words) took 0.4s, 370565 effective words/s
INFO - 2023-11-30 16:49:45,857: EPOCH 14: training on 191080 raw words (135594 effective words) took 0.4s, 370256 effective words/s
INFO - 2023-11-30 16:49:46,297: EPOCH 15: training on 191080 raw words (135619 effective words) took 0.4s, 309928 effective words/s
INFO - 2023-11-30 16:49:46,750: EPOCH 16: training on 191080 raw words (135617 effective words) took 0.4s, 302024 effective words/s
INFO - 2023-11-30 16:49:47,110: EPOCH 17: training on 191080 raw words (135640 effective words) took 0.4s, 380968 effective words/s
INFO - 2023-11-30 16:49:47,470: EPOCH 18: training on 191080 raw words (135401 effective words) took 0.4s, 380061 effective words/s
INFO - 2023-11-30 16:49:47,892: EPOCH 19: training on 191080 raw words (135514 effective words) took 0.4s, 323677 effective words/s
INFO - 2023-11-30 16:49:47,893: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712228 effective words) took 7.5s, 363234 effective words/s', 'datetime': '2023-11-30T16:49:47.893393', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:47,893: collecting all words and their counts
INFO - 2023-11-30 16:49:47,894: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:47,945: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:47,945: Updating model with new vocabulary
INFO - 2023-11-30 16:49:47,962: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:47.962457', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:47,999: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:48,000: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:49:48,000: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135242.35325807068 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:49:48.000198', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:48,058: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:48,059: updating layer weights
INFO - 2023-11-30 16:49:48,060: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:48.059965', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:48,060: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:48,061: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:48.061584', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:48,431: EPOCH 0: training on 191080 raw words (135149 effective words) took 0.4s, 378149 effective words/s
INFO - 2023-11-30 16:49:48,803: EPOCH 1: training on 191080 raw words (135158 effective words) took 0.4s, 367211 effective words/s
INFO - 2023-11-30 16:49:49,155: EPOCH 2: training on 191080 raw words (135174 effective words) took 0.3s, 400394 effective words/s
INFO - 2023-11-30 16:49:49,485: EPOCH 3: training on 191080 raw words (134954 effective words) took 0.3s, 411453 effective words/s
INFO - 2023-11-30 16:49:49,848: EPOCH 4: training on 191080 raw words (135206 effective words) took 0.4s, 375785 effective words/s
INFO - 2023-11-30 16:49:50,194: EPOCH 5: training on 191080 raw words (135348 effective words) took 0.3s, 395481 effective words/s
INFO - 2023-11-30 16:49:50,555: EPOCH 6: training on 191080 raw words (135335 effective words) took 0.4s, 378978 effective words/s
INFO - 2023-11-30 16:49:50,910: EPOCH 7: training on 191080 raw words (135181 effective words) took 0.4s, 383526 effective words/s
INFO - 2023-11-30 16:49:51,233: EPOCH 8: training on 191080 raw words (135370 effective words) took 0.3s, 424086 effective words/s
INFO - 2023-11-30 16:49:51,581: EPOCH 9: training on 191080 raw words (135213 effective words) took 0.3s, 391777 effective words/s
INFO - 2023-11-30 16:49:51,889: EPOCH 10: training on 191080 raw words (135014 effective words) took 0.3s, 442959 effective words/s
INFO - 2023-11-30 16:49:52,165: EPOCH 11: training on 191080 raw words (135420 effective words) took 0.3s, 495651 effective words/s
INFO - 2023-11-30 16:49:52,440: EPOCH 12: training on 191080 raw words (135297 effective words) took 0.3s, 494956 effective words/s
INFO - 2023-11-30 16:49:52,724: EPOCH 13: training on 191080 raw words (135108 effective words) took 0.3s, 481554 effective words/s
INFO - 2023-11-30 16:49:53,006: EPOCH 14: training on 191080 raw words (135265 effective words) took 0.3s, 482659 effective words/s
INFO - 2023-11-30 16:49:53,291: EPOCH 15: training on 191080 raw words (135324 effective words) took 0.3s, 478964 effective words/s
INFO - 2023-11-30 16:49:53,573: EPOCH 16: training on 191080 raw words (135121 effective words) took 0.3s, 484246 effective words/s
INFO - 2023-11-30 16:49:53,860: EPOCH 17: training on 191080 raw words (134990 effective words) took 0.3s, 475575 effective words/s
INFO - 2023-11-30 16:49:54,142: EPOCH 18: training on 191080 raw words (135219 effective words) took 0.3s, 483481 effective words/s
INFO - 2023-11-30 16:49:54,431: EPOCH 19: training on 191080 raw words (135099 effective words) took 0.3s, 471368 effective words/s
INFO - 2023-11-30 16:49:54,431: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2703945 effective words) took 6.4s, 424502 effective words/s', 'datetime': '2023-11-30T16:49:54.431725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:54,432: collecting all words and their counts
INFO - 2023-11-30 16:49:54,432: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:49:54,474: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:49:54,474: Updating model with new vocabulary
INFO - 2023-11-30 16:49:54,491: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:49:54.491060', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:54,507: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:49:54,507: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:49:54,507: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135438.52455477702 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:49:54.507951', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:49:54,539: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:49:54,539: updating layer weights
INFO - 2023-11-30 16:49:54,540: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:49:54.540021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:49:54,540: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:49:54,540: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:49:54.540285', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:49:54,846: EPOCH 0: training on 191080 raw words (135405 effective words) took 0.3s, 446079 effective words/s
INFO - 2023-11-30 16:49:55,149: EPOCH 1: training on 191080 raw words (135533 effective words) took 0.3s, 450593 effective words/s
INFO - 2023-11-30 16:49:55,449: EPOCH 2: training on 191080 raw words (135200 effective words) took 0.3s, 454079 effective words/s
INFO - 2023-11-30 16:49:55,748: EPOCH 3: training on 191080 raw words (135389 effective words) took 0.3s, 456814 effective words/s
INFO - 2023-11-30 16:49:56,042: EPOCH 4: training on 191080 raw words (135376 effective words) took 0.3s, 465764 effective words/s
INFO - 2023-11-30 16:49:56,336: EPOCH 5: training on 191080 raw words (135248 effective words) took 0.3s, 463761 effective words/s
INFO - 2023-11-30 16:49:56,630: EPOCH 6: training on 191080 raw words (135511 effective words) took 0.3s, 465009 effective words/s
INFO - 2023-11-30 16:49:56,928: EPOCH 7: training on 191080 raw words (135503 effective words) took 0.3s, 459111 effective words/s
INFO - 2023-11-30 16:49:57,223: EPOCH 8: training on 191080 raw words (135515 effective words) took 0.3s, 463622 effective words/s
INFO - 2023-11-30 16:49:57,541: EPOCH 9: training on 191080 raw words (135432 effective words) took 0.3s, 428929 effective words/s
INFO - 2023-11-30 16:49:57,843: EPOCH 10: training on 191080 raw words (135522 effective words) took 0.3s, 453500 effective words/s
INFO - 2023-11-30 16:49:58,138: EPOCH 11: training on 191080 raw words (135503 effective words) took 0.3s, 463302 effective words/s
INFO - 2023-11-30 16:49:58,435: EPOCH 12: training on 191080 raw words (135491 effective words) took 0.3s, 460251 effective words/s
INFO - 2023-11-30 16:49:58,739: EPOCH 13: training on 191080 raw words (135480 effective words) took 0.3s, 448782 effective words/s
INFO - 2023-11-30 16:49:59,035: EPOCH 14: training on 191080 raw words (135398 effective words) took 0.3s, 461260 effective words/s
INFO - 2023-11-30 16:49:59,326: EPOCH 15: training on 191080 raw words (135371 effective words) took 0.3s, 469324 effective words/s
INFO - 2023-11-30 16:49:59,621: EPOCH 16: training on 191080 raw words (135359 effective words) took 0.3s, 463073 effective words/s
INFO - 2023-11-30 16:49:59,908: EPOCH 17: training on 191080 raw words (135416 effective words) took 0.3s, 475622 effective words/s
INFO - 2023-11-30 16:50:00,199: EPOCH 18: training on 191080 raw words (135420 effective words) took 0.3s, 469932 effective words/s
INFO - 2023-11-30 16:50:00,570: EPOCH 19: training on 191080 raw words (135580 effective words) took 0.4s, 367726 effective words/s
INFO - 2023-11-30 16:50:00,571: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708652 effective words) took 6.0s, 449147 effective words/s', 'datetime': '2023-11-30T16:50:00.571074', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:00,571: collecting all words and their counts
INFO - 2023-11-30 16:50:00,571: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:00,605: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:00,605: Updating model with new vocabulary
INFO - 2023-11-30 16:50:00,619: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:00.619093', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:00,636: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:00,637: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:00,637: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135597.86563786195 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:50:00.637161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:00,661: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:00,661: updating layer weights
INFO - 2023-11-30 16:50:00,662: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:00.662128', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:00,662: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:00,662: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:00.662517', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:00,946: EPOCH 0: training on 191080 raw words (135649 effective words) took 0.3s, 512078 effective words/s
INFO - 2023-11-30 16:50:01,274: EPOCH 1: training on 191080 raw words (135743 effective words) took 0.3s, 417931 effective words/s
INFO - 2023-11-30 16:50:01,601: EPOCH 2: training on 191080 raw words (135630 effective words) took 0.3s, 420132 effective words/s
INFO - 2023-11-30 16:50:01,902: EPOCH 3: training on 191080 raw words (135559 effective words) took 0.3s, 453966 effective words/s
INFO - 2023-11-30 16:50:02,230: EPOCH 4: training on 191080 raw words (135550 effective words) took 0.3s, 416880 effective words/s
INFO - 2023-11-30 16:50:02,566: EPOCH 5: training on 191080 raw words (135660 effective words) took 0.3s, 407884 effective words/s
INFO - 2023-11-30 16:50:02,906: EPOCH 6: training on 191080 raw words (135452 effective words) took 0.3s, 402010 effective words/s
INFO - 2023-11-30 16:50:03,237: EPOCH 7: training on 191080 raw words (135806 effective words) took 0.3s, 412748 effective words/s
INFO - 2023-11-30 16:50:03,596: EPOCH 8: training on 191080 raw words (135680 effective words) took 0.3s, 395022 effective words/s
INFO - 2023-11-30 16:50:03,927: EPOCH 9: training on 191080 raw words (135717 effective words) took 0.3s, 415057 effective words/s
INFO - 2023-11-30 16:50:04,250: EPOCH 10: training on 191080 raw words (135402 effective words) took 0.3s, 423258 effective words/s
INFO - 2023-11-30 16:50:04,567: EPOCH 11: training on 191080 raw words (135625 effective words) took 0.3s, 432008 effective words/s
INFO - 2023-11-30 16:50:04,852: EPOCH 12: training on 191080 raw words (135624 effective words) took 0.3s, 481275 effective words/s
INFO - 2023-11-30 16:50:05,130: EPOCH 13: training on 191080 raw words (135637 effective words) took 0.3s, 491420 effective words/s
INFO - 2023-11-30 16:50:05,417: EPOCH 14: training on 191080 raw words (135750 effective words) took 0.3s, 478241 effective words/s
INFO - 2023-11-30 16:50:05,712: EPOCH 15: training on 191080 raw words (135546 effective words) took 0.3s, 463634 effective words/s
INFO - 2023-11-30 16:50:05,996: EPOCH 16: training on 191080 raw words (135489 effective words) took 0.3s, 481341 effective words/s
INFO - 2023-11-30 16:50:06,279: EPOCH 17: training on 191080 raw words (135677 effective words) took 0.3s, 482749 effective words/s
INFO - 2023-11-30 16:50:06,589: EPOCH 18: training on 191080 raw words (135306 effective words) took 0.3s, 440853 effective words/s
INFO - 2023-11-30 16:50:06,972: EPOCH 19: training on 191080 raw words (135405 effective words) took 0.4s, 356552 effective words/s
INFO - 2023-11-30 16:50:06,972: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711907 effective words) took 6.3s, 429776 effective words/s', 'datetime': '2023-11-30T16:50:06.972772', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:06,973: collecting all words and their counts
INFO - 2023-11-30 16:50:06,973: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:07,029: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:07,030: Updating model with new vocabulary
INFO - 2023-11-30 16:50:07,087: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:07.087840', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:07,169: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:07,170: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:07,170: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135688.63707015367 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:50:07.170493', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:07,259: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:07,259: updating layer weights
INFO - 2023-11-30 16:50:07,259: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:07.259690', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:07,259: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:07,259: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:07.259978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:07,648: EPOCH 0: training on 191080 raw words (135772 effective words) took 0.4s, 351813 effective words/s
INFO - 2023-11-30 16:50:08,088: EPOCH 1: training on 191080 raw words (135638 effective words) took 0.4s, 310168 effective words/s
INFO - 2023-11-30 16:50:08,602: EPOCH 2: training on 191080 raw words (135760 effective words) took 0.5s, 265887 effective words/s
INFO - 2023-11-30 16:50:09,329: EPOCH 3: training on 191080 raw words (135704 effective words) took 0.7s, 188209 effective words/s
INFO - 2023-11-30 16:50:09,975: EPOCH 4: training on 191080 raw words (135550 effective words) took 0.6s, 211752 effective words/s
INFO - 2023-11-30 16:50:10,423: EPOCH 5: training on 191080 raw words (135767 effective words) took 0.4s, 306439 effective words/s
INFO - 2023-11-30 16:50:10,849: EPOCH 6: training on 191080 raw words (135429 effective words) took 0.4s, 341780 effective words/s
INFO - 2023-11-30 16:50:11,341: EPOCH 7: training on 191080 raw words (135720 effective words) took 0.5s, 278950 effective words/s
INFO - 2023-11-30 16:50:11,905: EPOCH 8: training on 191080 raw words (135729 effective words) took 0.6s, 242069 effective words/s
INFO - 2023-11-30 16:50:12,610: EPOCH 9: training on 191080 raw words (135847 effective words) took 0.7s, 194225 effective words/s
INFO - 2023-11-30 16:50:13,217: EPOCH 10: training on 191080 raw words (135662 effective words) took 0.6s, 225848 effective words/s
INFO - 2023-11-30 16:50:13,828: EPOCH 11: training on 191080 raw words (135861 effective words) took 0.6s, 224919 effective words/s
INFO - 2023-11-30 16:50:14,386: EPOCH 12: training on 191080 raw words (135652 effective words) took 0.6s, 245278 effective words/s
INFO - 2023-11-30 16:50:14,857: EPOCH 13: training on 191080 raw words (135856 effective words) took 0.5s, 290505 effective words/s
INFO - 2023-11-30 16:50:15,317: EPOCH 14: training on 191080 raw words (135512 effective words) took 0.5s, 297417 effective words/s
INFO - 2023-11-30 16:50:15,797: EPOCH 15: training on 191080 raw words (135686 effective words) took 0.5s, 284687 effective words/s
INFO - 2023-11-30 16:50:16,249: EPOCH 16: training on 191080 raw words (135622 effective words) took 0.4s, 302951 effective words/s
INFO - 2023-11-30 16:50:16,698: EPOCH 17: training on 191080 raw words (135464 effective words) took 0.4s, 304277 effective words/s
INFO - 2023-11-30 16:50:17,103: EPOCH 18: training on 191080 raw words (135867 effective words) took 0.4s, 365013 effective words/s
INFO - 2023-11-30 16:50:17,486: EPOCH 19: training on 191080 raw words (135765 effective words) took 0.4s, 384992 effective words/s
INFO - 2023-11-30 16:50:17,487: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2713863 effective words) took 10.2s, 265364 effective words/s', 'datetime': '2023-11-30T16:50:17.487050', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:17,487: collecting all words and their counts
INFO - 2023-11-30 16:50:17,487: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:17,526: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:17,526: Updating model with new vocabulary
INFO - 2023-11-30 16:50:17,543: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:17.543456', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:17,563: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:17,564: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:17,564: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135495.00835432787 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:50:17.564249', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:17,596: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:17,597: updating layer weights
INFO - 2023-11-30 16:50:17,597: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:17.597716', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:17,597: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:17,598: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:17.598045', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:17,982: EPOCH 0: training on 191080 raw words (135390 effective words) took 0.4s, 355520 effective words/s
INFO - 2023-11-30 16:50:18,406: EPOCH 1: training on 191080 raw words (135583 effective words) took 0.4s, 323098 effective words/s
INFO - 2023-11-30 16:50:18,806: EPOCH 2: training on 191080 raw words (135592 effective words) took 0.4s, 341973 effective words/s
INFO - 2023-11-30 16:50:19,176: EPOCH 3: training on 191080 raw words (135557 effective words) took 0.4s, 370302 effective words/s
INFO - 2023-11-30 16:50:19,542: EPOCH 4: training on 191080 raw words (135397 effective words) took 0.4s, 373045 effective words/s
INFO - 2023-11-30 16:50:19,921: EPOCH 5: training on 191080 raw words (135385 effective words) took 0.4s, 384001 effective words/s
INFO - 2023-11-30 16:50:20,307: EPOCH 6: training on 191080 raw words (135292 effective words) took 0.4s, 353925 effective words/s
INFO - 2023-11-30 16:50:20,661: EPOCH 7: training on 191080 raw words (135428 effective words) took 0.4s, 386067 effective words/s
INFO - 2023-11-30 16:50:21,012: EPOCH 8: training on 191080 raw words (135476 effective words) took 0.3s, 401855 effective words/s
INFO - 2023-11-30 16:50:21,386: EPOCH 9: training on 191080 raw words (135649 effective words) took 0.4s, 365995 effective words/s
INFO - 2023-11-30 16:50:21,808: EPOCH 10: training on 191080 raw words (135333 effective words) took 0.4s, 323628 effective words/s
INFO - 2023-11-30 16:50:22,215: EPOCH 11: training on 191080 raw words (135706 effective words) took 0.4s, 336069 effective words/s
INFO - 2023-11-30 16:50:22,587: EPOCH 12: training on 191080 raw words (135592 effective words) took 0.4s, 367951 effective words/s
INFO - 2023-11-30 16:50:22,936: EPOCH 13: training on 191080 raw words (135560 effective words) took 0.3s, 392344 effective words/s
INFO - 2023-11-30 16:50:23,226: EPOCH 14: training on 191080 raw words (135662 effective words) took 0.3s, 473103 effective words/s
INFO - 2023-11-30 16:50:23,502: EPOCH 15: training on 191080 raw words (135493 effective words) took 0.3s, 494685 effective words/s
INFO - 2023-11-30 16:50:23,795: EPOCH 16: training on 191080 raw words (135487 effective words) took 0.3s, 467122 effective words/s
INFO - 2023-11-30 16:50:24,153: EPOCH 17: training on 191080 raw words (135685 effective words) took 0.4s, 381661 effective words/s
INFO - 2023-11-30 16:50:24,441: EPOCH 18: training on 191080 raw words (135610 effective words) took 0.3s, 475501 effective words/s
INFO - 2023-11-30 16:50:24,731: EPOCH 19: training on 191080 raw words (135348 effective words) took 0.3s, 471302 effective words/s
INFO - 2023-11-30 16:50:24,731: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710225 effective words) took 7.1s, 379931 effective words/s', 'datetime': '2023-11-30T16:50:24.731658', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:24,731: collecting all words and their counts
INFO - 2023-11-30 16:50:24,732: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:24,758: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:24,758: Updating model with new vocabulary
INFO - 2023-11-30 16:50:24,771: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:24.771061', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:24,787: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:24,787: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:24,787: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135464.05894307944 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:50:24.787326', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:24,810: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:24,810: updating layer weights
INFO - 2023-11-30 16:50:24,810: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:24.810549', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:24,810: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:24,810: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:24.810794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:25,103: EPOCH 0: training on 191080 raw words (135561 effective words) took 0.3s, 466184 effective words/s
INFO - 2023-11-30 16:50:25,401: EPOCH 1: training on 191080 raw words (135418 effective words) took 0.3s, 491683 effective words/s
INFO - 2023-11-30 16:50:25,713: EPOCH 2: training on 191080 raw words (135310 effective words) took 0.3s, 437053 effective words/s
INFO - 2023-11-30 16:50:26,030: EPOCH 3: training on 191080 raw words (135274 effective words) took 0.3s, 430936 effective words/s
INFO - 2023-11-30 16:50:26,329: EPOCH 4: training on 191080 raw words (135440 effective words) took 0.3s, 458377 effective words/s
INFO - 2023-11-30 16:50:26,618: EPOCH 5: training on 191080 raw words (135369 effective words) took 0.3s, 472460 effective words/s
INFO - 2023-11-30 16:50:26,909: EPOCH 6: training on 191080 raw words (135520 effective words) took 0.3s, 469214 effective words/s
INFO - 2023-11-30 16:50:27,202: EPOCH 7: training on 191080 raw words (135430 effective words) took 0.3s, 467728 effective words/s
INFO - 2023-11-30 16:50:27,509: EPOCH 8: training on 191080 raw words (135664 effective words) took 0.3s, 444672 effective words/s
INFO - 2023-11-30 16:50:27,801: EPOCH 9: training on 191080 raw words (135521 effective words) took 0.3s, 468592 effective words/s
INFO - 2023-11-30 16:50:28,094: EPOCH 10: training on 191080 raw words (135738 effective words) took 0.3s, 468625 effective words/s
INFO - 2023-11-30 16:50:28,386: EPOCH 11: training on 191080 raw words (135505 effective words) took 0.3s, 467681 effective words/s
INFO - 2023-11-30 16:50:28,676: EPOCH 12: training on 191080 raw words (135463 effective words) took 0.3s, 491856 effective words/s
INFO - 2023-11-30 16:50:28,964: EPOCH 13: training on 191080 raw words (135573 effective words) took 0.3s, 476733 effective words/s
INFO - 2023-11-30 16:50:29,253: EPOCH 14: training on 191080 raw words (135374 effective words) took 0.3s, 471884 effective words/s
INFO - 2023-11-30 16:50:29,532: EPOCH 15: training on 191080 raw words (135440 effective words) took 0.3s, 490437 effective words/s
INFO - 2023-11-30 16:50:29,816: EPOCH 16: training on 191080 raw words (135541 effective words) took 0.3s, 480431 effective words/s
INFO - 2023-11-30 16:50:30,122: EPOCH 17: training on 191080 raw words (135393 effective words) took 0.3s, 446445 effective words/s
INFO - 2023-11-30 16:50:30,416: EPOCH 18: training on 191080 raw words (135443 effective words) took 0.3s, 464360 effective words/s
INFO - 2023-11-30 16:50:30,724: EPOCH 19: training on 191080 raw words (135692 effective words) took 0.3s, 446439 effective words/s
INFO - 2023-11-30 16:50:30,724: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709669 effective words) took 5.9s, 458183 effective words/s', 'datetime': '2023-11-30T16:50:30.724880', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:30,725: collecting all words and their counts
INFO - 2023-11-30 16:50:30,725: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:30,753: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:30,754: Updating model with new vocabulary
INFO - 2023-11-30 16:50:30,766: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:30.766721', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:30,782: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:30,782: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:30,782: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135419.03563637106 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:50:30.782856', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:30,805: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:30,805: updating layer weights
INFO - 2023-11-30 16:50:30,806: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:30.806278', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:30,806: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:30,806: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:30.806568', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:31,083: EPOCH 0: training on 191080 raw words (135328 effective words) took 0.3s, 493308 effective words/s
INFO - 2023-11-30 16:50:31,445: EPOCH 1: training on 191080 raw words (135412 effective words) took 0.4s, 377114 effective words/s
INFO - 2023-11-30 16:50:31,730: EPOCH 2: training on 191080 raw words (135454 effective words) took 0.3s, 479146 effective words/s
INFO - 2023-11-30 16:50:32,010: EPOCH 3: training on 191080 raw words (135359 effective words) took 0.3s, 489004 effective words/s
INFO - 2023-11-30 16:50:32,288: EPOCH 4: training on 191080 raw words (135479 effective words) took 0.3s, 492738 effective words/s
INFO - 2023-11-30 16:50:32,571: EPOCH 5: training on 191080 raw words (135581 effective words) took 0.3s, 483765 effective words/s
INFO - 2023-11-30 16:50:32,862: EPOCH 6: training on 191080 raw words (135544 effective words) took 0.3s, 469389 effective words/s
INFO - 2023-11-30 16:50:33,197: EPOCH 7: training on 191080 raw words (135449 effective words) took 0.3s, 408329 effective words/s
INFO - 2023-11-30 16:50:33,542: EPOCH 8: training on 191080 raw words (135514 effective words) took 0.3s, 395692 effective words/s
INFO - 2023-11-30 16:50:33,915: EPOCH 9: training on 191080 raw words (135549 effective words) took 0.4s, 366416 effective words/s
INFO - 2023-11-30 16:50:34,245: EPOCH 10: training on 191080 raw words (135407 effective words) took 0.3s, 414796 effective words/s
INFO - 2023-11-30 16:50:34,587: EPOCH 11: training on 191080 raw words (135224 effective words) took 0.3s, 399731 effective words/s
INFO - 2023-11-30 16:50:34,979: EPOCH 12: training on 191080 raw words (135432 effective words) took 0.4s, 348362 effective words/s
INFO - 2023-11-30 16:50:35,318: EPOCH 13: training on 191080 raw words (135584 effective words) took 0.3s, 402994 effective words/s
INFO - 2023-11-30 16:50:35,670: EPOCH 14: training on 191080 raw words (135263 effective words) took 0.3s, 387362 effective words/s
INFO - 2023-11-30 16:50:35,970: EPOCH 15: training on 191080 raw words (135248 effective words) took 0.3s, 456386 effective words/s
INFO - 2023-11-30 16:50:36,251: EPOCH 16: training on 191080 raw words (135585 effective words) took 0.3s, 485481 effective words/s
INFO - 2023-11-30 16:50:36,572: EPOCH 17: training on 191080 raw words (135370 effective words) took 0.3s, 425773 effective words/s
INFO - 2023-11-30 16:50:36,864: EPOCH 18: training on 191080 raw words (135464 effective words) took 0.3s, 468108 effective words/s
INFO - 2023-11-30 16:50:37,158: EPOCH 19: training on 191080 raw words (135384 effective words) took 0.3s, 497241 effective words/s
INFO - 2023-11-30 16:50:37,159: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708630 effective words) took 6.4s, 426399 effective words/s', 'datetime': '2023-11-30T16:50:37.159032', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:37,159: collecting all words and their counts
INFO - 2023-11-30 16:50:37,159: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:37,190: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:37,190: Updating model with new vocabulary
INFO - 2023-11-30 16:50:37,204: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:37.204506', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:37,221: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:37,221: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:37,221: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135553.59949975315 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:50:37.221374', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:37,248: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:37,248: updating layer weights
INFO - 2023-11-30 16:50:37,249: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:37.249170', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:37,249: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:37,249: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:37.249336', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:37,584: EPOCH 0: training on 191080 raw words (135662 effective words) took 0.3s, 409007 effective words/s
INFO - 2023-11-30 16:50:37,988: EPOCH 1: training on 191080 raw words (135707 effective words) took 0.4s, 338749 effective words/s
INFO - 2023-11-30 16:50:38,337: EPOCH 2: training on 191080 raw words (135431 effective words) took 0.3s, 391794 effective words/s
INFO - 2023-11-30 16:50:38,742: EPOCH 3: training on 191080 raw words (135592 effective words) took 0.4s, 336485 effective words/s
INFO - 2023-11-30 16:50:39,196: EPOCH 4: training on 191080 raw words (135400 effective words) took 0.4s, 301492 effective words/s
INFO - 2023-11-30 16:50:39,707: EPOCH 5: training on 191080 raw words (135572 effective words) took 0.5s, 267911 effective words/s
INFO - 2023-11-30 16:50:40,184: EPOCH 6: training on 191080 raw words (135789 effective words) took 0.5s, 287473 effective words/s
INFO - 2023-11-30 16:50:40,602: EPOCH 7: training on 191080 raw words (135526 effective words) took 0.4s, 327753 effective words/s
INFO - 2023-11-30 16:50:40,999: EPOCH 8: training on 191080 raw words (135670 effective words) took 0.4s, 344168 effective words/s
INFO - 2023-11-30 16:50:41,445: EPOCH 9: training on 191080 raw words (135593 effective words) took 0.4s, 306536 effective words/s
INFO - 2023-11-30 16:50:41,864: EPOCH 10: training on 191080 raw words (135611 effective words) took 0.4s, 326604 effective words/s
INFO - 2023-11-30 16:50:42,285: EPOCH 11: training on 191080 raw words (135490 effective words) took 0.4s, 324907 effective words/s
INFO - 2023-11-30 16:50:42,706: EPOCH 12: training on 191080 raw words (135679 effective words) took 0.4s, 324932 effective words/s
INFO - 2023-11-30 16:50:43,186: EPOCH 13: training on 191080 raw words (135450 effective words) took 0.5s, 284363 effective words/s
INFO - 2023-11-30 16:50:43,612: EPOCH 14: training on 191080 raw words (135575 effective words) took 0.4s, 321064 effective words/s
INFO - 2023-11-30 16:50:44,120: EPOCH 15: training on 191080 raw words (135450 effective words) took 0.5s, 268665 effective words/s
INFO - 2023-11-30 16:50:44,696: EPOCH 16: training on 191080 raw words (135564 effective words) took 0.6s, 237042 effective words/s
INFO - 2023-11-30 16:50:45,311: EPOCH 17: training on 191080 raw words (135457 effective words) took 0.6s, 222076 effective words/s
INFO - 2023-11-30 16:50:46,070: EPOCH 18: training on 191080 raw words (135630 effective words) took 0.8s, 179834 effective words/s
INFO - 2023-11-30 16:50:46,605: EPOCH 19: training on 191080 raw words (135543 effective words) took 0.5s, 256890 effective words/s
INFO - 2023-11-30 16:50:46,605: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711391 effective words) took 9.4s, 289797 effective words/s', 'datetime': '2023-11-30T16:50:46.605602', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:46,605: collecting all words and their counts
INFO - 2023-11-30 16:50:46,606: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:46,654: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:46,654: Updating model with new vocabulary
INFO - 2023-11-30 16:50:46,677: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:46.677329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:46,702: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:46,702: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:46,702: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135545.13533640327 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:50:46.702617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:46,747: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:46,748: updating layer weights
INFO - 2023-11-30 16:50:46,748: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:46.748847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:46,749: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:46,749: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:46.749471', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:47,255: EPOCH 0: training on 191080 raw words (135448 effective words) took 0.5s, 271517 effective words/s
INFO - 2023-11-30 16:50:47,710: EPOCH 1: training on 191080 raw words (135508 effective words) took 0.5s, 300352 effective words/s
INFO - 2023-11-30 16:50:48,137: EPOCH 2: training on 191080 raw words (135563 effective words) took 0.4s, 321154 effective words/s
INFO - 2023-11-30 16:50:48,429: EPOCH 3: training on 191080 raw words (135459 effective words) took 0.3s, 468109 effective words/s
INFO - 2023-11-30 16:50:48,718: EPOCH 4: training on 191080 raw words (135601 effective words) took 0.3s, 474229 effective words/s
INFO - 2023-11-30 16:50:49,009: EPOCH 5: training on 191080 raw words (135466 effective words) took 0.3s, 470081 effective words/s
INFO - 2023-11-30 16:50:49,298: EPOCH 6: training on 191080 raw words (135390 effective words) took 0.3s, 471521 effective words/s
INFO - 2023-11-30 16:50:49,585: EPOCH 7: training on 191080 raw words (135507 effective words) took 0.3s, 477378 effective words/s
INFO - 2023-11-30 16:50:49,868: EPOCH 8: training on 191080 raw words (135396 effective words) took 0.3s, 482673 effective words/s
INFO - 2023-11-30 16:50:50,150: EPOCH 9: training on 191080 raw words (135702 effective words) took 0.3s, 486115 effective words/s
INFO - 2023-11-30 16:50:50,428: EPOCH 10: training on 191080 raw words (135256 effective words) took 0.3s, 490668 effective words/s
INFO - 2023-11-30 16:50:50,724: EPOCH 11: training on 191080 raw words (135613 effective words) took 0.3s, 460896 effective words/s
INFO - 2023-11-30 16:50:51,007: EPOCH 12: training on 191080 raw words (135557 effective words) took 0.3s, 484581 effective words/s
INFO - 2023-11-30 16:50:51,291: EPOCH 13: training on 191080 raw words (135599 effective words) took 0.3s, 482079 effective words/s
INFO - 2023-11-30 16:50:51,575: EPOCH 14: training on 191080 raw words (135632 effective words) took 0.3s, 482292 effective words/s
INFO - 2023-11-30 16:50:51,861: EPOCH 15: training on 191080 raw words (135577 effective words) took 0.3s, 478507 effective words/s
INFO - 2023-11-30 16:50:52,145: EPOCH 16: training on 191080 raw words (135566 effective words) took 0.3s, 481542 effective words/s
INFO - 2023-11-30 16:50:52,426: EPOCH 17: training on 191080 raw words (135488 effective words) took 0.3s, 485352 effective words/s
INFO - 2023-11-30 16:50:52,712: EPOCH 18: training on 191080 raw words (135597 effective words) took 0.3s, 478703 effective words/s
INFO - 2023-11-30 16:50:52,997: EPOCH 19: training on 191080 raw words (135422 effective words) took 0.3s, 479150 effective words/s
INFO - 2023-11-30 16:50:52,998: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710347 effective words) took 6.2s, 433759 effective words/s', 'datetime': '2023-11-30T16:50:52.998221', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:52,998: collecting all words and their counts
INFO - 2023-11-30 16:50:52,998: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:53,031: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:53,031: Updating model with new vocabulary
INFO - 2023-11-30 16:50:53,043: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:53.043790', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:53,058: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:53,059: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:53,059: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135591.64303285492 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:50:53.059242', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:53,084: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:53,084: updating layer weights
INFO - 2023-11-30 16:50:53,085: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:53.085046', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:53,085: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:53,085: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:53.085316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:53,382: EPOCH 0: training on 191080 raw words (135630 effective words) took 0.3s, 459717 effective words/s
INFO - 2023-11-30 16:50:53,681: EPOCH 1: training on 191080 raw words (135556 effective words) took 0.3s, 457178 effective words/s
INFO - 2023-11-30 16:50:54,051: EPOCH 2: training on 191080 raw words (135656 effective words) took 0.4s, 369392 effective words/s
INFO - 2023-11-30 16:50:54,388: EPOCH 3: training on 191080 raw words (135614 effective words) took 0.3s, 406768 effective words/s
INFO - 2023-11-30 16:50:54,688: EPOCH 4: training on 191080 raw words (135380 effective words) took 0.3s, 454915 effective words/s
INFO - 2023-11-30 16:50:54,984: EPOCH 5: training on 191080 raw words (135717 effective words) took 0.3s, 462828 effective words/s
INFO - 2023-11-30 16:50:55,280: EPOCH 6: training on 191080 raw words (135459 effective words) took 0.3s, 461947 effective words/s
INFO - 2023-11-30 16:50:55,577: EPOCH 7: training on 191080 raw words (135703 effective words) took 0.3s, 460757 effective words/s
INFO - 2023-11-30 16:50:55,873: EPOCH 8: training on 191080 raw words (135720 effective words) took 0.3s, 463511 effective words/s
INFO - 2023-11-30 16:50:56,171: EPOCH 9: training on 191080 raw words (135658 effective words) took 0.3s, 459295 effective words/s
INFO - 2023-11-30 16:50:56,462: EPOCH 10: training on 191080 raw words (135649 effective words) took 0.3s, 469630 effective words/s
INFO - 2023-11-30 16:50:56,774: EPOCH 11: training on 191080 raw words (135539 effective words) took 0.3s, 438028 effective words/s
INFO - 2023-11-30 16:50:57,074: EPOCH 12: training on 191080 raw words (135692 effective words) took 0.3s, 456522 effective words/s
INFO - 2023-11-30 16:50:57,368: EPOCH 13: training on 191080 raw words (135308 effective words) took 0.3s, 462671 effective words/s
INFO - 2023-11-30 16:50:57,660: EPOCH 14: training on 191080 raw words (135685 effective words) took 0.3s, 469213 effective words/s
INFO - 2023-11-30 16:50:57,955: EPOCH 15: training on 191080 raw words (135482 effective words) took 0.3s, 462894 effective words/s
INFO - 2023-11-30 16:50:58,231: EPOCH 16: training on 191080 raw words (135578 effective words) took 0.3s, 495930 effective words/s
INFO - 2023-11-30 16:50:58,502: EPOCH 17: training on 191080 raw words (135620 effective words) took 0.3s, 504471 effective words/s
INFO - 2023-11-30 16:50:58,817: EPOCH 18: training on 191080 raw words (135609 effective words) took 0.3s, 434233 effective words/s
INFO - 2023-11-30 16:50:59,114: EPOCH 19: training on 191080 raw words (135646 effective words) took 0.3s, 460497 effective words/s
INFO - 2023-11-30 16:50:59,114: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711901 effective words) took 6.0s, 449783 effective words/s', 'datetime': '2023-11-30T16:50:59.114803', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:59,115: collecting all words and their counts
INFO - 2023-11-30 16:50:59,115: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:50:59,146: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:50:59,146: Updating model with new vocabulary
INFO - 2023-11-30 16:50:59,164: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:50:59.164767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:59,180: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:50:59,180: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:50:59,180: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135325.431646485 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:50:59.180552', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:50:59,211: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:50:59,211: updating layer weights
INFO - 2023-11-30 16:50:59,211: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:50:59.211721', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:50:59,212: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:50:59,212: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:50:59.212408', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:50:59,485: EPOCH 0: training on 191080 raw words (135556 effective words) took 0.3s, 503239 effective words/s
INFO - 2023-11-30 16:50:59,776: EPOCH 1: training on 191080 raw words (135160 effective words) took 0.3s, 468611 effective words/s
INFO - 2023-11-30 16:51:00,062: EPOCH 2: training on 191080 raw words (135090 effective words) took 0.3s, 477038 effective words/s
INFO - 2023-11-30 16:51:00,352: EPOCH 3: training on 191080 raw words (135209 effective words) took 0.3s, 469935 effective words/s
INFO - 2023-11-30 16:51:00,642: EPOCH 4: training on 191080 raw words (135279 effective words) took 0.3s, 472112 effective words/s
INFO - 2023-11-30 16:51:00,933: EPOCH 5: training on 191080 raw words (135350 effective words) took 0.3s, 468449 effective words/s
INFO - 2023-11-30 16:51:01,217: EPOCH 6: training on 191080 raw words (135312 effective words) took 0.3s, 481229 effective words/s
INFO - 2023-11-30 16:51:01,532: EPOCH 7: training on 191080 raw words (135262 effective words) took 0.3s, 433650 effective words/s
INFO - 2023-11-30 16:51:01,821: EPOCH 8: training on 191080 raw words (135237 effective words) took 0.3s, 472607 effective words/s
INFO - 2023-11-30 16:51:02,115: EPOCH 9: training on 191080 raw words (135318 effective words) took 0.3s, 465293 effective words/s
INFO - 2023-11-30 16:51:02,408: EPOCH 10: training on 191080 raw words (135034 effective words) took 0.3s, 464844 effective words/s
INFO - 2023-11-30 16:51:02,695: EPOCH 11: training on 191080 raw words (135212 effective words) took 0.3s, 474882 effective words/s
INFO - 2023-11-30 16:51:02,984: EPOCH 12: training on 191080 raw words (135414 effective words) took 0.3s, 473537 effective words/s
INFO - 2023-11-30 16:51:03,330: EPOCH 13: training on 191080 raw words (134937 effective words) took 0.3s, 392026 effective words/s
INFO - 2023-11-30 16:51:03,715: EPOCH 14: training on 191080 raw words (135376 effective words) took 0.4s, 355041 effective words/s
INFO - 2023-11-30 16:51:04,097: EPOCH 15: training on 191080 raw words (135301 effective words) took 0.4s, 357310 effective words/s
INFO - 2023-11-30 16:51:04,478: EPOCH 16: training on 191080 raw words (135549 effective words) took 0.4s, 359172 effective words/s
INFO - 2023-11-30 16:51:04,865: EPOCH 17: training on 191080 raw words (135354 effective words) took 0.4s, 352750 effective words/s
INFO - 2023-11-30 16:51:05,246: EPOCH 18: training on 191080 raw words (135556 effective words) took 0.4s, 358555 effective words/s
INFO - 2023-11-30 16:51:05,634: EPOCH 19: training on 191080 raw words (135376 effective words) took 0.4s, 351675 effective words/s
INFO - 2023-11-30 16:51:05,634: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2705882 effective words) took 6.4s, 421356 effective words/s', 'datetime': '2023-11-30T16:51:05.634891', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:05,635: collecting all words and their counts
INFO - 2023-11-30 16:51:05,635: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:05,675: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:05,675: Updating model with new vocabulary
INFO - 2023-11-30 16:51:05,695: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:05.695271', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:05,719: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:05,720: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:05,720: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135595.39014152525 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:51:05.720397', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:05,757: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:05,757: updating layer weights
INFO - 2023-11-30 16:51:05,757: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:05.757666', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:05,757: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:05,758: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:05.757987', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:06,164: EPOCH 0: training on 191080 raw words (135605 effective words) took 0.4s, 337354 effective words/s
INFO - 2023-11-30 16:51:06,587: EPOCH 1: training on 191080 raw words (135485 effective words) took 0.4s, 323150 effective words/s
INFO - 2023-11-30 16:51:07,033: EPOCH 2: training on 191080 raw words (135557 effective words) took 0.4s, 305905 effective words/s
INFO - 2023-11-30 16:51:07,474: EPOCH 3: training on 191080 raw words (135551 effective words) took 0.4s, 310221 effective words/s
INFO - 2023-11-30 16:51:07,902: EPOCH 4: training on 191080 raw words (135592 effective words) took 0.4s, 319665 effective words/s
INFO - 2023-11-30 16:51:08,328: EPOCH 5: training on 191080 raw words (135553 effective words) took 0.4s, 320678 effective words/s
INFO - 2023-11-30 16:51:08,769: EPOCH 6: training on 191080 raw words (135611 effective words) took 0.4s, 309767 effective words/s
INFO - 2023-11-30 16:51:09,190: EPOCH 7: training on 191080 raw words (135513 effective words) took 0.4s, 325308 effective words/s
INFO - 2023-11-30 16:51:09,639: EPOCH 8: training on 191080 raw words (135706 effective words) took 0.4s, 304508 effective words/s
INFO - 2023-11-30 16:51:10,174: EPOCH 9: training on 191080 raw words (135327 effective words) took 0.5s, 255004 effective words/s
INFO - 2023-11-30 16:51:10,713: EPOCH 10: training on 191080 raw words (135572 effective words) took 0.5s, 253532 effective words/s
INFO - 2023-11-30 16:51:11,202: EPOCH 11: training on 191080 raw words (135390 effective words) took 0.5s, 279104 effective words/s
INFO - 2023-11-30 16:51:11,672: EPOCH 12: training on 191080 raw words (135773 effective words) took 0.5s, 291672 effective words/s
INFO - 2023-11-30 16:51:12,147: EPOCH 13: training on 191080 raw words (135643 effective words) took 0.4s, 310603 effective words/s
INFO - 2023-11-30 16:51:12,516: EPOCH 14: training on 191080 raw words (135664 effective words) took 0.4s, 371402 effective words/s
INFO - 2023-11-30 16:51:12,789: EPOCH 15: training on 191080 raw words (135303 effective words) took 0.3s, 500298 effective words/s
INFO - 2023-11-30 16:51:13,062: EPOCH 16: training on 191080 raw words (135505 effective words) took 0.3s, 501438 effective words/s
INFO - 2023-11-30 16:51:13,336: EPOCH 17: training on 191080 raw words (135587 effective words) took 0.3s, 497770 effective words/s
INFO - 2023-11-30 16:51:13,613: EPOCH 18: training on 191080 raw words (135437 effective words) took 0.3s, 494098 effective words/s
INFO - 2023-11-30 16:51:13,884: EPOCH 19: training on 191080 raw words (135619 effective words) took 0.3s, 503900 effective words/s
INFO - 2023-11-30 16:51:13,885: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710993 effective words) took 8.1s, 333578 effective words/s', 'datetime': '2023-11-30T16:51:13.885178', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:13,885: collecting all words and their counts
INFO - 2023-11-30 16:51:13,885: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:13,913: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:13,913: Updating model with new vocabulary
INFO - 2023-11-30 16:51:13,924: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:13.924818', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:13,939: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:13,939: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:13,939: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135263.8147915417 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:51:13.939195', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:13,961: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:13,961: updating layer weights
INFO - 2023-11-30 16:51:13,961: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:13.961711', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:13,961: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:13,961: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:13.961968', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:14,226: EPOCH 0: training on 191080 raw words (135016 effective words) took 0.3s, 514620 effective words/s
INFO - 2023-11-30 16:51:14,493: EPOCH 1: training on 191080 raw words (135159 effective words) took 0.3s, 511665 effective words/s
INFO - 2023-11-30 16:51:14,759: EPOCH 2: training on 191080 raw words (135163 effective words) took 0.3s, 513810 effective words/s
INFO - 2023-11-30 16:51:15,019: EPOCH 3: training on 191080 raw words (135240 effective words) took 0.3s, 524914 effective words/s
INFO - 2023-11-30 16:51:15,284: EPOCH 4: training on 191080 raw words (135129 effective words) took 0.3s, 515107 effective words/s
INFO - 2023-11-30 16:51:15,550: EPOCH 5: training on 191080 raw words (135183 effective words) took 0.3s, 513389 effective words/s
INFO - 2023-11-30 16:51:15,813: EPOCH 6: training on 191080 raw words (135332 effective words) took 0.3s, 518294 effective words/s
INFO - 2023-11-30 16:51:16,079: EPOCH 7: training on 191080 raw words (135361 effective words) took 0.3s, 514506 effective words/s
INFO - 2023-11-30 16:51:16,346: EPOCH 8: training on 191080 raw words (135391 effective words) took 0.3s, 510785 effective words/s
INFO - 2023-11-30 16:51:16,611: EPOCH 9: training on 191080 raw words (135202 effective words) took 0.3s, 513851 effective words/s
INFO - 2023-11-30 16:51:16,873: EPOCH 10: training on 191080 raw words (135239 effective words) took 0.3s, 521823 effective words/s
INFO - 2023-11-30 16:51:17,135: EPOCH 11: training on 191080 raw words (135135 effective words) took 0.3s, 520362 effective words/s
INFO - 2023-11-30 16:51:17,396: EPOCH 12: training on 191080 raw words (135364 effective words) took 0.3s, 524050 effective words/s
INFO - 2023-11-30 16:51:17,658: EPOCH 13: training on 191080 raw words (135133 effective words) took 0.3s, 521150 effective words/s
INFO - 2023-11-30 16:51:17,915: EPOCH 14: training on 191080 raw words (135317 effective words) took 0.3s, 530782 effective words/s
INFO - 2023-11-30 16:51:18,176: EPOCH 15: training on 191080 raw words (135402 effective words) took 0.3s, 522604 effective words/s
INFO - 2023-11-30 16:51:18,460: EPOCH 16: training on 191080 raw words (135276 effective words) took 0.3s, 480429 effective words/s
INFO - 2023-11-30 16:51:18,719: EPOCH 17: training on 191080 raw words (135379 effective words) took 0.3s, 526653 effective words/s
INFO - 2023-11-30 16:51:18,980: EPOCH 18: training on 191080 raw words (135348 effective words) took 0.3s, 525336 effective words/s
INFO - 2023-11-30 16:51:19,241: EPOCH 19: training on 191080 raw words (135544 effective words) took 0.3s, 523801 effective words/s
INFO - 2023-11-30 16:51:19,241: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2705313 effective words) took 5.3s, 512411 effective words/s', 'datetime': '2023-11-30T16:51:19.241652', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:19,241: collecting all words and their counts
INFO - 2023-11-30 16:51:19,242: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:19,269: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:19,269: Updating model with new vocabulary
INFO - 2023-11-30 16:51:19,281: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:19.281044', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:19,294: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:19,295: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:19,295: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135487.31913805375 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:51:19.295179', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:19,317: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:19,317: updating layer weights
INFO - 2023-11-30 16:51:19,317: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:19.317710', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:19,317: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:19,318: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:19.317994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:19,592: EPOCH 0: training on 191080 raw words (135556 effective words) took 0.3s, 496898 effective words/s
INFO - 2023-11-30 16:51:19,874: EPOCH 1: training on 191080 raw words (135365 effective words) took 0.3s, 485136 effective words/s
INFO - 2023-11-30 16:51:20,152: EPOCH 2: training on 191080 raw words (135418 effective words) took 0.3s, 491388 effective words/s
INFO - 2023-11-30 16:51:20,428: EPOCH 3: training on 191080 raw words (135431 effective words) took 0.3s, 493678 effective words/s
INFO - 2023-11-30 16:51:20,698: EPOCH 4: training on 191080 raw words (135518 effective words) took 0.3s, 506601 effective words/s
INFO - 2023-11-30 16:51:20,975: EPOCH 5: training on 191080 raw words (135563 effective words) took 0.3s, 494383 effective words/s
INFO - 2023-11-30 16:51:21,251: EPOCH 6: training on 191080 raw words (135258 effective words) took 0.3s, 493962 effective words/s
INFO - 2023-11-30 16:51:21,534: EPOCH 7: training on 191080 raw words (135623 effective words) took 0.3s, 483832 effective words/s
INFO - 2023-11-30 16:51:21,808: EPOCH 8: training on 191080 raw words (135493 effective words) took 0.3s, 498465 effective words/s
INFO - 2023-11-30 16:51:22,085: EPOCH 9: training on 191080 raw words (135536 effective words) took 0.3s, 493169 effective words/s
INFO - 2023-11-30 16:51:22,360: EPOCH 10: training on 191080 raw words (135497 effective words) took 0.3s, 497494 effective words/s
INFO - 2023-11-30 16:51:22,717: EPOCH 11: training on 191080 raw words (135317 effective words) took 0.4s, 382276 effective words/s
INFO - 2023-11-30 16:51:23,015: EPOCH 12: training on 191080 raw words (135728 effective words) took 0.3s, 457857 effective words/s
INFO - 2023-11-30 16:51:23,292: EPOCH 13: training on 191080 raw words (135455 effective words) took 0.3s, 493907 effective words/s
INFO - 2023-11-30 16:51:23,564: EPOCH 14: training on 191080 raw words (135389 effective words) took 0.3s, 503370 effective words/s
INFO - 2023-11-30 16:51:23,838: EPOCH 15: training on 191080 raw words (135471 effective words) took 0.3s, 497347 effective words/s
INFO - 2023-11-30 16:51:24,109: EPOCH 16: training on 191080 raw words (135562 effective words) took 0.3s, 504732 effective words/s
INFO - 2023-11-30 16:51:24,408: EPOCH 17: training on 191080 raw words (135332 effective words) took 0.3s, 469927 effective words/s
INFO - 2023-11-30 16:51:24,714: EPOCH 18: training on 191080 raw words (135560 effective words) took 0.3s, 446642 effective words/s
INFO - 2023-11-30 16:51:25,007: EPOCH 19: training on 191080 raw words (135735 effective words) took 0.3s, 466341 effective words/s
INFO - 2023-11-30 16:51:25,008: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709807 effective words) took 5.7s, 476241 effective words/s', 'datetime': '2023-11-30T16:51:25.008122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:25,008: collecting all words and their counts
INFO - 2023-11-30 16:51:25,008: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:25,040: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:25,041: Updating model with new vocabulary
INFO - 2023-11-30 16:51:25,054: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:25.054515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:25,070: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:25,070: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:25,070: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135110.2233649005 word corpus (70.7%% of prior 191080)', 'datetime': '2023-11-30T16:51:25.070237', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:25,092: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:25,093: updating layer weights
INFO - 2023-11-30 16:51:25,093: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:25.093456', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:25,093: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:25,093: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:25.093681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:25,365: EPOCH 0: training on 191080 raw words (135215 effective words) took 0.3s, 502772 effective words/s
INFO - 2023-11-30 16:51:25,630: EPOCH 1: training on 191080 raw words (135168 effective words) took 0.3s, 513987 effective words/s
INFO - 2023-11-30 16:51:25,899: EPOCH 2: training on 191080 raw words (135025 effective words) took 0.3s, 507358 effective words/s
INFO - 2023-11-30 16:51:26,170: EPOCH 3: training on 191080 raw words (135114 effective words) took 0.3s, 501751 effective words/s
INFO - 2023-11-30 16:51:26,440: EPOCH 4: training on 191080 raw words (135295 effective words) took 0.3s, 505683 effective words/s
INFO - 2023-11-30 16:51:26,707: EPOCH 5: training on 191080 raw words (134826 effective words) took 0.3s, 510121 effective words/s
INFO - 2023-11-30 16:51:26,968: EPOCH 6: training on 191080 raw words (135302 effective words) took 0.3s, 521051 effective words/s
INFO - 2023-11-30 16:51:27,231: EPOCH 7: training on 191080 raw words (135184 effective words) took 0.3s, 519176 effective words/s
INFO - 2023-11-30 16:51:27,492: EPOCH 8: training on 191080 raw words (135120 effective words) took 0.3s, 522734 effective words/s
INFO - 2023-11-30 16:51:27,851: EPOCH 9: training on 191080 raw words (135105 effective words) took 0.4s, 380143 effective words/s
INFO - 2023-11-30 16:51:28,207: EPOCH 10: training on 191080 raw words (135069 effective words) took 0.4s, 382727 effective words/s
INFO - 2023-11-30 16:51:28,564: EPOCH 11: training on 191080 raw words (135165 effective words) took 0.4s, 381044 effective words/s
INFO - 2023-11-30 16:51:28,927: EPOCH 12: training on 191080 raw words (135069 effective words) took 0.3s, 409072 effective words/s
INFO - 2023-11-30 16:51:29,303: EPOCH 13: training on 191080 raw words (135019 effective words) took 0.4s, 361487 effective words/s
INFO - 2023-11-30 16:51:29,662: EPOCH 14: training on 191080 raw words (135193 effective words) took 0.4s, 380899 effective words/s
INFO - 2023-11-30 16:51:30,047: EPOCH 15: training on 191080 raw words (135010 effective words) took 0.4s, 353292 effective words/s
INFO - 2023-11-30 16:51:30,398: EPOCH 16: training on 191080 raw words (134948 effective words) took 0.3s, 414948 effective words/s
INFO - 2023-11-30 16:51:30,770: EPOCH 17: training on 191080 raw words (135326 effective words) took 0.4s, 366334 effective words/s
INFO - 2023-11-30 16:51:31,145: EPOCH 18: training on 191080 raw words (134919 effective words) took 0.4s, 362716 effective words/s
INFO - 2023-11-30 16:51:31,523: EPOCH 19: training on 191080 raw words (135079 effective words) took 0.4s, 360491 effective words/s
INFO - 2023-11-30 16:51:31,524: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2702151 effective words) took 6.4s, 420221 effective words/s', 'datetime': '2023-11-30T16:51:31.524128', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:31,524: collecting all words and their counts
INFO - 2023-11-30 16:51:31,524: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:31,565: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:31,565: Updating model with new vocabulary
INFO - 2023-11-30 16:51:31,589: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:31.589851', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:31,615: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:31,615: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:31,616: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135514.0284626931 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:51:31.616234', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:31,655: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:31,655: updating layer weights
INFO - 2023-11-30 16:51:31,656: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:31.656478', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:31,656: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:31,657: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:31.657140', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:32,056: EPOCH 0: training on 191080 raw words (135622 effective words) took 0.4s, 368593 effective words/s
INFO - 2023-11-30 16:51:32,479: EPOCH 1: training on 191080 raw words (135530 effective words) took 0.4s, 322681 effective words/s
INFO - 2023-11-30 16:51:32,878: EPOCH 2: training on 191080 raw words (135617 effective words) took 0.4s, 342304 effective words/s
INFO - 2023-11-30 16:51:33,297: EPOCH 3: training on 191080 raw words (135471 effective words) took 0.4s, 325784 effective words/s
INFO - 2023-11-30 16:51:33,727: EPOCH 4: training on 191080 raw words (135582 effective words) took 0.4s, 318150 effective words/s
INFO - 2023-11-30 16:51:34,171: EPOCH 5: training on 191080 raw words (135466 effective words) took 0.4s, 307299 effective words/s
INFO - 2023-11-30 16:51:34,598: EPOCH 6: training on 191080 raw words (135509 effective words) took 0.4s, 319845 effective words/s
INFO - 2023-11-30 16:51:35,034: EPOCH 7: training on 191080 raw words (135547 effective words) took 0.4s, 313428 effective words/s
INFO - 2023-11-30 16:51:35,480: EPOCH 8: training on 191080 raw words (135625 effective words) took 0.4s, 306479 effective words/s
INFO - 2023-11-30 16:51:35,928: EPOCH 9: training on 191080 raw words (135653 effective words) took 0.4s, 305584 effective words/s
INFO - 2023-11-30 16:51:36,356: EPOCH 10: training on 191080 raw words (135234 effective words) took 0.4s, 341033 effective words/s
INFO - 2023-11-30 16:51:36,684: EPOCH 11: training on 191080 raw words (135629 effective words) took 0.3s, 417909 effective words/s
INFO - 2023-11-30 16:51:36,955: EPOCH 12: training on 191080 raw words (135456 effective words) took 0.3s, 504901 effective words/s
INFO - 2023-11-30 16:51:37,225: EPOCH 13: training on 191080 raw words (135549 effective words) took 0.3s, 505965 effective words/s
INFO - 2023-11-30 16:51:37,499: EPOCH 14: training on 191080 raw words (135552 effective words) took 0.3s, 497711 effective words/s
INFO - 2023-11-30 16:51:37,779: EPOCH 15: training on 191080 raw words (135551 effective words) took 0.3s, 488657 effective words/s
INFO - 2023-11-30 16:51:38,054: EPOCH 16: training on 191080 raw words (135693 effective words) took 0.3s, 498548 effective words/s
INFO - 2023-11-30 16:51:38,330: EPOCH 17: training on 191080 raw words (135691 effective words) took 0.3s, 495158 effective words/s
INFO - 2023-11-30 16:51:38,605: EPOCH 18: training on 191080 raw words (135768 effective words) took 0.3s, 498782 effective words/s
INFO - 2023-11-30 16:51:38,881: EPOCH 19: training on 191080 raw words (135601 effective words) took 0.3s, 494472 effective words/s
INFO - 2023-11-30 16:51:38,882: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711346 effective words) took 7.2s, 375297 effective words/s', 'datetime': '2023-11-30T16:51:38.882232', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:38,882: collecting all words and their counts
INFO - 2023-11-30 16:51:38,882: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:38,909: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:38,909: Updating model with new vocabulary
INFO - 2023-11-30 16:51:38,921: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:38.921349', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:38,935: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:38,935: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:51:38,935: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135349.635993338 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:51:38.935704', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:38,957: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:38,957: updating layer weights
INFO - 2023-11-30 16:51:38,958: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:38.958274', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:38,958: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:38,958: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:38.958576', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:39,223: EPOCH 0: training on 191080 raw words (135456 effective words) took 0.3s, 516001 effective words/s
INFO - 2023-11-30 16:51:39,492: EPOCH 1: training on 191080 raw words (135332 effective words) took 0.3s, 506925 effective words/s
INFO - 2023-11-30 16:51:39,759: EPOCH 2: training on 191080 raw words (135282 effective words) took 0.3s, 511323 effective words/s
INFO - 2023-11-30 16:51:40,032: EPOCH 3: training on 191080 raw words (135476 effective words) took 0.3s, 500659 effective words/s
INFO - 2023-11-30 16:51:40,300: EPOCH 4: training on 191080 raw words (135380 effective words) took 0.3s, 510857 effective words/s
INFO - 2023-11-30 16:51:40,565: EPOCH 5: training on 191080 raw words (135465 effective words) took 0.3s, 515373 effective words/s
INFO - 2023-11-30 16:51:40,834: EPOCH 6: training on 191080 raw words (135419 effective words) took 0.3s, 508937 effective words/s
INFO - 2023-11-30 16:51:41,104: EPOCH 7: training on 191080 raw words (135276 effective words) took 0.3s, 504377 effective words/s
INFO - 2023-11-30 16:51:41,371: EPOCH 8: training on 191080 raw words (135232 effective words) took 0.3s, 511485 effective words/s
INFO - 2023-11-30 16:51:41,685: EPOCH 9: training on 191080 raw words (135311 effective words) took 0.3s, 434595 effective words/s
INFO - 2023-11-30 16:51:41,982: EPOCH 10: training on 191080 raw words (135240 effective words) took 0.3s, 458553 effective words/s
INFO - 2023-11-30 16:51:42,253: EPOCH 11: training on 191080 raw words (135503 effective words) took 0.3s, 504510 effective words/s
INFO - 2023-11-30 16:51:42,523: EPOCH 12: training on 191080 raw words (135455 effective words) took 0.3s, 507444 effective words/s
INFO - 2023-11-30 16:51:42,787: EPOCH 13: training on 191080 raw words (135349 effective words) took 0.3s, 516922 effective words/s
INFO - 2023-11-30 16:51:43,053: EPOCH 14: training on 191080 raw words (135365 effective words) took 0.3s, 513160 effective words/s
INFO - 2023-11-30 16:51:43,317: EPOCH 15: training on 191080 raw words (135317 effective words) took 0.3s, 516614 effective words/s
INFO - 2023-11-30 16:51:43,586: EPOCH 16: training on 191080 raw words (135667 effective words) took 0.3s, 509410 effective words/s
INFO - 2023-11-30 16:51:43,852: EPOCH 17: training on 191080 raw words (135416 effective words) took 0.3s, 513224 effective words/s
INFO - 2023-11-30 16:51:44,116: EPOCH 18: training on 191080 raw words (135397 effective words) took 0.3s, 518250 effective words/s
INFO - 2023-11-30 16:51:44,383: EPOCH 19: training on 191080 raw words (135324 effective words) took 0.3s, 511530 effective words/s
INFO - 2023-11-30 16:51:44,383: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2707662 effective words) took 5.4s, 499115 effective words/s', 'datetime': '2023-11-30T16:51:44.383629', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:44,383: collecting all words and their counts
INFO - 2023-11-30 16:51:44,383: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:44,410: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:44,410: Updating model with new vocabulary
INFO - 2023-11-30 16:51:44,423: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:44.423329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:44,438: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:44,438: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:44,438: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135698.52992502184 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:51:44.438425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:44,460: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:44,460: updating layer weights
INFO - 2023-11-30 16:51:44,460: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:44.460931', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:44,461: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:44,461: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:44.461132', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:44,738: EPOCH 0: training on 191080 raw words (135802 effective words) took 0.3s, 493511 effective words/s
INFO - 2023-11-30 16:51:45,020: EPOCH 1: training on 191080 raw words (135971 effective words) took 0.3s, 485914 effective words/s
INFO - 2023-11-30 16:51:45,295: EPOCH 2: training on 191080 raw words (135779 effective words) took 0.3s, 497697 effective words/s
INFO - 2023-11-30 16:51:45,576: EPOCH 3: training on 191080 raw words (135505 effective words) took 0.3s, 486489 effective words/s
INFO - 2023-11-30 16:51:45,912: EPOCH 4: training on 191080 raw words (135725 effective words) took 0.3s, 406697 effective words/s
INFO - 2023-11-30 16:51:46,244: EPOCH 5: training on 191080 raw words (135632 effective words) took 0.3s, 412052 effective words/s
INFO - 2023-11-30 16:51:46,574: EPOCH 6: training on 191080 raw words (135557 effective words) took 0.3s, 414226 effective words/s
INFO - 2023-11-30 16:51:46,879: EPOCH 7: training on 191080 raw words (135701 effective words) took 0.3s, 448219 effective words/s
INFO - 2023-11-30 16:51:47,167: EPOCH 8: training on 191080 raw words (135813 effective words) took 0.3s, 476559 effective words/s
INFO - 2023-11-30 16:51:47,439: EPOCH 9: training on 191080 raw words (135731 effective words) took 0.3s, 502602 effective words/s
INFO - 2023-11-30 16:51:47,713: EPOCH 10: training on 191080 raw words (135589 effective words) took 0.3s, 499285 effective words/s
INFO - 2023-11-30 16:51:47,984: EPOCH 11: training on 191080 raw words (135697 effective words) took 0.3s, 505323 effective words/s
INFO - 2023-11-30 16:51:48,256: EPOCH 12: training on 191080 raw words (135657 effective words) took 0.3s, 503241 effective words/s
INFO - 2023-11-30 16:51:48,557: EPOCH 13: training on 191080 raw words (135762 effective words) took 0.3s, 453722 effective words/s
INFO - 2023-11-30 16:51:48,860: EPOCH 14: training on 191080 raw words (135453 effective words) took 0.3s, 451822 effective words/s
INFO - 2023-11-30 16:51:49,152: EPOCH 15: training on 191080 raw words (135697 effective words) took 0.3s, 468544 effective words/s
INFO - 2023-11-30 16:51:49,428: EPOCH 16: training on 191080 raw words (135760 effective words) took 0.3s, 496223 effective words/s
INFO - 2023-11-30 16:51:49,699: EPOCH 17: training on 191080 raw words (135517 effective words) took 0.3s, 503786 effective words/s
INFO - 2023-11-30 16:51:49,989: EPOCH 18: training on 191080 raw words (135675 effective words) took 0.3s, 471459 effective words/s
INFO - 2023-11-30 16:51:50,262: EPOCH 19: training on 191080 raw words (135782 effective words) took 0.3s, 502302 effective words/s
INFO - 2023-11-30 16:51:50,262: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2713805 effective words) took 5.8s, 467777 effective words/s', 'datetime': '2023-11-30T16:51:50.262717', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:50,262: collecting all words and their counts
INFO - 2023-11-30 16:51:50,263: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:50,290: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:50,290: Updating model with new vocabulary
INFO - 2023-11-30 16:51:50,302: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:50.302172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:50,316: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:50,316: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:50,316: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135680.19570381712 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:51:50.316847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:50,339: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:50,340: updating layer weights
INFO - 2023-11-30 16:51:50,341: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:50.341020', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:50,341: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:50,341: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:50.341671', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:50,623: EPOCH 0: training on 191080 raw words (135860 effective words) took 0.3s, 487209 effective words/s
INFO - 2023-11-30 16:51:50,912: EPOCH 1: training on 191080 raw words (135776 effective words) took 0.3s, 472934 effective words/s
INFO - 2023-11-30 16:51:51,205: EPOCH 2: training on 191080 raw words (135536 effective words) took 0.3s, 467400 effective words/s
INFO - 2023-11-30 16:51:51,482: EPOCH 3: training on 191080 raw words (135815 effective words) took 0.3s, 495806 effective words/s
INFO - 2023-11-30 16:51:51,768: EPOCH 4: training on 191080 raw words (135788 effective words) took 0.3s, 477797 effective words/s
INFO - 2023-11-30 16:51:52,168: EPOCH 5: training on 191080 raw words (135596 effective words) took 0.4s, 341763 effective words/s
INFO - 2023-11-30 16:51:52,519: EPOCH 6: training on 191080 raw words (135714 effective words) took 0.3s, 389442 effective words/s
INFO - 2023-11-30 16:51:52,903: EPOCH 7: training on 191080 raw words (135643 effective words) took 0.4s, 356486 effective words/s
INFO - 2023-11-30 16:51:53,257: EPOCH 8: training on 191080 raw words (135719 effective words) took 0.4s, 387011 effective words/s
INFO - 2023-11-30 16:51:53,619: EPOCH 9: training on 191080 raw words (135788 effective words) took 0.4s, 377627 effective words/s
INFO - 2023-11-30 16:51:53,977: EPOCH 10: training on 191080 raw words (135507 effective words) took 0.4s, 382076 effective words/s
INFO - 2023-11-30 16:51:54,333: EPOCH 11: training on 191080 raw words (135495 effective words) took 0.4s, 384049 effective words/s
INFO - 2023-11-30 16:51:54,690: EPOCH 12: training on 191080 raw words (135591 effective words) took 0.4s, 383108 effective words/s
INFO - 2023-11-30 16:51:55,076: EPOCH 13: training on 191080 raw words (135529 effective words) took 0.4s, 378469 effective words/s
INFO - 2023-11-30 16:51:55,454: EPOCH 14: training on 191080 raw words (135721 effective words) took 0.4s, 362151 effective words/s
INFO - 2023-11-30 16:51:55,857: EPOCH 15: training on 191080 raw words (135520 effective words) took 0.4s, 338274 effective words/s
INFO - 2023-11-30 16:51:56,241: EPOCH 16: training on 191080 raw words (135831 effective words) took 0.4s, 357180 effective words/s
INFO - 2023-11-30 16:51:56,661: EPOCH 17: training on 191080 raw words (135566 effective words) took 0.4s, 324969 effective words/s
INFO - 2023-11-30 16:51:57,035: EPOCH 18: training on 191080 raw words (135760 effective words) took 0.4s, 366371 effective words/s
INFO - 2023-11-30 16:51:57,415: EPOCH 19: training on 191080 raw words (135888 effective words) took 0.4s, 360665 effective words/s
INFO - 2023-11-30 16:51:57,415: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2713643 effective words) took 7.1s, 383631 effective words/s', 'datetime': '2023-11-30T16:51:57.415523', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:57,415: collecting all words and their counts
INFO - 2023-11-30 16:51:57,416: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:51:57,459: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:51:57,459: Updating model with new vocabulary
INFO - 2023-11-30 16:51:57,477: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:51:57.477851', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:57,500: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:51:57,501: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:51:57,501: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135550.77493907275 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:51:57.501106', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:51:57,536: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:51:57,536: updating layer weights
INFO - 2023-11-30 16:51:57,537: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:51:57.537203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:51:57,537: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:51:57,537: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:51:57.537588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:51:57,956: EPOCH 0: training on 191080 raw words (135557 effective words) took 0.4s, 326450 effective words/s
INFO - 2023-11-30 16:51:58,357: EPOCH 1: training on 191080 raw words (135515 effective words) took 0.4s, 340924 effective words/s
INFO - 2023-11-30 16:51:58,758: EPOCH 2: training on 191080 raw words (135707 effective words) took 0.4s, 341131 effective words/s
INFO - 2023-11-30 16:51:59,205: EPOCH 3: training on 191080 raw words (135698 effective words) took 0.4s, 305633 effective words/s
INFO - 2023-11-30 16:51:59,609: EPOCH 4: training on 191080 raw words (135773 effective words) took 0.4s, 338199 effective words/s
INFO - 2023-11-30 16:52:00,051: EPOCH 5: training on 191080 raw words (135536 effective words) took 0.4s, 309009 effective words/s
INFO - 2023-11-30 16:52:00,451: EPOCH 6: training on 191080 raw words (135351 effective words) took 0.4s, 341287 effective words/s
INFO - 2023-11-30 16:52:00,835: EPOCH 7: training on 191080 raw words (135416 effective words) took 0.4s, 355739 effective words/s
INFO - 2023-11-30 16:52:01,103: EPOCH 8: training on 191080 raw words (135464 effective words) took 0.3s, 509693 effective words/s
INFO - 2023-11-30 16:52:01,371: EPOCH 9: training on 191080 raw words (135456 effective words) took 0.3s, 508553 effective words/s
INFO - 2023-11-30 16:52:01,644: EPOCH 10: training on 191080 raw words (135615 effective words) took 0.3s, 502455 effective words/s
INFO - 2023-11-30 16:52:01,913: EPOCH 11: training on 191080 raw words (135663 effective words) took 0.3s, 507416 effective words/s
INFO - 2023-11-30 16:52:02,189: EPOCH 12: training on 191080 raw words (135462 effective words) took 0.3s, 494848 effective words/s
INFO - 2023-11-30 16:52:02,469: EPOCH 13: training on 191080 raw words (135565 effective words) took 0.3s, 488353 effective words/s
INFO - 2023-11-30 16:52:02,745: EPOCH 14: training on 191080 raw words (135545 effective words) took 0.3s, 495590 effective words/s
INFO - 2023-11-30 16:52:03,015: EPOCH 15: training on 191080 raw words (135308 effective words) took 0.3s, 505835 effective words/s
INFO - 2023-11-30 16:52:03,287: EPOCH 16: training on 191080 raw words (135694 effective words) took 0.3s, 503118 effective words/s
INFO - 2023-11-30 16:52:03,556: EPOCH 17: training on 191080 raw words (135348 effective words) took 0.3s, 507514 effective words/s
INFO - 2023-11-30 16:52:03,831: EPOCH 18: training on 191080 raw words (135820 effective words) took 0.3s, 498973 effective words/s
INFO - 2023-11-30 16:52:04,102: EPOCH 19: training on 191080 raw words (135391 effective words) took 0.3s, 503569 effective words/s
INFO - 2023-11-30 16:52:04,102: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710884 effective words) took 6.6s, 412942 effective words/s', 'datetime': '2023-11-30T16:52:04.102639', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:04,102: collecting all words and their counts
INFO - 2023-11-30 16:52:04,103: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:04,130: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:04,130: Updating model with new vocabulary
INFO - 2023-11-30 16:52:04,142: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:04.142327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:04,157: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:04,157: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:04,157: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135353.9720391813 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:52:04.157723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:04,183: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:04,183: updating layer weights
INFO - 2023-11-30 16:52:04,184: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:04.183994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:04,184: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:04,184: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:04.184222', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:04,444: EPOCH 0: training on 191080 raw words (135467 effective words) took 0.3s, 527208 effective words/s
INFO - 2023-11-30 16:52:04,710: EPOCH 1: training on 191080 raw words (135159 effective words) took 0.3s, 512777 effective words/s
INFO - 2023-11-30 16:52:04,972: EPOCH 2: training on 191080 raw words (135402 effective words) took 0.3s, 520844 effective words/s
INFO - 2023-11-30 16:52:05,238: EPOCH 3: training on 191080 raw words (135245 effective words) took 0.3s, 514573 effective words/s
INFO - 2023-11-30 16:52:05,499: EPOCH 4: training on 191080 raw words (135411 effective words) took 0.3s, 521757 effective words/s
INFO - 2023-11-30 16:52:05,761: EPOCH 5: training on 191080 raw words (135421 effective words) took 0.3s, 521953 effective words/s
INFO - 2023-11-30 16:52:06,025: EPOCH 6: training on 191080 raw words (135485 effective words) took 0.2s, 554974 effective words/s
INFO - 2023-11-30 16:52:06,289: EPOCH 7: training on 191080 raw words (135417 effective words) took 0.3s, 517088 effective words/s
INFO - 2023-11-30 16:52:06,557: EPOCH 8: training on 191080 raw words (135542 effective words) took 0.3s, 510224 effective words/s
INFO - 2023-11-30 16:52:06,819: EPOCH 9: training on 191080 raw words (135464 effective words) took 0.3s, 521810 effective words/s
INFO - 2023-11-30 16:52:07,086: EPOCH 10: training on 191080 raw words (135057 effective words) took 0.3s, 510834 effective words/s
INFO - 2023-11-30 16:52:07,342: EPOCH 11: training on 191080 raw words (135347 effective words) took 0.3s, 535570 effective words/s
INFO - 2023-11-30 16:52:07,602: EPOCH 12: training on 191080 raw words (135245 effective words) took 0.3s, 523495 effective words/s
INFO - 2023-11-30 16:52:07,865: EPOCH 13: training on 191080 raw words (135148 effective words) took 0.3s, 519012 effective words/s
INFO - 2023-11-30 16:52:08,126: EPOCH 14: training on 191080 raw words (135315 effective words) took 0.3s, 522747 effective words/s
INFO - 2023-11-30 16:52:08,385: EPOCH 15: training on 191080 raw words (135280 effective words) took 0.3s, 526420 effective words/s
INFO - 2023-11-30 16:52:08,650: EPOCH 16: training on 191080 raw words (135422 effective words) took 0.3s, 516185 effective words/s
INFO - 2023-11-30 16:52:08,908: EPOCH 17: training on 191080 raw words (135426 effective words) took 0.3s, 529995 effective words/s
INFO - 2023-11-30 16:52:09,165: EPOCH 18: training on 191080 raw words (135426 effective words) took 0.3s, 530942 effective words/s
INFO - 2023-11-30 16:52:09,426: EPOCH 19: training on 191080 raw words (135031 effective words) took 0.3s, 521841 effective words/s
INFO - 2023-11-30 16:52:09,427: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2706710 effective words) took 5.2s, 516269 effective words/s', 'datetime': '2023-11-30T16:52:09.427147', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:09,427: collecting all words and their counts
INFO - 2023-11-30 16:52:09,427: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:09,454: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:09,454: Updating model with new vocabulary
INFO - 2023-11-30 16:52:09,466: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:09.466138', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:09,480: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:09,480: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:09,480: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135345.2896287877 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:52:09.480644', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:09,502: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:09,502: updating layer weights
INFO - 2023-11-30 16:52:09,503: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:09.503182', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:09,503: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:09,503: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:09.503420', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:09,780: EPOCH 0: training on 191080 raw words (135201 effective words) took 0.3s, 492434 effective words/s
INFO - 2023-11-30 16:52:10,052: EPOCH 1: training on 191080 raw words (135263 effective words) took 0.3s, 500956 effective words/s
INFO - 2023-11-30 16:52:10,323: EPOCH 2: training on 191080 raw words (135363 effective words) took 0.3s, 502876 effective words/s
INFO - 2023-11-30 16:52:10,602: EPOCH 3: training on 191080 raw words (135251 effective words) took 0.3s, 489357 effective words/s
INFO - 2023-11-30 16:52:10,876: EPOCH 4: training on 191080 raw words (135581 effective words) took 0.3s, 499479 effective words/s
INFO - 2023-11-30 16:52:11,149: EPOCH 5: training on 191080 raw words (135420 effective words) took 0.3s, 500418 effective words/s
INFO - 2023-11-30 16:52:11,424: EPOCH 6: training on 191080 raw words (135317 effective words) took 0.3s, 495450 effective words/s
INFO - 2023-11-30 16:52:11,700: EPOCH 7: training on 191080 raw words (135260 effective words) took 0.3s, 495411 effective words/s
INFO - 2023-11-30 16:52:11,973: EPOCH 8: training on 191080 raw words (135492 effective words) took 0.3s, 499377 effective words/s
INFO - 2023-11-30 16:52:12,241: EPOCH 9: training on 191080 raw words (135194 effective words) took 0.3s, 509921 effective words/s
INFO - 2023-11-30 16:52:12,509: EPOCH 10: training on 191080 raw words (135431 effective words) took 0.3s, 508465 effective words/s
INFO - 2023-11-30 16:52:12,785: EPOCH 11: training on 191080 raw words (135032 effective words) took 0.3s, 494336 effective words/s
INFO - 2023-11-30 16:52:13,110: EPOCH 12: training on 191080 raw words (135358 effective words) took 0.3s, 419375 effective words/s
INFO - 2023-11-30 16:52:13,391: EPOCH 13: training on 191080 raw words (135436 effective words) took 0.3s, 485739 effective words/s
INFO - 2023-11-30 16:52:13,666: EPOCH 14: training on 191080 raw words (135292 effective words) took 0.3s, 495846 effective words/s
INFO - 2023-11-30 16:52:13,939: EPOCH 15: training on 191080 raw words (135247 effective words) took 0.3s, 499105 effective words/s
INFO - 2023-11-30 16:52:14,215: EPOCH 16: training on 191080 raw words (135282 effective words) took 0.3s, 495331 effective words/s
INFO - 2023-11-30 16:52:14,490: EPOCH 17: training on 191080 raw words (135570 effective words) took 0.3s, 496569 effective words/s
INFO - 2023-11-30 16:52:14,767: EPOCH 18: training on 191080 raw words (135355 effective words) took 0.3s, 493193 effective words/s
INFO - 2023-11-30 16:52:15,043: EPOCH 19: training on 191080 raw words (135311 effective words) took 0.3s, 496255 effective words/s
INFO - 2023-11-30 16:52:15,043: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2706656 effective words) took 5.5s, 488571 effective words/s', 'datetime': '2023-11-30T16:52:15.043493', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:15,043: collecting all words and their counts
INFO - 2023-11-30 16:52:15,043: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:15,071: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:15,071: Updating model with new vocabulary
INFO - 2023-11-30 16:52:15,082: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:15.082886', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:15,097: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:15,097: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:15,097: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135515.55259153366 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:52:15.097535', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:15,120: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:15,120: updating layer weights
INFO - 2023-11-30 16:52:15,120: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:15.120738', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:15,120: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:15,120: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:15.120967', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:15,409: EPOCH 0: training on 191080 raw words (135283 effective words) took 0.3s, 473298 effective words/s
INFO - 2023-11-30 16:52:15,746: EPOCH 1: training on 191080 raw words (135671 effective words) took 0.3s, 406971 effective words/s
INFO - 2023-11-30 16:52:16,051: EPOCH 2: training on 191080 raw words (135626 effective words) took 0.3s, 447976 effective words/s
INFO - 2023-11-30 16:52:16,438: EPOCH 3: training on 191080 raw words (135493 effective words) took 0.4s, 353372 effective words/s
INFO - 2023-11-30 16:52:16,708: EPOCH 4: training on 191080 raw words (135362 effective words) took 0.3s, 504566 effective words/s
INFO - 2023-11-30 16:52:17,042: EPOCH 5: training on 191080 raw words (135601 effective words) took 0.3s, 409683 effective words/s
INFO - 2023-11-30 16:52:17,322: EPOCH 6: training on 191080 raw words (135696 effective words) took 0.3s, 487547 effective words/s
INFO - 2023-11-30 16:52:17,594: EPOCH 7: training on 191080 raw words (135426 effective words) took 0.3s, 503482 effective words/s
INFO - 2023-11-30 16:52:17,869: EPOCH 8: training on 191080 raw words (135538 effective words) took 0.3s, 496417 effective words/s
INFO - 2023-11-30 16:52:18,143: EPOCH 9: training on 191080 raw words (135414 effective words) took 0.3s, 500525 effective words/s
INFO - 2023-11-30 16:52:18,422: EPOCH 10: training on 191080 raw words (135504 effective words) took 0.3s, 489719 effective words/s
INFO - 2023-11-30 16:52:18,694: EPOCH 11: training on 191080 raw words (135692 effective words) took 0.3s, 502993 effective words/s
INFO - 2023-11-30 16:52:19,016: EPOCH 12: training on 191080 raw words (135608 effective words) took 0.3s, 423989 effective words/s
INFO - 2023-11-30 16:52:19,393: EPOCH 13: training on 191080 raw words (135445 effective words) took 0.4s, 362712 effective words/s
INFO - 2023-11-30 16:52:19,773: EPOCH 14: training on 191080 raw words (135293 effective words) took 0.4s, 359482 effective words/s
INFO - 2023-11-30 16:52:20,140: EPOCH 15: training on 191080 raw words (135457 effective words) took 0.4s, 372539 effective words/s
INFO - 2023-11-30 16:52:20,522: EPOCH 16: training on 191080 raw words (135553 effective words) took 0.4s, 357632 effective words/s
INFO - 2023-11-30 16:52:20,907: EPOCH 17: training on 191080 raw words (135405 effective words) took 0.4s, 353791 effective words/s
INFO - 2023-11-30 16:52:21,286: EPOCH 18: training on 191080 raw words (135348 effective words) took 0.4s, 360562 effective words/s
INFO - 2023-11-30 16:52:21,737: EPOCH 19: training on 191080 raw words (135614 effective words) took 0.4s, 303112 effective words/s
INFO - 2023-11-30 16:52:21,737: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710029 effective words) took 6.6s, 409583 effective words/s', 'datetime': '2023-11-30T16:52:21.737648', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:21,737: collecting all words and their counts
INFO - 2023-11-30 16:52:21,738: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:21,783: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:21,784: Updating model with new vocabulary
INFO - 2023-11-30 16:52:21,802: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:21.802534', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:21,836: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:21,836: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:21,836: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135427.25667572056 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:52:21.836915', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:21,875: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:21,875: updating layer weights
INFO - 2023-11-30 16:52:21,876: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:21.876373', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:21,877: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:21,877: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:21.877870', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:22,337: EPOCH 0: training on 191080 raw words (135426 effective words) took 0.5s, 298593 effective words/s
INFO - 2023-11-30 16:52:22,795: EPOCH 1: training on 191080 raw words (135295 effective words) took 0.5s, 300570 effective words/s
INFO - 2023-11-30 16:52:23,208: EPOCH 2: training on 191080 raw words (135366 effective words) took 0.4s, 330215 effective words/s
INFO - 2023-11-30 16:52:23,691: EPOCH 3: training on 191080 raw words (135632 effective words) took 0.5s, 283770 effective words/s
INFO - 2023-11-30 16:52:24,137: EPOCH 4: training on 191080 raw words (135260 effective words) took 0.4s, 305429 effective words/s
INFO - 2023-11-30 16:52:24,582: EPOCH 5: training on 191080 raw words (135516 effective words) took 0.4s, 306946 effective words/s
INFO - 2023-11-30 16:52:25,005: EPOCH 6: training on 191080 raw words (135572 effective words) took 0.4s, 323017 effective words/s
INFO - 2023-11-30 16:52:25,400: EPOCH 7: training on 191080 raw words (135377 effective words) took 0.4s, 345778 effective words/s
INFO - 2023-11-30 16:52:25,858: EPOCH 8: training on 191080 raw words (135349 effective words) took 0.5s, 297532 effective words/s
INFO - 2023-11-30 16:52:26,248: EPOCH 9: training on 191080 raw words (135530 effective words) took 0.4s, 350855 effective words/s
INFO - 2023-11-30 16:52:26,638: EPOCH 10: training on 191080 raw words (135373 effective words) took 0.4s, 349639 effective words/s
INFO - 2023-11-30 16:52:27,016: EPOCH 11: training on 191080 raw words (135538 effective words) took 0.4s, 362332 effective words/s
INFO - 2023-11-30 16:52:27,413: EPOCH 12: training on 191080 raw words (135607 effective words) took 0.4s, 344545 effective words/s
INFO - 2023-11-30 16:52:27,814: EPOCH 13: training on 191080 raw words (135581 effective words) took 0.4s, 340398 effective words/s
INFO - 2023-11-30 16:52:28,193: EPOCH 14: training on 191080 raw words (135596 effective words) took 0.4s, 360579 effective words/s
INFO - 2023-11-30 16:52:28,558: EPOCH 15: training on 191080 raw words (135365 effective words) took 0.4s, 373940 effective words/s
INFO - 2023-11-30 16:52:28,925: EPOCH 16: training on 191080 raw words (135485 effective words) took 0.4s, 373098 effective words/s
INFO - 2023-11-30 16:52:29,293: EPOCH 17: training on 191080 raw words (135244 effective words) took 0.4s, 369841 effective words/s
INFO - 2023-11-30 16:52:29,675: EPOCH 18: training on 191080 raw words (135367 effective words) took 0.4s, 357278 effective words/s
INFO - 2023-11-30 16:52:30,044: EPOCH 19: training on 191080 raw words (135523 effective words) took 0.4s, 371034 effective words/s
INFO - 2023-11-30 16:52:30,044: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709002 effective words) took 8.2s, 331727 effective words/s', 'datetime': '2023-11-30T16:52:30.044799', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:30,045: collecting all words and their counts
INFO - 2023-11-30 16:52:30,045: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:30,081: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:30,081: Updating model with new vocabulary
INFO - 2023-11-30 16:52:30,096: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:30.096897', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:30,116: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:30,116: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:30,117: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135096.64392787646 word corpus (70.7%% of prior 191080)', 'datetime': '2023-11-30T16:52:30.116992', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:30,148: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:30,148: updating layer weights
INFO - 2023-11-30 16:52:30,148: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:30.148841', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:30,149: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:30,149: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:30.149182', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:30,532: EPOCH 0: training on 191080 raw words (135022 effective words) took 0.4s, 355574 effective words/s
INFO - 2023-11-30 16:52:30,888: EPOCH 1: training on 191080 raw words (135205 effective words) took 0.4s, 382727 effective words/s
INFO - 2023-11-30 16:52:31,172: EPOCH 2: training on 191080 raw words (135045 effective words) took 0.3s, 479697 effective words/s
INFO - 2023-11-30 16:52:31,461: EPOCH 3: training on 191080 raw words (135167 effective words) took 0.3s, 470892 effective words/s
INFO - 2023-11-30 16:52:31,749: EPOCH 4: training on 191080 raw words (134957 effective words) took 0.3s, 473902 effective words/s
INFO - 2023-11-30 16:52:32,046: EPOCH 5: training on 191080 raw words (135073 effective words) took 0.3s, 457601 effective words/s
INFO - 2023-11-30 16:52:32,337: EPOCH 6: training on 191080 raw words (135033 effective words) took 0.3s, 468072 effective words/s
INFO - 2023-11-30 16:52:32,626: EPOCH 7: training on 191080 raw words (135149 effective words) took 0.3s, 472988 effective words/s
INFO - 2023-11-30 16:52:32,914: EPOCH 8: training on 191080 raw words (135250 effective words) took 0.3s, 473504 effective words/s
INFO - 2023-11-30 16:52:33,204: EPOCH 9: training on 191080 raw words (135388 effective words) took 0.3s, 470277 effective words/s
INFO - 2023-11-30 16:52:33,489: EPOCH 10: training on 191080 raw words (135155 effective words) took 0.3s, 478892 effective words/s
INFO - 2023-11-30 16:52:33,777: EPOCH 11: training on 191080 raw words (135315 effective words) took 0.3s, 473706 effective words/s
INFO - 2023-11-30 16:52:34,068: EPOCH 12: training on 191080 raw words (135205 effective words) took 0.3s, 470098 effective words/s
INFO - 2023-11-30 16:52:34,354: EPOCH 13: training on 191080 raw words (134845 effective words) took 0.3s, 475762 effective words/s
INFO - 2023-11-30 16:52:34,639: EPOCH 14: training on 191080 raw words (134793 effective words) took 0.3s, 477845 effective words/s
INFO - 2023-11-30 16:52:34,944: EPOCH 15: training on 191080 raw words (135176 effective words) took 0.3s, 447486 effective words/s
INFO - 2023-11-30 16:52:35,225: EPOCH 16: training on 191080 raw words (135032 effective words) took 0.3s, 484650 effective words/s
INFO - 2023-11-30 16:52:35,506: EPOCH 17: training on 191080 raw words (134950 effective words) took 0.3s, 484115 effective words/s
INFO - 2023-11-30 16:52:35,785: EPOCH 18: training on 191080 raw words (135223 effective words) took 0.3s, 489369 effective words/s
INFO - 2023-11-30 16:52:36,079: EPOCH 19: training on 191080 raw words (135163 effective words) took 0.3s, 462933 effective words/s
INFO - 2023-11-30 16:52:36,080: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2702146 effective words) took 5.9s, 455621 effective words/s', 'datetime': '2023-11-30T16:52:36.080174', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:36,080: collecting all words and their counts
INFO - 2023-11-30 16:52:36,080: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:36,109: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:36,109: Updating model with new vocabulary
INFO - 2023-11-30 16:52:36,123: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:36.123449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:36,140: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:36,140: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:36,140: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135533.88944992807 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:52:36.140487', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:36,163: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:36,163: updating layer weights
INFO - 2023-11-30 16:52:36,163: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:36.163779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:36,163: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:36,164: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:36.164085', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:36,459: EPOCH 0: training on 191080 raw words (135365 effective words) took 0.3s, 462206 effective words/s
INFO - 2023-11-30 16:52:36,766: EPOCH 1: training on 191080 raw words (135443 effective words) took 0.3s, 444055 effective words/s
INFO - 2023-11-30 16:52:37,067: EPOCH 2: training on 191080 raw words (135446 effective words) took 0.3s, 453469 effective words/s
INFO - 2023-11-30 16:52:37,365: EPOCH 3: training on 191080 raw words (135467 effective words) took 0.3s, 459656 effective words/s
INFO - 2023-11-30 16:52:37,659: EPOCH 4: training on 191080 raw words (135541 effective words) took 0.3s, 465159 effective words/s
INFO - 2023-11-30 16:52:37,975: EPOCH 5: training on 191080 raw words (135545 effective words) took 0.3s, 432475 effective words/s
INFO - 2023-11-30 16:52:38,289: EPOCH 6: training on 191080 raw words (135619 effective words) took 0.3s, 435009 effective words/s
INFO - 2023-11-30 16:52:38,584: EPOCH 7: training on 191080 raw words (135524 effective words) took 0.3s, 463681 effective words/s
INFO - 2023-11-30 16:52:38,885: EPOCH 8: training on 191080 raw words (135521 effective words) took 0.3s, 454331 effective words/s
INFO - 2023-11-30 16:52:39,185: EPOCH 9: training on 191080 raw words (135860 effective words) took 0.3s, 456111 effective words/s
INFO - 2023-11-30 16:52:39,476: EPOCH 10: training on 191080 raw words (135568 effective words) took 0.3s, 469070 effective words/s
INFO - 2023-11-30 16:52:39,778: EPOCH 11: training on 191080 raw words (135616 effective words) took 0.3s, 453587 effective words/s
INFO - 2023-11-30 16:52:40,070: EPOCH 12: training on 191080 raw words (135570 effective words) took 0.3s, 468266 effective words/s
INFO - 2023-11-30 16:52:40,367: EPOCH 13: training on 191080 raw words (135535 effective words) took 0.3s, 459679 effective words/s
INFO - 2023-11-30 16:52:40,666: EPOCH 14: training on 191080 raw words (135215 effective words) took 0.3s, 456825 effective words/s
INFO - 2023-11-30 16:52:40,963: EPOCH 15: training on 191080 raw words (135406 effective words) took 0.3s, 458485 effective words/s
INFO - 2023-11-30 16:52:41,257: EPOCH 16: training on 191080 raw words (135607 effective words) took 0.3s, 465877 effective words/s
INFO - 2023-11-30 16:52:41,570: EPOCH 17: training on 191080 raw words (135591 effective words) took 0.3s, 437069 effective words/s
INFO - 2023-11-30 16:52:41,912: EPOCH 18: training on 191080 raw words (135583 effective words) took 0.3s, 401452 effective words/s
INFO - 2023-11-30 16:52:42,221: EPOCH 19: training on 191080 raw words (135705 effective words) took 0.3s, 442124 effective words/s
INFO - 2023-11-30 16:52:42,221: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2710727 effective words) took 6.1s, 447501 effective words/s', 'datetime': '2023-11-30T16:52:42.221755', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:42,221: collecting all words and their counts
INFO - 2023-11-30 16:52:42,222: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:42,252: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:42,253: Updating model with new vocabulary
INFO - 2023-11-30 16:52:42,266: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:42.266123', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:42,282: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:42,282: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:52:42,283: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135639.25225784598 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:52:42.283006', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:42,307: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:42,307: updating layer weights
INFO - 2023-11-30 16:52:42,307: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:42.307707', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:42,307: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:42,307: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:42.307956', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:42,589: EPOCH 0: training on 191080 raw words (135691 effective words) took 0.3s, 485471 effective words/s
INFO - 2023-11-30 16:52:42,915: EPOCH 1: training on 191080 raw words (135560 effective words) took 0.3s, 419406 effective words/s
INFO - 2023-11-30 16:52:43,202: EPOCH 2: training on 191080 raw words (135638 effective words) took 0.3s, 477728 effective words/s
INFO - 2023-11-30 16:52:43,500: EPOCH 3: training on 191080 raw words (135583 effective words) took 0.3s, 458614 effective words/s
INFO - 2023-11-30 16:52:43,796: EPOCH 4: training on 191080 raw words (135843 effective words) took 0.3s, 463049 effective words/s
INFO - 2023-11-30 16:52:44,072: EPOCH 5: training on 191080 raw words (135639 effective words) took 0.3s, 497580 effective words/s
INFO - 2023-11-30 16:52:44,355: EPOCH 6: training on 191080 raw words (135655 effective words) took 0.3s, 483055 effective words/s
INFO - 2023-11-30 16:52:44,683: EPOCH 7: training on 191080 raw words (135708 effective words) took 0.3s, 416537 effective words/s
INFO - 2023-11-30 16:52:44,977: EPOCH 8: training on 191080 raw words (135605 effective words) took 0.3s, 466676 effective words/s
INFO - 2023-11-30 16:52:45,271: EPOCH 9: training on 191080 raw words (135746 effective words) took 0.3s, 466672 effective words/s
INFO - 2023-11-30 16:52:45,548: EPOCH 10: training on 191080 raw words (135591 effective words) took 0.3s, 493060 effective words/s
INFO - 2023-11-30 16:52:45,856: EPOCH 11: training on 191080 raw words (135777 effective words) took 0.3s, 444975 effective words/s
INFO - 2023-11-30 16:52:46,146: EPOCH 12: training on 191080 raw words (135581 effective words) took 0.3s, 472255 effective words/s
INFO - 2023-11-30 16:52:46,446: EPOCH 13: training on 191080 raw words (135453 effective words) took 0.3s, 455076 effective words/s
INFO - 2023-11-30 16:52:46,738: EPOCH 14: training on 191080 raw words (135592 effective words) took 0.3s, 468411 effective words/s
INFO - 2023-11-30 16:52:47,023: EPOCH 15: training on 191080 raw words (135502 effective words) took 0.3s, 480373 effective words/s
INFO - 2023-11-30 16:52:47,314: EPOCH 16: training on 191080 raw words (135708 effective words) took 0.3s, 471381 effective words/s
INFO - 2023-11-30 16:52:47,602: EPOCH 17: training on 191080 raw words (135615 effective words) took 0.3s, 475920 effective words/s
INFO - 2023-11-30 16:52:47,892: EPOCH 18: training on 191080 raw words (135705 effective words) took 0.3s, 470274 effective words/s
INFO - 2023-11-30 16:52:48,224: EPOCH 19: training on 191080 raw words (135529 effective words) took 0.3s, 412098 effective words/s
INFO - 2023-11-30 16:52:48,224: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712721 effective words) took 5.9s, 458499 effective words/s', 'datetime': '2023-11-30T16:52:48.224623', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:48,224: collecting all words and their counts
INFO - 2023-11-30 16:52:48,225: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:48,269: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:48,269: Updating model with new vocabulary
INFO - 2023-11-30 16:52:48,288: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:48.288098', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:48,317: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:48,317: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:52:48,317: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135396.61867914902 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:52:48.317935', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:48,353: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:48,353: updating layer weights
INFO - 2023-11-30 16:52:48,354: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:48.354156', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:48,354: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:48,354: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:48.354705', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:48,775: EPOCH 0: training on 191080 raw words (135501 effective words) took 0.4s, 324770 effective words/s
INFO - 2023-11-30 16:52:49,197: EPOCH 1: training on 191080 raw words (135361 effective words) took 0.4s, 328842 effective words/s
INFO - 2023-11-30 16:52:49,617: EPOCH 2: training on 191080 raw words (135402 effective words) took 0.4s, 325629 effective words/s
INFO - 2023-11-30 16:52:50,041: EPOCH 3: training on 191080 raw words (135508 effective words) took 0.4s, 322590 effective words/s
INFO - 2023-11-30 16:52:50,443: EPOCH 4: training on 191080 raw words (135319 effective words) took 0.4s, 339063 effective words/s
INFO - 2023-11-30 16:52:50,865: EPOCH 5: training on 191080 raw words (135440 effective words) took 0.4s, 323198 effective words/s
INFO - 2023-11-30 16:52:51,289: EPOCH 6: training on 191080 raw words (135357 effective words) took 0.4s, 322442 effective words/s
INFO - 2023-11-30 16:52:51,734: EPOCH 7: training on 191080 raw words (135343 effective words) took 0.4s, 307096 effective words/s
INFO - 2023-11-30 16:52:52,169: EPOCH 8: training on 191080 raw words (135632 effective words) took 0.4s, 314148 effective words/s
INFO - 2023-11-30 16:52:52,610: EPOCH 9: training on 191080 raw words (135270 effective words) took 0.4s, 309019 effective words/s
INFO - 2023-11-30 16:52:53,066: EPOCH 10: training on 191080 raw words (135539 effective words) took 0.5s, 299853 effective words/s
INFO - 2023-11-30 16:52:53,510: EPOCH 11: training on 191080 raw words (135297 effective words) took 0.4s, 307200 effective words/s
INFO - 2023-11-30 16:52:53,964: EPOCH 12: training on 191080 raw words (135311 effective words) took 0.4s, 301106 effective words/s
INFO - 2023-11-30 16:52:54,427: EPOCH 13: training on 191080 raw words (135455 effective words) took 0.5s, 294624 effective words/s
INFO - 2023-11-30 16:52:54,904: EPOCH 14: training on 191080 raw words (135482 effective words) took 0.5s, 285819 effective words/s
INFO - 2023-11-30 16:52:55,377: EPOCH 15: training on 191080 raw words (135245 effective words) took 0.5s, 288026 effective words/s
INFO - 2023-11-30 16:52:55,863: EPOCH 16: training on 191080 raw words (135499 effective words) took 0.5s, 281484 effective words/s
INFO - 2023-11-30 16:52:56,338: EPOCH 17: training on 191080 raw words (135344 effective words) took 0.5s, 287204 effective words/s
INFO - 2023-11-30 16:52:56,823: EPOCH 18: training on 191080 raw words (135293 effective words) took 0.5s, 281535 effective words/s
INFO - 2023-11-30 16:52:57,217: EPOCH 19: training on 191080 raw words (135549 effective words) took 0.4s, 347957 effective words/s
INFO - 2023-11-30 16:52:57,217: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2708147 effective words) took 8.9s, 305578 effective words/s', 'datetime': '2023-11-30T16:52:57.217345', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:57,217: collecting all words and their counts
INFO - 2023-11-30 16:52:57,217: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:52:57,246: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:52:57,246: Updating model with new vocabulary
INFO - 2023-11-30 16:52:57,258: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:52:57.258602', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:57,273: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:52:57,274: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 16:52:57,274: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135400.9993792747 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:52:57.274249', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:52:57,297: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:52:57,297: updating layer weights
INFO - 2023-11-30 16:52:57,297: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:52:57.297690', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:52:57,297: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:52:57,298: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:52:57.297980', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:52:57,583: EPOCH 0: training on 191080 raw words (135387 effective words) took 0.3s, 477678 effective words/s
INFO - 2023-11-30 16:52:57,906: EPOCH 1: training on 191080 raw words (135470 effective words) took 0.3s, 422952 effective words/s
INFO - 2023-11-30 16:52:58,205: EPOCH 2: training on 191080 raw words (135271 effective words) took 0.3s, 457451 effective words/s
INFO - 2023-11-30 16:52:58,484: EPOCH 3: training on 191080 raw words (135356 effective words) took 0.3s, 489143 effective words/s
INFO - 2023-11-30 16:52:58,768: EPOCH 4: training on 191080 raw words (135171 effective words) took 0.3s, 480212 effective words/s
INFO - 2023-11-30 16:52:59,051: EPOCH 5: training on 191080 raw words (135326 effective words) took 0.3s, 482369 effective words/s
INFO - 2023-11-30 16:52:59,329: EPOCH 6: training on 191080 raw words (135328 effective words) took 0.3s, 492047 effective words/s
INFO - 2023-11-30 16:52:59,662: EPOCH 7: training on 191080 raw words (135332 effective words) took 0.3s, 409670 effective words/s
INFO - 2023-11-30 16:52:59,941: EPOCH 8: training on 191080 raw words (135233 effective words) took 0.3s, 488271 effective words/s
INFO - 2023-11-30 16:53:00,238: EPOCH 9: training on 191080 raw words (135182 effective words) took 0.3s, 458662 effective words/s
INFO - 2023-11-30 16:53:00,524: EPOCH 10: training on 191080 raw words (135448 effective words) took 0.3s, 478149 effective words/s
INFO - 2023-11-30 16:53:00,803: EPOCH 11: training on 191080 raw words (135557 effective words) took 0.3s, 490253 effective words/s
INFO - 2023-11-30 16:53:01,092: EPOCH 12: training on 191080 raw words (135542 effective words) took 0.3s, 473024 effective words/s
INFO - 2023-11-30 16:53:01,415: EPOCH 13: training on 191080 raw words (135565 effective words) took 0.3s, 423514 effective words/s
INFO - 2023-11-30 16:53:01,709: EPOCH 14: training on 191080 raw words (135514 effective words) took 0.3s, 465440 effective words/s
INFO - 2023-11-30 16:53:01,993: EPOCH 15: training on 191080 raw words (135519 effective words) took 0.3s, 482694 effective words/s
INFO - 2023-11-30 16:53:02,273: EPOCH 16: training on 191080 raw words (135598 effective words) took 0.3s, 488792 effective words/s
INFO - 2023-11-30 16:53:02,553: EPOCH 17: training on 191080 raw words (135279 effective words) took 0.3s, 487035 effective words/s
INFO - 2023-11-30 16:53:02,832: EPOCH 18: training on 191080 raw words (135508 effective words) took 0.3s, 488878 effective words/s
INFO - 2023-11-30 16:53:03,170: EPOCH 19: training on 191080 raw words (135380 effective words) took 0.3s, 404539 effective words/s
INFO - 2023-11-30 16:53:03,171: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2707966 effective words) took 5.9s, 461098 effective words/s', 'datetime': '2023-11-30T16:53:03.171015', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:03,171: collecting all words and their counts
INFO - 2023-11-30 16:53:03,171: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:03,201: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:03,201: Updating model with new vocabulary
INFO - 2023-11-30 16:53:03,217: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:03.217745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:03,233: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:03,233: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:03,233: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135414.0231282659 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:53:03.233671', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:03,258: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:03,258: updating layer weights
INFO - 2023-11-30 16:53:03,259: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:03.259233', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:03,259: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:03,259: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:03.259472', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:03,596: EPOCH 0: training on 191080 raw words (135404 effective words) took 0.3s, 411669 effective words/s
INFO - 2023-11-30 16:53:03,902: EPOCH 1: training on 191080 raw words (135393 effective words) took 0.3s, 445557 effective words/s
INFO - 2023-11-30 16:53:04,199: EPOCH 2: training on 191080 raw words (135436 effective words) took 0.3s, 460407 effective words/s
INFO - 2023-11-30 16:53:04,493: EPOCH 3: training on 191080 raw words (135443 effective words) took 0.3s, 465523 effective words/s
INFO - 2023-11-30 16:53:04,797: EPOCH 4: training on 191080 raw words (135391 effective words) took 0.3s, 449283 effective words/s
INFO - 2023-11-30 16:53:05,094: EPOCH 5: training on 191080 raw words (135615 effective words) took 0.3s, 460211 effective words/s
INFO - 2023-11-30 16:53:05,436: EPOCH 6: training on 191080 raw words (135201 effective words) took 0.3s, 398775 effective words/s
INFO - 2023-11-30 16:53:05,746: EPOCH 7: training on 191080 raw words (135652 effective words) took 0.3s, 441919 effective words/s
INFO - 2023-11-30 16:53:06,066: EPOCH 8: training on 191080 raw words (135357 effective words) took 0.3s, 426229 effective words/s
INFO - 2023-11-30 16:53:06,421: EPOCH 9: training on 191080 raw words (135268 effective words) took 0.4s, 384174 effective words/s
INFO - 2023-11-30 16:53:06,729: EPOCH 10: training on 191080 raw words (135243 effective words) took 0.3s, 443868 effective words/s
INFO - 2023-11-30 16:53:07,029: EPOCH 11: training on 191080 raw words (135421 effective words) took 0.3s, 455397 effective words/s
INFO - 2023-11-30 16:53:07,337: EPOCH 12: training on 191080 raw words (135497 effective words) took 0.3s, 443338 effective words/s
INFO - 2023-11-30 16:53:07,662: EPOCH 13: training on 191080 raw words (135384 effective words) took 0.3s, 419424 effective words/s
INFO - 2023-11-30 16:53:07,998: EPOCH 14: training on 191080 raw words (135295 effective words) took 0.3s, 407107 effective words/s
INFO - 2023-11-30 16:53:08,314: EPOCH 15: training on 191080 raw words (135341 effective words) took 0.3s, 431545 effective words/s
INFO - 2023-11-30 16:53:08,656: EPOCH 16: training on 191080 raw words (135248 effective words) took 0.3s, 398639 effective words/s
INFO - 2023-11-30 16:53:08,958: EPOCH 17: training on 191080 raw words (135231 effective words) took 0.3s, 452543 effective words/s
INFO - 2023-11-30 16:53:09,285: EPOCH 18: training on 191080 raw words (135553 effective words) took 0.3s, 418168 effective words/s
INFO - 2023-11-30 16:53:09,601: EPOCH 19: training on 191080 raw words (135298 effective words) took 0.3s, 431639 effective words/s
INFO - 2023-11-30 16:53:09,602: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2707671 effective words) took 6.3s, 426911 effective words/s', 'datetime': '2023-11-30T16:53:09.602069', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:09,602: collecting all words and their counts
INFO - 2023-11-30 16:53:09,602: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:09,632: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:09,632: Updating model with new vocabulary
INFO - 2023-11-30 16:53:09,651: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:09.651331', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:09,670: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:09,670: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:09,671: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135549.23009199652 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:53:09.671103', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:09,704: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:09,705: updating layer weights
INFO - 2023-11-30 16:53:09,705: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:09.705473', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:09,705: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:09,705: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:09.705826', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:10,003: EPOCH 0: training on 191080 raw words (135597 effective words) took 0.3s, 459284 effective words/s
INFO - 2023-11-30 16:53:10,301: EPOCH 1: training on 191080 raw words (135478 effective words) took 0.3s, 459538 effective words/s
INFO - 2023-11-30 16:53:10,598: EPOCH 2: training on 191080 raw words (135466 effective words) took 0.3s, 459831 effective words/s
INFO - 2023-11-30 16:53:10,891: EPOCH 3: training on 191080 raw words (135336 effective words) took 0.3s, 464749 effective words/s
INFO - 2023-11-30 16:53:11,177: EPOCH 4: training on 191080 raw words (135704 effective words) took 0.3s, 479076 effective words/s
INFO - 2023-11-30 16:53:11,462: EPOCH 5: training on 191080 raw words (135521 effective words) took 0.3s, 479421 effective words/s
INFO - 2023-11-30 16:53:11,765: EPOCH 6: training on 191080 raw words (135542 effective words) took 0.3s, 451223 effective words/s
INFO - 2023-11-30 16:53:12,072: EPOCH 7: training on 191080 raw words (135644 effective words) took 0.3s, 445638 effective words/s
INFO - 2023-11-30 16:53:12,369: EPOCH 8: training on 191080 raw words (135595 effective words) took 0.3s, 460885 effective words/s
INFO - 2023-11-30 16:53:12,747: EPOCH 9: training on 191080 raw words (135584 effective words) took 0.4s, 361722 effective words/s
INFO - 2023-11-30 16:53:13,128: EPOCH 10: training on 191080 raw words (135639 effective words) took 0.4s, 359594 effective words/s
INFO - 2023-11-30 16:53:13,564: EPOCH 11: training on 191080 raw words (135585 effective words) took 0.4s, 313170 effective words/s
INFO - 2023-11-30 16:53:13,966: EPOCH 12: training on 191080 raw words (135588 effective words) took 0.4s, 339377 effective words/s
INFO - 2023-11-30 16:53:14,341: EPOCH 13: training on 191080 raw words (135503 effective words) took 0.4s, 365631 effective words/s
INFO - 2023-11-30 16:53:14,725: EPOCH 14: training on 191080 raw words (135550 effective words) took 0.4s, 355348 effective words/s
INFO - 2023-11-30 16:53:15,132: EPOCH 15: training on 191080 raw words (135512 effective words) took 0.4s, 336174 effective words/s
INFO - 2023-11-30 16:53:15,541: EPOCH 16: training on 191080 raw words (135579 effective words) took 0.4s, 338022 effective words/s
INFO - 2023-11-30 16:53:15,975: EPOCH 17: training on 191080 raw words (135473 effective words) took 0.4s, 314728 effective words/s
INFO - 2023-11-30 16:53:16,384: EPOCH 18: training on 191080 raw words (135607 effective words) took 0.4s, 334458 effective words/s
INFO - 2023-11-30 16:53:16,786: EPOCH 19: training on 191080 raw words (135516 effective words) took 0.4s, 339769 effective words/s
INFO - 2023-11-30 16:53:16,786: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711019 effective words) took 7.1s, 382884 effective words/s', 'datetime': '2023-11-30T16:53:16.786473', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:16,786: collecting all words and their counts
INFO - 2023-11-30 16:53:16,787: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:16,836: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:16,836: Updating model with new vocabulary
INFO - 2023-11-30 16:53:16,862: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:16.862782', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:16,894: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:16,895: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:16,895: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135515.93291471663 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:53:16.895530', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:16,934: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:16,935: updating layer weights
INFO - 2023-11-30 16:53:16,935: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:16.935819', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:16,936: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:16,936: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:16.936240', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:17,393: EPOCH 0: training on 191080 raw words (135454 effective words) took 0.5s, 298757 effective words/s
INFO - 2023-11-30 16:53:17,837: EPOCH 1: training on 191080 raw words (135552 effective words) took 0.4s, 307906 effective words/s
INFO - 2023-11-30 16:53:18,266: EPOCH 2: training on 191080 raw words (135640 effective words) took 0.4s, 318898 effective words/s
INFO - 2023-11-30 16:53:18,695: EPOCH 3: training on 191080 raw words (135753 effective words) took 0.4s, 331609 effective words/s
INFO - 2023-11-30 16:53:19,122: EPOCH 4: training on 191080 raw words (135627 effective words) took 0.4s, 320405 effective words/s
INFO - 2023-11-30 16:53:19,537: EPOCH 5: training on 191080 raw words (135538 effective words) took 0.4s, 328701 effective words/s
INFO - 2023-11-30 16:53:19,967: EPOCH 6: training on 191080 raw words (135531 effective words) took 0.4s, 329043 effective words/s
INFO - 2023-11-30 16:53:20,389: EPOCH 7: training on 191080 raw words (135629 effective words) took 0.4s, 323324 effective words/s
INFO - 2023-11-30 16:53:20,811: EPOCH 8: training on 191080 raw words (135523 effective words) took 0.4s, 323902 effective words/s
INFO - 2023-11-30 16:53:21,244: EPOCH 9: training on 191080 raw words (135472 effective words) took 0.4s, 315643 effective words/s
INFO - 2023-11-30 16:53:21,577: EPOCH 10: training on 191080 raw words (135563 effective words) took 0.3s, 412087 effective words/s
INFO - 2023-11-30 16:53:21,869: EPOCH 11: training on 191080 raw words (135609 effective words) took 0.3s, 468348 effective words/s
INFO - 2023-11-30 16:53:22,168: EPOCH 12: training on 191080 raw words (135553 effective words) took 0.3s, 456153 effective words/s
INFO - 2023-11-30 16:53:22,515: EPOCH 13: training on 191080 raw words (135617 effective words) took 0.3s, 395077 effective words/s
INFO - 2023-11-30 16:53:22,817: EPOCH 14: training on 191080 raw words (135763 effective words) took 0.3s, 459158 effective words/s
INFO - 2023-11-30 16:53:23,109: EPOCH 15: training on 191080 raw words (135448 effective words) took 0.3s, 467050 effective words/s
INFO - 2023-11-30 16:53:23,460: EPOCH 16: training on 191080 raw words (135614 effective words) took 0.3s, 389651 effective words/s
INFO - 2023-11-30 16:53:23,754: EPOCH 17: training on 191080 raw words (135489 effective words) took 0.3s, 465178 effective words/s
INFO - 2023-11-30 16:53:24,050: EPOCH 18: training on 191080 raw words (135410 effective words) took 0.3s, 462061 effective words/s
INFO - 2023-11-30 16:53:24,328: EPOCH 19: training on 191080 raw words (135487 effective words) took 0.3s, 491451 effective words/s
INFO - 2023-11-30 16:53:24,329: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711272 effective words) took 7.4s, 366750 effective words/s', 'datetime': '2023-11-30T16:53:24.329176', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:24,329: collecting all words and their counts
INFO - 2023-11-30 16:53:24,329: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:24,363: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:24,363: Updating model with new vocabulary
INFO - 2023-11-30 16:53:24,378: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:24.378483', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:24,396: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:24,397: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:24,397: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135376.1411415381 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:53:24.397485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:24,424: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:24,424: updating layer weights
INFO - 2023-11-30 16:53:24,424: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:24.424892', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:24,425: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:24,425: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:24.425148', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:24,711: EPOCH 0: training on 191080 raw words (135342 effective words) took 0.3s, 476678 effective words/s
INFO - 2023-11-30 16:53:25,075: EPOCH 1: training on 191080 raw words (135250 effective words) took 0.4s, 374180 effective words/s
INFO - 2023-11-30 16:53:25,472: EPOCH 2: training on 191080 raw words (135243 effective words) took 0.4s, 343763 effective words/s
INFO - 2023-11-30 16:53:25,806: EPOCH 3: training on 191080 raw words (135180 effective words) took 0.3s, 409306 effective words/s
INFO - 2023-11-30 16:53:26,122: EPOCH 4: training on 191080 raw words (135369 effective words) took 0.3s, 432520 effective words/s
INFO - 2023-11-30 16:53:26,480: EPOCH 5: training on 191080 raw words (135444 effective words) took 0.4s, 380416 effective words/s
INFO - 2023-11-30 16:53:26,781: EPOCH 6: training on 191080 raw words (135198 effective words) took 0.3s, 455082 effective words/s
INFO - 2023-11-30 16:53:27,064: EPOCH 7: training on 191080 raw words (135410 effective words) took 0.3s, 522985 effective words/s
INFO - 2023-11-30 16:53:27,342: EPOCH 8: training on 191080 raw words (135430 effective words) took 0.3s, 490681 effective words/s
INFO - 2023-11-30 16:53:27,639: EPOCH 9: training on 191080 raw words (135336 effective words) took 0.3s, 459435 effective words/s
INFO - 2023-11-30 16:53:27,922: EPOCH 10: training on 191080 raw words (135364 effective words) took 0.3s, 483205 effective words/s
INFO - 2023-11-30 16:53:28,200: EPOCH 11: training on 191080 raw words (135499 effective words) took 0.3s, 490883 effective words/s
INFO - 2023-11-30 16:53:28,494: EPOCH 12: training on 191080 raw words (135146 effective words) took 0.3s, 465362 effective words/s
INFO - 2023-11-30 16:53:28,791: EPOCH 13: training on 191080 raw words (135349 effective words) took 0.3s, 460255 effective words/s
INFO - 2023-11-30 16:53:29,079: EPOCH 14: training on 191080 raw words (135276 effective words) took 0.3s, 473266 effective words/s
INFO - 2023-11-30 16:53:29,419: EPOCH 15: training on 191080 raw words (135536 effective words) took 0.3s, 402076 effective words/s
INFO - 2023-11-30 16:53:29,688: EPOCH 16: training on 191080 raw words (135270 effective words) took 0.3s, 506268 effective words/s
INFO - 2023-11-30 16:53:29,972: EPOCH 17: training on 191080 raw words (135552 effective words) took 0.3s, 481941 effective words/s
INFO - 2023-11-30 16:53:30,272: EPOCH 18: training on 191080 raw words (135336 effective words) took 0.3s, 455481 effective words/s
INFO - 2023-11-30 16:53:30,569: EPOCH 19: training on 191080 raw words (135179 effective words) took 0.3s, 457910 effective words/s
INFO - 2023-11-30 16:53:30,570: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2706709 effective words) took 6.1s, 440470 effective words/s', 'datetime': '2023-11-30T16:53:30.570327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:30,570: collecting all words and their counts
INFO - 2023-11-30 16:53:30,571: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:30,602: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:30,602: Updating model with new vocabulary
INFO - 2023-11-30 16:53:30,618: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:30.618039', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:30,634: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:30,635: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:30,635: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135483.568614819 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:53:30.635120', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:30,661: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:30,661: updating layer weights
INFO - 2023-11-30 16:53:30,661: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:30.661885', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:30,662: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:30,662: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:30.662177', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:30,967: EPOCH 0: training on 191080 raw words (135401 effective words) took 0.3s, 447514 effective words/s
INFO - 2023-11-30 16:53:31,279: EPOCH 1: training on 191080 raw words (135400 effective words) took 0.3s, 436913 effective words/s
INFO - 2023-11-30 16:53:31,610: EPOCH 2: training on 191080 raw words (135396 effective words) took 0.3s, 413141 effective words/s
INFO - 2023-11-30 16:53:31,935: EPOCH 3: training on 191080 raw words (135457 effective words) took 0.3s, 419899 effective words/s
INFO - 2023-11-30 16:53:32,252: EPOCH 4: training on 191080 raw words (135553 effective words) took 0.3s, 431146 effective words/s
INFO - 2023-11-30 16:53:32,553: EPOCH 5: training on 191080 raw words (135309 effective words) took 0.3s, 454420 effective words/s
INFO - 2023-11-30 16:53:32,854: EPOCH 6: training on 191080 raw words (135423 effective words) took 0.3s, 453466 effective words/s
INFO - 2023-11-30 16:53:33,150: EPOCH 7: training on 191080 raw words (135458 effective words) took 0.3s, 460546 effective words/s
INFO - 2023-11-30 16:53:33,467: EPOCH 8: training on 191080 raw words (135441 effective words) took 0.3s, 430828 effective words/s
INFO - 2023-11-30 16:53:33,777: EPOCH 9: training on 191080 raw words (135647 effective words) took 0.3s, 442307 effective words/s
INFO - 2023-11-30 16:53:34,080: EPOCH 10: training on 191080 raw words (135488 effective words) took 0.3s, 450469 effective words/s
INFO - 2023-11-30 16:53:34,380: EPOCH 11: training on 191080 raw words (135349 effective words) took 0.3s, 454412 effective words/s
INFO - 2023-11-30 16:53:34,716: EPOCH 12: training on 191080 raw words (135366 effective words) took 0.3s, 407408 effective words/s
INFO - 2023-11-30 16:53:35,014: EPOCH 13: training on 191080 raw words (135548 effective words) took 0.3s, 459074 effective words/s
INFO - 2023-11-30 16:53:35,309: EPOCH 14: training on 191080 raw words (135563 effective words) took 0.3s, 463275 effective words/s
INFO - 2023-11-30 16:53:35,615: EPOCH 15: training on 191080 raw words (135388 effective words) took 0.3s, 446096 effective words/s
INFO - 2023-11-30 16:53:35,908: EPOCH 16: training on 191080 raw words (135486 effective words) took 0.3s, 466323 effective words/s
INFO - 2023-11-30 16:53:36,254: EPOCH 17: training on 191080 raw words (135472 effective words) took 0.3s, 394620 effective words/s
INFO - 2023-11-30 16:53:36,564: EPOCH 18: training on 191080 raw words (135495 effective words) took 0.3s, 439774 effective words/s
INFO - 2023-11-30 16:53:36,963: EPOCH 19: training on 191080 raw words (135601 effective words) took 0.4s, 342624 effective words/s
INFO - 2023-11-30 16:53:36,964: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709241 effective words) took 6.3s, 429919 effective words/s', 'datetime': '2023-11-30T16:53:36.964122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:36,964: collecting all words and their counts
INFO - 2023-11-30 16:53:36,964: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:37,012: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:37,012: Updating model with new vocabulary
INFO - 2023-11-30 16:53:37,030: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:37.030122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:37,051: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:37,052: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:37,052: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135198.29651868207 word corpus (70.8%% of prior 191080)', 'datetime': '2023-11-30T16:53:37.052341', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:37,087: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:37,087: updating layer weights
INFO - 2023-11-30 16:53:37,088: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:37.088373', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:37,088: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:37,088: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:37.088891', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:37,474: EPOCH 0: training on 191080 raw words (135368 effective words) took 0.4s, 354758 effective words/s
INFO - 2023-11-30 16:53:37,866: EPOCH 1: training on 191080 raw words (135426 effective words) took 0.4s, 349076 effective words/s
INFO - 2023-11-30 16:53:38,265: EPOCH 2: training on 191080 raw words (135229 effective words) took 0.4s, 341629 effective words/s
INFO - 2023-11-30 16:53:38,655: EPOCH 3: training on 191080 raw words (135206 effective words) took 0.4s, 349340 effective words/s
INFO - 2023-11-30 16:53:39,041: EPOCH 4: training on 191080 raw words (135222 effective words) took 0.4s, 353127 effective words/s
INFO - 2023-11-30 16:53:39,427: EPOCH 5: training on 191080 raw words (135111 effective words) took 0.4s, 352652 effective words/s
INFO - 2023-11-30 16:53:39,836: EPOCH 6: training on 191080 raw words (135123 effective words) took 0.4s, 333640 effective words/s
INFO - 2023-11-30 16:53:40,233: EPOCH 7: training on 191080 raw words (135068 effective words) took 0.4s, 353995 effective words/s
INFO - 2023-11-30 16:53:40,661: EPOCH 8: training on 191080 raw words (135180 effective words) took 0.4s, 340041 effective words/s
INFO - 2023-11-30 16:53:41,088: EPOCH 9: training on 191080 raw words (135103 effective words) took 0.4s, 319200 effective words/s
INFO - 2023-11-30 16:53:41,491: EPOCH 10: training on 191080 raw words (135196 effective words) took 0.4s, 338831 effective words/s
INFO - 2023-11-30 16:53:41,928: EPOCH 11: training on 191080 raw words (135322 effective words) took 0.4s, 311726 effective words/s
INFO - 2023-11-30 16:53:42,364: EPOCH 12: training on 191080 raw words (135180 effective words) took 0.4s, 313053 effective words/s
INFO - 2023-11-30 16:53:42,806: EPOCH 13: training on 191080 raw words (135312 effective words) took 0.4s, 308916 effective words/s
INFO - 2023-11-30 16:53:43,273: EPOCH 14: training on 191080 raw words (135385 effective words) took 0.4s, 307720 effective words/s
INFO - 2023-11-30 16:53:43,748: EPOCH 15: training on 191080 raw words (135326 effective words) took 0.5s, 287811 effective words/s
INFO - 2023-11-30 16:53:44,227: EPOCH 16: training on 191080 raw words (135119 effective words) took 0.5s, 284159 effective words/s
INFO - 2023-11-30 16:53:44,737: EPOCH 17: training on 191080 raw words (135153 effective words) took 0.5s, 267077 effective words/s
INFO - 2023-11-30 16:53:45,205: EPOCH 18: training on 191080 raw words (135056 effective words) took 0.4s, 313646 effective words/s
INFO - 2023-11-30 16:53:45,666: EPOCH 19: training on 191080 raw words (135328 effective words) took 0.5s, 296484 effective words/s
INFO - 2023-11-30 16:53:45,666: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2704413 effective words) took 8.6s, 315301 effective words/s', 'datetime': '2023-11-30T16:53:45.666422', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:45,666: collecting all words and their counts
INFO - 2023-11-30 16:53:45,666: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:45,702: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:45,702: Updating model with new vocabulary
INFO - 2023-11-30 16:53:45,716: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:45.716389', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:45,735: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:45,735: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:45,736: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135598.15896321076 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:53:45.736022', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:45,764: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:45,765: updating layer weights
INFO - 2023-11-30 16:53:45,765: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:45.765630', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:45,765: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:45,766: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:45.766065', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:46,076: EPOCH 0: training on 191080 raw words (135477 effective words) took 0.3s, 440860 effective words/s
INFO - 2023-11-30 16:53:46,362: EPOCH 1: training on 191080 raw words (135528 effective words) took 0.3s, 477727 effective words/s
INFO - 2023-11-30 16:53:46,639: EPOCH 2: training on 191080 raw words (135453 effective words) took 0.3s, 492833 effective words/s
INFO - 2023-11-30 16:53:46,915: EPOCH 3: training on 191080 raw words (135570 effective words) took 0.3s, 496440 effective words/s
INFO - 2023-11-30 16:53:47,199: EPOCH 4: training on 191080 raw words (135762 effective words) took 0.3s, 482954 effective words/s
INFO - 2023-11-30 16:53:47,498: EPOCH 5: training on 191080 raw words (135521 effective words) took 0.3s, 456053 effective words/s
INFO - 2023-11-30 16:53:47,790: EPOCH 6: training on 191080 raw words (135591 effective words) took 0.3s, 468772 effective words/s
INFO - 2023-11-30 16:53:48,078: EPOCH 7: training on 191080 raw words (135637 effective words) took 0.3s, 507773 effective words/s
INFO - 2023-11-30 16:53:48,372: EPOCH 8: training on 191080 raw words (135569 effective words) took 0.3s, 465526 effective words/s
INFO - 2023-11-30 16:53:48,665: EPOCH 9: training on 191080 raw words (135784 effective words) took 0.3s, 467862 effective words/s
INFO - 2023-11-30 16:53:48,949: EPOCH 10: training on 191080 raw words (135468 effective words) took 0.3s, 480544 effective words/s
INFO - 2023-11-30 16:53:49,239: EPOCH 11: training on 191080 raw words (135688 effective words) took 0.3s, 473229 effective words/s
INFO - 2023-11-30 16:53:49,529: EPOCH 12: training on 191080 raw words (135755 effective words) took 0.3s, 472189 effective words/s
INFO - 2023-11-30 16:53:49,813: EPOCH 13: training on 191080 raw words (135649 effective words) took 0.3s, 482011 effective words/s
INFO - 2023-11-30 16:53:50,106: EPOCH 14: training on 191080 raw words (135601 effective words) took 0.3s, 465440 effective words/s
INFO - 2023-11-30 16:53:50,404: EPOCH 15: training on 191080 raw words (135549 effective words) took 0.3s, 459213 effective words/s
INFO - 2023-11-30 16:53:50,697: EPOCH 16: training on 191080 raw words (135523 effective words) took 0.3s, 466198 effective words/s
INFO - 2023-11-30 16:53:50,970: EPOCH 17: training on 191080 raw words (135429 effective words) took 0.3s, 501307 effective words/s
INFO - 2023-11-30 16:53:51,253: EPOCH 18: training on 191080 raw words (135471 effective words) took 0.3s, 483441 effective words/s
INFO - 2023-11-30 16:53:51,535: EPOCH 19: training on 191080 raw words (135488 effective words) took 0.3s, 484670 effective words/s
INFO - 2023-11-30 16:53:51,535: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2711513 effective words) took 5.8s, 469992 effective words/s', 'datetime': '2023-11-30T16:53:51.535535', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:51,535: collecting all words and their counts
INFO - 2023-11-30 16:53:51,535: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:51,566: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:51,566: Updating model with new vocabulary
INFO - 2023-11-30 16:53:51,579: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:51.579241', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:51,595: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:51,595: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:51,596: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135487.55520931364 word corpus (70.9%% of prior 191080)', 'datetime': '2023-11-30T16:53:51.595985', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:51,620: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:51,620: updating layer weights
INFO - 2023-11-30 16:53:51,621: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:51.621016', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:51,621: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:51,621: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:51.621282', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:51,903: EPOCH 0: training on 191080 raw words (135562 effective words) took 0.3s, 485641 effective words/s
INFO - 2023-11-30 16:53:52,187: EPOCH 1: training on 191080 raw words (135395 effective words) took 0.3s, 481408 effective words/s
INFO - 2023-11-30 16:53:52,526: EPOCH 2: training on 191080 raw words (135622 effective words) took 0.3s, 402979 effective words/s
INFO - 2023-11-30 16:53:52,812: EPOCH 3: training on 191080 raw words (135218 effective words) took 0.3s, 476007 effective words/s
INFO - 2023-11-30 16:53:53,101: EPOCH 4: training on 191080 raw words (135481 effective words) took 0.3s, 494432 effective words/s
INFO - 2023-11-30 16:53:53,386: EPOCH 5: training on 191080 raw words (135434 effective words) took 0.3s, 479177 effective words/s
INFO - 2023-11-30 16:53:53,671: EPOCH 6: training on 191080 raw words (135543 effective words) took 0.3s, 480515 effective words/s
INFO - 2023-11-30 16:53:53,955: EPOCH 7: training on 191080 raw words (135560 effective words) took 0.3s, 481065 effective words/s
INFO - 2023-11-30 16:53:54,248: EPOCH 8: training on 191080 raw words (135608 effective words) took 0.3s, 466702 effective words/s
INFO - 2023-11-30 16:53:54,529: EPOCH 9: training on 191080 raw words (135415 effective words) took 0.3s, 487019 effective words/s
INFO - 2023-11-30 16:53:54,817: EPOCH 10: training on 191080 raw words (135433 effective words) took 0.3s, 474285 effective words/s
INFO - 2023-11-30 16:53:55,096: EPOCH 11: training on 191080 raw words (135518 effective words) took 0.3s, 489481 effective words/s
INFO - 2023-11-30 16:53:55,373: EPOCH 12: training on 191080 raw words (135591 effective words) took 0.3s, 494288 effective words/s
INFO - 2023-11-30 16:53:55,659: EPOCH 13: training on 191080 raw words (135414 effective words) took 0.3s, 478281 effective words/s
INFO - 2023-11-30 16:53:55,940: EPOCH 14: training on 191080 raw words (135597 effective words) took 0.3s, 486716 effective words/s
INFO - 2023-11-30 16:53:56,214: EPOCH 15: training on 191080 raw words (135327 effective words) took 0.3s, 498745 effective words/s
INFO - 2023-11-30 16:53:56,505: EPOCH 16: training on 191080 raw words (135455 effective words) took 0.3s, 469074 effective words/s
INFO - 2023-11-30 16:53:56,796: EPOCH 17: training on 191080 raw words (135669 effective words) took 0.3s, 470187 effective words/s
INFO - 2023-11-30 16:53:57,065: EPOCH 18: training on 191080 raw words (135680 effective words) took 0.3s, 508922 effective words/s
INFO - 2023-11-30 16:53:57,330: EPOCH 19: training on 191080 raw words (135347 effective words) took 0.3s, 515882 effective words/s
INFO - 2023-11-30 16:53:57,330: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2709869 effective words) took 5.7s, 474651 effective words/s', 'datetime': '2023-11-30T16:53:57.330616', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:57,330: collecting all words and their counts
INFO - 2023-11-30 16:53:57,330: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 16:53:57,360: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 16:53:57,360: Updating model with new vocabulary
INFO - 2023-11-30 16:53:57,371: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T16:53:57.371694', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:57,386: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 16:53:57,386: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 16:53:57,386: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 135627.08246825234 word corpus (71.0%% of prior 191080)', 'datetime': '2023-11-30T16:53:57.386476', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 16:53:57,409: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 16:53:57,409: updating layer weights
INFO - 2023-11-30 16:53:57,410: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T16:53:57.410331', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 16:53:57,410: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 16:53:57,411: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T16:53:57.411347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:53:57,715: EPOCH 0: training on 191080 raw words (135611 effective words) took 0.3s, 453107 effective words/s
INFO - 2023-11-30 16:53:58,031: EPOCH 1: training on 191080 raw words (135569 effective words) took 0.3s, 433194 effective words/s
INFO - 2023-11-30 16:53:58,320: EPOCH 2: training on 191080 raw words (135601 effective words) took 0.3s, 473746 effective words/s
INFO - 2023-11-30 16:53:58,596: EPOCH 3: training on 191080 raw words (135513 effective words) took 0.3s, 494075 effective words/s
INFO - 2023-11-30 16:53:58,874: EPOCH 4: training on 191080 raw words (135567 effective words) took 0.3s, 491605 effective words/s
INFO - 2023-11-30 16:53:59,154: EPOCH 5: training on 191080 raw words (135653 effective words) took 0.3s, 489934 effective words/s
INFO - 2023-11-30 16:53:59,427: EPOCH 6: training on 191080 raw words (135708 effective words) took 0.3s, 500284 effective words/s
INFO - 2023-11-30 16:53:59,703: EPOCH 7: training on 191080 raw words (135455 effective words) took 0.3s, 495301 effective words/s
INFO - 2023-11-30 16:53:59,983: EPOCH 8: training on 191080 raw words (135741 effective words) took 0.3s, 488339 effective words/s
INFO - 2023-11-30 16:54:00,263: EPOCH 9: training on 191080 raw words (135709 effective words) took 0.3s, 489737 effective words/s
INFO - 2023-11-30 16:54:00,535: EPOCH 10: training on 191080 raw words (135672 effective words) took 0.3s, 502886 effective words/s
INFO - 2023-11-30 16:54:00,868: EPOCH 11: training on 191080 raw words (135706 effective words) took 0.3s, 410532 effective words/s
INFO - 2023-11-30 16:54:01,244: EPOCH 12: training on 191080 raw words (135828 effective words) took 0.4s, 363920 effective words/s
INFO - 2023-11-30 16:54:01,637: EPOCH 13: training on 191080 raw words (135498 effective words) took 0.4s, 347506 effective words/s
INFO - 2023-11-30 16:54:02,108: EPOCH 14: training on 191080 raw words (135661 effective words) took 0.5s, 289932 effective words/s
INFO - 2023-11-30 16:54:02,476: EPOCH 15: training on 191080 raw words (135672 effective words) took 0.4s, 371417 effective words/s
INFO - 2023-11-30 16:54:02,844: EPOCH 16: training on 191080 raw words (135674 effective words) took 0.4s, 371966 effective words/s
INFO - 2023-11-30 16:54:03,244: EPOCH 17: training on 191080 raw words (135722 effective words) took 0.4s, 342144 effective words/s
INFO - 2023-11-30 16:54:03,613: EPOCH 18: training on 191080 raw words (135472 effective words) took 0.4s, 370069 effective words/s
INFO - 2023-11-30 16:54:04,023: EPOCH 19: training on 191080 raw words (135318 effective words) took 0.4s, 332989 effective words/s
INFO - 2023-11-30 16:54:04,023: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2712350 effective words) took 6.6s, 410210 effective words/s', 'datetime': '2023-11-30T16:54:04.023844', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 16:54:04,027: storing 4777x128 projection weights into POS.txt
