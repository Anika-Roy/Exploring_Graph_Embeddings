INFO - 2023-11-30 14:13:28,504: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-30T14:13:28.495141', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-30 14:13:28,504: collecting all words and their counts
INFO - 2023-11-30 14:13:28,505: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:28,541: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:28,541: Creating a fresh vocabulary
INFO - 2023-11-30 14:13:28,552: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 4777 unique words (100.00% of original 4777, drops 0)', 'datetime': '2023-11-30T14:13:28.551990', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:28,552: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 191080 word corpus (100.00% of original 191080, drops 0)', 'datetime': '2023-11-30T14:13:28.552205', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:28,567: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:28,567: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:13:28,567: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111591.86127547765 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:13:28.567877', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:28,590: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:28,590: resetting layer weights
INFO - 2023-11-30 14:13:28,593: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:28.593290', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-30 14:13:28,593: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:28.593449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:28,821: EPOCH 0: training on 191080 raw words (111598 effective words) took 0.2s, 509862 effective words/s
INFO - 2023-11-30 14:13:29,044: EPOCH 1: training on 191080 raw words (111641 effective words) took 0.2s, 506039 effective words/s
INFO - 2023-11-30 14:13:29,288: EPOCH 2: training on 191080 raw words (111532 effective words) took 0.2s, 463234 effective words/s
INFO - 2023-11-30 14:13:29,517: EPOCH 3: training on 191080 raw words (111667 effective words) took 0.2s, 490980 effective words/s
INFO - 2023-11-30 14:13:29,763: EPOCH 4: training on 191080 raw words (111569 effective words) took 0.2s, 457537 effective words/s
INFO - 2023-11-30 14:13:30,031: EPOCH 5: training on 191080 raw words (111816 effective words) took 0.3s, 421855 effective words/s
INFO - 2023-11-30 14:13:30,288: EPOCH 6: training on 191080 raw words (111579 effective words) took 0.3s, 437357 effective words/s
INFO - 2023-11-30 14:13:30,529: EPOCH 7: training on 191080 raw words (111530 effective words) took 0.2s, 468994 effective words/s
INFO - 2023-11-30 14:13:30,778: EPOCH 8: training on 191080 raw words (111711 effective words) took 0.2s, 453010 effective words/s
INFO - 2023-11-30 14:13:31,015: EPOCH 9: training on 191080 raw words (111526 effective words) took 0.2s, 475459 effective words/s
INFO - 2023-11-30 14:13:31,306: EPOCH 10: training on 191080 raw words (111465 effective words) took 0.3s, 386067 effective words/s
INFO - 2023-11-30 14:13:31,578: EPOCH 11: training on 191080 raw words (111584 effective words) took 0.3s, 414301 effective words/s
INFO - 2023-11-30 14:13:31,818: EPOCH 12: training on 191080 raw words (111360 effective words) took 0.2s, 468966 effective words/s
INFO - 2023-11-30 14:13:32,047: EPOCH 13: training on 191080 raw words (111581 effective words) took 0.2s, 494620 effective words/s
INFO - 2023-11-30 14:13:32,298: EPOCH 14: training on 191080 raw words (111427 effective words) took 0.2s, 448901 effective words/s
INFO - 2023-11-30 14:13:32,525: EPOCH 15: training on 191080 raw words (111503 effective words) took 0.2s, 496953 effective words/s
INFO - 2023-11-30 14:13:32,750: EPOCH 16: training on 191080 raw words (111412 effective words) took 0.2s, 500535 effective words/s
INFO - 2023-11-30 14:13:32,977: EPOCH 17: training on 191080 raw words (111680 effective words) took 0.2s, 497209 effective words/s
INFO - 2023-11-30 14:13:33,199: EPOCH 18: training on 191080 raw words (111413 effective words) took 0.2s, 508659 effective words/s
INFO - 2023-11-30 14:13:33,429: EPOCH 19: training on 191080 raw words (111481 effective words) took 0.2s, 487762 effective words/s
INFO - 2023-11-30 14:13:33,430: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231075 effective words) took 4.8s, 461296 effective words/s', 'datetime': '2023-11-30T14:13:33.430118', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:33,430: collecting all words and their counts
INFO - 2023-11-30 14:13:33,430: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:33,458: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:33,458: Updating model with new vocabulary
INFO - 2023-11-30 14:13:33,470: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:13:33.470021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:33,484: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:33,484: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:13:33,484: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 112054.36406184445 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:13:33.484661', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:33,507: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:33,507: updating layer weights
INFO - 2023-11-30 14:13:33,508: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:33.508534', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:13:33,508: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:13:33,508: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:33.508794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:33,737: EPOCH 0: training on 191080 raw words (112173 effective words) took 0.2s, 495505 effective words/s
INFO - 2023-11-30 14:13:33,947: EPOCH 1: training on 191080 raw words (112012 effective words) took 0.2s, 538678 effective words/s
INFO - 2023-11-30 14:13:34,161: EPOCH 2: training on 191080 raw words (112141 effective words) took 0.2s, 531197 effective words/s
INFO - 2023-11-30 14:13:34,369: EPOCH 3: training on 191080 raw words (112093 effective words) took 0.2s, 543618 effective words/s
INFO - 2023-11-30 14:13:34,601: EPOCH 4: training on 191080 raw words (112157 effective words) took 0.2s, 489576 effective words/s
INFO - 2023-11-30 14:13:34,806: EPOCH 5: training on 191080 raw words (112117 effective words) took 0.2s, 555361 effective words/s
INFO - 2023-11-30 14:13:35,012: EPOCH 6: training on 191080 raw words (112044 effective words) took 0.2s, 549636 effective words/s
INFO - 2023-11-30 14:13:35,214: EPOCH 7: training on 191080 raw words (112018 effective words) took 0.2s, 559000 effective words/s
INFO - 2023-11-30 14:13:35,424: EPOCH 8: training on 191080 raw words (112074 effective words) took 0.2s, 540905 effective words/s
INFO - 2023-11-30 14:13:35,637: EPOCH 9: training on 191080 raw words (112167 effective words) took 0.2s, 531380 effective words/s
INFO - 2023-11-30 14:13:35,851: EPOCH 10: training on 191080 raw words (112067 effective words) took 0.2s, 531217 effective words/s
INFO - 2023-11-30 14:13:36,057: EPOCH 11: training on 191080 raw words (111905 effective words) took 0.2s, 547626 effective words/s
INFO - 2023-11-30 14:13:36,285: EPOCH 12: training on 191080 raw words (112012 effective words) took 0.2s, 496220 effective words/s
INFO - 2023-11-30 14:13:36,525: EPOCH 13: training on 191080 raw words (111980 effective words) took 0.2s, 472740 effective words/s
INFO - 2023-11-30 14:13:36,763: EPOCH 14: training on 191080 raw words (112053 effective words) took 0.2s, 476076 effective words/s
INFO - 2023-11-30 14:13:37,007: EPOCH 15: training on 191080 raw words (111910 effective words) took 0.2s, 465005 effective words/s
INFO - 2023-11-30 14:13:37,246: EPOCH 16: training on 191080 raw words (112226 effective words) took 0.2s, 474061 effective words/s
INFO - 2023-11-30 14:13:37,486: EPOCH 17: training on 191080 raw words (112135 effective words) took 0.2s, 471378 effective words/s
INFO - 2023-11-30 14:13:37,709: EPOCH 18: training on 191080 raw words (112161 effective words) took 0.2s, 509460 effective words/s
INFO - 2023-11-30 14:13:37,938: EPOCH 19: training on 191080 raw words (111868 effective words) took 0.2s, 494974 effective words/s
INFO - 2023-11-30 14:13:37,938: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2241313 effective words) took 4.4s, 506001 effective words/s', 'datetime': '2023-11-30T14:13:37.938394', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:37,938: collecting all words and their counts
INFO - 2023-11-30 14:13:37,938: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:37,967: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:37,967: Updating model with new vocabulary
INFO - 2023-11-30 14:13:37,982: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:13:37.982428', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:38,000: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:38,000: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:13:38,000: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111651.60760674611 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:13:38.000956', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:38,027: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:38,027: updating layer weights
INFO - 2023-11-30 14:13:38,027: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:38.027802', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:13:38,027: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:13:38,028: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:38.028064', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:38,266: EPOCH 0: training on 191080 raw words (111737 effective words) took 0.2s, 473406 effective words/s
INFO - 2023-11-30 14:13:38,492: EPOCH 1: training on 191080 raw words (111683 effective words) took 0.2s, 501158 effective words/s
INFO - 2023-11-30 14:13:38,741: EPOCH 2: training on 191080 raw words (111601 effective words) took 0.2s, 450873 effective words/s
INFO - 2023-11-30 14:13:39,011: EPOCH 3: training on 191080 raw words (111733 effective words) took 0.3s, 418498 effective words/s
INFO - 2023-11-30 14:13:39,259: EPOCH 4: training on 191080 raw words (111534 effective words) took 0.2s, 455220 effective words/s
INFO - 2023-11-30 14:13:39,483: EPOCH 5: training on 191080 raw words (111666 effective words) took 0.2s, 503139 effective words/s
INFO - 2023-11-30 14:13:39,711: EPOCH 6: training on 191080 raw words (111697 effective words) took 0.2s, 495709 effective words/s
INFO - 2023-11-30 14:13:39,935: EPOCH 7: training on 191080 raw words (111720 effective words) took 0.2s, 506115 effective words/s
INFO - 2023-11-30 14:13:40,162: EPOCH 8: training on 191080 raw words (111543 effective words) took 0.2s, 495674 effective words/s
INFO - 2023-11-30 14:13:40,393: EPOCH 9: training on 191080 raw words (111804 effective words) took 0.2s, 488487 effective words/s
INFO - 2023-11-30 14:13:40,621: EPOCH 10: training on 191080 raw words (111922 effective words) took 0.2s, 496168 effective words/s
INFO - 2023-11-30 14:13:40,844: EPOCH 11: training on 191080 raw words (111596 effective words) took 0.2s, 506592 effective words/s
INFO - 2023-11-30 14:13:41,072: EPOCH 12: training on 191080 raw words (111704 effective words) took 0.2s, 495641 effective words/s
INFO - 2023-11-30 14:13:41,314: EPOCH 13: training on 191080 raw words (111690 effective words) took 0.2s, 465951 effective words/s
INFO - 2023-11-30 14:13:41,545: EPOCH 14: training on 191080 raw words (111531 effective words) took 0.2s, 487550 effective words/s
INFO - 2023-11-30 14:13:41,780: EPOCH 15: training on 191080 raw words (111741 effective words) took 0.2s, 481314 effective words/s
INFO - 2023-11-30 14:13:42,019: EPOCH 16: training on 191080 raw words (111552 effective words) took 0.2s, 471506 effective words/s
INFO - 2023-11-30 14:13:42,276: EPOCH 17: training on 191080 raw words (111540 effective words) took 0.3s, 438598 effective words/s
INFO - 2023-11-30 14:13:42,521: EPOCH 18: training on 191080 raw words (111805 effective words) took 0.2s, 460184 effective words/s
INFO - 2023-11-30 14:13:42,760: EPOCH 19: training on 191080 raw words (111696 effective words) took 0.2s, 472173 effective words/s
INFO - 2023-11-30 14:13:42,761: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233495 effective words) took 4.7s, 471910 effective words/s', 'datetime': '2023-11-30T14:13:42.761066', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:42,761: collecting all words and their counts
INFO - 2023-11-30 14:13:42,761: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:42,790: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:42,790: Updating model with new vocabulary
INFO - 2023-11-30 14:13:42,804: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:13:42.804723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:42,825: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:42,825: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:13:42,825: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111750.42830052009 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:13:42.825879', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:42,857: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:42,857: updating layer weights
INFO - 2023-11-30 14:13:42,857: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:42.857826', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:13:42,857: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:13:42,858: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:42.858096', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:43,147: EPOCH 0: training on 191080 raw words (111752 effective words) took 0.3s, 389625 effective words/s
INFO - 2023-11-30 14:13:43,365: EPOCH 1: training on 191080 raw words (111556 effective words) took 0.2s, 518194 effective words/s
INFO - 2023-11-30 14:13:43,607: EPOCH 2: training on 191080 raw words (112015 effective words) took 0.2s, 467920 effective words/s
INFO - 2023-11-30 14:13:43,831: EPOCH 3: training on 191080 raw words (111584 effective words) took 0.2s, 504078 effective words/s
INFO - 2023-11-30 14:13:44,164: EPOCH 4: training on 191080 raw words (111645 effective words) took 0.3s, 337576 effective words/s
INFO - 2023-11-30 14:13:44,507: EPOCH 5: training on 191080 raw words (111921 effective words) took 0.3s, 328887 effective words/s
INFO - 2023-11-30 14:13:44,829: EPOCH 6: training on 191080 raw words (111701 effective words) took 0.3s, 351712 effective words/s
INFO - 2023-11-30 14:13:45,123: EPOCH 7: training on 191080 raw words (111444 effective words) took 0.3s, 383027 effective words/s
INFO - 2023-11-30 14:13:45,441: EPOCH 8: training on 191080 raw words (111647 effective words) took 0.3s, 354647 effective words/s
INFO - 2023-11-30 14:13:45,751: EPOCH 9: training on 191080 raw words (111855 effective words) took 0.3s, 364270 effective words/s
INFO - 2023-11-30 14:13:46,060: EPOCH 10: training on 191080 raw words (111753 effective words) took 0.3s, 365960 effective words/s
INFO - 2023-11-30 14:13:46,356: EPOCH 11: training on 191080 raw words (111715 effective words) took 0.3s, 381157 effective words/s
INFO - 2023-11-30 14:13:46,651: EPOCH 12: training on 191080 raw words (111630 effective words) took 0.3s, 382284 effective words/s
INFO - 2023-11-30 14:13:46,967: EPOCH 13: training on 191080 raw words (111685 effective words) took 0.3s, 358305 effective words/s
INFO - 2023-11-30 14:13:47,320: EPOCH 14: training on 191080 raw words (111960 effective words) took 0.4s, 319402 effective words/s
INFO - 2023-11-30 14:13:47,678: EPOCH 15: training on 191080 raw words (111556 effective words) took 0.4s, 315357 effective words/s
INFO - 2023-11-30 14:13:48,053: EPOCH 16: training on 191080 raw words (111799 effective words) took 0.4s, 301745 effective words/s
INFO - 2023-11-30 14:13:48,429: EPOCH 17: training on 191080 raw words (111788 effective words) took 0.4s, 300128 effective words/s
INFO - 2023-11-30 14:13:48,755: EPOCH 18: training on 191080 raw words (111807 effective words) took 0.3s, 346939 effective words/s
INFO - 2023-11-30 14:13:49,100: EPOCH 19: training on 191080 raw words (111565 effective words) took 0.3s, 326381 effective words/s
INFO - 2023-11-30 14:13:49,100: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234378 effective words) took 6.2s, 357919 effective words/s', 'datetime': '2023-11-30T14:13:49.100916', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:49,101: collecting all words and their counts
INFO - 2023-11-30 14:13:49,101: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:49,147: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:49,147: Updating model with new vocabulary
INFO - 2023-11-30 14:13:49,167: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:13:49.167807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:49,195: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:49,195: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:13:49,195: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111933.01249945225 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:13:49.195641', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:49,241: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:49,242: updating layer weights
INFO - 2023-11-30 14:13:49,242: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:49.242762', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:13:49,243: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:13:49,243: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:49.243347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:49,663: EPOCH 0: training on 191080 raw words (111785 effective words) took 0.4s, 268471 effective words/s
INFO - 2023-11-30 14:13:50,037: EPOCH 1: training on 191080 raw words (112135 effective words) took 0.4s, 302677 effective words/s
INFO - 2023-11-30 14:13:50,435: EPOCH 2: training on 191080 raw words (111880 effective words) took 0.4s, 283738 effective words/s
INFO - 2023-11-30 14:13:50,842: EPOCH 3: training on 191080 raw words (111868 effective words) took 0.4s, 277200 effective words/s
INFO - 2023-11-30 14:13:51,208: EPOCH 4: training on 191080 raw words (112099 effective words) took 0.4s, 309315 effective words/s
INFO - 2023-11-30 14:13:51,574: EPOCH 5: training on 191080 raw words (112055 effective words) took 0.4s, 309486 effective words/s
INFO - 2023-11-30 14:13:51,979: EPOCH 6: training on 191080 raw words (111694 effective words) took 0.4s, 278474 effective words/s
INFO - 2023-11-30 14:13:52,365: EPOCH 7: training on 191080 raw words (111691 effective words) took 0.4s, 292504 effective words/s
INFO - 2023-11-30 14:13:52,767: EPOCH 8: training on 191080 raw words (111967 effective words) took 0.4s, 280812 effective words/s
INFO - 2023-11-30 14:13:53,131: EPOCH 9: training on 191080 raw words (112006 effective words) took 0.4s, 311423 effective words/s
INFO - 2023-11-30 14:13:53,470: EPOCH 10: training on 191080 raw words (112171 effective words) took 0.3s, 334684 effective words/s
INFO - 2023-11-30 14:13:53,800: EPOCH 11: training on 191080 raw words (111904 effective words) took 0.3s, 342340 effective words/s
INFO - 2023-11-30 14:13:54,112: EPOCH 12: training on 191080 raw words (112007 effective words) took 0.3s, 362006 effective words/s
INFO - 2023-11-30 14:13:54,422: EPOCH 13: training on 191080 raw words (112207 effective words) took 0.3s, 365207 effective words/s
INFO - 2023-11-30 14:13:54,721: EPOCH 14: training on 191080 raw words (111811 effective words) took 0.3s, 378022 effective words/s
INFO - 2023-11-30 14:13:55,018: EPOCH 15: training on 191080 raw words (111841 effective words) took 0.3s, 380480 effective words/s
INFO - 2023-11-30 14:13:55,309: EPOCH 16: training on 191080 raw words (111848 effective words) took 0.3s, 388594 effective words/s
INFO - 2023-11-30 14:13:55,602: EPOCH 17: training on 191080 raw words (111777 effective words) took 0.3s, 384954 effective words/s
INFO - 2023-11-30 14:13:55,897: EPOCH 18: training on 191080 raw words (111858 effective words) took 0.3s, 382682 effective words/s
INFO - 2023-11-30 14:13:56,205: EPOCH 19: training on 191080 raw words (112118 effective words) took 0.3s, 368424 effective words/s
INFO - 2023-11-30 14:13:56,205: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2238722 effective words) took 7.0s, 321571 effective words/s', 'datetime': '2023-11-30T14:13:56.205403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:56,205: collecting all words and their counts
INFO - 2023-11-30 14:13:56,205: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:13:56,243: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:13:56,243: Updating model with new vocabulary
INFO - 2023-11-30 14:13:56,263: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:13:56.263316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:56,284: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:13:56,285: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:13:56,285: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111576.90390257239 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:13:56.285278', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:13:56,323: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:13:56,323: updating layer weights
INFO - 2023-11-30 14:13:56,324: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:13:56.324328', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:13:56,324: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:13:56,324: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:13:56.324634', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:13:56,598: EPOCH 0: training on 191080 raw words (111739 effective words) took 0.3s, 412420 effective words/s
INFO - 2023-11-30 14:13:56,895: EPOCH 1: training on 191080 raw words (111548 effective words) took 0.3s, 378904 effective words/s
INFO - 2023-11-30 14:13:57,163: EPOCH 2: training on 191080 raw words (111415 effective words) took 0.3s, 421603 effective words/s
INFO - 2023-11-30 14:13:57,445: EPOCH 3: training on 191080 raw words (111395 effective words) took 0.3s, 399030 effective words/s
INFO - 2023-11-30 14:13:57,744: EPOCH 4: training on 191080 raw words (111679 effective words) took 0.3s, 377185 effective words/s
INFO - 2023-11-30 14:13:57,986: EPOCH 5: training on 191080 raw words (111696 effective words) took 0.2s, 466216 effective words/s
INFO - 2023-11-30 14:13:58,221: EPOCH 6: training on 191080 raw words (111588 effective words) took 0.2s, 480493 effective words/s
INFO - 2023-11-30 14:13:58,495: EPOCH 7: training on 191080 raw words (111615 effective words) took 0.3s, 410238 effective words/s
INFO - 2023-11-30 14:13:58,756: EPOCH 8: training on 191080 raw words (111541 effective words) took 0.3s, 433007 effective words/s
INFO - 2023-11-30 14:13:58,982: EPOCH 9: training on 191080 raw words (111395 effective words) took 0.2s, 499228 effective words/s
INFO - 2023-11-30 14:13:59,207: EPOCH 10: training on 191080 raw words (111709 effective words) took 0.2s, 501981 effective words/s
INFO - 2023-11-30 14:13:59,426: EPOCH 11: training on 191080 raw words (111661 effective words) took 0.2s, 515550 effective words/s
INFO - 2023-11-30 14:13:59,647: EPOCH 12: training on 191080 raw words (111431 effective words) took 0.2s, 508915 effective words/s
INFO - 2023-11-30 14:13:59,874: EPOCH 13: training on 191080 raw words (111418 effective words) took 0.2s, 495611 effective words/s
INFO - 2023-11-30 14:14:00,112: EPOCH 14: training on 191080 raw words (111522 effective words) took 0.2s, 474382 effective words/s
INFO - 2023-11-30 14:14:00,335: EPOCH 15: training on 191080 raw words (111678 effective words) took 0.2s, 505672 effective words/s
INFO - 2023-11-30 14:14:00,556: EPOCH 16: training on 191080 raw words (111644 effective words) took 0.2s, 510576 effective words/s
INFO - 2023-11-30 14:14:00,774: EPOCH 17: training on 191080 raw words (111605 effective words) took 0.2s, 519496 effective words/s
INFO - 2023-11-30 14:14:00,997: EPOCH 18: training on 191080 raw words (111773 effective words) took 0.2s, 507172 effective words/s
INFO - 2023-11-30 14:14:01,221: EPOCH 19: training on 191080 raw words (111535 effective words) took 0.2s, 501955 effective words/s
INFO - 2023-11-30 14:14:01,221: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231587 effective words) took 4.9s, 455731 effective words/s', 'datetime': '2023-11-30T14:14:01.221497', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:01,221: collecting all words and their counts
INFO - 2023-11-30 14:14:01,221: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:01,249: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:01,249: Updating model with new vocabulary
INFO - 2023-11-30 14:14:01,262: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:01.262153', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:01,278: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:01,278: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:01,279: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111802.66962404402 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:01.278965', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:01,302: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:01,302: updating layer weights
INFO - 2023-11-30 14:14:01,303: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:01.302990', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:01,303: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:01,303: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:01.303229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:01,540: EPOCH 0: training on 191080 raw words (111788 effective words) took 0.2s, 475914 effective words/s
INFO - 2023-11-30 14:14:01,785: EPOCH 1: training on 191080 raw words (111647 effective words) took 0.2s, 460151 effective words/s
INFO - 2023-11-30 14:14:02,025: EPOCH 2: training on 191080 raw words (111879 effective words) took 0.2s, 470305 effective words/s
INFO - 2023-11-30 14:14:02,270: EPOCH 3: training on 191080 raw words (111962 effective words) took 0.2s, 464222 effective words/s
INFO - 2023-11-30 14:14:02,522: EPOCH 4: training on 191080 raw words (111592 effective words) took 0.2s, 447017 effective words/s
INFO - 2023-11-30 14:14:02,763: EPOCH 5: training on 191080 raw words (111757 effective words) took 0.2s, 466534 effective words/s
INFO - 2023-11-30 14:14:03,015: EPOCH 6: training on 191080 raw words (111833 effective words) took 0.2s, 448896 effective words/s
INFO - 2023-11-30 14:14:03,313: EPOCH 7: training on 191080 raw words (111789 effective words) took 0.3s, 377427 effective words/s
INFO - 2023-11-30 14:14:03,593: EPOCH 8: training on 191080 raw words (111878 effective words) took 0.3s, 404708 effective words/s
INFO - 2023-11-30 14:14:03,863: EPOCH 9: training on 191080 raw words (111921 effective words) took 0.3s, 417762 effective words/s
INFO - 2023-11-30 14:14:04,184: EPOCH 10: training on 191080 raw words (111582 effective words) took 0.3s, 351072 effective words/s
INFO - 2023-11-30 14:14:04,466: EPOCH 11: training on 191080 raw words (111730 effective words) took 0.3s, 401837 effective words/s
INFO - 2023-11-30 14:14:04,711: EPOCH 12: training on 191080 raw words (111833 effective words) took 0.2s, 459642 effective words/s
INFO - 2023-11-30 14:14:04,966: EPOCH 13: training on 191080 raw words (111910 effective words) took 0.3s, 446209 effective words/s
INFO - 2023-11-30 14:14:05,210: EPOCH 14: training on 191080 raw words (111869 effective words) took 0.2s, 463978 effective words/s
INFO - 2023-11-30 14:14:05,449: EPOCH 15: training on 191080 raw words (111758 effective words) took 0.2s, 486790 effective words/s
INFO - 2023-11-30 14:14:05,708: EPOCH 16: training on 191080 raw words (111917 effective words) took 0.3s, 436201 effective words/s
INFO - 2023-11-30 14:14:05,964: EPOCH 17: training on 191080 raw words (111749 effective words) took 0.3s, 441151 effective words/s
INFO - 2023-11-30 14:14:06,219: EPOCH 18: training on 191080 raw words (111546 effective words) took 0.3s, 442571 effective words/s
INFO - 2023-11-30 14:14:06,457: EPOCH 19: training on 191080 raw words (111725 effective words) took 0.2s, 474610 effective words/s
INFO - 2023-11-30 14:14:06,457: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2235665 effective words) took 5.2s, 433742 effective words/s', 'datetime': '2023-11-30T14:14:06.457769', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:06,457: collecting all words and their counts
INFO - 2023-11-30 14:14:06,458: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:06,486: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:06,487: Updating model with new vocabulary
INFO - 2023-11-30 14:14:06,502: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:06.502416', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:06,521: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:06,522: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:06,522: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111813.60142811402 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:06.522282', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:06,552: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:06,552: updating layer weights
INFO - 2023-11-30 14:14:06,553: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:06.553058', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:06,553: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:06,553: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:06.553434', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:06,802: EPOCH 0: training on 191080 raw words (111864 effective words) took 0.2s, 455715 effective words/s
INFO - 2023-11-30 14:14:07,033: EPOCH 1: training on 191080 raw words (111876 effective words) took 0.2s, 487692 effective words/s
INFO - 2023-11-30 14:14:07,258: EPOCH 2: training on 191080 raw words (111654 effective words) took 0.2s, 503665 effective words/s
INFO - 2023-11-30 14:14:07,482: EPOCH 3: training on 191080 raw words (111759 effective words) took 0.2s, 504558 effective words/s
INFO - 2023-11-30 14:14:07,705: EPOCH 4: training on 191080 raw words (111867 effective words) took 0.2s, 506135 effective words/s
INFO - 2023-11-30 14:14:07,938: EPOCH 5: training on 191080 raw words (111865 effective words) took 0.2s, 484984 effective words/s
INFO - 2023-11-30 14:14:08,165: EPOCH 6: training on 191080 raw words (112013 effective words) took 0.2s, 499555 effective words/s
INFO - 2023-11-30 14:14:08,397: EPOCH 7: training on 191080 raw words (111961 effective words) took 0.2s, 487841 effective words/s
INFO - 2023-11-30 14:14:08,622: EPOCH 8: training on 191080 raw words (111727 effective words) took 0.2s, 501664 effective words/s
INFO - 2023-11-30 14:14:08,864: EPOCH 9: training on 191080 raw words (111586 effective words) took 0.2s, 465357 effective words/s
INFO - 2023-11-30 14:14:09,102: EPOCH 10: training on 191080 raw words (112023 effective words) took 0.2s, 474955 effective words/s
INFO - 2023-11-30 14:14:09,330: EPOCH 11: training on 191080 raw words (111803 effective words) took 0.2s, 497119 effective words/s
INFO - 2023-11-30 14:14:09,550: EPOCH 12: training on 191080 raw words (111855 effective words) took 0.2s, 515505 effective words/s
INFO - 2023-11-30 14:14:09,782: EPOCH 13: training on 191080 raw words (111773 effective words) took 0.2s, 485195 effective words/s
INFO - 2023-11-30 14:14:10,005: EPOCH 14: training on 191080 raw words (111922 effective words) took 0.2s, 509934 effective words/s
INFO - 2023-11-30 14:14:10,218: EPOCH 15: training on 191080 raw words (111913 effective words) took 0.2s, 529979 effective words/s
INFO - 2023-11-30 14:14:10,447: EPOCH 16: training on 191080 raw words (111662 effective words) took 0.2s, 492424 effective words/s
INFO - 2023-11-30 14:14:10,676: EPOCH 17: training on 191080 raw words (111680 effective words) took 0.2s, 494704 effective words/s
INFO - 2023-11-30 14:14:10,905: EPOCH 18: training on 191080 raw words (111852 effective words) took 0.2s, 493846 effective words/s
INFO - 2023-11-30 14:14:11,149: EPOCH 19: training on 191080 raw words (111753 effective words) took 0.2s, 462547 effective words/s
INFO - 2023-11-30 14:14:11,150: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236408 effective words) took 4.6s, 486558 effective words/s', 'datetime': '2023-11-30T14:14:11.149958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:11,150: collecting all words and their counts
INFO - 2023-11-30 14:14:11,150: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:11,179: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:11,179: Updating model with new vocabulary
INFO - 2023-11-30 14:14:11,196: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:11.196200', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:11,216: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:11,216: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:11,217: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111599.30252016698 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:14:11.217043', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:11,247: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:11,247: updating layer weights
INFO - 2023-11-30 14:14:11,248: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:11.248159', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:11,248: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:11,248: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:11.248958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:11,514: EPOCH 0: training on 191080 raw words (111641 effective words) took 0.3s, 425675 effective words/s
INFO - 2023-11-30 14:14:11,760: EPOCH 1: training on 191080 raw words (111709 effective words) took 0.2s, 457830 effective words/s
INFO - 2023-11-30 14:14:12,019: EPOCH 2: training on 191080 raw words (111608 effective words) took 0.3s, 436013 effective words/s
INFO - 2023-11-30 14:14:12,269: EPOCH 3: training on 191080 raw words (111531 effective words) took 0.2s, 450601 effective words/s
INFO - 2023-11-30 14:14:12,700: EPOCH 4: training on 191080 raw words (111655 effective words) took 0.4s, 261109 effective words/s
INFO - 2023-11-30 14:14:12,975: EPOCH 5: training on 191080 raw words (111543 effective words) took 0.3s, 410083 effective words/s
INFO - 2023-11-30 14:14:13,206: EPOCH 6: training on 191080 raw words (111414 effective words) took 0.2s, 487394 effective words/s
INFO - 2023-11-30 14:14:13,443: EPOCH 7: training on 191080 raw words (111605 effective words) took 0.2s, 475167 effective words/s
INFO - 2023-11-30 14:14:13,675: EPOCH 8: training on 191080 raw words (111481 effective words) took 0.2s, 486667 effective words/s
INFO - 2023-11-30 14:14:13,905: EPOCH 9: training on 191080 raw words (111750 effective words) took 0.2s, 491024 effective words/s
INFO - 2023-11-30 14:14:14,132: EPOCH 10: training on 191080 raw words (111432 effective words) took 0.2s, 494777 effective words/s
INFO - 2023-11-30 14:14:14,365: EPOCH 11: training on 191080 raw words (111517 effective words) took 0.2s, 485117 effective words/s
INFO - 2023-11-30 14:14:14,594: EPOCH 12: training on 191080 raw words (111593 effective words) took 0.2s, 491740 effective words/s
INFO - 2023-11-30 14:14:14,821: EPOCH 13: training on 191080 raw words (111446 effective words) took 0.2s, 495052 effective words/s
INFO - 2023-11-30 14:14:15,052: EPOCH 14: training on 191080 raw words (111589 effective words) took 0.2s, 489867 effective words/s
INFO - 2023-11-30 14:14:15,340: EPOCH 15: training on 191080 raw words (111542 effective words) took 0.3s, 389820 effective words/s
INFO - 2023-11-30 14:14:15,694: EPOCH 16: training on 191080 raw words (111391 effective words) took 0.4s, 318073 effective words/s
INFO - 2023-11-30 14:14:16,042: EPOCH 17: training on 191080 raw words (111613 effective words) took 0.3s, 323717 effective words/s
INFO - 2023-11-30 14:14:16,379: EPOCH 18: training on 191080 raw words (111751 effective words) took 0.3s, 335243 effective words/s
INFO - 2023-11-30 14:14:16,718: EPOCH 19: training on 191080 raw words (111636 effective words) took 0.3s, 331827 effective words/s
INFO - 2023-11-30 14:14:16,719: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231447 effective words) took 5.5s, 407938 effective words/s', 'datetime': '2023-11-30T14:14:16.719159', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:16,719: collecting all words and their counts
INFO - 2023-11-30 14:14:16,719: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:16,762: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:16,763: Updating model with new vocabulary
INFO - 2023-11-30 14:14:16,781: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:16.781564', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:16,803: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:16,803: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:14:16,803: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111542.68448078714 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:14:16.803806', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:16,836: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:16,836: updating layer weights
INFO - 2023-11-30 14:14:16,837: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:16.837144', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:16,837: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:16,837: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:16.837482', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:17,210: EPOCH 0: training on 191080 raw words (111370 effective words) took 0.4s, 301042 effective words/s
INFO - 2023-11-30 14:14:17,515: EPOCH 1: training on 191080 raw words (111688 effective words) took 0.3s, 370853 effective words/s
INFO - 2023-11-30 14:14:17,790: EPOCH 2: training on 191080 raw words (111589 effective words) took 0.3s, 409437 effective words/s
INFO - 2023-11-30 14:14:18,078: EPOCH 3: training on 191080 raw words (111420 effective words) took 0.3s, 390619 effective words/s
INFO - 2023-11-30 14:14:18,520: EPOCH 4: training on 191080 raw words (111567 effective words) took 0.4s, 254478 effective words/s
INFO - 2023-11-30 14:14:18,989: EPOCH 5: training on 191080 raw words (111493 effective words) took 0.5s, 241197 effective words/s
INFO - 2023-11-30 14:14:19,514: EPOCH 6: training on 191080 raw words (111412 effective words) took 0.5s, 214195 effective words/s
INFO - 2023-11-30 14:14:19,936: EPOCH 7: training on 191080 raw words (111377 effective words) took 0.4s, 275800 effective words/s
INFO - 2023-11-30 14:14:20,351: EPOCH 8: training on 191080 raw words (111648 effective words) took 0.4s, 271269 effective words/s
INFO - 2023-11-30 14:14:20,821: EPOCH 9: training on 191080 raw words (111504 effective words) took 0.5s, 239663 effective words/s
INFO - 2023-11-30 14:14:21,227: EPOCH 10: training on 191080 raw words (111622 effective words) took 0.4s, 278711 effective words/s
INFO - 2023-11-30 14:14:21,614: EPOCH 11: training on 191080 raw words (111463 effective words) took 0.4s, 290867 effective words/s
INFO - 2023-11-30 14:14:22,006: EPOCH 12: training on 191080 raw words (111685 effective words) took 0.4s, 288134 effective words/s
INFO - 2023-11-30 14:14:22,391: EPOCH 13: training on 191080 raw words (111732 effective words) took 0.4s, 293341 effective words/s
INFO - 2023-11-30 14:14:22,796: EPOCH 14: training on 191080 raw words (111570 effective words) took 0.4s, 280134 effective words/s
INFO - 2023-11-30 14:14:23,160: EPOCH 15: training on 191080 raw words (111483 effective words) took 0.4s, 310599 effective words/s
INFO - 2023-11-30 14:14:23,540: EPOCH 16: training on 191080 raw words (111334 effective words) took 0.4s, 295615 effective words/s
INFO - 2023-11-30 14:14:23,887: EPOCH 17: training on 191080 raw words (111481 effective words) took 0.3s, 325107 effective words/s
INFO - 2023-11-30 14:14:24,199: EPOCH 18: training on 191080 raw words (111426 effective words) took 0.3s, 360976 effective words/s
INFO - 2023-11-30 14:14:24,421: EPOCH 19: training on 191080 raw words (111606 effective words) took 0.2s, 509815 effective words/s
INFO - 2023-11-30 14:14:24,421: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230470 effective words) took 7.6s, 294105 effective words/s', 'datetime': '2023-11-30T14:14:24.421569', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:24,421: collecting all words and their counts
INFO - 2023-11-30 14:14:24,421: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:24,449: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:24,449: Updating model with new vocabulary
INFO - 2023-11-30 14:14:24,462: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:24.462059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:24,478: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:24,478: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:14:24,478: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111765.9854759481 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:24.478290', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:24,503: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:24,503: updating layer weights
INFO - 2023-11-30 14:14:24,504: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:24.504121', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:24,504: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:24,504: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:24.504551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:24,761: EPOCH 0: training on 191080 raw words (111750 effective words) took 0.3s, 440509 effective words/s
INFO - 2023-11-30 14:14:25,023: EPOCH 1: training on 191080 raw words (111694 effective words) took 0.3s, 430542 effective words/s
INFO - 2023-11-30 14:14:25,289: EPOCH 2: training on 191080 raw words (111910 effective words) took 0.3s, 426017 effective words/s
INFO - 2023-11-30 14:14:25,519: EPOCH 3: training on 191080 raw words (111869 effective words) took 0.2s, 492053 effective words/s
INFO - 2023-11-30 14:14:25,768: EPOCH 4: training on 191080 raw words (111684 effective words) took 0.2s, 451807 effective words/s
INFO - 2023-11-30 14:14:26,015: EPOCH 5: training on 191080 raw words (111807 effective words) took 0.2s, 458008 effective words/s
INFO - 2023-11-30 14:14:26,275: EPOCH 6: training on 191080 raw words (111779 effective words) took 0.3s, 433387 effective words/s
INFO - 2023-11-30 14:14:26,529: EPOCH 7: training on 191080 raw words (111797 effective words) took 0.3s, 444763 effective words/s
INFO - 2023-11-30 14:14:26,794: EPOCH 8: training on 191080 raw words (111784 effective words) took 0.3s, 440696 effective words/s
INFO - 2023-11-30 14:14:27,049: EPOCH 9: training on 191080 raw words (111780 effective words) took 0.3s, 442418 effective words/s
INFO - 2023-11-30 14:14:27,304: EPOCH 10: training on 191080 raw words (111856 effective words) took 0.3s, 442855 effective words/s
INFO - 2023-11-30 14:14:27,550: EPOCH 11: training on 191080 raw words (111823 effective words) took 0.2s, 459464 effective words/s
INFO - 2023-11-30 14:14:27,783: EPOCH 12: training on 191080 raw words (111606 effective words) took 0.2s, 484449 effective words/s
INFO - 2023-11-30 14:14:28,035: EPOCH 13: training on 191080 raw words (111681 effective words) took 0.2s, 446970 effective words/s
INFO - 2023-11-30 14:14:28,287: EPOCH 14: training on 191080 raw words (111718 effective words) took 0.2s, 462206 effective words/s
INFO - 2023-11-30 14:14:28,553: EPOCH 15: training on 191080 raw words (111932 effective words) took 0.3s, 423188 effective words/s
INFO - 2023-11-30 14:14:28,789: EPOCH 16: training on 191080 raw words (111863 effective words) took 0.2s, 481891 effective words/s
INFO - 2023-11-30 14:14:29,012: EPOCH 17: training on 191080 raw words (111623 effective words) took 0.2s, 505670 effective words/s
INFO - 2023-11-30 14:14:29,295: EPOCH 18: training on 191080 raw words (111865 effective words) took 0.3s, 398799 effective words/s
INFO - 2023-11-30 14:14:29,526: EPOCH 19: training on 191080 raw words (112024 effective words) took 0.2s, 489405 effective words/s
INFO - 2023-11-30 14:14:29,526: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2235845 effective words) took 5.0s, 445205 effective words/s', 'datetime': '2023-11-30T14:14:29.526794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:29,527: collecting all words and their counts
INFO - 2023-11-30 14:14:29,527: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:29,557: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:29,557: Updating model with new vocabulary
INFO - 2023-11-30 14:14:29,574: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:29.573946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:29,597: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:29,597: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:14:29,597: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111639.88312157328 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:14:29.597732', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:29,627: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:29,627: updating layer weights
INFO - 2023-11-30 14:14:29,628: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:29.628071', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:29,628: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:29,628: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:29.628349', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:29,868: EPOCH 0: training on 191080 raw words (111658 effective words) took 0.2s, 471408 effective words/s
INFO - 2023-11-30 14:14:30,096: EPOCH 1: training on 191080 raw words (111712 effective words) took 0.2s, 495577 effective words/s
INFO - 2023-11-30 14:14:30,309: EPOCH 2: training on 191080 raw words (111864 effective words) took 0.2s, 531581 effective words/s
INFO - 2023-11-30 14:14:30,518: EPOCH 3: training on 191080 raw words (111490 effective words) took 0.2s, 539807 effective words/s
INFO - 2023-11-30 14:14:30,739: EPOCH 4: training on 191080 raw words (111699 effective words) took 0.2s, 512219 effective words/s
INFO - 2023-11-30 14:14:30,961: EPOCH 5: training on 191080 raw words (111519 effective words) took 0.2s, 510043 effective words/s
INFO - 2023-11-30 14:14:31,176: EPOCH 6: training on 191080 raw words (111490 effective words) took 0.2s, 525257 effective words/s
INFO - 2023-11-30 14:14:31,399: EPOCH 7: training on 191080 raw words (111491 effective words) took 0.2s, 506060 effective words/s
INFO - 2023-11-30 14:14:31,601: EPOCH 8: training on 191080 raw words (111516 effective words) took 0.2s, 557671 effective words/s
INFO - 2023-11-30 14:14:31,803: EPOCH 9: training on 191080 raw words (111651 effective words) took 0.2s, 560120 effective words/s
INFO - 2023-11-30 14:14:32,004: EPOCH 10: training on 191080 raw words (111831 effective words) took 0.2s, 561003 effective words/s
INFO - 2023-11-30 14:14:32,215: EPOCH 11: training on 191080 raw words (111620 effective words) took 0.2s, 534492 effective words/s
INFO - 2023-11-30 14:14:32,420: EPOCH 12: training on 191080 raw words (111614 effective words) took 0.2s, 550344 effective words/s
INFO - 2023-11-30 14:14:32,650: EPOCH 13: training on 191080 raw words (111656 effective words) took 0.2s, 489952 effective words/s
INFO - 2023-11-30 14:14:32,854: EPOCH 14: training on 191080 raw words (111562 effective words) took 0.2s, 555287 effective words/s
INFO - 2023-11-30 14:14:33,060: EPOCH 15: training on 191080 raw words (111707 effective words) took 0.2s, 549208 effective words/s
INFO - 2023-11-30 14:14:33,269: EPOCH 16: training on 191080 raw words (111449 effective words) took 0.2s, 539957 effective words/s
INFO - 2023-11-30 14:14:33,495: EPOCH 17: training on 191080 raw words (111440 effective words) took 0.2s, 497476 effective words/s
INFO - 2023-11-30 14:14:33,718: EPOCH 18: training on 191080 raw words (111759 effective words) took 0.2s, 507261 effective words/s
INFO - 2023-11-30 14:14:33,924: EPOCH 19: training on 191080 raw words (111508 effective words) took 0.2s, 549046 effective words/s
INFO - 2023-11-30 14:14:33,924: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232236 effective words) took 4.3s, 519615 effective words/s', 'datetime': '2023-11-30T14:14:33.924467', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:33,924: collecting all words and their counts
INFO - 2023-11-30 14:14:33,924: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:33,950: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:33,950: Updating model with new vocabulary
INFO - 2023-11-30 14:14:33,963: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:33.963392', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:33,985: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:33,986: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:14:33,986: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111606.74149980968 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:14:33.986294', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:34,012: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:34,012: updating layer weights
INFO - 2023-11-30 14:14:34,013: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:34.013327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:34,013: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:34,013: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:34.013583', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:34,255: EPOCH 0: training on 191080 raw words (111508 effective words) took 0.2s, 467068 effective words/s
INFO - 2023-11-30 14:14:34,523: EPOCH 1: training on 191080 raw words (111500 effective words) took 0.3s, 420438 effective words/s
INFO - 2023-11-30 14:14:34,747: EPOCH 2: training on 191080 raw words (111655 effective words) took 0.2s, 504124 effective words/s
INFO - 2023-11-30 14:14:34,970: EPOCH 3: training on 191080 raw words (111448 effective words) took 0.2s, 504271 effective words/s
INFO - 2023-11-30 14:14:35,216: EPOCH 4: training on 191080 raw words (111518 effective words) took 0.2s, 458752 effective words/s
INFO - 2023-11-30 14:14:35,443: EPOCH 5: training on 191080 raw words (111527 effective words) took 0.2s, 495916 effective words/s
INFO - 2023-11-30 14:14:35,670: EPOCH 6: training on 191080 raw words (111625 effective words) took 0.2s, 495962 effective words/s
INFO - 2023-11-30 14:14:35,893: EPOCH 7: training on 191080 raw words (111606 effective words) took 0.2s, 506117 effective words/s
INFO - 2023-11-30 14:14:36,119: EPOCH 8: training on 191080 raw words (111472 effective words) took 0.2s, 499081 effective words/s
INFO - 2023-11-30 14:14:36,360: EPOCH 9: training on 191080 raw words (111504 effective words) took 0.2s, 467645 effective words/s
INFO - 2023-11-30 14:14:36,594: EPOCH 10: training on 191080 raw words (111505 effective words) took 0.2s, 482645 effective words/s
INFO - 2023-11-30 14:14:36,825: EPOCH 11: training on 191080 raw words (111500 effective words) took 0.2s, 488045 effective words/s
INFO - 2023-11-30 14:14:37,068: EPOCH 12: training on 191080 raw words (111670 effective words) took 0.2s, 462954 effective words/s
INFO - 2023-11-30 14:14:37,315: EPOCH 13: training on 191080 raw words (111628 effective words) took 0.2s, 456050 effective words/s
INFO - 2023-11-30 14:14:37,541: EPOCH 14: training on 191080 raw words (111515 effective words) took 0.2s, 499524 effective words/s
INFO - 2023-11-30 14:14:37,786: EPOCH 15: training on 191080 raw words (111604 effective words) took 0.2s, 460451 effective words/s
INFO - 2023-11-30 14:14:38,009: EPOCH 16: training on 191080 raw words (111822 effective words) took 0.2s, 506141 effective words/s
INFO - 2023-11-30 14:14:38,235: EPOCH 17: training on 191080 raw words (111595 effective words) took 0.2s, 498542 effective words/s
INFO - 2023-11-30 14:14:38,467: EPOCH 18: training on 191080 raw words (111563 effective words) took 0.2s, 485603 effective words/s
INFO - 2023-11-30 14:14:38,708: EPOCH 19: training on 191080 raw words (111474 effective words) took 0.2s, 468569 effective words/s
INFO - 2023-11-30 14:14:38,708: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231239 effective words) took 4.7s, 475280 effective words/s', 'datetime': '2023-11-30T14:14:38.708286', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:38,708: collecting all words and their counts
INFO - 2023-11-30 14:14:38,708: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:38,734: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:38,735: Updating model with new vocabulary
INFO - 2023-11-30 14:14:38,748: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:38.748557', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:38,764: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:38,764: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:38,764: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111326.2359455323 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:14:38.764847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:38,790: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:38,790: updating layer weights
INFO - 2023-11-30 14:14:38,790: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:38.790667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:38,790: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:38,790: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:38.790908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:39,013: EPOCH 0: training on 191080 raw words (111449 effective words) took 0.2s, 505187 effective words/s
INFO - 2023-11-30 14:14:39,219: EPOCH 1: training on 191080 raw words (111154 effective words) took 0.2s, 546077 effective words/s
INFO - 2023-11-30 14:14:39,457: EPOCH 2: training on 191080 raw words (111474 effective words) took 0.2s, 474264 effective words/s
INFO - 2023-11-30 14:14:39,722: EPOCH 3: training on 191080 raw words (111397 effective words) took 0.3s, 423960 effective words/s
INFO - 2023-11-30 14:14:40,062: EPOCH 4: training on 191080 raw words (111551 effective words) took 0.3s, 330791 effective words/s
INFO - 2023-11-30 14:14:40,332: EPOCH 5: training on 191080 raw words (111291 effective words) took 0.3s, 417519 effective words/s
INFO - 2023-11-30 14:14:40,600: EPOCH 6: training on 191080 raw words (111412 effective words) took 0.3s, 419295 effective words/s
INFO - 2023-11-30 14:14:40,862: EPOCH 7: training on 191080 raw words (111390 effective words) took 0.3s, 429879 effective words/s
INFO - 2023-11-30 14:14:41,129: EPOCH 8: training on 191080 raw words (111219 effective words) took 0.3s, 421256 effective words/s
INFO - 2023-11-30 14:14:41,392: EPOCH 9: training on 191080 raw words (111308 effective words) took 0.3s, 428780 effective words/s
INFO - 2023-11-30 14:14:41,651: EPOCH 10: training on 191080 raw words (111384 effective words) took 0.3s, 435469 effective words/s
INFO - 2023-11-30 14:14:41,939: EPOCH 11: training on 191080 raw words (111197 effective words) took 0.3s, 389923 effective words/s
INFO - 2023-11-30 14:14:42,213: EPOCH 12: training on 191080 raw words (111348 effective words) took 0.3s, 410725 effective words/s
INFO - 2023-11-30 14:14:42,505: EPOCH 13: training on 191080 raw words (111399 effective words) took 0.3s, 386547 effective words/s
INFO - 2023-11-30 14:14:42,819: EPOCH 14: training on 191080 raw words (111247 effective words) took 0.3s, 357016 effective words/s
INFO - 2023-11-30 14:14:43,090: EPOCH 15: training on 191080 raw words (111388 effective words) took 0.3s, 416188 effective words/s
INFO - 2023-11-30 14:14:43,361: EPOCH 16: training on 191080 raw words (111355 effective words) took 0.3s, 415855 effective words/s
INFO - 2023-11-30 14:14:43,646: EPOCH 17: training on 191080 raw words (111421 effective words) took 0.3s, 394696 effective words/s
INFO - 2023-11-30 14:14:43,938: EPOCH 18: training on 191080 raw words (111358 effective words) took 0.3s, 385009 effective words/s
INFO - 2023-11-30 14:14:44,212: EPOCH 19: training on 191080 raw words (111374 effective words) took 0.3s, 411895 effective words/s
INFO - 2023-11-30 14:14:44,212: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2227116 effective words) took 5.4s, 410799 effective words/s', 'datetime': '2023-11-30T14:14:44.212439', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:44,212: collecting all words and their counts
INFO - 2023-11-30 14:14:44,212: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:44,248: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:44,248: Updating model with new vocabulary
INFO - 2023-11-30 14:14:44,264: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:44.264340', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:44,283: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:44,284: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:44,284: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111656.07016467961 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:14:44.284238', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:44,314: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:44,314: updating layer weights
INFO - 2023-11-30 14:14:44,315: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:44.315329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:44,315: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:44,315: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:44.315646', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:44,637: EPOCH 0: training on 191080 raw words (111592 effective words) took 0.3s, 350293 effective words/s
INFO - 2023-11-30 14:14:44,956: EPOCH 1: training on 191080 raw words (111662 effective words) took 0.3s, 353714 effective words/s
INFO - 2023-11-30 14:14:45,256: EPOCH 2: training on 191080 raw words (111669 effective words) took 0.3s, 375349 effective words/s
INFO - 2023-11-30 14:14:45,558: EPOCH 3: training on 191080 raw words (111616 effective words) took 0.3s, 372583 effective words/s
INFO - 2023-11-30 14:14:45,870: EPOCH 4: training on 191080 raw words (111495 effective words) took 0.3s, 361410 effective words/s
INFO - 2023-11-30 14:14:46,196: EPOCH 5: training on 191080 raw words (111674 effective words) took 0.3s, 345377 effective words/s
INFO - 2023-11-30 14:14:46,525: EPOCH 6: training on 191080 raw words (111724 effective words) took 0.3s, 342746 effective words/s
INFO - 2023-11-30 14:14:46,949: EPOCH 7: training on 191080 raw words (111688 effective words) took 0.4s, 265251 effective words/s
INFO - 2023-11-30 14:14:47,297: EPOCH 8: training on 191080 raw words (111547 effective words) took 0.3s, 324532 effective words/s
INFO - 2023-11-30 14:14:47,622: EPOCH 9: training on 191080 raw words (111608 effective words) took 0.3s, 347246 effective words/s
INFO - 2023-11-30 14:14:47,930: EPOCH 10: training on 191080 raw words (111658 effective words) took 0.3s, 365243 effective words/s
INFO - 2023-11-30 14:14:48,251: EPOCH 11: training on 191080 raw words (111827 effective words) took 0.3s, 351428 effective words/s
INFO - 2023-11-30 14:14:48,526: EPOCH 12: training on 191080 raw words (111813 effective words) took 0.3s, 412953 effective words/s
INFO - 2023-11-30 14:14:48,785: EPOCH 13: training on 191080 raw words (111525 effective words) took 0.3s, 438182 effective words/s
INFO - 2023-11-30 14:14:49,032: EPOCH 14: training on 191080 raw words (111645 effective words) took 0.2s, 455983 effective words/s
INFO - 2023-11-30 14:14:49,273: EPOCH 15: training on 191080 raw words (111623 effective words) took 0.2s, 468052 effective words/s
INFO - 2023-11-30 14:14:49,498: EPOCH 16: training on 191080 raw words (111693 effective words) took 0.2s, 500570 effective words/s
INFO - 2023-11-30 14:14:49,742: EPOCH 17: training on 191080 raw words (111488 effective words) took 0.2s, 462148 effective words/s
INFO - 2023-11-30 14:14:49,960: EPOCH 18: training on 191080 raw words (111566 effective words) took 0.2s, 516492 effective words/s
INFO - 2023-11-30 14:14:50,187: EPOCH 19: training on 191080 raw words (111386 effective words) took 0.2s, 497042 effective words/s
INFO - 2023-11-30 14:14:50,187: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232499 effective words) took 5.9s, 380198 effective words/s', 'datetime': '2023-11-30T14:14:50.187750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:50,187: collecting all words and their counts
INFO - 2023-11-30 14:14:50,188: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:50,215: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:50,215: Updating model with new vocabulary
INFO - 2023-11-30 14:14:50,226: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:50.226623', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:50,241: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:50,241: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:50,241: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111806.67371931425 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:50.241628', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:50,264: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:50,264: updating layer weights
INFO - 2023-11-30 14:14:50,264: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:50.264872', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:50,265: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:50,265: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:50.265086', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:50,500: EPOCH 0: training on 191080 raw words (111655 effective words) took 0.2s, 478738 effective words/s
INFO - 2023-11-30 14:14:50,704: EPOCH 1: training on 191080 raw words (111674 effective words) took 0.2s, 552917 effective words/s
INFO - 2023-11-30 14:14:50,907: EPOCH 2: training on 191080 raw words (111911 effective words) took 0.2s, 559286 effective words/s
INFO - 2023-11-30 14:14:51,116: EPOCH 3: training on 191080 raw words (112027 effective words) took 0.2s, 539717 effective words/s
INFO - 2023-11-30 14:14:51,336: EPOCH 4: training on 191080 raw words (111936 effective words) took 0.2s, 514991 effective words/s
INFO - 2023-11-30 14:14:51,554: EPOCH 5: training on 191080 raw words (111678 effective words) took 0.2s, 519454 effective words/s
INFO - 2023-11-30 14:14:51,795: EPOCH 6: training on 191080 raw words (111763 effective words) took 0.2s, 468104 effective words/s
INFO - 2023-11-30 14:14:51,999: EPOCH 7: training on 191080 raw words (111887 effective words) took 0.2s, 552827 effective words/s
INFO - 2023-11-30 14:14:52,213: EPOCH 8: training on 191080 raw words (111818 effective words) took 0.2s, 528614 effective words/s
INFO - 2023-11-30 14:14:52,420: EPOCH 9: training on 191080 raw words (111904 effective words) took 0.2s, 546614 effective words/s
INFO - 2023-11-30 14:14:52,626: EPOCH 10: training on 191080 raw words (111988 effective words) took 0.2s, 548759 effective words/s
INFO - 2023-11-30 14:14:52,837: EPOCH 11: training on 191080 raw words (111780 effective words) took 0.2s, 535887 effective words/s
INFO - 2023-11-30 14:14:53,045: EPOCH 12: training on 191080 raw words (111677 effective words) took 0.2s, 544301 effective words/s
INFO - 2023-11-30 14:14:53,258: EPOCH 13: training on 191080 raw words (111817 effective words) took 0.2s, 530303 effective words/s
INFO - 2023-11-30 14:14:53,464: EPOCH 14: training on 191080 raw words (111826 effective words) took 0.2s, 548504 effective words/s
INFO - 2023-11-30 14:14:53,670: EPOCH 15: training on 191080 raw words (111855 effective words) took 0.2s, 550449 effective words/s
INFO - 2023-11-30 14:14:53,872: EPOCH 16: training on 191080 raw words (111996 effective words) took 0.2s, 559569 effective words/s
INFO - 2023-11-30 14:14:54,082: EPOCH 17: training on 191080 raw words (111813 effective words) took 0.2s, 539153 effective words/s
INFO - 2023-11-30 14:14:54,289: EPOCH 18: training on 191080 raw words (111636 effective words) took 0.2s, 545935 effective words/s
INFO - 2023-11-30 14:14:54,563: EPOCH 19: training on 191080 raw words (111798 effective words) took 0.3s, 411818 effective words/s
INFO - 2023-11-30 14:14:54,563: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236439 effective words) took 4.3s, 520289 effective words/s', 'datetime': '2023-11-30T14:14:54.563657', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:54,563: collecting all words and their counts
INFO - 2023-11-30 14:14:54,564: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:54,590: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:54,590: Updating model with new vocabulary
INFO - 2023-11-30 14:14:54,602: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:54.602964', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:54,617: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:54,617: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:14:54,617: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111798.86857375468 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:54.617795', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:54,641: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:54,641: updating layer weights
INFO - 2023-11-30 14:14:54,641: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:54.641900', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:54,642: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:54,642: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:54.642102', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:54,867: EPOCH 0: training on 191080 raw words (111882 effective words) took 0.2s, 502377 effective words/s
INFO - 2023-11-30 14:14:55,150: EPOCH 1: training on 191080 raw words (111814 effective words) took 0.3s, 397256 effective words/s
INFO - 2023-11-30 14:14:55,422: EPOCH 2: training on 191080 raw words (111741 effective words) took 0.3s, 416996 effective words/s
INFO - 2023-11-30 14:14:55,684: EPOCH 3: training on 191080 raw words (111751 effective words) took 0.3s, 431205 effective words/s
INFO - 2023-11-30 14:14:55,915: EPOCH 4: training on 191080 raw words (111447 effective words) took 0.2s, 488350 effective words/s
INFO - 2023-11-30 14:14:56,164: EPOCH 5: training on 191080 raw words (111740 effective words) took 0.2s, 452995 effective words/s
INFO - 2023-11-30 14:14:56,405: EPOCH 6: training on 191080 raw words (111667 effective words) took 0.2s, 470214 effective words/s
INFO - 2023-11-30 14:14:56,649: EPOCH 7: training on 191080 raw words (111816 effective words) took 0.2s, 462241 effective words/s
INFO - 2023-11-30 14:14:56,879: EPOCH 8: training on 191080 raw words (111790 effective words) took 0.2s, 491632 effective words/s
INFO - 2023-11-30 14:14:57,124: EPOCH 9: training on 191080 raw words (111925 effective words) took 0.2s, 462122 effective words/s
INFO - 2023-11-30 14:14:57,349: EPOCH 10: training on 191080 raw words (112040 effective words) took 0.2s, 502494 effective words/s
INFO - 2023-11-30 14:14:57,586: EPOCH 11: training on 191080 raw words (111671 effective words) took 0.2s, 477009 effective words/s
INFO - 2023-11-30 14:14:57,808: EPOCH 12: training on 191080 raw words (112114 effective words) took 0.2s, 510144 effective words/s
INFO - 2023-11-30 14:14:58,029: EPOCH 13: training on 191080 raw words (111809 effective words) took 0.2s, 509671 effective words/s
INFO - 2023-11-30 14:14:58,251: EPOCH 14: training on 191080 raw words (111803 effective words) took 0.2s, 511165 effective words/s
INFO - 2023-11-30 14:14:58,474: EPOCH 15: training on 191080 raw words (111990 effective words) took 0.2s, 506242 effective words/s
INFO - 2023-11-30 14:14:58,718: EPOCH 16: training on 191080 raw words (111766 effective words) took 0.2s, 463273 effective words/s
INFO - 2023-11-30 14:14:58,938: EPOCH 17: training on 191080 raw words (111616 effective words) took 0.2s, 511854 effective words/s
INFO - 2023-11-30 14:14:59,159: EPOCH 18: training on 191080 raw words (111809 effective words) took 0.2s, 511170 effective words/s
INFO - 2023-11-30 14:14:59,384: EPOCH 19: training on 191080 raw words (111743 effective words) took 0.2s, 501350 effective words/s
INFO - 2023-11-30 14:14:59,385: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2235934 effective words) took 4.7s, 471425 effective words/s', 'datetime': '2023-11-30T14:14:59.385124', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:59,385: collecting all words and their counts
INFO - 2023-11-30 14:14:59,385: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:14:59,417: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:14:59,417: Updating model with new vocabulary
INFO - 2023-11-30 14:14:59,429: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:14:59.429785', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:59,444: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:14:59,444: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:14:59,444: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111709.331142829 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:14:59.444202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:14:59,467: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:14:59,467: updating layer weights
INFO - 2023-11-30 14:14:59,467: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:14:59.467533', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:14:59,467: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:14:59,467: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:14:59.467767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:14:59,730: EPOCH 0: training on 191080 raw words (111664 effective words) took 0.3s, 428549 effective words/s
INFO - 2023-11-30 14:14:59,934: EPOCH 1: training on 191080 raw words (111653 effective words) took 0.2s, 552571 effective words/s
INFO - 2023-11-30 14:15:00,143: EPOCH 2: training on 191080 raw words (111982 effective words) took 0.2s, 543620 effective words/s
INFO - 2023-11-30 14:15:00,346: EPOCH 3: training on 191080 raw words (111622 effective words) took 0.2s, 555240 effective words/s
INFO - 2023-11-30 14:15:00,550: EPOCH 4: training on 191080 raw words (111729 effective words) took 0.2s, 553131 effective words/s
INFO - 2023-11-30 14:15:00,752: EPOCH 5: training on 191080 raw words (111650 effective words) took 0.2s, 560092 effective words/s
INFO - 2023-11-30 14:15:00,959: EPOCH 6: training on 191080 raw words (111621 effective words) took 0.2s, 543945 effective words/s
INFO - 2023-11-30 14:15:01,167: EPOCH 7: training on 191080 raw words (111660 effective words) took 0.2s, 544021 effective words/s
INFO - 2023-11-30 14:15:01,376: EPOCH 8: training on 191080 raw words (111564 effective words) took 0.2s, 539225 effective words/s
INFO - 2023-11-30 14:15:01,590: EPOCH 9: training on 191080 raw words (111824 effective words) took 0.2s, 528241 effective words/s
INFO - 2023-11-30 14:15:01,859: EPOCH 10: training on 191080 raw words (111662 effective words) took 0.3s, 418698 effective words/s
INFO - 2023-11-30 14:15:02,086: EPOCH 11: training on 191080 raw words (111710 effective words) took 0.2s, 499449 effective words/s
INFO - 2023-11-30 14:15:02,293: EPOCH 12: training on 191080 raw words (111741 effective words) took 0.2s, 544745 effective words/s
INFO - 2023-11-30 14:15:02,496: EPOCH 13: training on 191080 raw words (111665 effective words) took 0.2s, 586431 effective words/s
INFO - 2023-11-30 14:15:02,701: EPOCH 14: training on 191080 raw words (111746 effective words) took 0.2s, 553195 effective words/s
INFO - 2023-11-30 14:15:02,904: EPOCH 15: training on 191080 raw words (111838 effective words) took 0.2s, 554910 effective words/s
INFO - 2023-11-30 14:15:03,112: EPOCH 16: training on 191080 raw words (111756 effective words) took 0.2s, 543344 effective words/s
INFO - 2023-11-30 14:15:03,313: EPOCH 17: training on 191080 raw words (111734 effective words) took 0.2s, 610458 effective words/s
INFO - 2023-11-30 14:15:03,524: EPOCH 18: training on 191080 raw words (111769 effective words) took 0.2s, 536568 effective words/s
INFO - 2023-11-30 14:15:03,785: EPOCH 19: training on 191080 raw words (111597 effective words) took 0.3s, 431685 effective words/s
INFO - 2023-11-30 14:15:03,786: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234187 effective words) took 4.3s, 517378 effective words/s', 'datetime': '2023-11-30T14:15:03.786180', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:03,786: collecting all words and their counts
INFO - 2023-11-30 14:15:03,786: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:03,820: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:03,820: Updating model with new vocabulary
INFO - 2023-11-30 14:15:03,835: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:03.835444', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:03,854: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:03,854: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:03,854: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111717.77472282028 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:15:03.854682', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:03,884: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:03,884: updating layer weights
INFO - 2023-11-30 14:15:03,884: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:03.884607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:03,884: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:03,884: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:03.884834', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:04,204: EPOCH 0: training on 191080 raw words (111686 effective words) took 0.3s, 352605 effective words/s
INFO - 2023-11-30 14:15:04,500: EPOCH 1: training on 191080 raw words (111705 effective words) took 0.3s, 381160 effective words/s
INFO - 2023-11-30 14:15:04,788: EPOCH 2: training on 191080 raw words (111695 effective words) took 0.3s, 391695 effective words/s
INFO - 2023-11-30 14:15:05,075: EPOCH 3: training on 191080 raw words (111642 effective words) took 0.3s, 393330 effective words/s
INFO - 2023-11-30 14:15:05,411: EPOCH 4: training on 191080 raw words (111534 effective words) took 0.3s, 334153 effective words/s
INFO - 2023-11-30 14:15:05,705: EPOCH 5: training on 191080 raw words (111670 effective words) took 0.3s, 384197 effective words/s
INFO - 2023-11-30 14:15:06,021: EPOCH 6: training on 191080 raw words (111883 effective words) took 0.3s, 356701 effective words/s
INFO - 2023-11-30 14:15:06,312: EPOCH 7: training on 191080 raw words (111767 effective words) took 0.3s, 387907 effective words/s
INFO - 2023-11-30 14:15:06,601: EPOCH 8: training on 191080 raw words (111712 effective words) took 0.3s, 389468 effective words/s
INFO - 2023-11-30 14:15:06,904: EPOCH 9: training on 191080 raw words (111604 effective words) took 0.3s, 371861 effective words/s
INFO - 2023-11-30 14:15:07,206: EPOCH 10: training on 191080 raw words (111648 effective words) took 0.3s, 373225 effective words/s
INFO - 2023-11-30 14:15:07,503: EPOCH 11: training on 191080 raw words (111815 effective words) took 0.3s, 381238 effective words/s
INFO - 2023-11-30 14:15:07,807: EPOCH 12: training on 191080 raw words (111756 effective words) took 0.3s, 377218 effective words/s
INFO - 2023-11-30 14:15:08,102: EPOCH 13: training on 191080 raw words (111697 effective words) took 0.3s, 382194 effective words/s
INFO - 2023-11-30 14:15:08,393: EPOCH 14: training on 191080 raw words (111792 effective words) took 0.3s, 417104 effective words/s
INFO - 2023-11-30 14:15:08,688: EPOCH 15: training on 191080 raw words (111736 effective words) took 0.3s, 382004 effective words/s
INFO - 2023-11-30 14:15:08,989: EPOCH 16: training on 191080 raw words (111681 effective words) took 0.3s, 374962 effective words/s
INFO - 2023-11-30 14:15:09,285: EPOCH 17: training on 191080 raw words (111559 effective words) took 0.3s, 380208 effective words/s
INFO - 2023-11-30 14:15:09,607: EPOCH 18: training on 191080 raw words (111658 effective words) took 0.3s, 350252 effective words/s
INFO - 2023-11-30 14:15:09,909: EPOCH 19: training on 191080 raw words (111761 effective words) took 0.3s, 373103 effective words/s
INFO - 2023-11-30 14:15:09,910: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234001 effective words) took 6.0s, 370777 effective words/s', 'datetime': '2023-11-30T14:15:09.910204', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:09,910: collecting all words and their counts
INFO - 2023-11-30 14:15:09,910: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:09,946: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:09,947: Updating model with new vocabulary
INFO - 2023-11-30 14:15:09,964: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:09.964895', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:09,987: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:09,987: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:15:09,987: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111520.9646167909 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:15:09.987908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:10,026: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:10,027: updating layer weights
INFO - 2023-11-30 14:15:10,027: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:10.027633', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:10,027: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:10,028: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:10.028016', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:10,311: EPOCH 0: training on 191080 raw words (111454 effective words) took 0.3s, 396834 effective words/s
INFO - 2023-11-30 14:15:10,608: EPOCH 1: training on 191080 raw words (111451 effective words) took 0.3s, 378790 effective words/s
INFO - 2023-11-30 14:15:10,886: EPOCH 2: training on 191080 raw words (111583 effective words) took 0.3s, 406780 effective words/s
INFO - 2023-11-30 14:15:11,168: EPOCH 3: training on 191080 raw words (111454 effective words) took 0.3s, 399746 effective words/s
INFO - 2023-11-30 14:15:11,451: EPOCH 4: training on 191080 raw words (111559 effective words) took 0.3s, 398230 effective words/s
INFO - 2023-11-30 14:15:11,732: EPOCH 5: training on 191080 raw words (111545 effective words) took 0.3s, 400486 effective words/s
INFO - 2023-11-30 14:15:12,015: EPOCH 6: training on 191080 raw words (111445 effective words) took 0.3s, 398843 effective words/s
INFO - 2023-11-30 14:15:12,292: EPOCH 7: training on 191080 raw words (111454 effective words) took 0.3s, 406078 effective words/s
INFO - 2023-11-30 14:15:12,553: EPOCH 8: training on 191080 raw words (111240 effective words) took 0.3s, 431926 effective words/s
INFO - 2023-11-30 14:15:12,751: EPOCH 9: training on 191080 raw words (111601 effective words) took 0.2s, 568878 effective words/s
INFO - 2023-11-30 14:15:12,957: EPOCH 10: training on 191080 raw words (111712 effective words) took 0.2s, 550119 effective words/s
INFO - 2023-11-30 14:15:13,161: EPOCH 11: training on 191080 raw words (111431 effective words) took 0.2s, 552246 effective words/s
INFO - 2023-11-30 14:15:13,363: EPOCH 12: training on 191080 raw words (111307 effective words) took 0.2s, 557536 effective words/s
INFO - 2023-11-30 14:15:13,567: EPOCH 13: training on 191080 raw words (111490 effective words) took 0.2s, 551963 effective words/s
INFO - 2023-11-30 14:15:13,773: EPOCH 14: training on 191080 raw words (111436 effective words) took 0.2s, 547166 effective words/s
INFO - 2023-11-30 14:15:13,976: EPOCH 15: training on 191080 raw words (111291 effective words) took 0.2s, 557282 effective words/s
INFO - 2023-11-30 14:15:14,179: EPOCH 16: training on 191080 raw words (111637 effective words) took 0.2s, 554703 effective words/s
INFO - 2023-11-30 14:15:14,399: EPOCH 17: training on 191080 raw words (111532 effective words) took 0.2s, 512287 effective words/s
INFO - 2023-11-30 14:15:14,626: EPOCH 18: training on 191080 raw words (111625 effective words) took 0.2s, 498709 effective words/s
INFO - 2023-11-30 14:15:14,841: EPOCH 19: training on 191080 raw words (111770 effective words) took 0.2s, 524616 effective words/s
INFO - 2023-11-30 14:15:14,842: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230017 effective words) took 4.8s, 463230 effective words/s', 'datetime': '2023-11-30T14:15:14.842202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:14,842: collecting all words and their counts
INFO - 2023-11-30 14:15:14,842: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:14,868: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:14,868: Updating model with new vocabulary
INFO - 2023-11-30 14:15:14,880: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:14.880326', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:14,894: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:14,894: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:15:14,894: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111447.53272527829 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:15:14.894960', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:14,917: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:14,917: updating layer weights
INFO - 2023-11-30 14:15:14,917: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:14.917835', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:14,917: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:14,918: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:14.918037', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:15,148: EPOCH 0: training on 191080 raw words (111606 effective words) took 0.2s, 488067 effective words/s
INFO - 2023-11-30 14:15:15,389: EPOCH 1: training on 191080 raw words (111635 effective words) took 0.2s, 468651 effective words/s
INFO - 2023-11-30 14:15:15,615: EPOCH 2: training on 191080 raw words (111409 effective words) took 0.2s, 499140 effective words/s
INFO - 2023-11-30 14:15:15,838: EPOCH 3: training on 191080 raw words (111355 effective words) took 0.2s, 504657 effective words/s
INFO - 2023-11-30 14:15:16,066: EPOCH 4: training on 191080 raw words (111552 effective words) took 0.2s, 493717 effective words/s
INFO - 2023-11-30 14:15:16,290: EPOCH 5: training on 191080 raw words (111587 effective words) took 0.2s, 504377 effective words/s
INFO - 2023-11-30 14:15:16,513: EPOCH 6: training on 191080 raw words (111389 effective words) took 0.2s, 504323 effective words/s
INFO - 2023-11-30 14:15:16,740: EPOCH 7: training on 191080 raw words (111457 effective words) took 0.2s, 495309 effective words/s
INFO - 2023-11-30 14:15:16,965: EPOCH 8: training on 191080 raw words (111332 effective words) took 0.2s, 501191 effective words/s
INFO - 2023-11-30 14:15:17,190: EPOCH 9: training on 191080 raw words (111541 effective words) took 0.2s, 501965 effective words/s
INFO - 2023-11-30 14:15:17,413: EPOCH 10: training on 191080 raw words (111492 effective words) took 0.2s, 505622 effective words/s
INFO - 2023-11-30 14:15:17,632: EPOCH 11: training on 191080 raw words (111673 effective words) took 0.2s, 514054 effective words/s
INFO - 2023-11-30 14:15:17,854: EPOCH 12: training on 191080 raw words (111357 effective words) took 0.2s, 508246 effective words/s
INFO - 2023-11-30 14:15:18,080: EPOCH 13: training on 191080 raw words (111430 effective words) took 0.2s, 498166 effective words/s
INFO - 2023-11-30 14:15:18,307: EPOCH 14: training on 191080 raw words (111335 effective words) took 0.2s, 494457 effective words/s
INFO - 2023-11-30 14:15:18,526: EPOCH 15: training on 191080 raw words (111265 effective words) took 0.2s, 514670 effective words/s
INFO - 2023-11-30 14:15:18,747: EPOCH 16: training on 191080 raw words (111346 effective words) took 0.2s, 509011 effective words/s
INFO - 2023-11-30 14:15:18,965: EPOCH 17: training on 191080 raw words (111412 effective words) took 0.2s, 515455 effective words/s
INFO - 2023-11-30 14:15:19,184: EPOCH 18: training on 191080 raw words (111323 effective words) took 0.2s, 514724 effective words/s
INFO - 2023-11-30 14:15:19,403: EPOCH 19: training on 191080 raw words (111468 effective words) took 0.2s, 512470 effective words/s
INFO - 2023-11-30 14:15:19,404: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2228964 effective words) took 4.5s, 496886 effective words/s', 'datetime': '2023-11-30T14:15:19.404014', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:19,404: collecting all words and their counts
INFO - 2023-11-30 14:15:19,404: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:19,431: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:19,431: Updating model with new vocabulary
INFO - 2023-11-30 14:15:19,442: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:19.442686', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:19,456: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:19,456: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:15:19,456: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111896.5238347349 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:15:19.456880', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:19,479: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:19,479: updating layer weights
INFO - 2023-11-30 14:15:19,479: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:19.479684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:19,479: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:19,479: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:19.479957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:19,707: EPOCH 0: training on 191080 raw words (111911 effective words) took 0.2s, 496813 effective words/s
INFO - 2023-11-30 14:15:19,911: EPOCH 1: training on 191080 raw words (112114 effective words) took 0.2s, 557123 effective words/s
INFO - 2023-11-30 14:15:20,120: EPOCH 2: training on 191080 raw words (112066 effective words) took 0.2s, 541082 effective words/s
INFO - 2023-11-30 14:15:20,329: EPOCH 3: training on 191080 raw words (112030 effective words) took 0.2s, 541108 effective words/s
INFO - 2023-11-30 14:15:20,537: EPOCH 4: training on 191080 raw words (111754 effective words) took 0.2s, 545020 effective words/s
INFO - 2023-11-30 14:15:20,742: EPOCH 5: training on 191080 raw words (111858 effective words) took 0.2s, 552117 effective words/s
INFO - 2023-11-30 14:15:20,947: EPOCH 6: training on 191080 raw words (112044 effective words) took 0.2s, 551356 effective words/s
INFO - 2023-11-30 14:15:21,154: EPOCH 7: training on 191080 raw words (111877 effective words) took 0.2s, 546039 effective words/s
INFO - 2023-11-30 14:15:21,359: EPOCH 8: training on 191080 raw words (112012 effective words) took 0.2s, 554015 effective words/s
INFO - 2023-11-30 14:15:21,564: EPOCH 9: training on 191080 raw words (111913 effective words) took 0.2s, 552978 effective words/s
INFO - 2023-11-30 14:15:21,770: EPOCH 10: training on 191080 raw words (112173 effective words) took 0.2s, 551493 effective words/s
INFO - 2023-11-30 14:15:21,977: EPOCH 11: training on 191080 raw words (111867 effective words) took 0.2s, 548875 effective words/s
INFO - 2023-11-30 14:15:22,185: EPOCH 12: training on 191080 raw words (111821 effective words) took 0.2s, 544096 effective words/s
INFO - 2023-11-30 14:15:22,392: EPOCH 13: training on 191080 raw words (112090 effective words) took 0.2s, 547684 effective words/s
INFO - 2023-11-30 14:15:22,596: EPOCH 14: training on 191080 raw words (111769 effective words) took 0.2s, 552939 effective words/s
INFO - 2023-11-30 14:15:22,797: EPOCH 15: training on 191080 raw words (112077 effective words) took 0.2s, 565906 effective words/s
INFO - 2023-11-30 14:15:22,997: EPOCH 16: training on 191080 raw words (111971 effective words) took 0.2s, 564549 effective words/s
INFO - 2023-11-30 14:15:23,204: EPOCH 17: training on 191080 raw words (111736 effective words) took 0.2s, 547239 effective words/s
INFO - 2023-11-30 14:15:23,406: EPOCH 18: training on 191080 raw words (111669 effective words) took 0.2s, 556788 effective words/s
INFO - 2023-11-30 14:15:23,615: EPOCH 19: training on 191080 raw words (112031 effective words) took 0.2s, 544415 effective words/s
INFO - 2023-11-30 14:15:23,615: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2238783 effective words) took 4.1s, 541399 effective words/s', 'datetime': '2023-11-30T14:15:23.615255', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:23,615: collecting all words and their counts
INFO - 2023-11-30 14:15:23,615: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:23,641: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:23,641: Updating model with new vocabulary
INFO - 2023-11-30 14:15:23,652: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:23.652359', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:23,666: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:23,666: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:23,666: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111910.12914479595 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:15:23.666828', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:23,688: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:23,688: updating layer weights
INFO - 2023-11-30 14:15:23,689: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:23.689117', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:23,689: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:23,689: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:23.689334', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:23,911: EPOCH 0: training on 191080 raw words (111974 effective words) took 0.2s, 509733 effective words/s
INFO - 2023-11-30 14:15:24,133: EPOCH 1: training on 191080 raw words (111698 effective words) took 0.2s, 507835 effective words/s
INFO - 2023-11-30 14:15:24,357: EPOCH 2: training on 191080 raw words (111833 effective words) took 0.2s, 502864 effective words/s
INFO - 2023-11-30 14:15:24,586: EPOCH 3: training on 191080 raw words (111934 effective words) took 0.2s, 495660 effective words/s
INFO - 2023-11-30 14:15:24,811: EPOCH 4: training on 191080 raw words (111798 effective words) took 0.2s, 501161 effective words/s
INFO - 2023-11-30 14:15:25,034: EPOCH 5: training on 191080 raw words (111775 effective words) took 0.2s, 507213 effective words/s
INFO - 2023-11-30 14:15:25,259: EPOCH 6: training on 191080 raw words (111817 effective words) took 0.2s, 500903 effective words/s
INFO - 2023-11-30 14:15:25,484: EPOCH 7: training on 191080 raw words (111884 effective words) took 0.2s, 502968 effective words/s
INFO - 2023-11-30 14:15:25,709: EPOCH 8: training on 191080 raw words (111904 effective words) took 0.2s, 502754 effective words/s
INFO - 2023-11-30 14:15:25,935: EPOCH 9: training on 191080 raw words (111908 effective words) took 0.2s, 499704 effective words/s
INFO - 2023-11-30 14:15:26,159: EPOCH 10: training on 191080 raw words (111809 effective words) took 0.2s, 505180 effective words/s
INFO - 2023-11-30 14:15:26,383: EPOCH 11: training on 191080 raw words (111830 effective words) took 0.2s, 504481 effective words/s
INFO - 2023-11-30 14:15:26,602: EPOCH 12: training on 191080 raw words (111898 effective words) took 0.2s, 516415 effective words/s
INFO - 2023-11-30 14:15:26,824: EPOCH 13: training on 191080 raw words (112044 effective words) took 0.2s, 509722 effective words/s
INFO - 2023-11-30 14:15:27,044: EPOCH 14: training on 191080 raw words (111688 effective words) took 0.2s, 510807 effective words/s
INFO - 2023-11-30 14:15:27,270: EPOCH 15: training on 191080 raw words (111959 effective words) took 0.2s, 501899 effective words/s
INFO - 2023-11-30 14:15:27,495: EPOCH 16: training on 191080 raw words (111754 effective words) took 0.2s, 500357 effective words/s
INFO - 2023-11-30 14:15:27,743: EPOCH 17: training on 191080 raw words (112083 effective words) took 0.2s, 457398 effective words/s
INFO - 2023-11-30 14:15:28,044: EPOCH 18: training on 191080 raw words (111768 effective words) took 0.3s, 374904 effective words/s
INFO - 2023-11-30 14:15:28,352: EPOCH 19: training on 191080 raw words (111673 effective words) took 0.3s, 366011 effective words/s
INFO - 2023-11-30 14:15:28,352: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2237031 effective words) took 4.7s, 479729 effective words/s', 'datetime': '2023-11-30T14:15:28.352572', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:28,352: collecting all words and their counts
INFO - 2023-11-30 14:15:28,352: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:28,388: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:28,388: Updating model with new vocabulary
INFO - 2023-11-30 14:15:28,404: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:28.404670', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:28,424: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:28,424: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:28,424: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111676.0476059319 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:15:28.424888', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:28,456: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:28,456: updating layer weights
INFO - 2023-11-30 14:15:28,456: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:28.456921', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:28,457: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:28,457: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:28.457201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:28,736: EPOCH 0: training on 191080 raw words (111711 effective words) took 0.3s, 403797 effective words/s
INFO - 2023-11-30 14:15:29,014: EPOCH 1: training on 191080 raw words (111687 effective words) took 0.3s, 406189 effective words/s
INFO - 2023-11-30 14:15:29,293: EPOCH 2: training on 191080 raw words (111682 effective words) took 0.3s, 405261 effective words/s
INFO - 2023-11-30 14:15:29,571: EPOCH 3: training on 191080 raw words (111551 effective words) took 0.3s, 404787 effective words/s
INFO - 2023-11-30 14:15:29,905: EPOCH 4: training on 191080 raw words (111673 effective words) took 0.3s, 337569 effective words/s
INFO - 2023-11-30 14:15:30,185: EPOCH 5: training on 191080 raw words (111755 effective words) took 0.3s, 404006 effective words/s
INFO - 2023-11-30 14:15:30,496: EPOCH 6: training on 191080 raw words (111701 effective words) took 0.3s, 362156 effective words/s
INFO - 2023-11-30 14:15:30,817: EPOCH 7: training on 191080 raw words (111745 effective words) took 0.3s, 351364 effective words/s
INFO - 2023-11-30 14:15:31,118: EPOCH 8: training on 191080 raw words (111997 effective words) took 0.3s, 375766 effective words/s
INFO - 2023-11-30 14:15:31,420: EPOCH 9: training on 191080 raw words (111931 effective words) took 0.3s, 374864 effective words/s
INFO - 2023-11-30 14:15:31,756: EPOCH 10: training on 191080 raw words (111507 effective words) took 0.3s, 334957 effective words/s
INFO - 2023-11-30 14:15:32,117: EPOCH 11: training on 191080 raw words (111498 effective words) took 0.4s, 312155 effective words/s
INFO - 2023-11-30 14:15:32,641: EPOCH 12: training on 191080 raw words (111692 effective words) took 0.5s, 214774 effective words/s
INFO - 2023-11-30 14:15:33,065: EPOCH 13: training on 191080 raw words (111760 effective words) took 0.4s, 265821 effective words/s
INFO - 2023-11-30 14:15:33,427: EPOCH 14: training on 191080 raw words (111703 effective words) took 0.4s, 311158 effective words/s
INFO - 2023-11-30 14:15:33,775: EPOCH 15: training on 191080 raw words (111625 effective words) took 0.3s, 324857 effective words/s
INFO - 2023-11-30 14:15:34,125: EPOCH 16: training on 191080 raw words (111562 effective words) took 0.3s, 321577 effective words/s
INFO - 2023-11-30 14:15:34,464: EPOCH 17: training on 191080 raw words (111730 effective words) took 0.3s, 333072 effective words/s
INFO - 2023-11-30 14:15:34,864: EPOCH 18: training on 191080 raw words (111829 effective words) took 0.4s, 282495 effective words/s
INFO - 2023-11-30 14:15:35,256: EPOCH 19: training on 191080 raw words (111386 effective words) took 0.4s, 286902 effective words/s
INFO - 2023-11-30 14:15:35,257: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233725 effective words) took 6.8s, 328502 effective words/s', 'datetime': '2023-11-30T14:15:35.257067', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:35,257: collecting all words and their counts
INFO - 2023-11-30 14:15:35,257: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:35,303: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:35,303: Updating model with new vocabulary
INFO - 2023-11-30 14:15:35,326: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:35.326678', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:35,360: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:35,360: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:35,360: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111803.65141230798 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:15:35.360832', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:35,406: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:35,407: updating layer weights
INFO - 2023-11-30 14:15:35,407: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:35.407807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:35,408: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:35,408: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:35.408539', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:35,793: EPOCH 0: training on 191080 raw words (111727 effective words) took 0.4s, 293030 effective words/s
INFO - 2023-11-30 14:15:36,176: EPOCH 1: training on 191080 raw words (112064 effective words) took 0.4s, 295653 effective words/s
INFO - 2023-11-30 14:15:36,540: EPOCH 2: training on 191080 raw words (111842 effective words) took 0.4s, 310092 effective words/s
INFO - 2023-11-30 14:15:36,821: EPOCH 3: training on 191080 raw words (111747 effective words) took 0.3s, 402424 effective words/s
INFO - 2023-11-30 14:15:37,047: EPOCH 4: training on 191080 raw words (111976 effective words) took 0.2s, 500999 effective words/s
INFO - 2023-11-30 14:15:37,275: EPOCH 5: training on 191080 raw words (111762 effective words) took 0.2s, 496374 effective words/s
INFO - 2023-11-30 14:15:37,503: EPOCH 6: training on 191080 raw words (111625 effective words) took 0.2s, 495570 effective words/s
INFO - 2023-11-30 14:15:37,752: EPOCH 7: training on 191080 raw words (111935 effective words) took 0.2s, 453854 effective words/s
INFO - 2023-11-30 14:15:37,976: EPOCH 8: training on 191080 raw words (111908 effective words) took 0.2s, 504047 effective words/s
INFO - 2023-11-30 14:15:38,203: EPOCH 9: training on 191080 raw words (111760 effective words) took 0.2s, 496924 effective words/s
INFO - 2023-11-30 14:15:38,443: EPOCH 10: training on 191080 raw words (111850 effective words) took 0.2s, 471401 effective words/s
INFO - 2023-11-30 14:15:38,680: EPOCH 11: training on 191080 raw words (111895 effective words) took 0.2s, 475488 effective words/s
INFO - 2023-11-30 14:15:38,900: EPOCH 12: training on 191080 raw words (111692 effective words) took 0.2s, 513273 effective words/s
INFO - 2023-11-30 14:15:39,121: EPOCH 13: training on 191080 raw words (111847 effective words) took 0.2s, 512578 effective words/s
INFO - 2023-11-30 14:15:39,346: EPOCH 14: training on 191080 raw words (111986 effective words) took 0.2s, 503830 effective words/s
INFO - 2023-11-30 14:15:39,568: EPOCH 15: training on 191080 raw words (111723 effective words) took 0.2s, 508509 effective words/s
INFO - 2023-11-30 14:15:39,797: EPOCH 16: training on 191080 raw words (111692 effective words) took 0.2s, 491733 effective words/s
INFO - 2023-11-30 14:15:40,046: EPOCH 17: training on 191080 raw words (111699 effective words) took 0.2s, 452197 effective words/s
INFO - 2023-11-30 14:15:40,268: EPOCH 18: training on 191080 raw words (111909 effective words) took 0.2s, 510673 effective words/s
INFO - 2023-11-30 14:15:40,487: EPOCH 19: training on 191080 raw words (111953 effective words) took 0.2s, 515499 effective words/s
INFO - 2023-11-30 14:15:40,488: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236592 effective words) took 5.1s, 440342 effective words/s', 'datetime': '2023-11-30T14:15:40.487939', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:40,488: collecting all words and their counts
INFO - 2023-11-30 14:15:40,488: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:40,514: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:40,514: Updating model with new vocabulary
INFO - 2023-11-30 14:15:40,525: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:40.525514', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:40,540: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:40,540: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:40,540: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111382.43524425989 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:15:40.540512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:40,562: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:40,562: updating layer weights
INFO - 2023-11-30 14:15:40,563: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:40.563236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:40,563: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:40,563: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:40.563438', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:40,765: EPOCH 0: training on 191080 raw words (111361 effective words) took 0.2s, 557111 effective words/s
INFO - 2023-11-30 14:15:40,975: EPOCH 1: training on 191080 raw words (111230 effective words) took 0.2s, 536586 effective words/s
INFO - 2023-11-30 14:15:41,181: EPOCH 2: training on 191080 raw words (111537 effective words) took 0.2s, 547665 effective words/s
INFO - 2023-11-30 14:15:41,389: EPOCH 3: training on 191080 raw words (111135 effective words) took 0.2s, 540033 effective words/s
INFO - 2023-11-30 14:15:41,592: EPOCH 4: training on 191080 raw words (111373 effective words) took 0.2s, 554733 effective words/s
INFO - 2023-11-30 14:15:41,797: EPOCH 5: training on 191080 raw words (111333 effective words) took 0.2s, 549195 effective words/s
INFO - 2023-11-30 14:15:42,001: EPOCH 6: training on 191080 raw words (111432 effective words) took 0.2s, 553718 effective words/s
INFO - 2023-11-30 14:15:42,208: EPOCH 7: training on 191080 raw words (111447 effective words) took 0.2s, 547680 effective words/s
INFO - 2023-11-30 14:15:42,415: EPOCH 8: training on 191080 raw words (111536 effective words) took 0.2s, 543996 effective words/s
INFO - 2023-11-30 14:15:42,619: EPOCH 9: training on 191080 raw words (111421 effective words) took 0.2s, 553598 effective words/s
INFO - 2023-11-30 14:15:42,824: EPOCH 10: training on 191080 raw words (111540 effective words) took 0.2s, 550353 effective words/s
INFO - 2023-11-30 14:15:43,034: EPOCH 11: training on 191080 raw words (111550 effective words) took 0.2s, 538309 effective words/s
INFO - 2023-11-30 14:15:43,241: EPOCH 12: training on 191080 raw words (111336 effective words) took 0.2s, 543143 effective words/s
INFO - 2023-11-30 14:15:43,446: EPOCH 13: training on 191080 raw words (111437 effective words) took 0.2s, 550894 effective words/s
INFO - 2023-11-30 14:15:43,653: EPOCH 14: training on 191080 raw words (111395 effective words) took 0.2s, 542666 effective words/s
INFO - 2023-11-30 14:15:43,860: EPOCH 15: training on 191080 raw words (111500 effective words) took 0.2s, 545154 effective words/s
INFO - 2023-11-30 14:15:44,062: EPOCH 16: training on 191080 raw words (111442 effective words) took 0.2s, 558043 effective words/s
INFO - 2023-11-30 14:15:44,267: EPOCH 17: training on 191080 raw words (111147 effective words) took 0.2s, 549544 effective words/s
INFO - 2023-11-30 14:15:44,473: EPOCH 18: training on 191080 raw words (111328 effective words) took 0.2s, 545045 effective words/s
INFO - 2023-11-30 14:15:44,676: EPOCH 19: training on 191080 raw words (111362 effective words) took 0.2s, 556248 effective words/s
INFO - 2023-11-30 14:15:44,676: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2227842 effective words) took 4.1s, 541639 effective words/s', 'datetime': '2023-11-30T14:15:44.676675', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:44,676: collecting all words and their counts
INFO - 2023-11-30 14:15:44,677: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:44,702: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:44,702: Updating model with new vocabulary
INFO - 2023-11-30 14:15:44,713: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:44.713522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:44,727: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:44,727: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:15:44,727: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111465.79720098703 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:15:44.727835', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:44,749: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:44,750: updating layer weights
INFO - 2023-11-30 14:15:44,750: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:44.750332', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:44,750: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:44,750: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:44.750515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:44,972: EPOCH 0: training on 191080 raw words (111372 effective words) took 0.2s, 507649 effective words/s
INFO - 2023-11-30 14:15:45,198: EPOCH 1: training on 191080 raw words (111325 effective words) took 0.2s, 495592 effective words/s
INFO - 2023-11-30 14:15:45,448: EPOCH 2: training on 191080 raw words (111595 effective words) took 0.2s, 451601 effective words/s
INFO - 2023-11-30 14:15:45,671: EPOCH 3: training on 191080 raw words (111567 effective words) took 0.2s, 504573 effective words/s
INFO - 2023-11-30 14:15:45,897: EPOCH 4: training on 191080 raw words (111440 effective words) took 0.2s, 499077 effective words/s
INFO - 2023-11-30 14:15:46,123: EPOCH 5: training on 191080 raw words (111446 effective words) took 0.2s, 497158 effective words/s
INFO - 2023-11-30 14:15:46,350: EPOCH 6: training on 191080 raw words (111416 effective words) took 0.2s, 496233 effective words/s
INFO - 2023-11-30 14:15:46,571: EPOCH 7: training on 191080 raw words (111532 effective words) took 0.2s, 509454 effective words/s
INFO - 2023-11-30 14:15:46,794: EPOCH 8: training on 191080 raw words (111205 effective words) took 0.2s, 504383 effective words/s
INFO - 2023-11-30 14:15:47,014: EPOCH 9: training on 191080 raw words (111097 effective words) took 0.2s, 511059 effective words/s
INFO - 2023-11-30 14:15:47,237: EPOCH 10: training on 191080 raw words (111360 effective words) took 0.2s, 545121 effective words/s
INFO - 2023-11-30 14:15:47,462: EPOCH 11: training on 191080 raw words (111346 effective words) took 0.2s, 500763 effective words/s
INFO - 2023-11-30 14:15:47,684: EPOCH 12: training on 191080 raw words (111412 effective words) took 0.2s, 505231 effective words/s
INFO - 2023-11-30 14:15:47,913: EPOCH 13: training on 191080 raw words (111452 effective words) took 0.2s, 492005 effective words/s
INFO - 2023-11-30 14:15:48,192: EPOCH 14: training on 191080 raw words (111519 effective words) took 0.3s, 402335 effective words/s
INFO - 2023-11-30 14:15:48,412: EPOCH 15: training on 191080 raw words (111532 effective words) took 0.2s, 513641 effective words/s
INFO - 2023-11-30 14:15:48,633: EPOCH 16: training on 191080 raw words (111472 effective words) took 0.2s, 508472 effective words/s
INFO - 2023-11-30 14:15:48,852: EPOCH 17: training on 191080 raw words (111447 effective words) took 0.2s, 513878 effective words/s
INFO - 2023-11-30 14:15:49,073: EPOCH 18: training on 191080 raw words (111347 effective words) took 0.2s, 509051 effective words/s
INFO - 2023-11-30 14:15:49,296: EPOCH 19: training on 191080 raw words (111287 effective words) took 0.2s, 504962 effective words/s
INFO - 2023-11-30 14:15:49,296: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2228169 effective words) took 4.5s, 490143 effective words/s', 'datetime': '2023-11-30T14:15:49.296548', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:49,296: collecting all words and their counts
INFO - 2023-11-30 14:15:49,296: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:49,322: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:49,322: Updating model with new vocabulary
INFO - 2023-11-30 14:15:49,333: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:49.333830', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:49,348: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:49,348: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 14:15:49,348: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111682.11227139042 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:15:49.348887', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:49,371: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:49,371: updating layer weights
INFO - 2023-11-30 14:15:49,372: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:49.372036', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:49,372: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:49,372: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:49.372276', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:49,578: EPOCH 0: training on 191080 raw words (111632 effective words) took 0.2s, 547407 effective words/s
INFO - 2023-11-30 14:15:49,781: EPOCH 1: training on 191080 raw words (111985 effective words) took 0.2s, 559794 effective words/s
INFO - 2023-11-30 14:15:49,989: EPOCH 2: training on 191080 raw words (111737 effective words) took 0.2s, 542295 effective words/s
INFO - 2023-11-30 14:15:50,197: EPOCH 3: training on 191080 raw words (111572 effective words) took 0.2s, 542650 effective words/s
INFO - 2023-11-30 14:15:50,402: EPOCH 4: training on 191080 raw words (111641 effective words) took 0.2s, 549739 effective words/s
INFO - 2023-11-30 14:15:50,605: EPOCH 5: training on 191080 raw words (111765 effective words) took 0.2s, 557397 effective words/s
INFO - 2023-11-30 14:15:50,811: EPOCH 6: training on 191080 raw words (111735 effective words) took 0.2s, 548771 effective words/s
INFO - 2023-11-30 14:15:51,038: EPOCH 7: training on 191080 raw words (111624 effective words) took 0.2s, 496316 effective words/s
INFO - 2023-11-30 14:15:51,249: EPOCH 8: training on 191080 raw words (111810 effective words) took 0.2s, 535257 effective words/s
INFO - 2023-11-30 14:15:51,459: EPOCH 9: training on 191080 raw words (111653 effective words) took 0.2s, 540044 effective words/s
INFO - 2023-11-30 14:15:51,665: EPOCH 10: training on 191080 raw words (111719 effective words) took 0.2s, 547532 effective words/s
INFO - 2023-11-30 14:15:51,895: EPOCH 11: training on 191080 raw words (111711 effective words) took 0.2s, 490592 effective words/s
INFO - 2023-11-30 14:15:52,177: EPOCH 12: training on 191080 raw words (111738 effective words) took 0.3s, 400232 effective words/s
INFO - 2023-11-30 14:15:52,459: EPOCH 13: training on 191080 raw words (111671 effective words) took 0.3s, 401164 effective words/s
INFO - 2023-11-30 14:15:52,728: EPOCH 14: training on 191080 raw words (111720 effective words) took 0.2s, 457193 effective words/s
INFO - 2023-11-30 14:15:53,002: EPOCH 15: training on 191080 raw words (111720 effective words) took 0.3s, 411699 effective words/s
INFO - 2023-11-30 14:15:53,289: EPOCH 16: training on 191080 raw words (111748 effective words) took 0.3s, 393344 effective words/s
INFO - 2023-11-30 14:15:53,571: EPOCH 17: training on 191080 raw words (111826 effective words) took 0.3s, 401057 effective words/s
INFO - 2023-11-30 14:15:53,857: EPOCH 18: training on 191080 raw words (111779 effective words) took 0.3s, 395351 effective words/s
INFO - 2023-11-30 14:15:54,144: EPOCH 19: training on 191080 raw words (111693 effective words) took 0.3s, 394142 effective words/s
INFO - 2023-11-30 14:15:54,144: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234479 effective words) took 4.8s, 468250 effective words/s', 'datetime': '2023-11-30T14:15:54.144352', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:54,144: collecting all words and their counts
INFO - 2023-11-30 14:15:54,144: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:15:54,182: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:15:54,182: Updating model with new vocabulary
INFO - 2023-11-30 14:15:54,198: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:15:54.198704', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:54,226: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:15:54,227: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:15:54,227: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111628.28104330486 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:15:54.227246', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:15:54,259: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:15:54,259: updating layer weights
INFO - 2023-11-30 14:15:54,260: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:15:54.260360', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:15:54,260: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:15:54,261: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:15:54.261023', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:15:54,589: EPOCH 0: training on 191080 raw words (111621 effective words) took 0.3s, 343905 effective words/s
INFO - 2023-11-30 14:15:54,898: EPOCH 1: training on 191080 raw words (111545 effective words) took 0.3s, 392313 effective words/s
INFO - 2023-11-30 14:15:55,277: EPOCH 2: training on 191080 raw words (111654 effective words) took 0.4s, 296674 effective words/s
INFO - 2023-11-30 14:15:55,619: EPOCH 3: training on 191080 raw words (111547 effective words) took 0.3s, 329913 effective words/s
INFO - 2023-11-30 14:15:56,080: EPOCH 4: training on 191080 raw words (111809 effective words) took 0.5s, 244452 effective words/s
INFO - 2023-11-30 14:15:56,453: EPOCH 5: training on 191080 raw words (111534 effective words) took 0.4s, 303386 effective words/s
INFO - 2023-11-30 14:15:56,801: EPOCH 6: training on 191080 raw words (111796 effective words) took 0.3s, 324449 effective words/s
INFO - 2023-11-30 14:15:57,188: EPOCH 7: training on 191080 raw words (111734 effective words) took 0.4s, 291667 effective words/s
INFO - 2023-11-30 14:15:57,576: EPOCH 8: training on 191080 raw words (111666 effective words) took 0.4s, 291362 effective words/s
INFO - 2023-11-30 14:15:57,926: EPOCH 9: training on 191080 raw words (111880 effective words) took 0.3s, 323160 effective words/s
INFO - 2023-11-30 14:15:58,292: EPOCH 10: training on 191080 raw words (111629 effective words) took 0.4s, 307937 effective words/s
INFO - 2023-11-30 14:15:58,651: EPOCH 11: training on 191080 raw words (111551 effective words) took 0.4s, 313627 effective words/s
INFO - 2023-11-30 14:15:59,006: EPOCH 12: training on 191080 raw words (111709 effective words) took 0.4s, 317811 effective words/s
INFO - 2023-11-30 14:15:59,360: EPOCH 13: training on 191080 raw words (111738 effective words) took 0.4s, 318312 effective words/s
INFO - 2023-11-30 14:15:59,709: EPOCH 14: training on 191080 raw words (111506 effective words) took 0.3s, 322075 effective words/s
INFO - 2023-11-30 14:16:00,063: EPOCH 15: training on 191080 raw words (111650 effective words) took 0.3s, 319194 effective words/s
INFO - 2023-11-30 14:16:00,430: EPOCH 16: training on 191080 raw words (111499 effective words) took 0.4s, 306497 effective words/s
INFO - 2023-11-30 14:16:00,791: EPOCH 17: training on 191080 raw words (111641 effective words) took 0.4s, 311807 effective words/s
INFO - 2023-11-30 14:16:01,133: EPOCH 18: training on 191080 raw words (111682 effective words) took 0.3s, 356534 effective words/s
INFO - 2023-11-30 14:16:01,430: EPOCH 19: training on 191080 raw words (111769 effective words) took 0.3s, 380361 effective words/s
INFO - 2023-11-30 14:16:01,431: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233160 effective words) took 7.2s, 311464 effective words/s', 'datetime': '2023-11-30T14:16:01.431251', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:01,431: collecting all words and their counts
INFO - 2023-11-30 14:16:01,431: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:01,470: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:01,471: Updating model with new vocabulary
INFO - 2023-11-30 14:16:01,487: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:01.487937', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:01,510: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:01,510: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:16:01,510: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111672.39197334406 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:16:01.510684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:01,545: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:01,545: updating layer weights
INFO - 2023-11-30 14:16:01,545: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:01.545799', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:01,545: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:01,546: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:01.546120', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:01,826: EPOCH 0: training on 191080 raw words (111528 effective words) took 0.3s, 418941 effective words/s
INFO - 2023-11-30 14:16:02,092: EPOCH 1: training on 191080 raw words (111687 effective words) took 0.3s, 425245 effective words/s
INFO - 2023-11-30 14:16:02,356: EPOCH 2: training on 191080 raw words (111692 effective words) took 0.3s, 427091 effective words/s
INFO - 2023-11-30 14:16:02,636: EPOCH 3: training on 191080 raw words (111654 effective words) took 0.3s, 402718 effective words/s
INFO - 2023-11-30 14:16:02,921: EPOCH 4: training on 191080 raw words (111714 effective words) took 0.3s, 397552 effective words/s
INFO - 2023-11-30 14:16:03,188: EPOCH 5: training on 191080 raw words (111631 effective words) took 0.3s, 422900 effective words/s
INFO - 2023-11-30 14:16:03,451: EPOCH 6: training on 191080 raw words (111600 effective words) took 0.3s, 429874 effective words/s
INFO - 2023-11-30 14:16:03,707: EPOCH 7: training on 191080 raw words (111797 effective words) took 0.3s, 440954 effective words/s
INFO - 2023-11-30 14:16:03,991: EPOCH 8: training on 191080 raw words (111634 effective words) took 0.3s, 397974 effective words/s
INFO - 2023-11-30 14:16:04,244: EPOCH 9: training on 191080 raw words (111641 effective words) took 0.3s, 446562 effective words/s
INFO - 2023-11-30 14:16:04,510: EPOCH 10: training on 191080 raw words (111424 effective words) took 0.3s, 423508 effective words/s
INFO - 2023-11-30 14:16:04,790: EPOCH 11: training on 191080 raw words (111870 effective words) took 0.3s, 404040 effective words/s
INFO - 2023-11-30 14:16:05,065: EPOCH 12: training on 191080 raw words (111562 effective words) took 0.3s, 409961 effective words/s
INFO - 2023-11-30 14:16:05,329: EPOCH 13: training on 191080 raw words (111694 effective words) took 0.3s, 427102 effective words/s
INFO - 2023-11-30 14:16:05,614: EPOCH 14: training on 191080 raw words (111700 effective words) took 0.3s, 397006 effective words/s
INFO - 2023-11-30 14:16:05,880: EPOCH 15: training on 191080 raw words (111678 effective words) took 0.3s, 424242 effective words/s
INFO - 2023-11-30 14:16:06,157: EPOCH 16: training on 191080 raw words (111878 effective words) took 0.3s, 410484 effective words/s
INFO - 2023-11-30 14:16:06,430: EPOCH 17: training on 191080 raw words (111677 effective words) took 0.3s, 413798 effective words/s
INFO - 2023-11-30 14:16:06,705: EPOCH 18: training on 191080 raw words (111677 effective words) took 0.3s, 411992 effective words/s
INFO - 2023-11-30 14:16:07,021: EPOCH 19: training on 191080 raw words (111538 effective words) took 0.3s, 356191 effective words/s
INFO - 2023-11-30 14:16:07,021: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233276 effective words) took 5.5s, 407870 effective words/s', 'datetime': '2023-11-30T14:16:07.021736', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:07,021: collecting all words and their counts
INFO - 2023-11-30 14:16:07,022: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:07,065: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:07,065: Updating model with new vocabulary
INFO - 2023-11-30 14:16:07,089: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:07.089769', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:07,120: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:07,121: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 14:16:07,121: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111990.44012056482 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:16:07.121158', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:07,170: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:07,171: updating layer weights
INFO - 2023-11-30 14:16:07,171: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:07.171525', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:07,171: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:07,172: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:07.172139', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:07,496: EPOCH 0: training on 191080 raw words (111898 effective words) took 0.3s, 349409 effective words/s
INFO - 2023-11-30 14:16:07,795: EPOCH 1: training on 191080 raw words (112030 effective words) took 0.3s, 378817 effective words/s
INFO - 2023-11-30 14:16:08,101: EPOCH 2: training on 191080 raw words (112178 effective words) took 0.3s, 369900 effective words/s
INFO - 2023-11-30 14:16:08,414: EPOCH 3: training on 191080 raw words (111841 effective words) took 0.3s, 361080 effective words/s
INFO - 2023-11-30 14:16:08,741: EPOCH 4: training on 191080 raw words (112028 effective words) took 0.3s, 346674 effective words/s
INFO - 2023-11-30 14:16:09,074: EPOCH 5: training on 191080 raw words (112108 effective words) took 0.3s, 340239 effective words/s
INFO - 2023-11-30 14:16:09,404: EPOCH 6: training on 191080 raw words (111632 effective words) took 0.3s, 340924 effective words/s
INFO - 2023-11-30 14:16:09,690: EPOCH 7: training on 191080 raw words (112032 effective words) took 0.3s, 397106 effective words/s
INFO - 2023-11-30 14:16:09,980: EPOCH 8: training on 191080 raw words (111896 effective words) took 0.3s, 388571 effective words/s
INFO - 2023-11-30 14:16:10,269: EPOCH 9: training on 191080 raw words (111972 effective words) took 0.3s, 392866 effective words/s
INFO - 2023-11-30 14:16:10,574: EPOCH 10: training on 191080 raw words (111918 effective words) took 0.3s, 371510 effective words/s
INFO - 2023-11-30 14:16:10,879: EPOCH 11: training on 191080 raw words (112168 effective words) took 0.3s, 372800 effective words/s
INFO - 2023-11-30 14:16:11,173: EPOCH 12: training on 191080 raw words (112000 effective words) took 0.3s, 385785 effective words/s
INFO - 2023-11-30 14:16:11,454: EPOCH 13: training on 191080 raw words (111727 effective words) took 0.3s, 400389 effective words/s
INFO - 2023-11-30 14:16:11,742: EPOCH 14: training on 191080 raw words (111913 effective words) took 0.3s, 391970 effective words/s
INFO - 2023-11-30 14:16:12,053: EPOCH 15: training on 191080 raw words (111963 effective words) took 0.3s, 364350 effective words/s
INFO - 2023-11-30 14:16:12,334: EPOCH 16: training on 191080 raw words (111941 effective words) took 0.3s, 402067 effective words/s
INFO - 2023-11-30 14:16:12,652: EPOCH 17: training on 191080 raw words (112022 effective words) took 0.3s, 356448 effective words/s
INFO - 2023-11-30 14:16:12,930: EPOCH 18: training on 191080 raw words (111923 effective words) took 0.3s, 405996 effective words/s
INFO - 2023-11-30 14:16:13,286: EPOCH 19: training on 191080 raw words (111895 effective words) took 0.4s, 317789 effective words/s
INFO - 2023-11-30 14:16:13,286: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2239085 effective words) took 6.1s, 366218 effective words/s', 'datetime': '2023-11-30T14:16:13.286568', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:13,286: collecting all words and their counts
INFO - 2023-11-30 14:16:13,287: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:13,334: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:13,334: Updating model with new vocabulary
INFO - 2023-11-30 14:16:13,354: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:13.354575', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:13,374: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:13,374: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:16:13,374: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111682.92236797203 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:16:13.374944', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:13,399: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:13,399: updating layer weights
INFO - 2023-11-30 14:16:13,399: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:13.399790', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:13,399: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:13,400: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:13.400084', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:13,608: EPOCH 0: training on 191080 raw words (111693 effective words) took 0.2s, 541089 effective words/s
INFO - 2023-11-30 14:16:13,814: EPOCH 1: training on 191080 raw words (111688 effective words) took 0.2s, 548934 effective words/s
INFO - 2023-11-30 14:16:14,021: EPOCH 2: training on 191080 raw words (111527 effective words) took 0.2s, 546105 effective words/s
INFO - 2023-11-30 14:16:14,230: EPOCH 3: training on 191080 raw words (111529 effective words) took 0.2s, 538621 effective words/s
INFO - 2023-11-30 14:16:14,437: EPOCH 4: training on 191080 raw words (111535 effective words) took 0.2s, 545435 effective words/s
INFO - 2023-11-30 14:16:14,639: EPOCH 5: training on 191080 raw words (111546 effective words) took 0.2s, 558932 effective words/s
INFO - 2023-11-30 14:16:14,859: EPOCH 6: training on 191080 raw words (111640 effective words) took 0.2s, 511874 effective words/s
INFO - 2023-11-30 14:16:15,086: EPOCH 7: training on 191080 raw words (111699 effective words) took 0.2s, 498129 effective words/s
INFO - 2023-11-30 14:16:15,306: EPOCH 8: training on 191080 raw words (111779 effective words) took 0.2s, 516394 effective words/s
INFO - 2023-11-30 14:16:15,506: EPOCH 9: training on 191080 raw words (111623 effective words) took 0.2s, 563454 effective words/s
INFO - 2023-11-30 14:16:15,711: EPOCH 10: training on 191080 raw words (111577 effective words) took 0.2s, 548959 effective words/s
INFO - 2023-11-30 14:16:15,919: EPOCH 11: training on 191080 raw words (111776 effective words) took 0.2s, 542975 effective words/s
INFO - 2023-11-30 14:16:16,159: EPOCH 12: training on 191080 raw words (111757 effective words) took 0.2s, 472295 effective words/s
INFO - 2023-11-30 14:16:16,426: EPOCH 13: training on 191080 raw words (111680 effective words) took 0.3s, 422724 effective words/s
INFO - 2023-11-30 14:16:16,674: EPOCH 14: training on 191080 raw words (111858 effective words) took 0.2s, 456040 effective words/s
INFO - 2023-11-30 14:16:16,906: EPOCH 15: training on 191080 raw words (111596 effective words) took 0.2s, 486704 effective words/s
INFO - 2023-11-30 14:16:17,140: EPOCH 16: training on 191080 raw words (111996 effective words) took 0.2s, 486479 effective words/s
INFO - 2023-11-30 14:16:17,378: EPOCH 17: training on 191080 raw words (111730 effective words) took 0.2s, 473026 effective words/s
INFO - 2023-11-30 14:16:17,627: EPOCH 18: training on 191080 raw words (111716 effective words) took 0.2s, 453852 effective words/s
INFO - 2023-11-30 14:16:17,865: EPOCH 19: training on 191080 raw words (111679 effective words) took 0.2s, 473774 effective words/s
INFO - 2023-11-30 14:16:17,865: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233624 effective words) took 4.5s, 500209 effective words/s', 'datetime': '2023-11-30T14:16:17.865598', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:17,865: collecting all words and their counts
INFO - 2023-11-30 14:16:17,866: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:17,893: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:17,894: Updating model with new vocabulary
INFO - 2023-11-30 14:16:17,912: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:17.912606', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:17,932: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:17,932: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:17,932: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111982.44118342454 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:16:17.932772', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:17,963: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:17,964: updating layer weights
INFO - 2023-11-30 14:16:17,964: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:17.964647', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:17,965: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:17,965: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:17.965390', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:18,197: EPOCH 0: training on 191080 raw words (111970 effective words) took 0.2s, 488826 effective words/s
INFO - 2023-11-30 14:16:18,432: EPOCH 1: training on 191080 raw words (111811 effective words) took 0.2s, 478779 effective words/s
INFO - 2023-11-30 14:16:18,684: EPOCH 2: training on 191080 raw words (111916 effective words) took 0.2s, 448288 effective words/s
INFO - 2023-11-30 14:16:18,922: EPOCH 3: training on 191080 raw words (112198 effective words) took 0.2s, 478454 effective words/s
INFO - 2023-11-30 14:16:19,150: EPOCH 4: training on 191080 raw words (111745 effective words) took 0.2s, 493258 effective words/s
INFO - 2023-11-30 14:16:19,441: EPOCH 5: training on 191080 raw words (112055 effective words) took 0.3s, 416619 effective words/s
INFO - 2023-11-30 14:16:19,719: EPOCH 6: training on 191080 raw words (112032 effective words) took 0.3s, 407878 effective words/s
INFO - 2023-11-30 14:16:19,953: EPOCH 7: training on 191080 raw words (111983 effective words) took 0.2s, 482741 effective words/s
INFO - 2023-11-30 14:16:20,226: EPOCH 8: training on 191080 raw words (112054 effective words) took 0.3s, 414461 effective words/s
INFO - 2023-11-30 14:16:20,450: EPOCH 9: training on 191080 raw words (111872 effective words) took 0.2s, 504919 effective words/s
INFO - 2023-11-30 14:16:20,675: EPOCH 10: training on 191080 raw words (112228 effective words) took 0.2s, 504320 effective words/s
INFO - 2023-11-30 14:16:20,897: EPOCH 11: training on 191080 raw words (111895 effective words) took 0.2s, 509263 effective words/s
INFO - 2023-11-30 14:16:21,119: EPOCH 12: training on 191080 raw words (112174 effective words) took 0.2s, 509337 effective words/s
INFO - 2023-11-30 14:16:21,346: EPOCH 13: training on 191080 raw words (112017 effective words) took 0.2s, 498359 effective words/s
INFO - 2023-11-30 14:16:21,570: EPOCH 14: training on 191080 raw words (111950 effective words) took 0.2s, 505677 effective words/s
INFO - 2023-11-30 14:16:21,794: EPOCH 15: training on 191080 raw words (112012 effective words) took 0.2s, 506262 effective words/s
INFO - 2023-11-30 14:16:22,017: EPOCH 16: training on 191080 raw words (111937 effective words) took 0.2s, 507723 effective words/s
INFO - 2023-11-30 14:16:22,241: EPOCH 17: training on 191080 raw words (112193 effective words) took 0.2s, 505952 effective words/s
INFO - 2023-11-30 14:16:22,492: EPOCH 18: training on 191080 raw words (112115 effective words) took 0.2s, 450384 effective words/s
INFO - 2023-11-30 14:16:22,748: EPOCH 19: training on 191080 raw words (112065 effective words) took 0.3s, 441277 effective words/s
INFO - 2023-11-30 14:16:22,749: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2240222 effective words) took 4.8s, 468346 effective words/s', 'datetime': '2023-11-30T14:16:22.749160', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:22,749: collecting all words and their counts
INFO - 2023-11-30 14:16:22,749: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:22,775: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:22,775: Updating model with new vocabulary
INFO - 2023-11-30 14:16:22,787: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:22.787591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:22,802: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:22,802: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:22,802: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111799.0435767524 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:16:22.802232', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:22,825: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:22,825: updating layer weights
INFO - 2023-11-30 14:16:22,825: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:22.825947', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:22,826: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:22,826: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:22.826143', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:23,033: EPOCH 0: training on 191080 raw words (111992 effective words) took 0.2s, 545551 effective words/s
INFO - 2023-11-30 14:16:23,243: EPOCH 1: training on 191080 raw words (111752 effective words) took 0.2s, 538679 effective words/s
INFO - 2023-11-30 14:16:23,507: EPOCH 2: training on 191080 raw words (111869 effective words) took 0.3s, 427289 effective words/s
INFO - 2023-11-30 14:16:23,714: EPOCH 3: training on 191080 raw words (111559 effective words) took 0.2s, 544809 effective words/s
INFO - 2023-11-30 14:16:23,974: EPOCH 4: training on 191080 raw words (111671 effective words) took 0.3s, 434021 effective words/s
INFO - 2023-11-30 14:16:24,215: EPOCH 5: training on 191080 raw words (111838 effective words) took 0.2s, 469918 effective words/s
INFO - 2023-11-30 14:16:24,483: EPOCH 6: training on 191080 raw words (111728 effective words) took 0.3s, 421298 effective words/s
INFO - 2023-11-30 14:16:24,751: EPOCH 7: training on 191080 raw words (111771 effective words) took 0.3s, 420344 effective words/s
INFO - 2023-11-30 14:16:25,012: EPOCH 8: training on 191080 raw words (111806 effective words) took 0.3s, 434061 effective words/s
INFO - 2023-11-30 14:16:25,270: EPOCH 9: training on 191080 raw words (111930 effective words) took 0.3s, 438973 effective words/s
INFO - 2023-11-30 14:16:25,542: EPOCH 10: training on 191080 raw words (111656 effective words) took 0.3s, 415570 effective words/s
INFO - 2023-11-30 14:16:25,806: EPOCH 11: training on 191080 raw words (111683 effective words) took 0.3s, 427101 effective words/s
INFO - 2023-11-30 14:16:26,071: EPOCH 12: training on 191080 raw words (111690 effective words) took 0.2s, 461885 effective words/s
INFO - 2023-11-30 14:16:26,354: EPOCH 13: training on 191080 raw words (111801 effective words) took 0.3s, 399111 effective words/s
INFO - 2023-11-30 14:16:26,616: EPOCH 14: training on 191080 raw words (111796 effective words) took 0.3s, 432361 effective words/s
INFO - 2023-11-30 14:16:26,886: EPOCH 15: training on 191080 raw words (111662 effective words) took 0.3s, 417567 effective words/s
INFO - 2023-11-30 14:16:27,155: EPOCH 16: training on 191080 raw words (111752 effective words) took 0.3s, 419593 effective words/s
INFO - 2023-11-30 14:16:27,421: EPOCH 17: training on 191080 raw words (111830 effective words) took 0.3s, 424452 effective words/s
INFO - 2023-11-30 14:16:27,685: EPOCH 18: training on 191080 raw words (111616 effective words) took 0.3s, 426244 effective words/s
INFO - 2023-11-30 14:16:27,962: EPOCH 19: training on 191080 raw words (111880 effective words) took 0.3s, 407821 effective words/s
INFO - 2023-11-30 14:16:27,963: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2235282 effective words) took 5.1s, 435141 effective words/s', 'datetime': '2023-11-30T14:16:27.963172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:27,963: collecting all words and their counts
INFO - 2023-11-30 14:16:27,963: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:27,997: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:27,997: Updating model with new vocabulary
INFO - 2023-11-30 14:16:28,012: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:28.012304', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:28,031: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:28,031: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:28,031: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111543.16419644334 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:16:28.031908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:28,063: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:28,063: updating layer weights
INFO - 2023-11-30 14:16:28,063: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:28.063786', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:28,063: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:28,064: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:28.064028', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:28,371: EPOCH 0: training on 191080 raw words (111627 effective words) took 0.3s, 366962 effective words/s
INFO - 2023-11-30 14:16:28,666: EPOCH 1: training on 191080 raw words (111545 effective words) took 0.3s, 381049 effective words/s
INFO - 2023-11-30 14:16:28,955: EPOCH 2: training on 191080 raw words (111399 effective words) took 0.3s, 389201 effective words/s
INFO - 2023-11-30 14:16:29,250: EPOCH 3: training on 191080 raw words (111540 effective words) took 0.3s, 382269 effective words/s
INFO - 2023-11-30 14:16:29,537: EPOCH 4: training on 191080 raw words (111526 effective words) took 0.3s, 393455 effective words/s
INFO - 2023-11-30 14:16:29,830: EPOCH 5: training on 191080 raw words (111349 effective words) took 0.3s, 383747 effective words/s
INFO - 2023-11-30 14:16:30,121: EPOCH 6: training on 191080 raw words (111556 effective words) took 0.3s, 386470 effective words/s
INFO - 2023-11-30 14:16:30,430: EPOCH 7: training on 191080 raw words (111598 effective words) took 0.3s, 365196 effective words/s
INFO - 2023-11-30 14:16:30,737: EPOCH 8: training on 191080 raw words (111492 effective words) took 0.3s, 367065 effective words/s
INFO - 2023-11-30 14:16:31,042: EPOCH 9: training on 191080 raw words (111401 effective words) took 0.3s, 368506 effective words/s
INFO - 2023-11-30 14:16:31,356: EPOCH 10: training on 191080 raw words (111623 effective words) took 0.3s, 358792 effective words/s
INFO - 2023-11-30 14:16:31,673: EPOCH 11: training on 191080 raw words (111538 effective words) took 0.3s, 355468 effective words/s
INFO - 2023-11-30 14:16:31,983: EPOCH 12: training on 191080 raw words (111505 effective words) took 0.3s, 362763 effective words/s
INFO - 2023-11-30 14:16:32,300: EPOCH 13: training on 191080 raw words (111738 effective words) took 0.3s, 356054 effective words/s
INFO - 2023-11-30 14:16:32,620: EPOCH 14: training on 191080 raw words (111407 effective words) took 0.3s, 352489 effective words/s
INFO - 2023-11-30 14:16:32,939: EPOCH 15: training on 191080 raw words (111437 effective words) took 0.3s, 352395 effective words/s
INFO - 2023-11-30 14:16:33,219: EPOCH 16: training on 191080 raw words (111483 effective words) took 0.3s, 403685 effective words/s
INFO - 2023-11-30 14:16:33,456: EPOCH 17: training on 191080 raw words (111812 effective words) took 0.2s, 477096 effective words/s
INFO - 2023-11-30 14:16:33,689: EPOCH 18: training on 191080 raw words (111566 effective words) took 0.2s, 482304 effective words/s
INFO - 2023-11-30 14:16:33,935: EPOCH 19: training on 191080 raw words (111365 effective words) took 0.2s, 457925 effective words/s
INFO - 2023-11-30 14:16:33,935: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230507 effective words) took 5.9s, 379887 effective words/s', 'datetime': '2023-11-30T14:16:33.935642', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:33,935: collecting all words and their counts
INFO - 2023-11-30 14:16:33,936: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:33,970: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:33,970: Updating model with new vocabulary
INFO - 2023-11-30 14:16:33,983: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:33.983386', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:33,998: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:33,998: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:16:33,998: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111671.77934267494 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:16:33.998823', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:34,024: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:34,024: updating layer weights
INFO - 2023-11-30 14:16:34,024: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:34.024655', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:34,024: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:34,025: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:34.025108', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:34,243: EPOCH 0: training on 191080 raw words (111821 effective words) took 0.2s, 518598 effective words/s
INFO - 2023-11-30 14:16:34,489: EPOCH 1: training on 191080 raw words (111644 effective words) took 0.2s, 457279 effective words/s
INFO - 2023-11-30 14:16:34,698: EPOCH 2: training on 191080 raw words (111531 effective words) took 0.2s, 557591 effective words/s
INFO - 2023-11-30 14:16:34,910: EPOCH 3: training on 191080 raw words (111738 effective words) took 0.2s, 531230 effective words/s
INFO - 2023-11-30 14:16:35,123: EPOCH 4: training on 191080 raw words (111774 effective words) took 0.2s, 529965 effective words/s
INFO - 2023-11-30 14:16:35,336: EPOCH 5: training on 191080 raw words (111804 effective words) took 0.2s, 531036 effective words/s
INFO - 2023-11-30 14:16:35,546: EPOCH 6: training on 191080 raw words (111716 effective words) took 0.2s, 538311 effective words/s
INFO - 2023-11-30 14:16:35,759: EPOCH 7: training on 191080 raw words (111805 effective words) took 0.2s, 529236 effective words/s
INFO - 2023-11-30 14:16:35,978: EPOCH 8: training on 191080 raw words (111518 effective words) took 0.2s, 516744 effective words/s
INFO - 2023-11-30 14:16:36,201: EPOCH 9: training on 191080 raw words (111579 effective words) took 0.2s, 504847 effective words/s
INFO - 2023-11-30 14:16:36,439: EPOCH 10: training on 191080 raw words (111494 effective words) took 0.2s, 472412 effective words/s
INFO - 2023-11-30 14:16:36,651: EPOCH 11: training on 191080 raw words (111895 effective words) took 0.2s, 534613 effective words/s
INFO - 2023-11-30 14:16:36,853: EPOCH 12: training on 191080 raw words (111622 effective words) took 0.2s, 558921 effective words/s
INFO - 2023-11-30 14:16:37,056: EPOCH 13: training on 191080 raw words (111763 effective words) took 0.2s, 556657 effective words/s
INFO - 2023-11-30 14:16:37,263: EPOCH 14: training on 191080 raw words (111501 effective words) took 0.2s, 545305 effective words/s
INFO - 2023-11-30 14:16:37,464: EPOCH 15: training on 191080 raw words (111826 effective words) took 0.2s, 562196 effective words/s
INFO - 2023-11-30 14:16:37,664: EPOCH 16: training on 191080 raw words (111608 effective words) took 0.2s, 563558 effective words/s
INFO - 2023-11-30 14:16:37,865: EPOCH 17: training on 191080 raw words (111899 effective words) took 0.2s, 564824 effective words/s
INFO - 2023-11-30 14:16:38,065: EPOCH 18: training on 191080 raw words (111821 effective words) took 0.2s, 566554 effective words/s
INFO - 2023-11-30 14:16:38,273: EPOCH 19: training on 191080 raw words (111511 effective words) took 0.2s, 541202 effective words/s
INFO - 2023-11-30 14:16:38,273: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233870 effective words) took 4.2s, 525795 effective words/s', 'datetime': '2023-11-30T14:16:38.273853', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:38,274: collecting all words and their counts
INFO - 2023-11-30 14:16:38,274: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:38,301: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:38,301: Updating model with new vocabulary
INFO - 2023-11-30 14:16:38,313: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:38.313172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:38,329: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:38,329: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:16:38,329: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111379.54519751962 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:16:38.329783', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:38,354: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:38,354: updating layer weights
INFO - 2023-11-30 14:16:38,354: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:38.354761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:38,354: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:38,355: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:38.354999', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:38,597: EPOCH 0: training on 191080 raw words (111414 effective words) took 0.2s, 464597 effective words/s
INFO - 2023-11-30 14:16:38,815: EPOCH 1: training on 191080 raw words (111342 effective words) took 0.2s, 516323 effective words/s
INFO - 2023-11-30 14:16:39,040: EPOCH 2: training on 191080 raw words (111509 effective words) took 0.2s, 501323 effective words/s
INFO - 2023-11-30 14:16:39,262: EPOCH 3: training on 191080 raw words (111593 effective words) took 0.2s, 507957 effective words/s
INFO - 2023-11-30 14:16:39,485: EPOCH 4: training on 191080 raw words (111180 effective words) took 0.2s, 503890 effective words/s
INFO - 2023-11-30 14:16:39,709: EPOCH 5: training on 191080 raw words (111443 effective words) took 0.2s, 502673 effective words/s
INFO - 2023-11-30 14:16:39,931: EPOCH 6: training on 191080 raw words (111156 effective words) took 0.2s, 505544 effective words/s
INFO - 2023-11-30 14:16:40,150: EPOCH 7: training on 191080 raw words (111563 effective words) took 0.2s, 514375 effective words/s
INFO - 2023-11-30 14:16:40,375: EPOCH 8: training on 191080 raw words (111559 effective words) took 0.2s, 501927 effective words/s
INFO - 2023-11-30 14:16:40,597: EPOCH 9: training on 191080 raw words (111626 effective words) took 0.2s, 508670 effective words/s
INFO - 2023-11-30 14:16:40,816: EPOCH 10: training on 191080 raw words (111548 effective words) took 0.2s, 513155 effective words/s
INFO - 2023-11-30 14:16:41,042: EPOCH 11: training on 191080 raw words (111608 effective words) took 0.2s, 499019 effective words/s
INFO - 2023-11-30 14:16:41,266: EPOCH 12: training on 191080 raw words (111456 effective words) took 0.2s, 502996 effective words/s
INFO - 2023-11-30 14:16:41,485: EPOCH 13: training on 191080 raw words (111350 effective words) took 0.2s, 513631 effective words/s
INFO - 2023-11-30 14:16:41,704: EPOCH 14: training on 191080 raw words (111221 effective words) took 0.2s, 514310 effective words/s
INFO - 2023-11-30 14:16:41,927: EPOCH 15: training on 191080 raw words (111438 effective words) took 0.2s, 503466 effective words/s
INFO - 2023-11-30 14:16:42,147: EPOCH 16: training on 191080 raw words (111353 effective words) took 0.2s, 511287 effective words/s
INFO - 2023-11-30 14:16:42,373: EPOCH 17: training on 191080 raw words (111207 effective words) took 0.2s, 497305 effective words/s
INFO - 2023-11-30 14:16:42,593: EPOCH 18: training on 191080 raw words (111510 effective words) took 0.2s, 512904 effective words/s
INFO - 2023-11-30 14:16:42,815: EPOCH 19: training on 191080 raw words (111527 effective words) took 0.2s, 506653 effective words/s
INFO - 2023-11-30 14:16:42,816: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2228603 effective words) took 4.5s, 499571 effective words/s', 'datetime': '2023-11-30T14:16:42.816145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:42,816: collecting all words and their counts
INFO - 2023-11-30 14:16:42,816: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:42,842: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:42,842: Updating model with new vocabulary
INFO - 2023-11-30 14:16:42,853: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:42.853617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:42,867: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:42,868: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:42,868: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111704.78322769115 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:16:42.868176', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:42,890: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:42,890: updating layer weights
INFO - 2023-11-30 14:16:42,891: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:42.891351', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:42,891: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:42,891: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:42.891576', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:43,091: EPOCH 0: training on 191080 raw words (111595 effective words) took 0.2s, 565270 effective words/s
INFO - 2023-11-30 14:16:43,296: EPOCH 1: training on 191080 raw words (111658 effective words) took 0.2s, 549487 effective words/s
INFO - 2023-11-30 14:16:43,504: EPOCH 2: training on 191080 raw words (111683 effective words) took 0.2s, 543583 effective words/s
INFO - 2023-11-30 14:16:43,708: EPOCH 3: training on 191080 raw words (111887 effective words) took 0.2s, 555349 effective words/s
INFO - 2023-11-30 14:16:43,913: EPOCH 4: training on 191080 raw words (111710 effective words) took 0.2s, 552067 effective words/s
INFO - 2023-11-30 14:16:44,129: EPOCH 5: training on 191080 raw words (111690 effective words) took 0.2s, 521938 effective words/s
INFO - 2023-11-30 14:16:44,334: EPOCH 6: training on 191080 raw words (111507 effective words) took 0.2s, 548712 effective words/s
INFO - 2023-11-30 14:16:44,539: EPOCH 7: training on 191080 raw words (111578 effective words) took 0.2s, 550951 effective words/s
INFO - 2023-11-30 14:16:44,743: EPOCH 8: training on 191080 raw words (111648 effective words) took 0.2s, 554100 effective words/s
INFO - 2023-11-30 14:16:44,942: EPOCH 9: training on 191080 raw words (111482 effective words) took 0.2s, 566640 effective words/s
INFO - 2023-11-30 14:16:45,150: EPOCH 10: training on 191080 raw words (111699 effective words) took 0.2s, 542544 effective words/s
INFO - 2023-11-30 14:16:45,357: EPOCH 11: training on 191080 raw words (111567 effective words) took 0.2s, 546040 effective words/s
INFO - 2023-11-30 14:16:45,561: EPOCH 12: training on 191080 raw words (111756 effective words) took 0.2s, 554666 effective words/s
INFO - 2023-11-30 14:16:45,765: EPOCH 13: training on 191080 raw words (111901 effective words) took 0.2s, 554451 effective words/s
INFO - 2023-11-30 14:16:45,972: EPOCH 14: training on 191080 raw words (111749 effective words) took 0.2s, 547555 effective words/s
INFO - 2023-11-30 14:16:46,181: EPOCH 15: training on 191080 raw words (111603 effective words) took 0.2s, 539382 effective words/s
INFO - 2023-11-30 14:16:46,386: EPOCH 16: training on 191080 raw words (111574 effective words) took 0.2s, 550914 effective words/s
INFO - 2023-11-30 14:16:46,590: EPOCH 17: training on 191080 raw words (111734 effective words) took 0.2s, 553268 effective words/s
INFO - 2023-11-30 14:16:46,800: EPOCH 18: training on 191080 raw words (111736 effective words) took 0.2s, 537579 effective words/s
INFO - 2023-11-30 14:16:47,004: EPOCH 19: training on 191080 raw words (111853 effective words) took 0.2s, 555242 effective words/s
INFO - 2023-11-30 14:16:47,004: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233610 effective words) took 4.1s, 543057 effective words/s', 'datetime': '2023-11-30T14:16:47.004771', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:47,004: collecting all words and their counts
INFO - 2023-11-30 14:16:47,005: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:47,030: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:47,030: Updating model with new vocabulary
INFO - 2023-11-30 14:16:47,042: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:47.042288', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:47,057: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:47,057: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:47,057: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111915.19147227204 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:16:47.057442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:47,079: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:47,079: updating layer weights
INFO - 2023-11-30 14:16:47,080: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:47.080256', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:47,080: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:47,080: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:47.080468', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:47,299: EPOCH 0: training on 191080 raw words (111783 effective words) took 0.2s, 515622 effective words/s
INFO - 2023-11-30 14:16:47,523: EPOCH 1: training on 191080 raw words (111885 effective words) took 0.2s, 503307 effective words/s
INFO - 2023-11-30 14:16:47,745: EPOCH 2: training on 191080 raw words (111885 effective words) took 0.2s, 511258 effective words/s
INFO - 2023-11-30 14:16:47,969: EPOCH 3: training on 191080 raw words (111878 effective words) took 0.2s, 506355 effective words/s
INFO - 2023-11-30 14:16:48,248: EPOCH 4: training on 191080 raw words (111923 effective words) took 0.3s, 403977 effective words/s
INFO - 2023-11-30 14:16:48,550: EPOCH 5: training on 191080 raw words (111848 effective words) took 0.3s, 373479 effective words/s
INFO - 2023-11-30 14:16:48,868: EPOCH 6: training on 191080 raw words (111763 effective words) took 0.3s, 355404 effective words/s
INFO - 2023-11-30 14:16:49,173: EPOCH 7: training on 191080 raw words (111995 effective words) took 0.3s, 370563 effective words/s
INFO - 2023-11-30 14:16:49,485: EPOCH 8: training on 191080 raw words (111806 effective words) took 0.3s, 361759 effective words/s
INFO - 2023-11-30 14:16:49,790: EPOCH 9: training on 191080 raw words (111776 effective words) took 0.3s, 370997 effective words/s
INFO - 2023-11-30 14:16:50,096: EPOCH 10: training on 191080 raw words (111881 effective words) took 0.3s, 369254 effective words/s
INFO - 2023-11-30 14:16:50,400: EPOCH 11: training on 191080 raw words (111822 effective words) took 0.3s, 371348 effective words/s
INFO - 2023-11-30 14:16:50,700: EPOCH 12: training on 191080 raw words (111861 effective words) took 0.3s, 376027 effective words/s
INFO - 2023-11-30 14:16:51,050: EPOCH 13: training on 191080 raw words (111935 effective words) took 0.3s, 323196 effective words/s
INFO - 2023-11-30 14:16:51,383: EPOCH 14: training on 191080 raw words (111860 effective words) took 0.3s, 338179 effective words/s
INFO - 2023-11-30 14:16:51,711: EPOCH 15: training on 191080 raw words (112101 effective words) took 0.3s, 345238 effective words/s
INFO - 2023-11-30 14:16:52,038: EPOCH 16: training on 191080 raw words (112144 effective words) took 0.3s, 346121 effective words/s
INFO - 2023-11-30 14:16:52,364: EPOCH 17: training on 191080 raw words (112106 effective words) took 0.3s, 348249 effective words/s
INFO - 2023-11-30 14:16:52,705: EPOCH 18: training on 191080 raw words (111813 effective words) took 0.3s, 330914 effective words/s
INFO - 2023-11-30 14:16:53,024: EPOCH 19: training on 191080 raw words (112035 effective words) took 0.3s, 353966 effective words/s
INFO - 2023-11-30 14:16:53,025: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2238100 effective words) took 5.9s, 376505 effective words/s', 'datetime': '2023-11-30T14:16:53.024982', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:53,025: collecting all words and their counts
INFO - 2023-11-30 14:16:53,025: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:53,064: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:53,064: Updating model with new vocabulary
INFO - 2023-11-30 14:16:53,080: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:53.080610', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:53,101: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:53,101: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:16:53,102: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111696.28669252619 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:16:53.102133', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:53,136: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:53,136: updating layer weights
INFO - 2023-11-30 14:16:53,136: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:53.136727', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:53,136: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:53,136: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:53.136966', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:53,438: EPOCH 0: training on 191080 raw words (111804 effective words) took 0.3s, 374245 effective words/s
INFO - 2023-11-30 14:16:53,736: EPOCH 1: training on 191080 raw words (111671 effective words) took 0.3s, 410649 effective words/s
INFO - 2023-11-30 14:16:54,037: EPOCH 2: training on 191080 raw words (111713 effective words) took 0.3s, 375256 effective words/s
INFO - 2023-11-30 14:16:54,340: EPOCH 3: training on 191080 raw words (111586 effective words) took 0.3s, 371805 effective words/s
INFO - 2023-11-30 14:16:54,660: EPOCH 4: training on 191080 raw words (111776 effective words) took 0.3s, 353676 effective words/s
INFO - 2023-11-30 14:16:54,978: EPOCH 5: training on 191080 raw words (111683 effective words) took 0.3s, 355653 effective words/s
INFO - 2023-11-30 14:16:55,306: EPOCH 6: training on 191080 raw words (111725 effective words) took 0.3s, 343756 effective words/s
INFO - 2023-11-30 14:16:55,641: EPOCH 7: training on 191080 raw words (111913 effective words) took 0.3s, 337990 effective words/s
INFO - 2023-11-30 14:16:55,957: EPOCH 8: training on 191080 raw words (111404 effective words) took 0.3s, 356913 effective words/s
INFO - 2023-11-30 14:16:56,272: EPOCH 9: training on 191080 raw words (111709 effective words) took 0.3s, 357518 effective words/s
INFO - 2023-11-30 14:16:56,610: EPOCH 10: training on 191080 raw words (111593 effective words) took 0.3s, 333339 effective words/s
INFO - 2023-11-30 14:16:56,931: EPOCH 11: training on 191080 raw words (111553 effective words) took 0.3s, 351551 effective words/s
INFO - 2023-11-30 14:16:57,253: EPOCH 12: training on 191080 raw words (111657 effective words) took 0.3s, 350585 effective words/s
INFO - 2023-11-30 14:16:57,482: EPOCH 13: training on 191080 raw words (111823 effective words) took 0.2s, 492991 effective words/s
INFO - 2023-11-30 14:16:57,678: EPOCH 14: training on 191080 raw words (111724 effective words) took 0.2s, 574858 effective words/s
INFO - 2023-11-30 14:16:57,876: EPOCH 15: training on 191080 raw words (111804 effective words) took 0.2s, 571946 effective words/s
INFO - 2023-11-30 14:16:58,095: EPOCH 16: training on 191080 raw words (111634 effective words) took 0.2s, 515578 effective words/s
INFO - 2023-11-30 14:16:58,303: EPOCH 17: training on 191080 raw words (111608 effective words) took 0.2s, 541530 effective words/s
INFO - 2023-11-30 14:16:58,528: EPOCH 18: training on 191080 raw words (111823 effective words) took 0.2s, 503569 effective words/s
INFO - 2023-11-30 14:16:58,746: EPOCH 19: training on 191080 raw words (111852 effective words) took 0.2s, 519144 effective words/s
INFO - 2023-11-30 14:16:58,746: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234055 effective words) took 5.6s, 398243 effective words/s', 'datetime': '2023-11-30T14:16:58.746850', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:58,747: collecting all words and their counts
INFO - 2023-11-30 14:16:58,747: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:16:58,773: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:16:58,773: Updating model with new vocabulary
INFO - 2023-11-30 14:16:58,784: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:16:58.784551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:58,798: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:16:58,798: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:16:58,798: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 112066.96044136788 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:16:58.798876', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:16:58,820: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:16:58,820: updating layer weights
INFO - 2023-11-30 14:16:58,821: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:16:58.821163', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:16:58,821: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:16:58,821: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:16:58.821335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:16:59,041: EPOCH 0: training on 191080 raw words (111963 effective words) took 0.2s, 514037 effective words/s
INFO - 2023-11-30 14:16:59,263: EPOCH 1: training on 191080 raw words (111921 effective words) took 0.2s, 509161 effective words/s
INFO - 2023-11-30 14:16:59,486: EPOCH 2: training on 191080 raw words (112312 effective words) took 0.2s, 508943 effective words/s
INFO - 2023-11-30 14:16:59,714: EPOCH 3: training on 191080 raw words (112111 effective words) took 0.2s, 496786 effective words/s
INFO - 2023-11-30 14:16:59,933: EPOCH 4: training on 191080 raw words (112056 effective words) took 0.2s, 515686 effective words/s
INFO - 2023-11-30 14:17:00,189: EPOCH 5: training on 191080 raw words (112032 effective words) took 0.3s, 441489 effective words/s
INFO - 2023-11-30 14:17:00,408: EPOCH 6: training on 191080 raw words (111778 effective words) took 0.2s, 516939 effective words/s
INFO - 2023-11-30 14:17:00,647: EPOCH 7: training on 191080 raw words (112157 effective words) took 0.2s, 473100 effective words/s
INFO - 2023-11-30 14:17:00,869: EPOCH 8: training on 191080 raw words (111993 effective words) took 0.2s, 509022 effective words/s
INFO - 2023-11-30 14:17:01,095: EPOCH 9: training on 191080 raw words (112173 effective words) took 0.2s, 501114 effective words/s
INFO - 2023-11-30 14:17:01,339: EPOCH 10: training on 191080 raw words (111797 effective words) took 0.2s, 463315 effective words/s
INFO - 2023-11-30 14:17:01,556: EPOCH 11: training on 191080 raw words (111908 effective words) took 0.2s, 521658 effective words/s
INFO - 2023-11-30 14:17:01,777: EPOCH 12: training on 191080 raw words (112271 effective words) took 0.2s, 511417 effective words/s
INFO - 2023-11-30 14:17:01,996: EPOCH 13: training on 191080 raw words (112275 effective words) took 0.2s, 518708 effective words/s
INFO - 2023-11-30 14:17:02,222: EPOCH 14: training on 191080 raw words (112047 effective words) took 0.2s, 500023 effective words/s
INFO - 2023-11-30 14:17:02,447: EPOCH 15: training on 191080 raw words (112188 effective words) took 0.2s, 504846 effective words/s
INFO - 2023-11-30 14:17:02,673: EPOCH 16: training on 191080 raw words (112068 effective words) took 0.2s, 499091 effective words/s
INFO - 2023-11-30 14:17:02,898: EPOCH 17: training on 191080 raw words (112060 effective words) took 0.2s, 505348 effective words/s
INFO - 2023-11-30 14:17:03,151: EPOCH 18: training on 191080 raw words (112273 effective words) took 0.3s, 446846 effective words/s
INFO - 2023-11-30 14:17:03,371: EPOCH 19: training on 191080 raw words (111941 effective words) took 0.2s, 514106 effective words/s
INFO - 2023-11-30 14:17:03,371: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2241324 effective words) took 4.6s, 492552 effective words/s', 'datetime': '2023-11-30T14:17:03.371852', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:03,371: collecting all words and their counts
INFO - 2023-11-30 14:17:03,372: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:03,397: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:03,397: Updating model with new vocabulary
INFO - 2023-11-30 14:17:03,409: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:03.409122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:03,423: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:03,423: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:03,423: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111815.75893655527 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:03.423345', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:03,445: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:03,445: updating layer weights
INFO - 2023-11-30 14:17:03,445: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:03.445827', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:03,445: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:03,446: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:03.446015', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:03,646: EPOCH 0: training on 191080 raw words (111727 effective words) took 0.2s, 562134 effective words/s
INFO - 2023-11-30 14:17:03,883: EPOCH 1: training on 191080 raw words (111767 effective words) took 0.2s, 477116 effective words/s
INFO - 2023-11-30 14:17:04,087: EPOCH 2: training on 191080 raw words (111908 effective words) took 0.2s, 553951 effective words/s
INFO - 2023-11-30 14:17:04,294: EPOCH 3: training on 191080 raw words (111985 effective words) took 0.2s, 547749 effective words/s
INFO - 2023-11-30 14:17:04,501: EPOCH 4: training on 191080 raw words (111835 effective words) took 0.2s, 548205 effective words/s
INFO - 2023-11-30 14:17:04,738: EPOCH 5: training on 191080 raw words (111835 effective words) took 0.2s, 474844 effective words/s
INFO - 2023-11-30 14:17:04,943: EPOCH 6: training on 191080 raw words (111881 effective words) took 0.2s, 553024 effective words/s
INFO - 2023-11-30 14:17:05,144: EPOCH 7: training on 191080 raw words (111927 effective words) took 0.2s, 564067 effective words/s
INFO - 2023-11-30 14:17:05,347: EPOCH 8: training on 191080 raw words (112020 effective words) took 0.2s, 559445 effective words/s
INFO - 2023-11-30 14:17:05,551: EPOCH 9: training on 191080 raw words (111861 effective words) took 0.2s, 554263 effective words/s
INFO - 2023-11-30 14:17:05,758: EPOCH 10: training on 191080 raw words (111831 effective words) took 0.2s, 544823 effective words/s
INFO - 2023-11-30 14:17:05,965: EPOCH 11: training on 191080 raw words (111909 effective words) took 0.2s, 548894 effective words/s
INFO - 2023-11-30 14:17:06,169: EPOCH 12: training on 191080 raw words (111810 effective words) took 0.2s, 552580 effective words/s
INFO - 2023-11-30 14:17:06,372: EPOCH 13: training on 191080 raw words (111897 effective words) took 0.2s, 556773 effective words/s
INFO - 2023-11-30 14:17:06,579: EPOCH 14: training on 191080 raw words (111986 effective words) took 0.2s, 548447 effective words/s
INFO - 2023-11-30 14:17:06,786: EPOCH 15: training on 191080 raw words (111894 effective words) took 0.2s, 548524 effective words/s
INFO - 2023-11-30 14:17:06,987: EPOCH 16: training on 191080 raw words (111690 effective words) took 0.2s, 561033 effective words/s
INFO - 2023-11-30 14:17:07,194: EPOCH 17: training on 191080 raw words (111854 effective words) took 0.2s, 547017 effective words/s
INFO - 2023-11-30 14:17:07,399: EPOCH 18: training on 191080 raw words (111915 effective words) took 0.2s, 552657 effective words/s
INFO - 2023-11-30 14:17:07,602: EPOCH 19: training on 191080 raw words (111754 effective words) took 0.2s, 553961 effective words/s
INFO - 2023-11-30 14:17:07,603: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2237286 effective words) took 4.2s, 538188 effective words/s', 'datetime': '2023-11-30T14:17:07.603173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:07,603: collecting all words and their counts
INFO - 2023-11-30 14:17:07,603: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:07,629: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:07,629: Updating model with new vocabulary
INFO - 2023-11-30 14:17:07,641: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:07.641030', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:07,655: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:07,655: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:17:07,655: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111523.40873544113 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:17:07.655384', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:07,678: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:07,678: updating layer weights
INFO - 2023-11-30 14:17:07,679: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:07.678981', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:07,679: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:07,679: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:07.679215', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:07,901: EPOCH 0: training on 191080 raw words (111371 effective words) took 0.2s, 506230 effective words/s
INFO - 2023-11-30 14:17:08,138: EPOCH 1: training on 191080 raw words (111377 effective words) took 0.2s, 474507 effective words/s
INFO - 2023-11-30 14:17:08,364: EPOCH 2: training on 191080 raw words (111314 effective words) took 0.2s, 497388 effective words/s
INFO - 2023-11-30 14:17:08,635: EPOCH 3: training on 191080 raw words (111718 effective words) took 0.3s, 416292 effective words/s
INFO - 2023-11-30 14:17:08,855: EPOCH 4: training on 191080 raw words (111484 effective words) took 0.2s, 512422 effective words/s
INFO - 2023-11-30 14:17:09,075: EPOCH 5: training on 191080 raw words (111631 effective words) took 0.2s, 510810 effective words/s
INFO - 2023-11-30 14:17:09,296: EPOCH 6: training on 191080 raw words (111429 effective words) took 0.2s, 510000 effective words/s
INFO - 2023-11-30 14:17:09,517: EPOCH 7: training on 191080 raw words (111456 effective words) took 0.2s, 510348 effective words/s
INFO - 2023-11-30 14:17:09,737: EPOCH 8: training on 191080 raw words (111739 effective words) took 0.2s, 512790 effective words/s
INFO - 2023-11-30 14:17:09,962: EPOCH 9: training on 191080 raw words (111521 effective words) took 0.2s, 500138 effective words/s
INFO - 2023-11-30 14:17:10,198: EPOCH 10: training on 191080 raw words (111293 effective words) took 0.2s, 477006 effective words/s
INFO - 2023-11-30 14:17:10,440: EPOCH 11: training on 191080 raw words (111668 effective words) took 0.2s, 465653 effective words/s
INFO - 2023-11-30 14:17:10,661: EPOCH 12: training on 191080 raw words (111299 effective words) took 0.2s, 508863 effective words/s
INFO - 2023-11-30 14:17:10,885: EPOCH 13: training on 191080 raw words (111680 effective words) took 0.2s, 502892 effective words/s
INFO - 2023-11-30 14:17:11,107: EPOCH 14: training on 191080 raw words (111410 effective words) took 0.2s, 508359 effective words/s
INFO - 2023-11-30 14:17:11,329: EPOCH 15: training on 191080 raw words (111550 effective words) took 0.2s, 506128 effective words/s
INFO - 2023-11-30 14:17:11,551: EPOCH 16: training on 191080 raw words (111559 effective words) took 0.2s, 509260 effective words/s
INFO - 2023-11-30 14:17:11,768: EPOCH 17: training on 191080 raw words (111557 effective words) took 0.2s, 517881 effective words/s
INFO - 2023-11-30 14:17:11,993: EPOCH 18: training on 191080 raw words (111468 effective words) took 0.2s, 501529 effective words/s
INFO - 2023-11-30 14:17:12,223: EPOCH 19: training on 191080 raw words (111572 effective words) took 0.2s, 489336 effective words/s
INFO - 2023-11-30 14:17:12,223: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230096 effective words) took 4.5s, 490747 effective words/s', 'datetime': '2023-11-30T14:17:12.223634', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:12,223: collecting all words and their counts
INFO - 2023-11-30 14:17:12,223: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:12,249: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:12,249: Updating model with new vocabulary
INFO - 2023-11-30 14:17:12,260: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:12.260885', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:12,276: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:12,276: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:12,276: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111618.4645126292 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:17:12.276620', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:12,301: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:12,301: updating layer weights
INFO - 2023-11-30 14:17:12,301: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:12.301480', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:12,301: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:12,301: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:12.301725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:12,528: EPOCH 0: training on 191080 raw words (111591 effective words) took 0.2s, 497241 effective words/s
INFO - 2023-11-30 14:17:12,737: EPOCH 1: training on 191080 raw words (111616 effective words) took 0.2s, 541760 effective words/s
INFO - 2023-11-30 14:17:12,946: EPOCH 2: training on 191080 raw words (111845 effective words) took 0.2s, 539118 effective words/s
INFO - 2023-11-30 14:17:13,156: EPOCH 3: training on 191080 raw words (111597 effective words) took 0.2s, 537859 effective words/s
INFO - 2023-11-30 14:17:13,427: EPOCH 4: training on 191080 raw words (111800 effective words) took 0.3s, 416357 effective words/s
INFO - 2023-11-30 14:17:13,627: EPOCH 5: training on 191080 raw words (111519 effective words) took 0.2s, 562404 effective words/s
INFO - 2023-11-30 14:17:13,833: EPOCH 6: training on 191080 raw words (111637 effective words) took 0.2s, 549294 effective words/s
INFO - 2023-11-30 14:17:14,041: EPOCH 7: training on 191080 raw words (111505 effective words) took 0.2s, 541671 effective words/s
INFO - 2023-11-30 14:17:14,255: EPOCH 8: training on 191080 raw words (111628 effective words) took 0.2s, 526792 effective words/s
INFO - 2023-11-30 14:17:14,464: EPOCH 9: training on 191080 raw words (111583 effective words) took 0.2s, 539242 effective words/s
INFO - 2023-11-30 14:17:14,671: EPOCH 10: training on 191080 raw words (111458 effective words) took 0.2s, 545499 effective words/s
INFO - 2023-11-30 14:17:14,878: EPOCH 11: training on 191080 raw words (111602 effective words) took 0.2s, 543727 effective words/s
INFO - 2023-11-30 14:17:15,086: EPOCH 12: training on 191080 raw words (111741 effective words) took 0.2s, 544554 effective words/s
INFO - 2023-11-30 14:17:15,294: EPOCH 13: training on 191080 raw words (111578 effective words) took 0.2s, 542698 effective words/s
INFO - 2023-11-30 14:17:15,531: EPOCH 14: training on 191080 raw words (111687 effective words) took 0.2s, 475571 effective words/s
INFO - 2023-11-30 14:17:15,803: EPOCH 15: training on 191080 raw words (111450 effective words) took 0.3s, 414329 effective words/s
INFO - 2023-11-30 14:17:16,073: EPOCH 16: training on 191080 raw words (111521 effective words) took 0.3s, 416965 effective words/s
INFO - 2023-11-30 14:17:16,353: EPOCH 17: training on 191080 raw words (111479 effective words) took 0.3s, 403446 effective words/s
INFO - 2023-11-30 14:17:16,623: EPOCH 18: training on 191080 raw words (111845 effective words) took 0.3s, 418955 effective words/s
INFO - 2023-11-30 14:17:16,999: EPOCH 19: training on 191080 raw words (111647 effective words) took 0.4s, 299591 effective words/s
INFO - 2023-11-30 14:17:16,999: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232329 effective words) took 4.7s, 475189 effective words/s', 'datetime': '2023-11-30T14:17:16.999610', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:16,999: collecting all words and their counts
INFO - 2023-11-30 14:17:17,000: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:17,035: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:17,036: Updating model with new vocabulary
INFO - 2023-11-30 14:17:17,052: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:17.052208', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:17,073: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:17,073: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:17,073: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111735.7201547361 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:17.073350', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:17,104: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:17,104: updating layer weights
INFO - 2023-11-30 14:17:17,105: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:17.104987', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:17,105: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:17,105: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:17.105311', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:17,409: EPOCH 0: training on 191080 raw words (111719 effective words) took 0.3s, 371460 effective words/s
INFO - 2023-11-30 14:17:17,701: EPOCH 1: training on 191080 raw words (111484 effective words) took 0.3s, 385470 effective words/s
INFO - 2023-11-30 14:17:18,003: EPOCH 2: training on 191080 raw words (111833 effective words) took 0.3s, 373781 effective words/s
INFO - 2023-11-30 14:17:18,303: EPOCH 3: training on 191080 raw words (111771 effective words) took 0.3s, 376722 effective words/s
INFO - 2023-11-30 14:17:18,627: EPOCH 4: training on 191080 raw words (111914 effective words) took 0.3s, 348550 effective words/s
INFO - 2023-11-30 14:17:18,929: EPOCH 5: training on 191080 raw words (111710 effective words) took 0.3s, 374096 effective words/s
INFO - 2023-11-30 14:17:19,228: EPOCH 6: training on 191080 raw words (111551 effective words) took 0.3s, 376173 effective words/s
INFO - 2023-11-30 14:17:19,549: EPOCH 7: training on 191080 raw words (111854 effective words) took 0.3s, 352200 effective words/s
INFO - 2023-11-30 14:17:19,851: EPOCH 8: training on 191080 raw words (111572 effective words) took 0.3s, 373230 effective words/s
INFO - 2023-11-30 14:17:20,152: EPOCH 9: training on 191080 raw words (111858 effective words) took 0.3s, 374944 effective words/s
INFO - 2023-11-30 14:17:20,454: EPOCH 10: training on 191080 raw words (111519 effective words) took 0.3s, 372593 effective words/s
INFO - 2023-11-30 14:17:20,782: EPOCH 11: training on 191080 raw words (111732 effective words) took 0.3s, 343518 effective words/s
INFO - 2023-11-30 14:17:21,082: EPOCH 12: training on 191080 raw words (111647 effective words) took 0.3s, 376022 effective words/s
INFO - 2023-11-30 14:17:21,388: EPOCH 13: training on 191080 raw words (111926 effective words) took 0.3s, 370354 effective words/s
INFO - 2023-11-30 14:17:21,696: EPOCH 14: training on 191080 raw words (111771 effective words) took 0.3s, 365486 effective words/s
INFO - 2023-11-30 14:17:21,970: EPOCH 15: training on 191080 raw words (111664 effective words) took 0.3s, 412371 effective words/s
INFO - 2023-11-30 14:17:22,239: EPOCH 16: training on 191080 raw words (111777 effective words) took 0.3s, 419892 effective words/s
INFO - 2023-11-30 14:17:22,557: EPOCH 17: training on 191080 raw words (111830 effective words) took 0.3s, 354958 effective words/s
INFO - 2023-11-30 14:17:22,845: EPOCH 18: training on 191080 raw words (111617 effective words) took 0.3s, 391602 effective words/s
INFO - 2023-11-30 14:17:23,119: EPOCH 19: training on 191080 raw words (111925 effective words) took 0.3s, 412771 effective words/s
INFO - 2023-11-30 14:17:23,120: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234674 effective words) took 6.0s, 371546 effective words/s', 'datetime': '2023-11-30T14:17:23.120004', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:23,120: collecting all words and their counts
INFO - 2023-11-30 14:17:23,120: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:23,154: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:23,154: Updating model with new vocabulary
INFO - 2023-11-30 14:17:23,169: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:23.169116', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:23,188: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:23,188: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:23,188: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111868.94449979471 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:23.188526', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:23,218: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:23,218: updating layer weights
INFO - 2023-11-30 14:17:23,219: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:23.219346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:23,219: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:23,219: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:23.219652', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:23,503: EPOCH 0: training on 191080 raw words (111811 effective words) took 0.3s, 396669 effective words/s
INFO - 2023-11-30 14:17:23,791: EPOCH 1: training on 191080 raw words (111578 effective words) took 0.3s, 391339 effective words/s
INFO - 2023-11-30 14:17:24,108: EPOCH 2: training on 191080 raw words (111743 effective words) took 0.3s, 356126 effective words/s
INFO - 2023-11-30 14:17:24,413: EPOCH 3: training on 191080 raw words (111997 effective words) took 0.3s, 370784 effective words/s
INFO - 2023-11-30 14:17:24,707: EPOCH 4: training on 191080 raw words (111891 effective words) took 0.3s, 384683 effective words/s
INFO - 2023-11-30 14:17:24,988: EPOCH 5: training on 191080 raw words (111737 effective words) took 0.3s, 400712 effective words/s
INFO - 2023-11-30 14:17:25,265: EPOCH 6: training on 191080 raw words (111840 effective words) took 0.3s, 409304 effective words/s
INFO - 2023-11-30 14:17:25,558: EPOCH 7: training on 191080 raw words (111916 effective words) took 0.3s, 385299 effective words/s
INFO - 2023-11-30 14:17:25,837: EPOCH 8: training on 191080 raw words (111826 effective words) took 0.3s, 405118 effective words/s
INFO - 2023-11-30 14:17:26,145: EPOCH 9: training on 191080 raw words (111657 effective words) took 0.3s, 365292 effective words/s
INFO - 2023-11-30 14:17:26,394: EPOCH 10: training on 191080 raw words (111904 effective words) took 0.2s, 455351 effective words/s
INFO - 2023-11-30 14:17:26,634: EPOCH 11: training on 191080 raw words (111918 effective words) took 0.2s, 471617 effective words/s
INFO - 2023-11-30 14:17:26,893: EPOCH 12: training on 191080 raw words (111754 effective words) took 0.3s, 435405 effective words/s
INFO - 2023-11-30 14:17:27,144: EPOCH 13: training on 191080 raw words (111773 effective words) took 0.2s, 452363 effective words/s
INFO - 2023-11-30 14:17:27,402: EPOCH 14: training on 191080 raw words (112037 effective words) took 0.3s, 439863 effective words/s
INFO - 2023-11-30 14:17:27,660: EPOCH 15: training on 191080 raw words (111713 effective words) took 0.3s, 437047 effective words/s
INFO - 2023-11-30 14:17:27,911: EPOCH 16: training on 191080 raw words (111739 effective words) took 0.2s, 450212 effective words/s
INFO - 2023-11-30 14:17:28,151: EPOCH 17: training on 191080 raw words (111893 effective words) took 0.2s, 472230 effective words/s
INFO - 2023-11-30 14:17:28,395: EPOCH 18: training on 191080 raw words (111991 effective words) took 0.2s, 462892 effective words/s
INFO - 2023-11-30 14:17:28,643: EPOCH 19: training on 191080 raw words (111893 effective words) took 0.2s, 456539 effective words/s
INFO - 2023-11-30 14:17:28,643: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236611 effective words) took 5.4s, 412343 effective words/s', 'datetime': '2023-11-30T14:17:28.643946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:28,644: collecting all words and their counts
INFO - 2023-11-30 14:17:28,644: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:28,679: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:28,679: Updating model with new vocabulary
INFO - 2023-11-30 14:17:28,696: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:28.696145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:28,717: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:28,718: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:17:28,718: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111690.86855920748 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:28.718330', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:28,751: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:28,751: updating layer weights
INFO - 2023-11-30 14:17:28,751: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:28.751551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:28,751: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:28,751: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:28.751950', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:29,034: EPOCH 0: training on 191080 raw words (111602 effective words) took 0.3s, 400297 effective words/s
INFO - 2023-11-30 14:17:29,313: EPOCH 1: training on 191080 raw words (111668 effective words) took 0.3s, 403274 effective words/s
INFO - 2023-11-30 14:17:29,579: EPOCH 2: training on 191080 raw words (111878 effective words) took 0.3s, 426162 effective words/s
INFO - 2023-11-30 14:17:29,854: EPOCH 3: training on 191080 raw words (111310 effective words) took 0.3s, 408159 effective words/s
INFO - 2023-11-30 14:17:30,124: EPOCH 4: training on 191080 raw words (111782 effective words) took 0.3s, 418572 effective words/s
INFO - 2023-11-30 14:17:30,389: EPOCH 5: training on 191080 raw words (111639 effective words) took 0.3s, 424818 effective words/s
INFO - 2023-11-30 14:17:30,663: EPOCH 6: training on 191080 raw words (111774 effective words) took 0.3s, 412106 effective words/s
INFO - 2023-11-30 14:17:30,939: EPOCH 7: training on 191080 raw words (111676 effective words) took 0.3s, 408681 effective words/s
INFO - 2023-11-30 14:17:31,209: EPOCH 8: training on 191080 raw words (111753 effective words) took 0.3s, 419077 effective words/s
INFO - 2023-11-30 14:17:31,472: EPOCH 9: training on 191080 raw words (111793 effective words) took 0.3s, 430057 effective words/s
INFO - 2023-11-30 14:17:31,741: EPOCH 10: training on 191080 raw words (111570 effective words) took 0.3s, 419072 effective words/s
INFO - 2023-11-30 14:17:32,011: EPOCH 11: training on 191080 raw words (111914 effective words) took 0.3s, 419399 effective words/s
INFO - 2023-11-30 14:17:32,289: EPOCH 12: training on 191080 raw words (111710 effective words) took 0.3s, 406220 effective words/s
INFO - 2023-11-30 14:17:32,554: EPOCH 13: training on 191080 raw words (111632 effective words) took 0.3s, 425767 effective words/s
INFO - 2023-11-30 14:17:32,815: EPOCH 14: training on 191080 raw words (111701 effective words) took 0.3s, 431966 effective words/s
INFO - 2023-11-30 14:17:33,080: EPOCH 15: training on 191080 raw words (111628 effective words) took 0.3s, 425890 effective words/s
INFO - 2023-11-30 14:17:33,377: EPOCH 16: training on 191080 raw words (111732 effective words) took 0.3s, 380465 effective words/s
INFO - 2023-11-30 14:17:33,649: EPOCH 17: training on 191080 raw words (111636 effective words) took 0.3s, 415600 effective words/s
INFO - 2023-11-30 14:17:33,922: EPOCH 18: training on 191080 raw words (111869 effective words) took 0.3s, 413300 effective words/s
INFO - 2023-11-30 14:17:34,181: EPOCH 19: training on 191080 raw words (111673 effective words) took 0.3s, 435638 effective words/s
INFO - 2023-11-30 14:17:34,181: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233940 effective words) took 5.4s, 411447 effective words/s', 'datetime': '2023-11-30T14:17:34.181608', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:34,181: collecting all words and their counts
INFO - 2023-11-30 14:17:34,182: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:34,216: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:34,216: Updating model with new vocabulary
INFO - 2023-11-30 14:17:34,232: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:34.232055', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:34,251: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:34,252: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:17:34,252: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111689.51311126236 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:34.252256', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:34,284: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:34,284: updating layer weights
INFO - 2023-11-30 14:17:34,285: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:34.285084', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:34,285: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:34,285: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:34.285389', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:34,567: EPOCH 0: training on 191080 raw words (111923 effective words) took 0.3s, 400217 effective words/s
INFO - 2023-11-30 14:17:34,851: EPOCH 1: training on 191080 raw words (111933 effective words) took 0.3s, 398382 effective words/s
INFO - 2023-11-30 14:17:35,117: EPOCH 2: training on 191080 raw words (111652 effective words) took 0.3s, 425353 effective words/s
INFO - 2023-11-30 14:17:35,401: EPOCH 3: training on 191080 raw words (111710 effective words) took 0.3s, 396270 effective words/s
INFO - 2023-11-30 14:17:35,685: EPOCH 4: training on 191080 raw words (111602 effective words) took 0.3s, 397813 effective words/s
INFO - 2023-11-30 14:17:35,959: EPOCH 5: training on 191080 raw words (111522 effective words) took 0.3s, 410518 effective words/s
INFO - 2023-11-30 14:17:36,263: EPOCH 6: training on 191080 raw words (111662 effective words) took 0.3s, 370212 effective words/s
INFO - 2023-11-30 14:17:36,515: EPOCH 7: training on 191080 raw words (111638 effective words) took 0.2s, 448613 effective words/s
INFO - 2023-11-30 14:17:36,761: EPOCH 8: training on 191080 raw words (111689 effective words) took 0.2s, 458682 effective words/s
INFO - 2023-11-30 14:17:37,008: EPOCH 9: training on 191080 raw words (111753 effective words) took 0.2s, 457875 effective words/s
INFO - 2023-11-30 14:17:37,255: EPOCH 10: training on 191080 raw words (111560 effective words) took 0.2s, 456821 effective words/s
INFO - 2023-11-30 14:17:37,502: EPOCH 11: training on 191080 raw words (111874 effective words) took 0.2s, 456851 effective words/s
INFO - 2023-11-30 14:17:37,763: EPOCH 12: training on 191080 raw words (111485 effective words) took 0.3s, 433543 effective words/s
INFO - 2023-11-30 14:17:38,010: EPOCH 13: training on 191080 raw words (111619 effective words) took 0.2s, 455473 effective words/s
INFO - 2023-11-30 14:17:38,260: EPOCH 14: training on 191080 raw words (111543 effective words) took 0.2s, 452637 effective words/s
INFO - 2023-11-30 14:17:38,506: EPOCH 15: training on 191080 raw words (111637 effective words) took 0.2s, 459213 effective words/s
INFO - 2023-11-30 14:17:38,756: EPOCH 16: training on 191080 raw words (111577 effective words) took 0.2s, 451236 effective words/s
INFO - 2023-11-30 14:17:39,013: EPOCH 17: training on 191080 raw words (111592 effective words) took 0.3s, 438793 effective words/s
INFO - 2023-11-30 14:17:39,268: EPOCH 18: training on 191080 raw words (111490 effective words) took 0.3s, 442170 effective words/s
INFO - 2023-11-30 14:17:39,510: EPOCH 19: training on 191080 raw words (111555 effective words) took 0.2s, 467025 effective words/s
INFO - 2023-11-30 14:17:39,510: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233016 effective words) took 5.2s, 427334 effective words/s', 'datetime': '2023-11-30T14:17:39.510957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:39,511: collecting all words and their counts
INFO - 2023-11-30 14:17:39,511: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:39,545: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:39,545: Updating model with new vocabulary
INFO - 2023-11-30 14:17:39,560: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:39.560088', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:39,578: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:39,578: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:17:39,581: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111609.51301550434 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:17:39.581681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:39,611: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:39,611: updating layer weights
INFO - 2023-11-30 14:17:39,611: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:39.611882', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:39,612: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:39,612: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:39.612088', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:39,888: EPOCH 0: training on 191080 raw words (111611 effective words) took 0.3s, 407908 effective words/s
INFO - 2023-11-30 14:17:40,162: EPOCH 1: training on 191080 raw words (111625 effective words) took 0.3s, 412603 effective words/s
INFO - 2023-11-30 14:17:40,430: EPOCH 2: training on 191080 raw words (111609 effective words) took 0.3s, 420768 effective words/s
INFO - 2023-11-30 14:17:40,692: EPOCH 3: training on 191080 raw words (111499 effective words) took 0.3s, 430021 effective words/s
INFO - 2023-11-30 14:17:41,012: EPOCH 4: training on 191080 raw words (111775 effective words) took 0.3s, 351671 effective words/s
INFO - 2023-11-30 14:17:41,332: EPOCH 5: training on 191080 raw words (111602 effective words) took 0.3s, 376599 effective words/s
INFO - 2023-11-30 14:17:41,605: EPOCH 6: training on 191080 raw words (111299 effective words) took 0.3s, 411865 effective words/s
INFO - 2023-11-30 14:17:41,868: EPOCH 7: training on 191080 raw words (111570 effective words) took 0.3s, 427871 effective words/s
INFO - 2023-11-30 14:17:42,139: EPOCH 8: training on 191080 raw words (111603 effective words) took 0.3s, 417365 effective words/s
INFO - 2023-11-30 14:17:42,442: EPOCH 9: training on 191080 raw words (111619 effective words) took 0.3s, 371748 effective words/s
INFO - 2023-11-30 14:17:42,736: EPOCH 10: training on 191080 raw words (111580 effective words) took 0.3s, 382833 effective words/s
INFO - 2023-11-30 14:17:43,037: EPOCH 11: training on 191080 raw words (111705 effective words) took 0.3s, 374257 effective words/s
INFO - 2023-11-30 14:17:43,335: EPOCH 12: training on 191080 raw words (111679 effective words) took 0.3s, 380332 effective words/s
INFO - 2023-11-30 14:17:43,617: EPOCH 13: training on 191080 raw words (111346 effective words) took 0.3s, 398425 effective words/s
INFO - 2023-11-30 14:17:43,883: EPOCH 14: training on 191080 raw words (111526 effective words) took 0.3s, 424371 effective words/s
INFO - 2023-11-30 14:17:44,148: EPOCH 15: training on 191080 raw words (111543 effective words) took 0.3s, 424685 effective words/s
INFO - 2023-11-30 14:17:44,422: EPOCH 16: training on 191080 raw words (111508 effective words) took 0.3s, 411916 effective words/s
INFO - 2023-11-30 14:17:44,719: EPOCH 17: training on 191080 raw words (111561 effective words) took 0.3s, 379361 effective words/s
INFO - 2023-11-30 14:17:45,002: EPOCH 18: training on 191080 raw words (111351 effective words) took 0.3s, 398272 effective words/s
INFO - 2023-11-30 14:17:45,267: EPOCH 19: training on 191080 raw words (111572 effective words) took 0.3s, 424246 effective words/s
INFO - 2023-11-30 14:17:45,267: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231183 effective words) took 5.7s, 394505 effective words/s', 'datetime': '2023-11-30T14:17:45.267912', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:45,268: collecting all words and their counts
INFO - 2023-11-30 14:17:45,268: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:45,303: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:45,303: Updating model with new vocabulary
INFO - 2023-11-30 14:17:45,320: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:45.320296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:45,342: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:45,342: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:45,342: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111745.02656451846 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:17:45.342513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:45,374: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:45,374: updating layer weights
INFO - 2023-11-30 14:17:45,375: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:45.375301', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:45,375: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:45,375: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:45.375603', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:45,679: EPOCH 0: training on 191080 raw words (111656 effective words) took 0.3s, 370414 effective words/s
INFO - 2023-11-30 14:17:45,931: EPOCH 1: training on 191080 raw words (111832 effective words) took 0.2s, 449910 effective words/s
INFO - 2023-11-30 14:17:46,181: EPOCH 2: training on 191080 raw words (111755 effective words) took 0.2s, 452789 effective words/s
INFO - 2023-11-30 14:17:46,436: EPOCH 3: training on 191080 raw words (111668 effective words) took 0.3s, 442871 effective words/s
INFO - 2023-11-30 14:17:46,685: EPOCH 4: training on 191080 raw words (111699 effective words) took 0.2s, 452546 effective words/s
INFO - 2023-11-30 14:17:46,930: EPOCH 5: training on 191080 raw words (111757 effective words) took 0.2s, 461601 effective words/s
INFO - 2023-11-30 14:17:47,181: EPOCH 6: training on 191080 raw words (111746 effective words) took 0.2s, 450975 effective words/s
INFO - 2023-11-30 14:17:47,443: EPOCH 7: training on 191080 raw words (111515 effective words) took 0.3s, 429810 effective words/s
INFO - 2023-11-30 14:17:47,694: EPOCH 8: training on 191080 raw words (111604 effective words) took 0.2s, 450178 effective words/s
INFO - 2023-11-30 14:17:47,941: EPOCH 9: training on 191080 raw words (111846 effective words) took 0.2s, 457841 effective words/s
INFO - 2023-11-30 14:17:48,190: EPOCH 10: training on 191080 raw words (111727 effective words) took 0.2s, 454739 effective words/s
INFO - 2023-11-30 14:17:48,441: EPOCH 11: training on 191080 raw words (111806 effective words) took 0.2s, 449642 effective words/s
INFO - 2023-11-30 14:17:48,686: EPOCH 12: training on 191080 raw words (111773 effective words) took 0.2s, 462590 effective words/s
INFO - 2023-11-30 14:17:48,926: EPOCH 13: training on 191080 raw words (111634 effective words) took 0.2s, 469733 effective words/s
INFO - 2023-11-30 14:17:49,174: EPOCH 14: training on 191080 raw words (111727 effective words) took 0.2s, 456477 effective words/s
INFO - 2023-11-30 14:17:49,418: EPOCH 15: training on 191080 raw words (111730 effective words) took 0.2s, 462941 effective words/s
INFO - 2023-11-30 14:17:49,666: EPOCH 16: training on 191080 raw words (111912 effective words) took 0.2s, 456361 effective words/s
INFO - 2023-11-30 14:17:49,915: EPOCH 17: training on 191080 raw words (111522 effective words) took 0.2s, 451545 effective words/s
INFO - 2023-11-30 14:17:50,167: EPOCH 18: training on 191080 raw words (111832 effective words) took 0.2s, 449779 effective words/s
INFO - 2023-11-30 14:17:50,409: EPOCH 19: training on 191080 raw words (111800 effective words) took 0.2s, 467771 effective words/s
INFO - 2023-11-30 14:17:50,409: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234541 effective words) took 5.0s, 443926 effective words/s', 'datetime': '2023-11-30T14:17:50.409337', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:50,409: collecting all words and their counts
INFO - 2023-11-30 14:17:50,409: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:50,443: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:50,443: Updating model with new vocabulary
INFO - 2023-11-30 14:17:50,459: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:50.459230', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:50,479: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:50,479: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:17:50,479: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111337.37881075096 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:17:50.479643', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:50,512: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:50,512: updating layer weights
INFO - 2023-11-30 14:17:50,512: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:50.512880', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:50,513: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:50,513: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:50.513146', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:50,816: EPOCH 0: training on 191080 raw words (111364 effective words) took 0.3s, 370022 effective words/s
INFO - 2023-11-30 14:17:51,097: EPOCH 1: training on 191080 raw words (111269 effective words) took 0.3s, 401157 effective words/s
INFO - 2023-11-30 14:17:51,371: EPOCH 2: training on 191080 raw words (111226 effective words) took 0.3s, 410180 effective words/s
INFO - 2023-11-30 14:17:51,639: EPOCH 3: training on 191080 raw words (111158 effective words) took 0.3s, 418258 effective words/s
INFO - 2023-11-30 14:17:51,907: EPOCH 4: training on 191080 raw words (111334 effective words) took 0.3s, 420318 effective words/s
INFO - 2023-11-30 14:17:52,172: EPOCH 5: training on 191080 raw words (111463 effective words) took 0.3s, 424922 effective words/s
INFO - 2023-11-30 14:17:52,446: EPOCH 6: training on 191080 raw words (111184 effective words) took 0.3s, 410103 effective words/s
INFO - 2023-11-30 14:17:52,712: EPOCH 7: training on 191080 raw words (111592 effective words) took 0.3s, 424971 effective words/s
INFO - 2023-11-30 14:17:52,988: EPOCH 8: training on 191080 raw words (111664 effective words) took 0.3s, 408660 effective words/s
INFO - 2023-11-30 14:17:53,254: EPOCH 9: training on 191080 raw words (111188 effective words) took 0.3s, 422533 effective words/s
INFO - 2023-11-30 14:17:53,538: EPOCH 10: training on 191080 raw words (111399 effective words) took 0.3s, 395181 effective words/s
INFO - 2023-11-30 14:17:53,815: EPOCH 11: training on 191080 raw words (111263 effective words) took 0.3s, 406035 effective words/s
INFO - 2023-11-30 14:17:54,079: EPOCH 12: training on 191080 raw words (111402 effective words) took 0.3s, 426691 effective words/s
INFO - 2023-11-30 14:17:54,407: EPOCH 13: training on 191080 raw words (111262 effective words) took 0.3s, 342084 effective words/s
INFO - 2023-11-30 14:17:54,700: EPOCH 14: training on 191080 raw words (111461 effective words) took 0.3s, 386339 effective words/s
INFO - 2023-11-30 14:17:54,982: EPOCH 15: training on 191080 raw words (111414 effective words) took 0.3s, 399098 effective words/s
INFO - 2023-11-30 14:17:55,251: EPOCH 16: training on 191080 raw words (111435 effective words) took 0.3s, 418477 effective words/s
INFO - 2023-11-30 14:17:55,517: EPOCH 17: training on 191080 raw words (111577 effective words) took 0.3s, 423510 effective words/s
INFO - 2023-11-30 14:17:55,783: EPOCH 18: training on 191080 raw words (111251 effective words) took 0.3s, 423335 effective words/s
INFO - 2023-11-30 14:17:56,049: EPOCH 19: training on 191080 raw words (111445 effective words) took 0.3s, 423658 effective words/s
INFO - 2023-11-30 14:17:56,049: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2227351 effective words) took 5.5s, 402329 effective words/s', 'datetime': '2023-11-30T14:17:56.049459', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:56,049: collecting all words and their counts
INFO - 2023-11-30 14:17:56,049: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:17:56,084: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:17:56,084: Updating model with new vocabulary
INFO - 2023-11-30 14:17:56,099: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:17:56.099054', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:56,117: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:17:56,117: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:17:56,118: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111304.82564284268 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:17:56.117977', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:17:56,147: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:17:56,147: updating layer weights
INFO - 2023-11-30 14:17:56,148: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:17:56.148666', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:17:56,148: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:17:56,149: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:17:56.148978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:17:56,440: EPOCH 0: training on 191080 raw words (111212 effective words) took 0.3s, 384297 effective words/s
INFO - 2023-11-30 14:17:56,718: EPOCH 1: training on 191080 raw words (111379 effective words) took 0.3s, 405499 effective words/s
INFO - 2023-11-30 14:17:57,028: EPOCH 2: training on 191080 raw words (111135 effective words) took 0.3s, 361923 effective words/s
INFO - 2023-11-30 14:17:57,267: EPOCH 3: training on 191080 raw words (111268 effective words) took 0.2s, 469232 effective words/s
INFO - 2023-11-30 14:17:57,514: EPOCH 4: training on 191080 raw words (111346 effective words) took 0.2s, 456074 effective words/s
INFO - 2023-11-30 14:17:57,758: EPOCH 5: training on 191080 raw words (111129 effective words) took 0.2s, 461056 effective words/s
INFO - 2023-11-30 14:17:58,013: EPOCH 6: training on 191080 raw words (111205 effective words) took 0.3s, 442797 effective words/s
INFO - 2023-11-30 14:17:58,262: EPOCH 7: training on 191080 raw words (111281 effective words) took 0.2s, 451725 effective words/s
INFO - 2023-11-30 14:17:58,511: EPOCH 8: training on 191080 raw words (111438 effective words) took 0.2s, 453535 effective words/s
INFO - 2023-11-30 14:17:58,759: EPOCH 9: training on 191080 raw words (111473 effective words) took 0.2s, 454559 effective words/s
INFO - 2023-11-30 14:17:59,001: EPOCH 10: training on 191080 raw words (111373 effective words) took 0.2s, 464549 effective words/s
INFO - 2023-11-30 14:17:59,247: EPOCH 11: training on 191080 raw words (111235 effective words) took 0.2s, 458138 effective words/s
INFO - 2023-11-30 14:17:59,498: EPOCH 12: training on 191080 raw words (111294 effective words) took 0.2s, 447725 effective words/s
INFO - 2023-11-30 14:17:59,747: EPOCH 13: training on 191080 raw words (111562 effective words) took 0.2s, 454600 effective words/s
INFO - 2023-11-30 14:17:59,997: EPOCH 14: training on 191080 raw words (111247 effective words) took 0.2s, 450761 effective words/s
INFO - 2023-11-30 14:18:00,248: EPOCH 15: training on 191080 raw words (111272 effective words) took 0.2s, 447642 effective words/s
INFO - 2023-11-30 14:18:00,490: EPOCH 16: training on 191080 raw words (111071 effective words) took 0.2s, 463695 effective words/s
INFO - 2023-11-30 14:18:00,732: EPOCH 17: training on 191080 raw words (111534 effective words) took 0.2s, 468115 effective words/s
INFO - 2023-11-30 14:18:00,986: EPOCH 18: training on 191080 raw words (111321 effective words) took 0.3s, 441980 effective words/s
INFO - 2023-11-30 14:18:01,237: EPOCH 19: training on 191080 raw words (111320 effective words) took 0.2s, 448146 effective words/s
INFO - 2023-11-30 14:18:01,238: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2226095 effective words) took 5.1s, 437434 effective words/s', 'datetime': '2023-11-30T14:18:01.238139', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:01,238: collecting all words and their counts
INFO - 2023-11-30 14:18:01,238: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:01,272: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:01,272: Updating model with new vocabulary
INFO - 2023-11-30 14:18:01,288: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:01.288580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:01,308: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:01,308: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:01,308: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111529.25940061385 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:01.308964', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:01,341: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:01,341: updating layer weights
INFO - 2023-11-30 14:18:01,341: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:01.341632', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:01,341: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:01,341: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:01.341890', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:01,640: EPOCH 0: training on 191080 raw words (111606 effective words) took 0.3s, 376974 effective words/s
INFO - 2023-11-30 14:18:01,937: EPOCH 1: training on 191080 raw words (111641 effective words) took 0.3s, 379935 effective words/s
INFO - 2023-11-30 14:18:02,217: EPOCH 2: training on 191080 raw words (111440 effective words) took 0.3s, 402163 effective words/s
INFO - 2023-11-30 14:18:02,496: EPOCH 3: training on 191080 raw words (111622 effective words) took 0.3s, 404305 effective words/s
INFO - 2023-11-30 14:18:02,777: EPOCH 4: training on 191080 raw words (111492 effective words) took 0.3s, 400201 effective words/s
INFO - 2023-11-30 14:18:03,055: EPOCH 5: training on 191080 raw words (111533 effective words) took 0.3s, 405067 effective words/s
INFO - 2023-11-30 14:18:03,325: EPOCH 6: training on 191080 raw words (111404 effective words) took 0.3s, 417561 effective words/s
INFO - 2023-11-30 14:18:03,591: EPOCH 7: training on 191080 raw words (111377 effective words) took 0.3s, 422335 effective words/s
INFO - 2023-11-30 14:18:03,858: EPOCH 8: training on 191080 raw words (111538 effective words) took 0.3s, 421786 effective words/s
INFO - 2023-11-30 14:18:04,123: EPOCH 9: training on 191080 raw words (111406 effective words) took 0.3s, 425305 effective words/s
INFO - 2023-11-30 14:18:04,416: EPOCH 10: training on 191080 raw words (111464 effective words) took 0.3s, 384731 effective words/s
INFO - 2023-11-30 14:18:04,686: EPOCH 11: training on 191080 raw words (111551 effective words) took 0.3s, 417293 effective words/s
INFO - 2023-11-30 14:18:04,963: EPOCH 12: training on 191080 raw words (111634 effective words) took 0.3s, 407313 effective words/s
INFO - 2023-11-30 14:18:05,224: EPOCH 13: training on 191080 raw words (111844 effective words) took 0.3s, 434038 effective words/s
INFO - 2023-11-30 14:18:05,492: EPOCH 14: training on 191080 raw words (111633 effective words) took 0.3s, 421116 effective words/s
INFO - 2023-11-30 14:18:05,756: EPOCH 15: training on 191080 raw words (111618 effective words) took 0.3s, 428168 effective words/s
INFO - 2023-11-30 14:18:06,022: EPOCH 16: training on 191080 raw words (111489 effective words) took 0.3s, 422216 effective words/s
INFO - 2023-11-30 14:18:06,330: EPOCH 17: training on 191080 raw words (111692 effective words) took 0.3s, 367036 effective words/s
INFO - 2023-11-30 14:18:06,631: EPOCH 18: training on 191080 raw words (111515 effective words) took 0.3s, 373849 effective words/s
INFO - 2023-11-30 14:18:06,911: EPOCH 19: training on 191080 raw words (111736 effective words) took 0.3s, 403492 effective words/s
INFO - 2023-11-30 14:18:06,911: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231235 effective words) took 5.6s, 400600 effective words/s', 'datetime': '2023-11-30T14:18:06.911749', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:06,911: collecting all words and their counts
INFO - 2023-11-30 14:18:06,912: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:06,950: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:06,950: Updating model with new vocabulary
INFO - 2023-11-30 14:18:06,979: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:06.979268', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:07,002: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:07,003: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:07,003: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 112000.95623857368 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:18:07.003163', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:07,045: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:07,045: updating layer weights
INFO - 2023-11-30 14:18:07,045: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:07.045756', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:07,045: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:07,046: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:07.046015', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:07,306: EPOCH 0: training on 191080 raw words (112084 effective words) took 0.3s, 435439 effective words/s
INFO - 2023-11-30 14:18:07,560: EPOCH 1: training on 191080 raw words (111883 effective words) took 0.3s, 446187 effective words/s
INFO - 2023-11-30 14:18:07,818: EPOCH 2: training on 191080 raw words (111913 effective words) took 0.3s, 438379 effective words/s
INFO - 2023-11-30 14:18:08,070: EPOCH 3: training on 191080 raw words (111868 effective words) took 0.2s, 451071 effective words/s
INFO - 2023-11-30 14:18:08,381: EPOCH 4: training on 191080 raw words (112059 effective words) took 0.3s, 364532 effective words/s
INFO - 2023-11-30 14:18:08,628: EPOCH 5: training on 191080 raw words (111871 effective words) took 0.2s, 458116 effective words/s
INFO - 2023-11-30 14:18:08,879: EPOCH 6: training on 191080 raw words (112005 effective words) took 0.2s, 451283 effective words/s
INFO - 2023-11-30 14:18:09,132: EPOCH 7: training on 191080 raw words (112009 effective words) took 0.3s, 447754 effective words/s
INFO - 2023-11-30 14:18:09,381: EPOCH 8: training on 191080 raw words (111850 effective words) took 0.2s, 454744 effective words/s
INFO - 2023-11-30 14:18:09,633: EPOCH 9: training on 191080 raw words (112073 effective words) took 0.3s, 447870 effective words/s
INFO - 2023-11-30 14:18:09,891: EPOCH 10: training on 191080 raw words (111838 effective words) took 0.3s, 438586 effective words/s
INFO - 2023-11-30 14:18:10,147: EPOCH 11: training on 191080 raw words (111951 effective words) took 0.3s, 442892 effective words/s
INFO - 2023-11-30 14:18:10,414: EPOCH 12: training on 191080 raw words (111938 effective words) took 0.3s, 423181 effective words/s
INFO - 2023-11-30 14:18:10,667: EPOCH 13: training on 191080 raw words (111983 effective words) took 0.3s, 447844 effective words/s
INFO - 2023-11-30 14:18:10,914: EPOCH 14: training on 191080 raw words (111757 effective words) took 0.2s, 457331 effective words/s
INFO - 2023-11-30 14:18:11,168: EPOCH 15: training on 191080 raw words (111843 effective words) took 0.3s, 445506 effective words/s
INFO - 2023-11-30 14:18:11,412: EPOCH 16: training on 191080 raw words (111841 effective words) took 0.2s, 464245 effective words/s
INFO - 2023-11-30 14:18:11,683: EPOCH 17: training on 191080 raw words (111994 effective words) took 0.3s, 418204 effective words/s
INFO - 2023-11-30 14:18:11,954: EPOCH 18: training on 191080 raw words (111872 effective words) took 0.3s, 418247 effective words/s
INFO - 2023-11-30 14:18:12,215: EPOCH 19: training on 191080 raw words (111844 effective words) took 0.2s, 471027 effective words/s
INFO - 2023-11-30 14:18:12,215: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2238476 effective words) took 5.2s, 432996 effective words/s', 'datetime': '2023-11-30T14:18:12.215900', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:12,216: collecting all words and their counts
INFO - 2023-11-30 14:18:12,216: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:12,257: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:12,257: Updating model with new vocabulary
INFO - 2023-11-30 14:18:12,274: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:12.274089', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:12,295: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:12,295: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:18:12,295: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111610.31956564655 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:12.295412', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:12,334: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:12,334: updating layer weights
INFO - 2023-11-30 14:18:12,334: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:12.334795', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:12,334: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:12,335: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:12.335059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:12,604: EPOCH 0: training on 191080 raw words (111563 effective words) took 0.3s, 417528 effective words/s
INFO - 2023-11-30 14:18:12,867: EPOCH 1: training on 191080 raw words (111235 effective words) took 0.3s, 427594 effective words/s
INFO - 2023-11-30 14:18:13,136: EPOCH 2: training on 191080 raw words (111492 effective words) took 0.3s, 418539 effective words/s
INFO - 2023-11-30 14:18:13,407: EPOCH 3: training on 191080 raw words (111393 effective words) took 0.3s, 416939 effective words/s
INFO - 2023-11-30 14:18:13,675: EPOCH 4: training on 191080 raw words (111716 effective words) took 0.3s, 420792 effective words/s
INFO - 2023-11-30 14:18:13,942: EPOCH 5: training on 191080 raw words (111549 effective words) took 0.3s, 423005 effective words/s
INFO - 2023-11-30 14:18:14,210: EPOCH 6: training on 191080 raw words (111744 effective words) took 0.3s, 421036 effective words/s
INFO - 2023-11-30 14:18:14,481: EPOCH 7: training on 191080 raw words (111461 effective words) took 0.3s, 416014 effective words/s
INFO - 2023-11-30 14:18:14,751: EPOCH 8: training on 191080 raw words (111697 effective words) took 0.3s, 418185 effective words/s
INFO - 2023-11-30 14:18:15,021: EPOCH 9: training on 191080 raw words (111656 effective words) took 0.3s, 418675 effective words/s
INFO - 2023-11-30 14:18:15,290: EPOCH 10: training on 191080 raw words (111818 effective words) took 0.3s, 419274 effective words/s
INFO - 2023-11-30 14:18:15,559: EPOCH 11: training on 191080 raw words (111615 effective words) took 0.3s, 420480 effective words/s
INFO - 2023-11-30 14:18:15,838: EPOCH 12: training on 191080 raw words (111516 effective words) took 0.3s, 403826 effective words/s
INFO - 2023-11-30 14:18:16,098: EPOCH 13: training on 191080 raw words (111407 effective words) took 0.3s, 433202 effective words/s
INFO - 2023-11-30 14:18:16,366: EPOCH 14: training on 191080 raw words (111926 effective words) took 0.3s, 421199 effective words/s
INFO - 2023-11-30 14:18:16,653: EPOCH 15: training on 191080 raw words (111683 effective words) took 0.3s, 393638 effective words/s
INFO - 2023-11-30 14:18:16,927: EPOCH 16: training on 191080 raw words (111420 effective words) took 0.3s, 411004 effective words/s
INFO - 2023-11-30 14:18:17,202: EPOCH 17: training on 191080 raw words (111625 effective words) took 0.3s, 410105 effective words/s
INFO - 2023-11-30 14:18:17,466: EPOCH 18: training on 191080 raw words (111617 effective words) took 0.2s, 461487 effective words/s
INFO - 2023-11-30 14:18:17,739: EPOCH 19: training on 191080 raw words (111558 effective words) took 0.3s, 413272 effective words/s
INFO - 2023-11-30 14:18:17,740: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231691 effective words) took 5.4s, 412905 effective words/s', 'datetime': '2023-11-30T14:18:17.740042', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:17,740: collecting all words and their counts
INFO - 2023-11-30 14:18:17,740: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:17,774: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:17,775: Updating model with new vocabulary
INFO - 2023-11-30 14:18:17,793: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:17.793324', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:17,815: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:17,815: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:18:17,815: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111558.97206995473 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:17.815574', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:17,853: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:17,853: updating layer weights
INFO - 2023-11-30 14:18:17,853: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:17.853853', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:17,854: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:17,854: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:17.854148', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:18,126: EPOCH 0: training on 191080 raw words (111492 effective words) took 0.3s, 413992 effective words/s
INFO - 2023-11-30 14:18:18,405: EPOCH 1: training on 191080 raw words (111589 effective words) took 0.3s, 404132 effective words/s
INFO - 2023-11-30 14:18:18,696: EPOCH 2: training on 191080 raw words (111715 effective words) took 0.3s, 388092 effective words/s
INFO - 2023-11-30 14:18:19,001: EPOCH 3: training on 191080 raw words (111663 effective words) took 0.3s, 369773 effective words/s
INFO - 2023-11-30 14:18:19,243: EPOCH 4: training on 191080 raw words (111523 effective words) took 0.2s, 465858 effective words/s
INFO - 2023-11-30 14:18:19,492: EPOCH 5: training on 191080 raw words (111457 effective words) took 0.2s, 453048 effective words/s
INFO - 2023-11-30 14:18:19,739: EPOCH 6: training on 191080 raw words (111484 effective words) took 0.2s, 455178 effective words/s
INFO - 2023-11-30 14:18:19,978: EPOCH 7: training on 191080 raw words (111705 effective words) took 0.2s, 472663 effective words/s
INFO - 2023-11-30 14:18:20,221: EPOCH 8: training on 191080 raw words (111541 effective words) took 0.2s, 464984 effective words/s
INFO - 2023-11-30 14:18:20,485: EPOCH 9: training on 191080 raw words (111678 effective words) took 0.3s, 428593 effective words/s
INFO - 2023-11-30 14:18:20,740: EPOCH 10: training on 191080 raw words (111766 effective words) took 0.3s, 442381 effective words/s
INFO - 2023-11-30 14:18:20,981: EPOCH 11: training on 191080 raw words (111378 effective words) took 0.2s, 468983 effective words/s
INFO - 2023-11-30 14:18:21,225: EPOCH 12: training on 191080 raw words (111603 effective words) took 0.2s, 461034 effective words/s
INFO - 2023-11-30 14:18:21,474: EPOCH 13: training on 191080 raw words (111509 effective words) took 0.2s, 453957 effective words/s
INFO - 2023-11-30 14:18:21,722: EPOCH 14: training on 191080 raw words (111495 effective words) took 0.2s, 455009 effective words/s
INFO - 2023-11-30 14:18:21,962: EPOCH 15: training on 191080 raw words (111610 effective words) took 0.2s, 468983 effective words/s
INFO - 2023-11-30 14:18:22,208: EPOCH 16: training on 191080 raw words (111763 effective words) took 0.2s, 461234 effective words/s
INFO - 2023-11-30 14:18:22,457: EPOCH 17: training on 191080 raw words (111578 effective words) took 0.2s, 452587 effective words/s
INFO - 2023-11-30 14:18:22,728: EPOCH 18: training on 191080 raw words (111593 effective words) took 0.3s, 417582 effective words/s
INFO - 2023-11-30 14:18:22,973: EPOCH 19: training on 191080 raw words (111404 effective words) took 0.2s, 459710 effective words/s
INFO - 2023-11-30 14:18:22,973: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231546 effective words) took 5.1s, 435927 effective words/s', 'datetime': '2023-11-30T14:18:22.973371', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:22,973: collecting all words and their counts
INFO - 2023-11-30 14:18:22,973: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:23,010: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:23,010: Updating model with new vocabulary
INFO - 2023-11-30 14:18:23,026: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:23.026548', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:23,047: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:23,047: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:23,047: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111548.80777602292 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:23.047954', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:23,080: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:23,080: updating layer weights
INFO - 2023-11-30 14:18:23,081: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:23.081104', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:23,081: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:23,081: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:23.081364', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:23,385: EPOCH 0: training on 191080 raw words (111348 effective words) took 0.3s, 369701 effective words/s
INFO - 2023-11-30 14:18:23,683: EPOCH 1: training on 191080 raw words (111436 effective words) took 0.3s, 378290 effective words/s
INFO - 2023-11-30 14:18:23,969: EPOCH 2: training on 191080 raw words (111179 effective words) took 0.3s, 392795 effective words/s
INFO - 2023-11-30 14:18:24,237: EPOCH 3: training on 191080 raw words (111499 effective words) took 0.3s, 421207 effective words/s
INFO - 2023-11-30 14:18:24,505: EPOCH 4: training on 191080 raw words (111486 effective words) took 0.3s, 420589 effective words/s
INFO - 2023-11-30 14:18:24,771: EPOCH 5: training on 191080 raw words (111402 effective words) took 0.3s, 423241 effective words/s
INFO - 2023-11-30 14:18:25,082: EPOCH 6: training on 191080 raw words (111571 effective words) took 0.3s, 360976 effective words/s
INFO - 2023-11-30 14:18:25,365: EPOCH 7: training on 191080 raw words (111548 effective words) took 0.3s, 403822 effective words/s
INFO - 2023-11-30 14:18:25,628: EPOCH 8: training on 191080 raw words (111661 effective words) took 0.3s, 429058 effective words/s
INFO - 2023-11-30 14:18:25,899: EPOCH 9: training on 191080 raw words (111323 effective words) took 0.3s, 414432 effective words/s
INFO - 2023-11-30 14:18:26,169: EPOCH 10: training on 191080 raw words (111559 effective words) took 0.3s, 417168 effective words/s
INFO - 2023-11-30 14:18:26,433: EPOCH 11: training on 191080 raw words (111448 effective words) took 0.3s, 427097 effective words/s
INFO - 2023-11-30 14:18:26,744: EPOCH 12: training on 191080 raw words (111711 effective words) took 0.3s, 362705 effective words/s
INFO - 2023-11-30 14:18:27,041: EPOCH 13: training on 191080 raw words (111515 effective words) took 0.3s, 378543 effective words/s
INFO - 2023-11-30 14:18:27,318: EPOCH 14: training on 191080 raw words (111482 effective words) took 0.3s, 407683 effective words/s
INFO - 2023-11-30 14:18:27,589: EPOCH 15: training on 191080 raw words (111819 effective words) took 0.3s, 416807 effective words/s
INFO - 2023-11-30 14:18:27,856: EPOCH 16: training on 191080 raw words (111464 effective words) took 0.3s, 421389 effective words/s
INFO - 2023-11-30 14:18:28,129: EPOCH 17: training on 191080 raw words (111413 effective words) took 0.3s, 411908 effective words/s
INFO - 2023-11-30 14:18:28,397: EPOCH 18: training on 191080 raw words (111461 effective words) took 0.3s, 421376 effective words/s
INFO - 2023-11-30 14:18:28,687: EPOCH 19: training on 191080 raw words (111788 effective words) took 0.3s, 389334 effective words/s
INFO - 2023-11-30 14:18:28,687: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230113 effective words) took 5.6s, 397776 effective words/s', 'datetime': '2023-11-30T14:18:28.687937', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:28,688: collecting all words and their counts
INFO - 2023-11-30 14:18:28,688: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:28,728: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:28,728: Updating model with new vocabulary
INFO - 2023-11-30 14:18:28,747: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:28.747821', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:28,770: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:28,770: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:28,770: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111188.74577934854 word corpus (58.2%% of prior 191080)', 'datetime': '2023-11-30T14:18:28.770741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:28,808: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:28,809: updating layer weights
INFO - 2023-11-30 14:18:28,809: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:28.809586', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:28,809: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:28,809: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:28.809957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:29,077: EPOCH 0: training on 191080 raw words (111083 effective words) took 0.3s, 423831 effective words/s
INFO - 2023-11-30 14:18:29,320: EPOCH 1: training on 191080 raw words (111261 effective words) took 0.2s, 463293 effective words/s
INFO - 2023-11-30 14:18:29,565: EPOCH 2: training on 191080 raw words (111016 effective words) took 0.2s, 458284 effective words/s
INFO - 2023-11-30 14:18:29,813: EPOCH 3: training on 191080 raw words (111164 effective words) took 0.2s, 452977 effective words/s
INFO - 2023-11-30 14:18:30,063: EPOCH 4: training on 191080 raw words (111343 effective words) took 0.2s, 450515 effective words/s
INFO - 2023-11-30 14:18:30,312: EPOCH 5: training on 191080 raw words (111202 effective words) took 0.2s, 451674 effective words/s
INFO - 2023-11-30 14:18:30,560: EPOCH 6: training on 191080 raw words (111142 effective words) took 0.2s, 453121 effective words/s
INFO - 2023-11-30 14:18:30,803: EPOCH 7: training on 191080 raw words (111231 effective words) took 0.2s, 463365 effective words/s
INFO - 2023-11-30 14:18:31,049: EPOCH 8: training on 191080 raw words (111332 effective words) took 0.2s, 458752 effective words/s
INFO - 2023-11-30 14:18:31,302: EPOCH 9: training on 191080 raw words (111232 effective words) took 0.3s, 443297 effective words/s
INFO - 2023-11-30 14:18:31,550: EPOCH 10: training on 191080 raw words (111102 effective words) took 0.2s, 494869 effective words/s
INFO - 2023-11-30 14:18:31,794: EPOCH 11: training on 191080 raw words (111121 effective words) took 0.2s, 462380 effective words/s
INFO - 2023-11-30 14:18:32,030: EPOCH 12: training on 191080 raw words (111205 effective words) took 0.2s, 476465 effective words/s
INFO - 2023-11-30 14:18:32,275: EPOCH 13: training on 191080 raw words (111179 effective words) took 0.2s, 458412 effective words/s
INFO - 2023-11-30 14:18:32,522: EPOCH 14: training on 191080 raw words (110730 effective words) took 0.2s, 453121 effective words/s
INFO - 2023-11-30 14:18:32,769: EPOCH 15: training on 191080 raw words (111172 effective words) took 0.2s, 456422 effective words/s
INFO - 2023-11-30 14:18:33,027: EPOCH 16: training on 191080 raw words (110964 effective words) took 0.3s, 435216 effective words/s
INFO - 2023-11-30 14:18:33,280: EPOCH 17: training on 191080 raw words (111266 effective words) took 0.3s, 444935 effective words/s
INFO - 2023-11-30 14:18:33,531: EPOCH 18: training on 191080 raw words (111199 effective words) took 0.2s, 447203 effective words/s
INFO - 2023-11-30 14:18:33,775: EPOCH 19: training on 191080 raw words (111109 effective words) took 0.2s, 460727 effective words/s
INFO - 2023-11-30 14:18:33,776: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2223053 effective words) took 5.0s, 447658 effective words/s', 'datetime': '2023-11-30T14:18:33.776104', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:33,776: collecting all words and their counts
INFO - 2023-11-30 14:18:33,776: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:33,810: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:33,810: Updating model with new vocabulary
INFO - 2023-11-30 14:18:33,825: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:33.825583', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:33,846: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:33,846: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:18:33,846: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111690.41298858455 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:18:33.846353', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:33,878: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:33,878: updating layer weights
INFO - 2023-11-30 14:18:33,879: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:33.879173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:33,879: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:33,879: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:33.879385', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:34,156: EPOCH 0: training on 191080 raw words (111568 effective words) took 0.3s, 406482 effective words/s
INFO - 2023-11-30 14:18:34,438: EPOCH 1: training on 191080 raw words (111668 effective words) took 0.3s, 399221 effective words/s
INFO - 2023-11-30 14:18:34,703: EPOCH 2: training on 191080 raw words (111692 effective words) took 0.3s, 426603 effective words/s
INFO - 2023-11-30 14:18:34,978: EPOCH 3: training on 191080 raw words (112010 effective words) took 0.3s, 412304 effective words/s
INFO - 2023-11-30 14:18:35,308: EPOCH 4: training on 191080 raw words (111668 effective words) took 0.3s, 341019 effective words/s
INFO - 2023-11-30 14:18:35,583: EPOCH 5: training on 191080 raw words (111798 effective words) took 0.3s, 411260 effective words/s
INFO - 2023-11-30 14:18:35,858: EPOCH 6: training on 191080 raw words (111856 effective words) took 0.3s, 416354 effective words/s
INFO - 2023-11-30 14:18:36,167: EPOCH 7: training on 191080 raw words (111634 effective words) took 0.3s, 364968 effective words/s
INFO - 2023-11-30 14:18:36,485: EPOCH 8: training on 191080 raw words (111961 effective words) took 0.3s, 354981 effective words/s
INFO - 2023-11-30 14:18:36,791: EPOCH 9: training on 191080 raw words (111499 effective words) took 0.3s, 368091 effective words/s
INFO - 2023-11-30 14:18:37,063: EPOCH 10: training on 191080 raw words (111941 effective words) took 0.3s, 415591 effective words/s
INFO - 2023-11-30 14:18:37,338: EPOCH 11: training on 191080 raw words (111736 effective words) took 0.3s, 417325 effective words/s
INFO - 2023-11-30 14:18:37,603: EPOCH 12: training on 191080 raw words (111674 effective words) took 0.3s, 424561 effective words/s
INFO - 2023-11-30 14:18:37,873: EPOCH 13: training on 191080 raw words (111583 effective words) took 0.3s, 417622 effective words/s
INFO - 2023-11-30 14:18:38,147: EPOCH 14: training on 191080 raw words (111717 effective words) took 0.3s, 412196 effective words/s
INFO - 2023-11-30 14:18:38,439: EPOCH 15: training on 191080 raw words (111567 effective words) took 0.3s, 386274 effective words/s
INFO - 2023-11-30 14:18:38,715: EPOCH 16: training on 191080 raw words (111834 effective words) took 0.3s, 409825 effective words/s
INFO - 2023-11-30 14:18:38,979: EPOCH 17: training on 191080 raw words (111675 effective words) took 0.3s, 428494 effective words/s
INFO - 2023-11-30 14:18:39,254: EPOCH 18: training on 191080 raw words (111627 effective words) took 0.3s, 409651 effective words/s
INFO - 2023-11-30 14:18:39,522: EPOCH 19: training on 191080 raw words (111702 effective words) took 0.3s, 420765 effective words/s
INFO - 2023-11-30 14:18:39,523: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234410 effective words) took 5.6s, 395917 effective words/s', 'datetime': '2023-11-30T14:18:39.523113', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:39,523: collecting all words and their counts
INFO - 2023-11-30 14:18:39,523: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:39,560: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:39,561: Updating model with new vocabulary
INFO - 2023-11-30 14:18:39,577: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:39.577393', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:39,598: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:39,598: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:18:39,598: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111585.85494093983 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:39.598603', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:39,631: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:39,631: updating layer weights
INFO - 2023-11-30 14:18:39,632: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:39.632123', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:39,632: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:39,632: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:39.632433', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:39,879: EPOCH 0: training on 191080 raw words (111688 effective words) took 0.2s, 456476 effective words/s
INFO - 2023-11-30 14:18:40,136: EPOCH 1: training on 191080 raw words (111587 effective words) took 0.3s, 440348 effective words/s
INFO - 2023-11-30 14:18:40,392: EPOCH 2: training on 191080 raw words (111610 effective words) took 0.3s, 441142 effective words/s
INFO - 2023-11-30 14:18:40,637: EPOCH 3: training on 191080 raw words (111395 effective words) took 0.2s, 458651 effective words/s
INFO - 2023-11-30 14:18:40,886: EPOCH 4: training on 191080 raw words (111594 effective words) took 0.2s, 454407 effective words/s
INFO - 2023-11-30 14:18:41,141: EPOCH 5: training on 191080 raw words (111730 effective words) took 0.3s, 444545 effective words/s
INFO - 2023-11-30 14:18:41,410: EPOCH 6: training on 191080 raw words (111711 effective words) took 0.3s, 419887 effective words/s
INFO - 2023-11-30 14:18:41,665: EPOCH 7: training on 191080 raw words (111737 effective words) took 0.3s, 442701 effective words/s
INFO - 2023-11-30 14:18:41,915: EPOCH 8: training on 191080 raw words (111525 effective words) took 0.2s, 451497 effective words/s
INFO - 2023-11-30 14:18:42,160: EPOCH 9: training on 191080 raw words (111700 effective words) took 0.2s, 459727 effective words/s
INFO - 2023-11-30 14:18:42,407: EPOCH 10: training on 191080 raw words (111601 effective words) took 0.2s, 457470 effective words/s
INFO - 2023-11-30 14:18:42,650: EPOCH 11: training on 191080 raw words (111752 effective words) took 0.2s, 465905 effective words/s
INFO - 2023-11-30 14:18:42,896: EPOCH 12: training on 191080 raw words (111881 effective words) took 0.2s, 461038 effective words/s
INFO - 2023-11-30 14:18:43,142: EPOCH 13: training on 191080 raw words (111638 effective words) took 0.2s, 459198 effective words/s
INFO - 2023-11-30 14:18:43,390: EPOCH 14: training on 191080 raw words (111565 effective words) took 0.2s, 455403 effective words/s
INFO - 2023-11-30 14:18:43,634: EPOCH 15: training on 191080 raw words (111721 effective words) took 0.2s, 462492 effective words/s
INFO - 2023-11-30 14:18:43,876: EPOCH 16: training on 191080 raw words (111709 effective words) took 0.2s, 465970 effective words/s
INFO - 2023-11-30 14:18:44,120: EPOCH 17: training on 191080 raw words (111491 effective words) took 0.2s, 462527 effective words/s
INFO - 2023-11-30 14:18:44,370: EPOCH 18: training on 191080 raw words (111426 effective words) took 0.2s, 451330 effective words/s
INFO - 2023-11-30 14:18:44,617: EPOCH 19: training on 191080 raw words (111574 effective words) took 0.2s, 457269 effective words/s
INFO - 2023-11-30 14:18:44,618: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232635 effective words) took 5.0s, 447821 effective words/s', 'datetime': '2023-11-30T14:18:44.618127', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:44,618: collecting all words and their counts
INFO - 2023-11-30 14:18:44,618: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:44,655: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:44,655: Updating model with new vocabulary
INFO - 2023-11-30 14:18:44,671: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:44.671517', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:44,691: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:44,691: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:44,692: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111663.99992031569 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:18:44.692084', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:44,725: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:44,725: updating layer weights
INFO - 2023-11-30 14:18:44,725: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:44.725607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:44,725: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:44,725: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:44.725949', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:45,045: EPOCH 0: training on 191080 raw words (111879 effective words) took 0.3s, 353636 effective words/s
INFO - 2023-11-30 14:18:45,383: EPOCH 1: training on 191080 raw words (111690 effective words) took 0.3s, 334286 effective words/s
INFO - 2023-11-30 14:18:45,666: EPOCH 2: training on 191080 raw words (111845 effective words) took 0.3s, 399821 effective words/s
INFO - 2023-11-30 14:18:45,930: EPOCH 3: training on 191080 raw words (111543 effective words) took 0.3s, 426453 effective words/s
INFO - 2023-11-30 14:18:46,200: EPOCH 4: training on 191080 raw words (111673 effective words) took 0.3s, 418891 effective words/s
INFO - 2023-11-30 14:18:46,476: EPOCH 5: training on 191080 raw words (111643 effective words) took 0.3s, 408261 effective words/s
INFO - 2023-11-30 14:18:46,742: EPOCH 6: training on 191080 raw words (111526 effective words) took 0.3s, 424445 effective words/s
INFO - 2023-11-30 14:18:47,018: EPOCH 7: training on 191080 raw words (111732 effective words) took 0.3s, 407955 effective words/s
INFO - 2023-11-30 14:18:47,290: EPOCH 8: training on 191080 raw words (111475 effective words) took 0.3s, 414523 effective words/s
INFO - 2023-11-30 14:18:47,561: EPOCH 9: training on 191080 raw words (111573 effective words) took 0.3s, 416708 effective words/s
INFO - 2023-11-30 14:18:47,827: EPOCH 10: training on 191080 raw words (111613 effective words) took 0.3s, 424804 effective words/s
INFO - 2023-11-30 14:18:48,101: EPOCH 11: training on 191080 raw words (111894 effective words) took 0.3s, 412062 effective words/s
INFO - 2023-11-30 14:18:48,372: EPOCH 12: training on 191080 raw words (111630 effective words) took 0.2s, 450605 effective words/s
INFO - 2023-11-30 14:18:48,636: EPOCH 13: training on 191080 raw words (111797 effective words) took 0.3s, 429236 effective words/s
INFO - 2023-11-30 14:18:48,905: EPOCH 14: training on 191080 raw words (111485 effective words) took 0.3s, 418565 effective words/s
INFO - 2023-11-30 14:18:49,187: EPOCH 15: training on 191080 raw words (111535 effective words) took 0.3s, 399667 effective words/s
INFO - 2023-11-30 14:18:49,457: EPOCH 16: training on 191080 raw words (111555 effective words) took 0.3s, 418205 effective words/s
INFO - 2023-11-30 14:18:49,773: EPOCH 17: training on 191080 raw words (111761 effective words) took 0.3s, 355783 effective words/s
INFO - 2023-11-30 14:18:50,085: EPOCH 18: training on 191080 raw words (111598 effective words) took 0.3s, 360943 effective words/s
INFO - 2023-11-30 14:18:50,404: EPOCH 19: training on 191080 raw words (111745 effective words) took 0.3s, 359372 effective words/s
INFO - 2023-11-30 14:18:50,404: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233192 effective words) took 5.7s, 393305 effective words/s', 'datetime': '2023-11-30T14:18:50.404324', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:50,404: collecting all words and their counts
INFO - 2023-11-30 14:18:50,404: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:50,453: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:50,454: Updating model with new vocabulary
INFO - 2023-11-30 14:18:50,479: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:50.479866', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:50,506: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:50,506: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:50,507: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111802.23301124491 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:18:50.507059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:50,538: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:50,539: updating layer weights
INFO - 2023-11-30 14:18:50,539: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:50.539431', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:50,539: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:50,539: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:50.539745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:50,794: EPOCH 0: training on 191080 raw words (111768 effective words) took 0.3s, 444626 effective words/s
INFO - 2023-11-30 14:18:51,049: EPOCH 1: training on 191080 raw words (112034 effective words) took 0.3s, 442969 effective words/s
INFO - 2023-11-30 14:18:51,322: EPOCH 2: training on 191080 raw words (111615 effective words) took 0.3s, 414311 effective words/s
INFO - 2023-11-30 14:18:51,575: EPOCH 3: training on 191080 raw words (111999 effective words) took 0.3s, 445918 effective words/s
INFO - 2023-11-30 14:18:51,829: EPOCH 4: training on 191080 raw words (111539 effective words) took 0.3s, 445796 effective words/s
INFO - 2023-11-30 14:18:52,079: EPOCH 5: training on 191080 raw words (111507 effective words) took 0.2s, 451073 effective words/s
INFO - 2023-11-30 14:18:52,329: EPOCH 6: training on 191080 raw words (112042 effective words) took 0.2s, 454557 effective words/s
INFO - 2023-11-30 14:18:52,572: EPOCH 7: training on 191080 raw words (111683 effective words) took 0.2s, 465131 effective words/s
INFO - 2023-11-30 14:18:52,817: EPOCH 8: training on 191080 raw words (111817 effective words) took 0.2s, 460879 effective words/s
INFO - 2023-11-30 14:18:53,073: EPOCH 9: training on 191080 raw words (112133 effective words) took 0.3s, 444306 effective words/s
INFO - 2023-11-30 14:18:53,319: EPOCH 10: training on 191080 raw words (111968 effective words) took 0.2s, 460807 effective words/s
INFO - 2023-11-30 14:18:53,570: EPOCH 11: training on 191080 raw words (111796 effective words) took 0.2s, 449444 effective words/s
INFO - 2023-11-30 14:18:53,821: EPOCH 12: training on 191080 raw words (111937 effective words) took 0.2s, 452545 effective words/s
INFO - 2023-11-30 14:18:54,063: EPOCH 13: training on 191080 raw words (112148 effective words) took 0.2s, 468383 effective words/s
INFO - 2023-11-30 14:18:54,314: EPOCH 14: training on 191080 raw words (111890 effective words) took 0.2s, 449737 effective words/s
INFO - 2023-11-30 14:18:54,554: EPOCH 15: training on 191080 raw words (111825 effective words) took 0.2s, 472950 effective words/s
INFO - 2023-11-30 14:18:54,802: EPOCH 16: training on 191080 raw words (111934 effective words) took 0.2s, 456198 effective words/s
INFO - 2023-11-30 14:18:55,046: EPOCH 17: training on 191080 raw words (111870 effective words) took 0.2s, 464737 effective words/s
INFO - 2023-11-30 14:18:55,296: EPOCH 18: training on 191080 raw words (112011 effective words) took 0.2s, 470377 effective words/s
INFO - 2023-11-30 14:18:55,548: EPOCH 19: training on 191080 raw words (112020 effective words) took 0.2s, 448197 effective words/s
INFO - 2023-11-30 14:18:55,549: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2237536 effective words) took 5.0s, 446684 effective words/s', 'datetime': '2023-11-30T14:18:55.549116', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:55,549: collecting all words and their counts
INFO - 2023-11-30 14:18:55,549: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:18:55,583: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:18:55,583: Updating model with new vocabulary
INFO - 2023-11-30 14:18:55,598: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:18:55.598741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:55,618: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:18:55,618: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:18:55,618: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111848.01201851826 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:18:55.618318', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:18:55,648: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:18:55,648: updating layer weights
INFO - 2023-11-30 14:18:55,648: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:18:55.648843', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:18:55,648: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:18:55,649: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:18:55.649056', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:18:55,924: EPOCH 0: training on 191080 raw words (111667 effective words) took 0.3s, 409229 effective words/s
INFO - 2023-11-30 14:18:56,188: EPOCH 1: training on 191080 raw words (111996 effective words) took 0.3s, 428777 effective words/s
INFO - 2023-11-30 14:18:56,454: EPOCH 2: training on 191080 raw words (111757 effective words) took 0.3s, 424226 effective words/s
INFO - 2023-11-30 14:18:56,724: EPOCH 3: training on 191080 raw words (111920 effective words) took 0.3s, 417985 effective words/s
INFO - 2023-11-30 14:18:56,993: EPOCH 4: training on 191080 raw words (111875 effective words) took 0.3s, 420315 effective words/s
INFO - 2023-11-30 14:18:57,261: EPOCH 5: training on 191080 raw words (111861 effective words) took 0.3s, 422751 effective words/s
INFO - 2023-11-30 14:18:57,536: EPOCH 6: training on 191080 raw words (111901 effective words) took 0.3s, 444067 effective words/s
INFO - 2023-11-30 14:18:57,816: EPOCH 7: training on 191080 raw words (112040 effective words) took 0.3s, 404304 effective words/s
INFO - 2023-11-30 14:18:58,105: EPOCH 8: training on 191080 raw words (111785 effective words) took 0.3s, 391680 effective words/s
INFO - 2023-11-30 14:18:58,402: EPOCH 9: training on 191080 raw words (111663 effective words) took 0.3s, 379116 effective words/s
INFO - 2023-11-30 14:18:58,718: EPOCH 10: training on 191080 raw words (111795 effective words) took 0.3s, 357362 effective words/s
INFO - 2023-11-30 14:18:59,038: EPOCH 11: training on 191080 raw words (111756 effective words) took 0.3s, 352333 effective words/s
INFO - 2023-11-30 14:18:59,330: EPOCH 12: training on 191080 raw words (111827 effective words) took 0.3s, 387903 effective words/s
INFO - 2023-11-30 14:18:59,609: EPOCH 13: training on 191080 raw words (111790 effective words) took 0.3s, 404998 effective words/s
INFO - 2023-11-30 14:18:59,871: EPOCH 14: training on 191080 raw words (112146 effective words) took 0.3s, 433807 effective words/s
INFO - 2023-11-30 14:19:00,145: EPOCH 15: training on 191080 raw words (111932 effective words) took 0.3s, 412329 effective words/s
INFO - 2023-11-30 14:19:00,390: EPOCH 16: training on 191080 raw words (111742 effective words) took 0.2s, 459636 effective words/s
INFO - 2023-11-30 14:19:00,642: EPOCH 17: training on 191080 raw words (112013 effective words) took 0.2s, 450791 effective words/s
INFO - 2023-11-30 14:19:00,888: EPOCH 18: training on 191080 raw words (111846 effective words) took 0.2s, 458912 effective words/s
INFO - 2023-11-30 14:19:01,138: EPOCH 19: training on 191080 raw words (111897 effective words) took 0.2s, 452897 effective words/s
INFO - 2023-11-30 14:19:01,138: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2237209 effective words) took 5.5s, 407557 effective words/s', 'datetime': '2023-11-30T14:19:01.138499', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:01,138: collecting all words and their counts
INFO - 2023-11-30 14:19:01,138: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:01,171: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:01,171: Updating model with new vocabulary
INFO - 2023-11-30 14:19:01,187: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:01.186962', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:01,203: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:01,203: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:19:01,203: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111616.67586105385 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:19:01.203674', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:01,229: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:01,229: updating layer weights
INFO - 2023-11-30 14:19:01,230: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:01.230413', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:01,230: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:01,230: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:01.230831', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:01,457: EPOCH 0: training on 191080 raw words (111414 effective words) took 0.2s, 498639 effective words/s
INFO - 2023-11-30 14:19:01,692: EPOCH 1: training on 191080 raw words (111555 effective words) took 0.2s, 480035 effective words/s
INFO - 2023-11-30 14:19:01,909: EPOCH 2: training on 191080 raw words (111746 effective words) took 0.2s, 520077 effective words/s
INFO - 2023-11-30 14:19:02,122: EPOCH 3: training on 191080 raw words (111792 effective words) took 0.2s, 531322 effective words/s
INFO - 2023-11-30 14:19:02,389: EPOCH 4: training on 191080 raw words (111718 effective words) took 0.3s, 421845 effective words/s
INFO - 2023-11-30 14:19:02,612: EPOCH 5: training on 191080 raw words (111743 effective words) took 0.2s, 506693 effective words/s
INFO - 2023-11-30 14:19:02,831: EPOCH 6: training on 191080 raw words (111846 effective words) took 0.2s, 516834 effective words/s
INFO - 2023-11-30 14:19:03,069: EPOCH 7: training on 191080 raw words (111852 effective words) took 0.2s, 478237 effective words/s
INFO - 2023-11-30 14:19:03,294: EPOCH 8: training on 191080 raw words (111698 effective words) took 0.2s, 501680 effective words/s
INFO - 2023-11-30 14:19:03,538: EPOCH 9: training on 191080 raw words (111634 effective words) took 0.2s, 462656 effective words/s
INFO - 2023-11-30 14:19:03,783: EPOCH 10: training on 191080 raw words (111676 effective words) took 0.2s, 460800 effective words/s
INFO - 2023-11-30 14:19:04,028: EPOCH 11: training on 191080 raw words (111812 effective words) took 0.2s, 460146 effective words/s
INFO - 2023-11-30 14:19:04,249: EPOCH 12: training on 191080 raw words (111457 effective words) took 0.2s, 510033 effective words/s
INFO - 2023-11-30 14:19:04,476: EPOCH 13: training on 191080 raw words (111654 effective words) took 0.2s, 495924 effective words/s
INFO - 2023-11-30 14:19:04,703: EPOCH 14: training on 191080 raw words (111389 effective words) took 0.2s, 496311 effective words/s
INFO - 2023-11-30 14:19:04,922: EPOCH 15: training on 191080 raw words (111507 effective words) took 0.2s, 516097 effective words/s
INFO - 2023-11-30 14:19:05,157: EPOCH 16: training on 191080 raw words (111554 effective words) took 0.2s, 479054 effective words/s
INFO - 2023-11-30 14:19:05,377: EPOCH 17: training on 191080 raw words (111289 effective words) took 0.2s, 510936 effective words/s
INFO - 2023-11-30 14:19:05,593: EPOCH 18: training on 191080 raw words (111497 effective words) took 0.2s, 521569 effective words/s
INFO - 2023-11-30 14:19:05,805: EPOCH 19: training on 191080 raw words (111568 effective words) took 0.2s, 531685 effective words/s
INFO - 2023-11-30 14:19:05,806: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232401 effective words) took 4.6s, 487934 effective words/s', 'datetime': '2023-11-30T14:19:05.806204', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:05,806: collecting all words and their counts
INFO - 2023-11-30 14:19:05,806: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:05,833: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:05,833: Updating model with new vocabulary
INFO - 2023-11-30 14:19:05,846: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:05.846256', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:05,863: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:05,863: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:19:05,863: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 112063.05621949129 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:19:05.863551', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:05,888: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:05,888: updating layer weights
INFO - 2023-11-30 14:19:05,888: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:05.888794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:05,888: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:05,889: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:05.889043', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:06,137: EPOCH 0: training on 191080 raw words (111953 effective words) took 0.2s, 455642 effective words/s
INFO - 2023-11-30 14:19:06,373: EPOCH 1: training on 191080 raw words (111997 effective words) took 0.2s, 478423 effective words/s
INFO - 2023-11-30 14:19:06,611: EPOCH 2: training on 191080 raw words (112043 effective words) took 0.2s, 475747 effective words/s
INFO - 2023-11-30 14:19:06,842: EPOCH 3: training on 191080 raw words (111932 effective words) took 0.2s, 489688 effective words/s
INFO - 2023-11-30 14:19:07,076: EPOCH 4: training on 191080 raw words (112105 effective words) took 0.2s, 521242 effective words/s
INFO - 2023-11-30 14:19:07,310: EPOCH 5: training on 191080 raw words (111990 effective words) took 0.2s, 483760 effective words/s
INFO - 2023-11-30 14:19:07,543: EPOCH 6: training on 191080 raw words (112252 effective words) took 0.2s, 486485 effective words/s
INFO - 2023-11-30 14:19:07,778: EPOCH 7: training on 191080 raw words (112088 effective words) took 0.2s, 481308 effective words/s
INFO - 2023-11-30 14:19:08,011: EPOCH 8: training on 191080 raw words (112339 effective words) took 0.2s, 485848 effective words/s
INFO - 2023-11-30 14:19:08,241: EPOCH 9: training on 191080 raw words (112056 effective words) took 0.2s, 493477 effective words/s
INFO - 2023-11-30 14:19:08,467: EPOCH 10: training on 191080 raw words (112149 effective words) took 0.2s, 501196 effective words/s
INFO - 2023-11-30 14:19:08,705: EPOCH 11: training on 191080 raw words (112098 effective words) took 0.2s, 476803 effective words/s
INFO - 2023-11-30 14:19:09,014: EPOCH 12: training on 191080 raw words (112078 effective words) took 0.3s, 364917 effective words/s
INFO - 2023-11-30 14:19:09,288: EPOCH 13: training on 191080 raw words (112309 effective words) took 0.3s, 445041 effective words/s
INFO - 2023-11-30 14:19:09,532: EPOCH 14: training on 191080 raw words (112128 effective words) took 0.2s, 463513 effective words/s
INFO - 2023-11-30 14:19:09,781: EPOCH 15: training on 191080 raw words (111806 effective words) took 0.2s, 453178 effective words/s
INFO - 2023-11-30 14:19:10,016: EPOCH 16: training on 191080 raw words (111971 effective words) took 0.2s, 481965 effective words/s
INFO - 2023-11-30 14:19:10,253: EPOCH 17: training on 191080 raw words (112265 effective words) took 0.2s, 478944 effective words/s
INFO - 2023-11-30 14:19:10,488: EPOCH 18: training on 191080 raw words (112012 effective words) took 0.2s, 480874 effective words/s
INFO - 2023-11-30 14:19:10,718: EPOCH 19: training on 191080 raw words (111978 effective words) took 0.2s, 492451 effective words/s
INFO - 2023-11-30 14:19:10,718: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2241549 effective words) took 4.8s, 464119 effective words/s', 'datetime': '2023-11-30T14:19:10.718843', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:10,719: collecting all words and their counts
INFO - 2023-11-30 14:19:10,719: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:10,745: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:10,745: Updating model with new vocabulary
INFO - 2023-11-30 14:19:10,757: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:10.757435', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:10,772: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:10,772: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:19:10,772: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111379.27683100954 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:19:10.772846', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:10,795: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:10,795: updating layer weights
INFO - 2023-11-30 14:19:10,795: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:10.795815', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:10,795: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:10,795: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:10.795975', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:10,995: EPOCH 0: training on 191080 raw words (111348 effective words) took 0.2s, 564749 effective words/s
INFO - 2023-11-30 14:19:11,199: EPOCH 1: training on 191080 raw words (111137 effective words) took 0.2s, 551141 effective words/s
INFO - 2023-11-30 14:19:11,407: EPOCH 2: training on 191080 raw words (111364 effective words) took 0.2s, 541525 effective words/s
INFO - 2023-11-30 14:19:11,636: EPOCH 3: training on 191080 raw words (111232 effective words) took 0.2s, 492281 effective words/s
INFO - 2023-11-30 14:19:11,854: EPOCH 4: training on 191080 raw words (111204 effective words) took 0.2s, 515319 effective words/s
INFO - 2023-11-30 14:19:12,082: EPOCH 5: training on 191080 raw words (111557 effective words) took 0.2s, 494542 effective words/s
INFO - 2023-11-30 14:19:12,296: EPOCH 6: training on 191080 raw words (111228 effective words) took 0.2s, 526836 effective words/s
INFO - 2023-11-30 14:19:12,510: EPOCH 7: training on 191080 raw words (111549 effective words) took 0.2s, 526385 effective words/s
INFO - 2023-11-30 14:19:12,733: EPOCH 8: training on 191080 raw words (111180 effective words) took 0.2s, 503145 effective words/s
INFO - 2023-11-30 14:19:12,947: EPOCH 9: training on 191080 raw words (111405 effective words) took 0.2s, 525329 effective words/s
INFO - 2023-11-30 14:19:13,171: EPOCH 10: training on 191080 raw words (111468 effective words) took 0.2s, 503530 effective words/s
INFO - 2023-11-30 14:19:13,401: EPOCH 11: training on 191080 raw words (111518 effective words) took 0.2s, 490103 effective words/s
INFO - 2023-11-30 14:19:13,650: EPOCH 12: training on 191080 raw words (111525 effective words) took 0.2s, 451429 effective words/s
INFO - 2023-11-30 14:19:13,861: EPOCH 13: training on 191080 raw words (111385 effective words) took 0.2s, 535075 effective words/s
INFO - 2023-11-30 14:19:14,077: EPOCH 14: training on 191080 raw words (111543 effective words) took 0.2s, 521757 effective words/s
INFO - 2023-11-30 14:19:14,308: EPOCH 15: training on 191080 raw words (111404 effective words) took 0.2s, 487042 effective words/s
INFO - 2023-11-30 14:19:14,575: EPOCH 16: training on 191080 raw words (111205 effective words) took 0.3s, 422190 effective words/s
INFO - 2023-11-30 14:19:14,789: EPOCH 17: training on 191080 raw words (111236 effective words) took 0.2s, 523743 effective words/s
INFO - 2023-11-30 14:19:14,996: EPOCH 18: training on 191080 raw words (111413 effective words) took 0.2s, 545594 effective words/s
INFO - 2023-11-30 14:19:15,215: EPOCH 19: training on 191080 raw words (111273 effective words) took 0.2s, 513525 effective words/s
INFO - 2023-11-30 14:19:15,215: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2227174 effective words) took 4.4s, 503939 effective words/s', 'datetime': '2023-11-30T14:19:15.215573', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:15,215: collecting all words and their counts
INFO - 2023-11-30 14:19:15,215: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:15,241: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:15,242: Updating model with new vocabulary
INFO - 2023-11-30 14:19:15,256: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:15.256168', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:15,281: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:15,282: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 14:19:15,282: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111702.85249799653 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:19:15.282347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:15,310: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:15,311: updating layer weights
INFO - 2023-11-30 14:19:15,311: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:15.311460', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:15,311: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:15,311: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:15.311825', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:15,595: EPOCH 0: training on 191080 raw words (111682 effective words) took 0.3s, 397850 effective words/s
INFO - 2023-11-30 14:19:15,830: EPOCH 1: training on 191080 raw words (111672 effective words) took 0.2s, 480600 effective words/s
INFO - 2023-11-30 14:19:16,072: EPOCH 2: training on 191080 raw words (111616 effective words) took 0.2s, 466206 effective words/s
INFO - 2023-11-30 14:19:16,352: EPOCH 3: training on 191080 raw words (111757 effective words) took 0.3s, 400901 effective words/s
INFO - 2023-11-30 14:19:16,653: EPOCH 4: training on 191080 raw words (111849 effective words) took 0.3s, 376288 effective words/s
INFO - 2023-11-30 14:19:16,973: EPOCH 5: training on 191080 raw words (111541 effective words) took 0.3s, 351143 effective words/s
INFO - 2023-11-30 14:19:17,280: EPOCH 6: training on 191080 raw words (111691 effective words) took 0.3s, 376510 effective words/s
INFO - 2023-11-30 14:19:17,583: EPOCH 7: training on 191080 raw words (111599 effective words) took 0.3s, 372043 effective words/s
INFO - 2023-11-30 14:19:17,881: EPOCH 8: training on 191080 raw words (111688 effective words) took 0.3s, 377907 effective words/s
INFO - 2023-11-30 14:19:18,208: EPOCH 9: training on 191080 raw words (111721 effective words) took 0.3s, 345635 effective words/s
INFO - 2023-11-30 14:19:18,553: EPOCH 10: training on 191080 raw words (111873 effective words) took 0.3s, 328154 effective words/s
INFO - 2023-11-30 14:19:18,858: EPOCH 11: training on 191080 raw words (111712 effective words) took 0.3s, 369452 effective words/s
INFO - 2023-11-30 14:19:19,166: EPOCH 12: training on 191080 raw words (111799 effective words) took 0.3s, 366798 effective words/s
INFO - 2023-11-30 14:19:19,532: EPOCH 13: training on 191080 raw words (111762 effective words) took 0.4s, 308033 effective words/s
INFO - 2023-11-30 14:19:19,884: EPOCH 14: training on 191080 raw words (111866 effective words) took 0.3s, 320028 effective words/s
INFO - 2023-11-30 14:19:20,244: EPOCH 15: training on 191080 raw words (111864 effective words) took 0.4s, 314663 effective words/s
INFO - 2023-11-30 14:19:20,573: EPOCH 16: training on 191080 raw words (111712 effective words) took 0.3s, 342707 effective words/s
INFO - 2023-11-30 14:19:20,941: EPOCH 17: training on 191080 raw words (111871 effective words) took 0.4s, 306102 effective words/s
INFO - 2023-11-30 14:19:21,257: EPOCH 18: training on 191080 raw words (111664 effective words) took 0.3s, 357052 effective words/s
INFO - 2023-11-30 14:19:21,580: EPOCH 19: training on 191080 raw words (111607 effective words) took 0.3s, 349055 effective words/s
INFO - 2023-11-30 14:19:21,580: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2234546 effective words) took 6.3s, 356468 effective words/s', 'datetime': '2023-11-30T14:19:21.580559', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:21,580: collecting all words and their counts
INFO - 2023-11-30 14:19:21,581: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:21,625: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:21,626: Updating model with new vocabulary
INFO - 2023-11-30 14:19:21,646: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:21.646333', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:21,671: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:21,671: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:19:21,671: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111774.13254259576 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:19:21.671813', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:21,711: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:21,711: updating layer weights
INFO - 2023-11-30 14:19:21,712: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:21.712023', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:21,712: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:21,712: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:21.712406', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:22,004: EPOCH 0: training on 191080 raw words (111932 effective words) took 0.3s, 386709 effective words/s
INFO - 2023-11-30 14:19:22,277: EPOCH 1: training on 191080 raw words (111907 effective words) took 0.3s, 416782 effective words/s
INFO - 2023-11-30 14:19:22,504: EPOCH 2: training on 191080 raw words (111842 effective words) took 0.2s, 498626 effective words/s
INFO - 2023-11-30 14:19:22,711: EPOCH 3: training on 191080 raw words (111730 effective words) took 0.2s, 546428 effective words/s
INFO - 2023-11-30 14:19:22,914: EPOCH 4: training on 191080 raw words (111846 effective words) took 0.2s, 556474 effective words/s
INFO - 2023-11-30 14:19:23,122: EPOCH 5: training on 191080 raw words (111755 effective words) took 0.2s, 545485 effective words/s
INFO - 2023-11-30 14:19:23,347: EPOCH 6: training on 191080 raw words (111742 effective words) took 0.2s, 499661 effective words/s
INFO - 2023-11-30 14:19:23,557: EPOCH 7: training on 191080 raw words (111716 effective words) took 0.2s, 538564 effective words/s
INFO - 2023-11-30 14:19:23,762: EPOCH 8: training on 191080 raw words (111780 effective words) took 0.2s, 552606 effective words/s
INFO - 2023-11-30 14:19:23,967: EPOCH 9: training on 191080 raw words (111731 effective words) took 0.2s, 551010 effective words/s
INFO - 2023-11-30 14:19:24,177: EPOCH 10: training on 191080 raw words (111964 effective words) took 0.2s, 540741 effective words/s
INFO - 2023-11-30 14:19:24,388: EPOCH 11: training on 191080 raw words (111773 effective words) took 0.2s, 534919 effective words/s
INFO - 2023-11-30 14:19:24,590: EPOCH 12: training on 191080 raw words (111841 effective words) took 0.2s, 558982 effective words/s
INFO - 2023-11-30 14:19:24,812: EPOCH 13: training on 191080 raw words (111970 effective words) took 0.2s, 513101 effective words/s
INFO - 2023-11-30 14:19:25,021: EPOCH 14: training on 191080 raw words (111570 effective words) took 0.2s, 537254 effective words/s
INFO - 2023-11-30 14:19:25,262: EPOCH 15: training on 191080 raw words (111668 effective words) took 0.2s, 468024 effective words/s
INFO - 2023-11-30 14:19:25,489: EPOCH 16: training on 191080 raw words (111733 effective words) took 0.2s, 498670 effective words/s
INFO - 2023-11-30 14:19:25,752: EPOCH 17: training on 191080 raw words (111804 effective words) took 0.3s, 428103 effective words/s
INFO - 2023-11-30 14:19:25,967: EPOCH 18: training on 191080 raw words (111888 effective words) took 0.2s, 527776 effective words/s
INFO - 2023-11-30 14:19:26,190: EPOCH 19: training on 191080 raw words (111909 effective words) took 0.2s, 507174 effective words/s
INFO - 2023-11-30 14:19:26,190: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236101 effective words) took 4.5s, 499320 effective words/s', 'datetime': '2023-11-30T14:19:26.190899', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:26,191: collecting all words and their counts
INFO - 2023-11-30 14:19:26,191: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:26,221: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:26,221: Updating model with new vocabulary
INFO - 2023-11-30 14:19:26,234: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:26.234045', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:26,251: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:26,252: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:19:26,252: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111729.30826850313 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:19:26.252369', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:26,279: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:26,279: updating layer weights
INFO - 2023-11-30 14:19:26,280: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:26.280438', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:26,280: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:26,280: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:26.280767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:26,541: EPOCH 0: training on 191080 raw words (111732 effective words) took 0.3s, 434344 effective words/s
INFO - 2023-11-30 14:19:26,789: EPOCH 1: training on 191080 raw words (111694 effective words) took 0.2s, 454532 effective words/s
INFO - 2023-11-30 14:19:27,024: EPOCH 2: training on 191080 raw words (111823 effective words) took 0.2s, 479878 effective words/s
INFO - 2023-11-30 14:19:27,257: EPOCH 3: training on 191080 raw words (111682 effective words) took 0.2s, 486325 effective words/s
INFO - 2023-11-30 14:19:27,537: EPOCH 4: training on 191080 raw words (111684 effective words) took 0.3s, 402249 effective words/s
INFO - 2023-11-30 14:19:27,768: EPOCH 5: training on 191080 raw words (111742 effective words) took 0.2s, 487770 effective words/s
INFO - 2023-11-30 14:19:27,999: EPOCH 6: training on 191080 raw words (111700 effective words) took 0.2s, 486679 effective words/s
INFO - 2023-11-30 14:19:28,257: EPOCH 7: training on 191080 raw words (111597 effective words) took 0.3s, 437973 effective words/s
INFO - 2023-11-30 14:19:28,479: EPOCH 8: training on 191080 raw words (111583 effective words) took 0.2s, 507036 effective words/s
INFO - 2023-11-30 14:19:28,706: EPOCH 9: training on 191080 raw words (111709 effective words) took 0.2s, 498811 effective words/s
INFO - 2023-11-30 14:19:28,934: EPOCH 10: training on 191080 raw words (111819 effective words) took 0.2s, 498420 effective words/s
INFO - 2023-11-30 14:19:29,159: EPOCH 11: training on 191080 raw words (111689 effective words) took 0.2s, 508498 effective words/s
INFO - 2023-11-30 14:19:29,388: EPOCH 12: training on 191080 raw words (111682 effective words) took 0.2s, 493266 effective words/s
INFO - 2023-11-30 14:19:29,616: EPOCH 13: training on 191080 raw words (111803 effective words) took 0.2s, 494923 effective words/s
INFO - 2023-11-30 14:19:29,852: EPOCH 14: training on 191080 raw words (111638 effective words) took 0.2s, 477696 effective words/s
INFO - 2023-11-30 14:19:30,094: EPOCH 15: training on 191080 raw words (111445 effective words) took 0.2s, 465372 effective words/s
INFO - 2023-11-30 14:19:30,389: EPOCH 16: training on 191080 raw words (111672 effective words) took 0.3s, 382195 effective words/s
INFO - 2023-11-30 14:19:30,678: EPOCH 17: training on 191080 raw words (111681 effective words) took 0.3s, 390187 effective words/s
INFO - 2023-11-30 14:19:30,940: EPOCH 18: training on 191080 raw words (111628 effective words) took 0.3s, 431924 effective words/s
INFO - 2023-11-30 14:19:31,193: EPOCH 19: training on 191080 raw words (111646 effective words) took 0.3s, 445992 effective words/s
INFO - 2023-11-30 14:19:31,193: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233649 effective words) took 4.9s, 454685 effective words/s', 'datetime': '2023-11-30T14:19:31.193432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:31,193: collecting all words and their counts
INFO - 2023-11-30 14:19:31,193: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:31,222: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:31,222: Updating model with new vocabulary
INFO - 2023-11-30 14:19:31,235: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:31.235657', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:31,252: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:31,252: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:19:31,252: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111813.40118585654 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:19:31.252503', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:31,277: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:31,277: updating layer weights
INFO - 2023-11-30 14:19:31,277: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:31.277739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:31,277: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:31,277: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:31.277966', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:31,492: EPOCH 0: training on 191080 raw words (111881 effective words) took 0.2s, 525931 effective words/s
INFO - 2023-11-30 14:19:31,705: EPOCH 1: training on 191080 raw words (111710 effective words) took 0.2s, 530230 effective words/s
INFO - 2023-11-30 14:19:31,946: EPOCH 2: training on 191080 raw words (111692 effective words) took 0.2s, 470195 effective words/s
INFO - 2023-11-30 14:19:32,182: EPOCH 3: training on 191080 raw words (112030 effective words) took 0.2s, 479227 effective words/s
INFO - 2023-11-30 14:19:32,429: EPOCH 4: training on 191080 raw words (111747 effective words) took 0.2s, 455685 effective words/s
INFO - 2023-11-30 14:19:32,658: EPOCH 5: training on 191080 raw words (111659 effective words) took 0.2s, 491978 effective words/s
INFO - 2023-11-30 14:19:32,892: EPOCH 6: training on 191080 raw words (111575 effective words) took 0.2s, 483220 effective words/s
INFO - 2023-11-30 14:19:33,139: EPOCH 7: training on 191080 raw words (111836 effective words) took 0.2s, 459441 effective words/s
INFO - 2023-11-30 14:19:33,365: EPOCH 8: training on 191080 raw words (111876 effective words) took 0.2s, 499213 effective words/s
INFO - 2023-11-30 14:19:33,595: EPOCH 9: training on 191080 raw words (111771 effective words) took 0.2s, 491782 effective words/s
INFO - 2023-11-30 14:19:33,832: EPOCH 10: training on 191080 raw words (112026 effective words) took 0.2s, 477633 effective words/s
INFO - 2023-11-30 14:19:34,063: EPOCH 11: training on 191080 raw words (111876 effective words) took 0.2s, 489271 effective words/s
INFO - 2023-11-30 14:19:34,289: EPOCH 12: training on 191080 raw words (111736 effective words) took 0.2s, 500341 effective words/s
INFO - 2023-11-30 14:19:34,516: EPOCH 13: training on 191080 raw words (111968 effective words) took 0.2s, 498762 effective words/s
INFO - 2023-11-30 14:19:34,734: EPOCH 14: training on 191080 raw words (111682 effective words) took 0.2s, 517235 effective words/s
INFO - 2023-11-30 14:19:34,962: EPOCH 15: training on 191080 raw words (111795 effective words) took 0.2s, 496229 effective words/s
INFO - 2023-11-30 14:19:35,190: EPOCH 16: training on 191080 raw words (111771 effective words) took 0.2s, 495308 effective words/s
INFO - 2023-11-30 14:19:35,415: EPOCH 17: training on 191080 raw words (111925 effective words) took 0.2s, 504717 effective words/s
INFO - 2023-11-30 14:19:35,641: EPOCH 18: training on 191080 raw words (111886 effective words) took 0.2s, 498643 effective words/s
INFO - 2023-11-30 14:19:35,866: EPOCH 19: training on 191080 raw words (111771 effective words) took 0.2s, 501766 effective words/s
INFO - 2023-11-30 14:19:35,867: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2236213 effective words) took 4.6s, 487286 effective words/s', 'datetime': '2023-11-30T14:19:35.867155', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:35,867: collecting all words and their counts
INFO - 2023-11-30 14:19:35,867: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:35,894: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:35,894: Updating model with new vocabulary
INFO - 2023-11-30 14:19:35,907: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:35.907233', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:35,923: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:35,923: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:19:35,923: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111674.84253258907 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:19:35.923449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:35,947: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:35,948: updating layer weights
INFO - 2023-11-30 14:19:35,948: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:35.948495', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:35,948: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:35,949: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:35.948930', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:36,196: EPOCH 0: training on 191080 raw words (111717 effective words) took 0.2s, 456998 effective words/s
INFO - 2023-11-30 14:19:36,449: EPOCH 1: training on 191080 raw words (111773 effective words) took 0.3s, 444614 effective words/s
INFO - 2023-11-30 14:19:36,700: EPOCH 2: training on 191080 raw words (111762 effective words) took 0.2s, 450329 effective words/s
INFO - 2023-11-30 14:19:36,977: EPOCH 3: training on 191080 raw words (111818 effective words) took 0.3s, 407068 effective words/s
INFO - 2023-11-30 14:19:37,255: EPOCH 4: training on 191080 raw words (111531 effective words) took 0.3s, 404744 effective words/s
INFO - 2023-11-30 14:19:37,531: EPOCH 5: training on 191080 raw words (111644 effective words) took 0.3s, 408207 effective words/s
INFO - 2023-11-30 14:19:37,870: EPOCH 6: training on 191080 raw words (111571 effective words) took 0.3s, 341564 effective words/s
INFO - 2023-11-30 14:19:38,196: EPOCH 7: training on 191080 raw words (111666 effective words) took 0.3s, 346140 effective words/s
INFO - 2023-11-30 14:19:38,542: EPOCH 8: training on 191080 raw words (111618 effective words) took 0.3s, 325147 effective words/s
INFO - 2023-11-30 14:19:38,888: EPOCH 9: training on 191080 raw words (111718 effective words) took 0.3s, 325753 effective words/s
INFO - 2023-11-30 14:19:39,228: EPOCH 10: training on 191080 raw words (111585 effective words) took 0.3s, 331356 effective words/s
INFO - 2023-11-30 14:19:39,520: EPOCH 11: training on 191080 raw words (111773 effective words) took 0.3s, 388385 effective words/s
INFO - 2023-11-30 14:19:39,847: EPOCH 12: training on 191080 raw words (111664 effective words) took 0.3s, 344954 effective words/s
INFO - 2023-11-30 14:19:40,197: EPOCH 13: training on 191080 raw words (111712 effective words) took 0.3s, 322146 effective words/s
INFO - 2023-11-30 14:19:40,534: EPOCH 14: training on 191080 raw words (111611 effective words) took 0.3s, 334219 effective words/s
INFO - 2023-11-30 14:19:40,909: EPOCH 15: training on 191080 raw words (111655 effective words) took 0.4s, 301253 effective words/s
INFO - 2023-11-30 14:19:41,293: EPOCH 16: training on 191080 raw words (111590 effective words) took 0.4s, 292422 effective words/s
INFO - 2023-11-30 14:19:41,648: EPOCH 17: training on 191080 raw words (111675 effective words) took 0.4s, 317899 effective words/s
INFO - 2023-11-30 14:19:42,006: EPOCH 18: training on 191080 raw words (111771 effective words) took 0.4s, 315022 effective words/s
INFO - 2023-11-30 14:19:42,399: EPOCH 19: training on 191080 raw words (111629 effective words) took 0.4s, 286537 effective words/s
INFO - 2023-11-30 14:19:42,399: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2233483 effective words) took 6.5s, 346245 effective words/s', 'datetime': '2023-11-30T14:19:42.399736', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:42,399: collecting all words and their counts
INFO - 2023-11-30 14:19:42,400: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:42,451: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:42,451: Updating model with new vocabulary
INFO - 2023-11-30 14:19:42,476: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:42.476171', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:42,506: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:42,506: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:19:42,506: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111548.97923020157 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:19:42.506700', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:42,545: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:42,545: updating layer weights
INFO - 2023-11-30 14:19:42,546: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:42.546471', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:42,546: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:42,546: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:42.546854', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:42,906: EPOCH 0: training on 191080 raw words (111668 effective words) took 0.4s, 313999 effective words/s
INFO - 2023-11-30 14:19:43,278: EPOCH 1: training on 191080 raw words (111521 effective words) took 0.4s, 308395 effective words/s
INFO - 2023-11-30 14:19:43,638: EPOCH 2: training on 191080 raw words (111543 effective words) took 0.4s, 312305 effective words/s
INFO - 2023-11-30 14:19:44,010: EPOCH 3: training on 191080 raw words (111590 effective words) took 0.4s, 303208 effective words/s
INFO - 2023-11-30 14:19:44,371: EPOCH 4: training on 191080 raw words (111602 effective words) took 0.4s, 313696 effective words/s
INFO - 2023-11-30 14:19:44,727: EPOCH 5: training on 191080 raw words (111442 effective words) took 0.4s, 315494 effective words/s
INFO - 2023-11-30 14:19:45,079: EPOCH 6: training on 191080 raw words (111543 effective words) took 0.3s, 320451 effective words/s
INFO - 2023-11-30 14:19:45,438: EPOCH 7: training on 191080 raw words (111552 effective words) took 0.4s, 314127 effective words/s
INFO - 2023-11-30 14:19:45,811: EPOCH 8: training on 191080 raw words (111840 effective words) took 0.4s, 303056 effective words/s
INFO - 2023-11-30 14:19:46,178: EPOCH 9: training on 191080 raw words (111435 effective words) took 0.4s, 307058 effective words/s
INFO - 2023-11-30 14:19:46,514: EPOCH 10: training on 191080 raw words (111579 effective words) took 0.3s, 335227 effective words/s
INFO - 2023-11-30 14:19:46,812: EPOCH 11: training on 191080 raw words (111609 effective words) took 0.3s, 378118 effective words/s
INFO - 2023-11-30 14:19:47,089: EPOCH 12: training on 191080 raw words (111706 effective words) took 0.3s, 407080 effective words/s
INFO - 2023-11-30 14:19:47,376: EPOCH 13: training on 191080 raw words (111669 effective words) took 0.3s, 393249 effective words/s
INFO - 2023-11-30 14:19:47,667: EPOCH 14: training on 191080 raw words (111410 effective words) took 0.3s, 386280 effective words/s
INFO - 2023-11-30 14:19:47,963: EPOCH 15: training on 191080 raw words (111448 effective words) took 0.3s, 380838 effective words/s
INFO - 2023-11-30 14:19:48,249: EPOCH 16: training on 191080 raw words (111535 effective words) took 0.3s, 394048 effective words/s
INFO - 2023-11-30 14:19:48,545: EPOCH 17: training on 191080 raw words (111548 effective words) took 0.3s, 380625 effective words/s
INFO - 2023-11-30 14:19:48,852: EPOCH 18: training on 191080 raw words (111632 effective words) took 0.3s, 366710 effective words/s
INFO - 2023-11-30 14:19:49,148: EPOCH 19: training on 191080 raw words (111269 effective words) took 0.3s, 380500 effective words/s
INFO - 2023-11-30 14:19:49,148: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231141 effective words) took 6.6s, 337979 effective words/s', 'datetime': '2023-11-30T14:19:49.148782', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:49,149: collecting all words and their counts
INFO - 2023-11-30 14:19:49,149: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:49,185: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:49,185: Updating model with new vocabulary
INFO - 2023-11-30 14:19:49,204: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:49.204597', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:49,227: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:49,228: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:19:49,228: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 112005.5207764665 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:19:49.228180', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:49,260: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:49,260: updating layer weights
INFO - 2023-11-30 14:19:49,261: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:49.261033', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:49,261: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:49,261: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:49.261363', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:49,553: EPOCH 0: training on 191080 raw words (112128 effective words) took 0.3s, 421526 effective words/s
INFO - 2023-11-30 14:19:49,868: EPOCH 1: training on 191080 raw words (111735 effective words) took 0.3s, 357470 effective words/s
INFO - 2023-11-30 14:19:50,145: EPOCH 2: training on 191080 raw words (111880 effective words) took 0.3s, 411128 effective words/s
INFO - 2023-11-30 14:19:50,424: EPOCH 3: training on 191080 raw words (111774 effective words) took 0.3s, 404735 effective words/s
INFO - 2023-11-30 14:19:50,726: EPOCH 4: training on 191080 raw words (112037 effective words) took 0.3s, 373997 effective words/s
INFO - 2023-11-30 14:19:51,017: EPOCH 5: training on 191080 raw words (112089 effective words) took 0.3s, 389951 effective words/s
INFO - 2023-11-30 14:19:51,304: EPOCH 6: training on 191080 raw words (112077 effective words) took 0.3s, 393376 effective words/s
INFO - 2023-11-30 14:19:51,617: EPOCH 7: training on 191080 raw words (111902 effective words) took 0.3s, 360893 effective words/s
INFO - 2023-11-30 14:19:51,916: EPOCH 8: training on 191080 raw words (111949 effective words) took 0.3s, 377684 effective words/s
INFO - 2023-11-30 14:19:52,217: EPOCH 9: training on 191080 raw words (111830 effective words) took 0.3s, 374706 effective words/s
INFO - 2023-11-30 14:19:52,538: EPOCH 10: training on 191080 raw words (111782 effective words) took 0.3s, 351934 effective words/s
INFO - 2023-11-30 14:19:52,828: EPOCH 11: training on 191080 raw words (111920 effective words) took 0.3s, 391728 effective words/s
INFO - 2023-11-30 14:19:53,134: EPOCH 12: training on 191080 raw words (111834 effective words) took 0.3s, 370372 effective words/s
INFO - 2023-11-30 14:19:53,410: EPOCH 13: training on 191080 raw words (112157 effective words) took 0.3s, 409406 effective words/s
INFO - 2023-11-30 14:19:53,682: EPOCH 14: training on 191080 raw words (112089 effective words) took 0.3s, 416711 effective words/s
INFO - 2023-11-30 14:19:53,922: EPOCH 15: training on 191080 raw words (112150 effective words) took 0.2s, 473486 effective words/s
INFO - 2023-11-30 14:19:54,170: EPOCH 16: training on 191080 raw words (111725 effective words) took 0.2s, 454642 effective words/s
INFO - 2023-11-30 14:19:54,407: EPOCH 17: training on 191080 raw words (111984 effective words) took 0.2s, 479294 effective words/s
INFO - 2023-11-30 14:19:54,698: EPOCH 18: training on 191080 raw words (112173 effective words) took 0.3s, 388303 effective words/s
INFO - 2023-11-30 14:19:54,938: EPOCH 19: training on 191080 raw words (112070 effective words) took 0.2s, 473517 effective words/s
INFO - 2023-11-30 14:19:54,938: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2239285 effective words) took 5.7s, 394449 effective words/s', 'datetime': '2023-11-30T14:19:54.938513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:54,938: collecting all words and their counts
INFO - 2023-11-30 14:19:54,938: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:19:54,974: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:19:54,974: Updating model with new vocabulary
INFO - 2023-11-30 14:19:54,986: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:19:54.986787', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:55,003: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:19:55,003: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:19:55,004: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111531.10309580393 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:19:55.004073', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:19:55,029: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:19:55,030: updating layer weights
INFO - 2023-11-30 14:19:55,030: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:19:55.030618', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:19:55,030: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:19:55,030: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:19:55.030884', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:19:55,261: EPOCH 0: training on 191080 raw words (111424 effective words) took 0.2s, 490979 effective words/s
INFO - 2023-11-30 14:19:55,482: EPOCH 1: training on 191080 raw words (111622 effective words) took 0.2s, 509000 effective words/s
INFO - 2023-11-30 14:19:55,732: EPOCH 2: training on 191080 raw words (111570 effective words) took 0.2s, 450745 effective words/s
INFO - 2023-11-30 14:19:55,981: EPOCH 3: training on 191080 raw words (111450 effective words) took 0.2s, 452823 effective words/s
INFO - 2023-11-30 14:19:56,274: EPOCH 4: training on 191080 raw words (111461 effective words) took 0.3s, 384233 effective words/s
INFO - 2023-11-30 14:19:56,663: EPOCH 5: training on 191080 raw words (111604 effective words) took 0.4s, 288193 effective words/s
INFO - 2023-11-30 14:19:56,979: EPOCH 6: training on 191080 raw words (111465 effective words) took 0.3s, 358865 effective words/s
INFO - 2023-11-30 14:19:57,233: EPOCH 7: training on 191080 raw words (111618 effective words) took 0.3s, 446145 effective words/s
INFO - 2023-11-30 14:19:57,473: EPOCH 8: training on 191080 raw words (111444 effective words) took 0.2s, 468423 effective words/s
INFO - 2023-11-30 14:19:57,730: EPOCH 9: training on 191080 raw words (111608 effective words) took 0.3s, 438787 effective words/s
INFO - 2023-11-30 14:19:57,978: EPOCH 10: training on 191080 raw words (111477 effective words) took 0.2s, 455255 effective words/s
INFO - 2023-11-30 14:19:58,239: EPOCH 11: training on 191080 raw words (111566 effective words) took 0.3s, 432816 effective words/s
INFO - 2023-11-30 14:19:58,490: EPOCH 12: training on 191080 raw words (111300 effective words) took 0.2s, 448561 effective words/s
INFO - 2023-11-30 14:19:58,742: EPOCH 13: training on 191080 raw words (111607 effective words) took 0.2s, 448233 effective words/s
INFO - 2023-11-30 14:19:58,988: EPOCH 14: training on 191080 raw words (111413 effective words) took 0.2s, 458936 effective words/s
INFO - 2023-11-30 14:19:59,233: EPOCH 15: training on 191080 raw words (111583 effective words) took 0.2s, 459668 effective words/s
INFO - 2023-11-30 14:19:59,521: EPOCH 16: training on 191080 raw words (111691 effective words) took 0.3s, 393433 effective words/s
INFO - 2023-11-30 14:19:59,863: EPOCH 17: training on 191080 raw words (111448 effective words) took 0.3s, 328256 effective words/s
INFO - 2023-11-30 14:20:00,122: EPOCH 18: training on 191080 raw words (111485 effective words) took 0.3s, 436060 effective words/s
INFO - 2023-11-30 14:20:00,355: EPOCH 19: training on 191080 raw words (111452 effective words) took 0.2s, 483321 effective words/s
INFO - 2023-11-30 14:20:00,355: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2230288 effective words) took 5.3s, 418903 effective words/s', 'datetime': '2023-11-30T14:20:00.355322', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:00,355: collecting all words and their counts
INFO - 2023-11-30 14:20:00,355: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:00,389: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:00,390: Updating model with new vocabulary
INFO - 2023-11-30 14:20:00,404: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:00.404599', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:00,422: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:00,422: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 14:20:00,423: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111376.1240262889 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:20:00.423042', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:00,450: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:00,450: updating layer weights
INFO - 2023-11-30 14:20:00,450: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:00.450874', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:00,451: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:00,451: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:00.451105', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:00,690: EPOCH 0: training on 191080 raw words (111339 effective words) took 0.2s, 468775 effective words/s
INFO - 2023-11-30 14:20:00,956: EPOCH 1: training on 191080 raw words (111243 effective words) took 0.3s, 423801 effective words/s
INFO - 2023-11-30 14:20:01,250: EPOCH 2: training on 191080 raw words (111319 effective words) took 0.3s, 382709 effective words/s
INFO - 2023-11-30 14:20:01,524: EPOCH 3: training on 191080 raw words (111257 effective words) took 0.3s, 409411 effective words/s
INFO - 2023-11-30 14:20:01,785: EPOCH 4: training on 191080 raw words (111579 effective words) took 0.3s, 431748 effective words/s
INFO - 2023-11-30 14:20:02,051: EPOCH 5: training on 191080 raw words (111419 effective words) took 0.3s, 424203 effective words/s
INFO - 2023-11-30 14:20:02,310: EPOCH 6: training on 191080 raw words (111428 effective words) took 0.3s, 435618 effective words/s
INFO - 2023-11-30 14:20:02,602: EPOCH 7: training on 191080 raw words (111580 effective words) took 0.3s, 385120 effective words/s
INFO - 2023-11-30 14:20:02,824: EPOCH 8: training on 191080 raw words (111219 effective words) took 0.2s, 505604 effective words/s
INFO - 2023-11-30 14:20:03,043: EPOCH 9: training on 191080 raw words (111490 effective words) took 0.2s, 513196 effective words/s
INFO - 2023-11-30 14:20:03,270: EPOCH 10: training on 191080 raw words (111435 effective words) took 0.2s, 498400 effective words/s
INFO - 2023-11-30 14:20:03,489: EPOCH 11: training on 191080 raw words (111464 effective words) took 0.2s, 512256 effective words/s
INFO - 2023-11-30 14:20:03,713: EPOCH 12: training on 191080 raw words (111590 effective words) took 0.2s, 503081 effective words/s
INFO - 2023-11-30 14:20:03,938: EPOCH 13: training on 191080 raw words (111432 effective words) took 0.2s, 501005 effective words/s
INFO - 2023-11-30 14:20:04,159: EPOCH 14: training on 191080 raw words (111374 effective words) took 0.2s, 508971 effective words/s
INFO - 2023-11-30 14:20:04,404: EPOCH 15: training on 191080 raw words (111226 effective words) took 0.2s, 461963 effective words/s
INFO - 2023-11-30 14:20:04,627: EPOCH 16: training on 191080 raw words (111473 effective words) took 0.2s, 505275 effective words/s
INFO - 2023-11-30 14:20:04,851: EPOCH 17: training on 191080 raw words (111392 effective words) took 0.2s, 501280 effective words/s
INFO - 2023-11-30 14:20:05,071: EPOCH 18: training on 191080 raw words (111147 effective words) took 0.2s, 510049 effective words/s
INFO - 2023-11-30 14:20:05,293: EPOCH 19: training on 191080 raw words (111373 effective words) took 0.2s, 507220 effective words/s
INFO - 2023-11-30 14:20:05,294: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2227779 effective words) took 4.8s, 460024 effective words/s', 'datetime': '2023-11-30T14:20:05.293955', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:05,294: collecting all words and their counts
INFO - 2023-11-30 14:20:05,294: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:05,320: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:05,320: Updating model with new vocabulary
INFO - 2023-11-30 14:20:05,331: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:05.331791', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:05,348: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:05,348: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:20:05,348: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111589.24002236471 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:20:05.348735', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:05,370: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:05,370: updating layer weights
INFO - 2023-11-30 14:20:05,371: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:05.371332', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:05,371: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:05,371: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:05.371547', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:05,579: EPOCH 0: training on 191080 raw words (111589 effective words) took 0.2s, 544152 effective words/s
INFO - 2023-11-30 14:20:05,819: EPOCH 1: training on 191080 raw words (111541 effective words) took 0.2s, 468531 effective words/s
INFO - 2023-11-30 14:20:06,034: EPOCH 2: training on 191080 raw words (111447 effective words) took 0.2s, 524937 effective words/s
INFO - 2023-11-30 14:20:06,260: EPOCH 3: training on 191080 raw words (111646 effective words) took 0.2s, 498908 effective words/s
INFO - 2023-11-30 14:20:06,487: EPOCH 4: training on 191080 raw words (111510 effective words) took 0.2s, 497158 effective words/s
INFO - 2023-11-30 14:20:06,715: EPOCH 5: training on 191080 raw words (111859 effective words) took 0.2s, 494861 effective words/s
INFO - 2023-11-30 14:20:06,937: EPOCH 6: training on 191080 raw words (111713 effective words) took 0.2s, 509440 effective words/s
INFO - 2023-11-30 14:20:07,185: EPOCH 7: training on 191080 raw words (111476 effective words) took 0.2s, 452906 effective words/s
INFO - 2023-11-30 14:20:07,407: EPOCH 8: training on 191080 raw words (111431 effective words) took 0.2s, 508048 effective words/s
INFO - 2023-11-30 14:20:07,627: EPOCH 9: training on 191080 raw words (111829 effective words) took 0.2s, 515179 effective words/s
INFO - 2023-11-30 14:20:07,838: EPOCH 10: training on 191080 raw words (111582 effective words) took 0.2s, 535387 effective words/s
INFO - 2023-11-30 14:20:08,050: EPOCH 11: training on 191080 raw words (111746 effective words) took 0.2s, 533528 effective words/s
INFO - 2023-11-30 14:20:08,272: EPOCH 12: training on 191080 raw words (111543 effective words) took 0.2s, 510030 effective words/s
INFO - 2023-11-30 14:20:08,480: EPOCH 13: training on 191080 raw words (111449 effective words) took 0.2s, 540355 effective words/s
INFO - 2023-11-30 14:20:08,728: EPOCH 14: training on 191080 raw words (111519 effective words) took 0.2s, 454631 effective words/s
INFO - 2023-11-30 14:20:08,946: EPOCH 15: training on 191080 raw words (111668 effective words) took 0.2s, 518733 effective words/s
INFO - 2023-11-30 14:20:09,156: EPOCH 16: training on 191080 raw words (111653 effective words) took 0.2s, 536315 effective words/s
INFO - 2023-11-30 14:20:09,371: EPOCH 17: training on 191080 raw words (111535 effective words) took 0.2s, 525219 effective words/s
INFO - 2023-11-30 14:20:09,585: EPOCH 18: training on 191080 raw words (111608 effective words) took 0.2s, 527085 effective words/s
INFO - 2023-11-30 14:20:09,838: EPOCH 19: training on 191080 raw words (111396 effective words) took 0.3s, 444963 effective words/s
INFO - 2023-11-30 14:20:09,838: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2231740 effective words) took 4.5s, 499611 effective words/s', 'datetime': '2023-11-30T14:20:09.838627', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:09,838: collecting all words and their counts
INFO - 2023-11-30 14:20:09,839: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:09,868: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:09,868: Updating model with new vocabulary
INFO - 2023-11-30 14:20:09,883: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:09.883461', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:09,899: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:09,899: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 14:20:09,899: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111448.98379385774 word corpus (58.3%% of prior 191080)', 'datetime': '2023-11-30T14:20:09.899649', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:09,923: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:09,923: updating layer weights
INFO - 2023-11-30 14:20:09,923: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:09.923943', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:09,924: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:09,924: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:09.924211', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:10,158: EPOCH 0: training on 191080 raw words (111364 effective words) took 0.2s, 481478 effective words/s
INFO - 2023-11-30 14:20:10,397: EPOCH 1: training on 191080 raw words (111541 effective words) took 0.2s, 470788 effective words/s
INFO - 2023-11-30 14:20:10,628: EPOCH 2: training on 191080 raw words (111557 effective words) took 0.2s, 488010 effective words/s
INFO - 2023-11-30 14:20:10,863: EPOCH 3: training on 191080 raw words (111431 effective words) took 0.2s, 478246 effective words/s
INFO - 2023-11-30 14:20:11,099: EPOCH 4: training on 191080 raw words (111463 effective words) took 0.2s, 477572 effective words/s
INFO - 2023-11-30 14:20:11,338: EPOCH 5: training on 191080 raw words (111231 effective words) took 0.2s, 469674 effective words/s
INFO - 2023-11-30 14:20:11,597: EPOCH 6: training on 191080 raw words (111069 effective words) took 0.3s, 433547 effective words/s
INFO - 2023-11-30 14:20:11,944: EPOCH 7: training on 191080 raw words (111430 effective words) took 0.3s, 322591 effective words/s
INFO - 2023-11-30 14:20:12,316: EPOCH 8: training on 191080 raw words (111478 effective words) took 0.4s, 302639 effective words/s
INFO - 2023-11-30 14:20:12,675: EPOCH 9: training on 191080 raw words (111567 effective words) took 0.4s, 313168 effective words/s
INFO - 2023-11-30 14:20:13,015: EPOCH 10: training on 191080 raw words (111527 effective words) took 0.3s, 331598 effective words/s
INFO - 2023-11-30 14:20:13,360: EPOCH 11: training on 191080 raw words (111239 effective words) took 0.3s, 324715 effective words/s
INFO - 2023-11-30 14:20:13,691: EPOCH 12: training on 191080 raw words (111574 effective words) took 0.3s, 342241 effective words/s
INFO - 2023-11-30 14:20:14,041: EPOCH 13: training on 191080 raw words (111477 effective words) took 0.3s, 322023 effective words/s
INFO - 2023-11-30 14:20:14,384: EPOCH 14: training on 191080 raw words (111377 effective words) took 0.3s, 328900 effective words/s
INFO - 2023-11-30 14:20:14,710: EPOCH 15: training on 191080 raw words (111368 effective words) took 0.3s, 344632 effective words/s
INFO - 2023-11-30 14:20:15,227: EPOCH 16: training on 191080 raw words (111607 effective words) took 0.5s, 217485 effective words/s
INFO - 2023-11-30 14:20:15,564: EPOCH 17: training on 191080 raw words (111461 effective words) took 0.3s, 333967 effective words/s
INFO - 2023-11-30 14:20:15,900: EPOCH 18: training on 191080 raw words (111467 effective words) took 0.3s, 334973 effective words/s
INFO - 2023-11-30 14:20:16,223: EPOCH 19: training on 191080 raw words (111317 effective words) took 0.3s, 347717 effective words/s
INFO - 2023-11-30 14:20:16,224: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2228545 effective words) took 6.3s, 353744 effective words/s', 'datetime': '2023-11-30T14:20:16.224234', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:16,224: collecting all words and their counts
INFO - 2023-11-30 14:20:16,224: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:16,261: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:16,262: Updating model with new vocabulary
INFO - 2023-11-30 14:20:16,278: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:16.278547', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:16,299: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:16,299: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:20:16,299: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111682.41445789648 word corpus (58.4%% of prior 191080)', 'datetime': '2023-11-30T14:20:16.299969', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:16,333: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:16,333: updating layer weights
INFO - 2023-11-30 14:20:16,333: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:16.333801', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:16,333: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:16,334: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:16.334131', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:16,633: EPOCH 0: training on 191080 raw words (111564 effective words) took 0.3s, 377025 effective words/s
INFO - 2023-11-30 14:20:16,940: EPOCH 1: training on 191080 raw words (111366 effective words) took 0.3s, 365520 effective words/s
INFO - 2023-11-30 14:20:17,253: EPOCH 2: training on 191080 raw words (111518 effective words) took 0.3s, 359942 effective words/s
INFO - 2023-11-30 14:20:17,551: EPOCH 3: training on 191080 raw words (111641 effective words) took 0.3s, 378836 effective words/s
INFO - 2023-11-30 14:20:17,854: EPOCH 4: training on 191080 raw words (111407 effective words) took 0.3s, 371544 effective words/s
INFO - 2023-11-30 14:20:18,157: EPOCH 5: training on 191080 raw words (111603 effective words) took 0.3s, 371860 effective words/s
INFO - 2023-11-30 14:20:18,462: EPOCH 6: training on 191080 raw words (111514 effective words) took 0.3s, 369615 effective words/s
INFO - 2023-11-30 14:20:18,768: EPOCH 7: training on 191080 raw words (111630 effective words) took 0.3s, 368940 effective words/s
INFO - 2023-11-30 14:20:19,073: EPOCH 8: training on 191080 raw words (111491 effective words) took 0.3s, 369611 effective words/s
INFO - 2023-11-30 14:20:19,380: EPOCH 9: training on 191080 raw words (111664 effective words) took 0.3s, 367747 effective words/s
INFO - 2023-11-30 14:20:19,682: EPOCH 10: training on 191080 raw words (111687 effective words) took 0.3s, 373368 effective words/s
INFO - 2023-11-30 14:20:19,944: EPOCH 11: training on 191080 raw words (111765 effective words) took 0.2s, 469090 effective words/s
INFO - 2023-11-30 14:20:20,202: EPOCH 12: training on 191080 raw words (111651 effective words) took 0.3s, 437597 effective words/s
INFO - 2023-11-30 14:20:20,464: EPOCH 13: training on 191080 raw words (111608 effective words) took 0.3s, 430229 effective words/s
INFO - 2023-11-30 14:20:20,725: EPOCH 14: training on 191080 raw words (111713 effective words) took 0.3s, 432621 effective words/s
INFO - 2023-11-30 14:20:20,979: EPOCH 15: training on 191080 raw words (111398 effective words) took 0.3s, 444040 effective words/s
INFO - 2023-11-30 14:20:21,255: EPOCH 16: training on 191080 raw words (111966 effective words) took 0.3s, 409842 effective words/s
INFO - 2023-11-30 14:20:21,536: EPOCH 17: training on 191080 raw words (111817 effective words) took 0.3s, 401893 effective words/s
INFO - 2023-11-30 14:20:21,868: EPOCH 18: training on 191080 raw words (111676 effective words) took 0.3s, 339475 effective words/s
INFO - 2023-11-30 14:20:22,149: EPOCH 19: training on 191080 raw words (111547 effective words) took 0.3s, 400775 effective words/s
INFO - 2023-11-30 14:20:22,149: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2232226 effective words) took 5.8s, 383862 effective words/s', 'datetime': '2023-11-30T14:20:22.149498', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:22,149: collecting all words and their counts
INFO - 2023-11-30 14:20:22,149: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:22,183: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:22,183: Updating model with new vocabulary
INFO - 2023-11-30 14:20:22,200: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:22.200091', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:22,220: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:22,220: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:20:22,220: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111755.42857868937 word corpus (58.5%% of prior 191080)', 'datetime': '2023-11-30T14:20:22.220366', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:22,251: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:22,251: updating layer weights
INFO - 2023-11-30 14:20:22,252: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:22.252344', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:22,252: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:22,253: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:22.253300', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:22,535: EPOCH 0: training on 191080 raw words (111615 effective words) took 0.3s, 401260 effective words/s
INFO - 2023-11-30 14:20:22,790: EPOCH 1: training on 191080 raw words (111783 effective words) took 0.3s, 442094 effective words/s
INFO - 2023-11-30 14:20:23,012: EPOCH 2: training on 191080 raw words (111675 effective words) took 0.2s, 509801 effective words/s
INFO - 2023-11-30 14:20:23,238: EPOCH 3: training on 191080 raw words (111657 effective words) took 0.2s, 498167 effective words/s
INFO - 2023-11-30 14:20:23,461: EPOCH 4: training on 191080 raw words (111726 effective words) took 0.2s, 505018 effective words/s
INFO - 2023-11-30 14:20:23,684: EPOCH 5: training on 191080 raw words (111589 effective words) took 0.2s, 505232 effective words/s
INFO - 2023-11-30 14:20:23,910: EPOCH 6: training on 191080 raw words (111845 effective words) took 0.2s, 499908 effective words/s
INFO - 2023-11-30 14:20:24,131: EPOCH 7: training on 191080 raw words (111573 effective words) took 0.2s, 511140 effective words/s
INFO - 2023-11-30 14:20:24,352: EPOCH 8: training on 191080 raw words (112050 effective words) took 0.2s, 511520 effective words/s
INFO - 2023-11-30 14:20:24,579: EPOCH 9: training on 191080 raw words (112033 effective words) took 0.2s, 498467 effective words/s
INFO - 2023-11-30 14:20:24,794: EPOCH 10: training on 191080 raw words (112054 effective words) took 0.2s, 528219 effective words/s
INFO - 2023-11-30 14:20:25,018: EPOCH 11: training on 191080 raw words (111760 effective words) took 0.2s, 503134 effective words/s
INFO - 2023-11-30 14:20:25,239: EPOCH 12: training on 191080 raw words (111668 effective words) took 0.2s, 509844 effective words/s
INFO - 2023-11-30 14:20:25,465: EPOCH 13: training on 191080 raw words (111794 effective words) took 0.2s, 500976 effective words/s
INFO - 2023-11-30 14:20:25,683: EPOCH 14: training on 191080 raw words (111870 effective words) took 0.2s, 517502 effective words/s
INFO - 2023-11-30 14:20:25,909: EPOCH 15: training on 191080 raw words (111864 effective words) took 0.2s, 500943 effective words/s
INFO - 2023-11-30 14:20:26,130: EPOCH 16: training on 191080 raw words (111801 effective words) took 0.2s, 509615 effective words/s
INFO - 2023-11-30 14:20:26,359: EPOCH 17: training on 191080 raw words (111685 effective words) took 0.2s, 491883 effective words/s
INFO - 2023-11-30 14:20:26,580: EPOCH 18: training on 191080 raw words (111739 effective words) took 0.2s, 512525 effective words/s
INFO - 2023-11-30 14:20:26,802: EPOCH 19: training on 191080 raw words (112090 effective words) took 0.2s, 510512 effective words/s
INFO - 2023-11-30 14:20:26,802: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2235871 effective words) took 4.5s, 491557 effective words/s', 'datetime': '2023-11-30T14:20:26.802259', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:26,802: collecting all words and their counts
INFO - 2023-11-30 14:20:26,802: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 14:20:26,828: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 14:20:26,828: Updating model with new vocabulary
INFO - 2023-11-30 14:20:26,840: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T14:20:26.840341', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:26,854: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 14:20:26,854: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 14:20:26,854: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111989.80032198515 word corpus (58.6%% of prior 191080)', 'datetime': '2023-11-30T14:20:26.854882', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 14:20:26,877: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 14:20:26,877: updating layer weights
INFO - 2023-11-30 14:20:26,877: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T14:20:26.877711', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 14:20:26,877: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 14:20:26,877: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T14:20:26.877908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:27,145: EPOCH 0: training on 191080 raw words (111933 effective words) took 0.3s, 422146 effective words/s
INFO - 2023-11-30 14:20:27,353: EPOCH 1: training on 191080 raw words (111927 effective words) took 0.2s, 544295 effective words/s
INFO - 2023-11-30 14:20:27,559: EPOCH 2: training on 191080 raw words (112037 effective words) took 0.2s, 548488 effective words/s
INFO - 2023-11-30 14:20:27,766: EPOCH 3: training on 191080 raw words (111852 effective words) took 0.2s, 548019 effective words/s
INFO - 2023-11-30 14:20:27,970: EPOCH 4: training on 191080 raw words (111851 effective words) took 0.2s, 555387 effective words/s
INFO - 2023-11-30 14:20:28,180: EPOCH 5: training on 191080 raw words (112055 effective words) took 0.2s, 541685 effective words/s
INFO - 2023-11-30 14:20:28,383: EPOCH 6: training on 191080 raw words (111918 effective words) took 0.2s, 557542 effective words/s
INFO - 2023-11-30 14:20:28,587: EPOCH 7: training on 191080 raw words (111978 effective words) took 0.2s, 558140 effective words/s
INFO - 2023-11-30 14:20:28,792: EPOCH 8: training on 191080 raw words (111954 effective words) took 0.2s, 551462 effective words/s
INFO - 2023-11-30 14:20:28,996: EPOCH 9: training on 191080 raw words (111844 effective words) took 0.2s, 554543 effective words/s
INFO - 2023-11-30 14:20:29,219: EPOCH 10: training on 191080 raw words (112156 effective words) took 0.2s, 510391 effective words/s
INFO - 2023-11-30 14:20:29,442: EPOCH 11: training on 191080 raw words (111756 effective words) took 0.2s, 505161 effective words/s
INFO - 2023-11-30 14:20:29,666: EPOCH 12: training on 191080 raw words (112047 effective words) took 0.2s, 505155 effective words/s
INFO - 2023-11-30 14:20:29,874: EPOCH 13: training on 191080 raw words (112147 effective words) took 0.2s, 545106 effective words/s
INFO - 2023-11-30 14:20:30,085: EPOCH 14: training on 191080 raw words (112086 effective words) took 0.2s, 539253 effective words/s
INFO - 2023-11-30 14:20:30,293: EPOCH 15: training on 191080 raw words (111966 effective words) took 0.2s, 544114 effective words/s
INFO - 2023-11-30 14:20:30,506: EPOCH 16: training on 191080 raw words (112241 effective words) took 0.2s, 531506 effective words/s
INFO - 2023-11-30 14:20:30,718: EPOCH 17: training on 191080 raw words (111902 effective words) took 0.2s, 532892 effective words/s
INFO - 2023-11-30 14:20:30,947: EPOCH 18: training on 191080 raw words (111864 effective words) took 0.2s, 494603 effective words/s
INFO - 2023-11-30 14:20:31,191: EPOCH 19: training on 191080 raw words (111955 effective words) took 0.2s, 464887 effective words/s
INFO - 2023-11-30 14:20:31,191: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2239469 effective words) took 4.3s, 519167 effective words/s', 'datetime': '2023-11-30T14:20:31.191589', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 14:20:31,194: storing 4777x128 projection weights into POS.txt
