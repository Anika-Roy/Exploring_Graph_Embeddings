INFO - 2023-11-30 15:36:44,196: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-30T15:36:44.156323', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-30 15:36:44,198: collecting all words and their counts
INFO - 2023-11-30 15:36:44,198: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:36:44,226: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:36:44,226: Creating a fresh vocabulary
INFO - 2023-11-30 15:36:44,237: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 4777 unique words (100.00% of original 4777, drops 0)', 'datetime': '2023-11-30T15:36:44.236973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:44,237: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 191080 word corpus (100.00% of original 191080, drops 0)', 'datetime': '2023-11-30T15:36:44.237127', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:44,251: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:36:44,252: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:36:44,252: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115680.8218727892 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:36:44.252278', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:44,277: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:36:44,277: resetting layer weights
INFO - 2023-11-30 15:36:44,280: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-30T15:36:44.280182', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-30 15:36:44,280: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:36:44.280377', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:44,565: EPOCH 0: training on 191080 raw words (115440 effective words) took 0.3s, 407936 effective words/s
INFO - 2023-11-30 15:36:44,827: EPOCH 1: training on 191080 raw words (115738 effective words) took 0.3s, 446634 effective words/s
INFO - 2023-11-30 15:36:45,060: EPOCH 2: training on 191080 raw words (115810 effective words) took 0.2s, 501871 effective words/s
INFO - 2023-11-30 15:36:45,282: EPOCH 3: training on 191080 raw words (115949 effective words) took 0.2s, 529292 effective words/s
INFO - 2023-11-30 15:36:45,508: EPOCH 4: training on 191080 raw words (115802 effective words) took 0.2s, 516035 effective words/s
INFO - 2023-11-30 15:36:45,729: EPOCH 5: training on 191080 raw words (115678 effective words) took 0.2s, 528882 effective words/s
INFO - 2023-11-30 15:36:45,954: EPOCH 6: training on 191080 raw words (115636 effective words) took 0.2s, 519857 effective words/s
INFO - 2023-11-30 15:36:46,175: EPOCH 7: training on 191080 raw words (115572 effective words) took 0.2s, 527776 effective words/s
INFO - 2023-11-30 15:36:46,512: EPOCH 8: training on 191080 raw words (115631 effective words) took 0.3s, 345880 effective words/s
INFO - 2023-11-30 15:36:46,751: EPOCH 9: training on 191080 raw words (115501 effective words) took 0.2s, 489576 effective words/s
INFO - 2023-11-30 15:36:46,981: EPOCH 10: training on 191080 raw words (115584 effective words) took 0.2s, 507070 effective words/s
INFO - 2023-11-30 15:36:47,262: EPOCH 11: training on 191080 raw words (115583 effective words) took 0.3s, 415817 effective words/s
INFO - 2023-11-30 15:36:47,488: EPOCH 12: training on 191080 raw words (115769 effective words) took 0.2s, 515438 effective words/s
INFO - 2023-11-30 15:36:47,714: EPOCH 13: training on 191080 raw words (115737 effective words) took 0.2s, 517679 effective words/s
INFO - 2023-11-30 15:36:47,939: EPOCH 14: training on 191080 raw words (115719 effective words) took 0.2s, 519495 effective words/s
INFO - 2023-11-30 15:36:48,165: EPOCH 15: training on 191080 raw words (115812 effective words) took 0.2s, 518384 effective words/s
INFO - 2023-11-30 15:36:48,390: EPOCH 16: training on 191080 raw words (115613 effective words) took 0.2s, 517578 effective words/s
INFO - 2023-11-30 15:36:48,618: EPOCH 17: training on 191080 raw words (115975 effective words) took 0.2s, 515863 effective words/s
INFO - 2023-11-30 15:36:48,840: EPOCH 18: training on 191080 raw words (115717 effective words) took 0.2s, 524958 effective words/s
INFO - 2023-11-30 15:36:49,064: EPOCH 19: training on 191080 raw words (115783 effective words) took 0.2s, 522350 effective words/s
INFO - 2023-11-30 15:36:49,065: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2314049 effective words) took 4.8s, 483650 effective words/s', 'datetime': '2023-11-30T15:36:49.065050', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:49,065: collecting all words and their counts
INFO - 2023-11-30 15:36:49,065: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:36:49,091: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:36:49,091: Updating model with new vocabulary
INFO - 2023-11-30 15:36:49,103: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:36:49.103493', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:49,118: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:36:49,118: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:36:49,118: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115665.8992876409 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:36:49.118257', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:49,142: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:36:49,142: updating layer weights
INFO - 2023-11-30 15:36:49,143: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:36:49.143421', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:36:49,143: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:36:49,143: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:36:49.143722', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:49,382: EPOCH 0: training on 191080 raw words (115643 effective words) took 0.2s, 530333 effective words/s
INFO - 2023-11-30 15:36:49,619: EPOCH 1: training on 191080 raw words (115766 effective words) took 0.2s, 492882 effective words/s
INFO - 2023-11-30 15:36:49,856: EPOCH 2: training on 191080 raw words (115574 effective words) took 0.2s, 494268 effective words/s
INFO - 2023-11-30 15:36:50,087: EPOCH 3: training on 191080 raw words (115665 effective words) took 0.2s, 504496 effective words/s
INFO - 2023-11-30 15:36:50,324: EPOCH 4: training on 191080 raw words (115826 effective words) took 0.2s, 494678 effective words/s
INFO - 2023-11-30 15:36:50,563: EPOCH 5: training on 191080 raw words (115704 effective words) took 0.2s, 488644 effective words/s
INFO - 2023-11-30 15:36:50,796: EPOCH 6: training on 191080 raw words (115439 effective words) took 0.2s, 499967 effective words/s
INFO - 2023-11-30 15:36:51,031: EPOCH 7: training on 191080 raw words (115536 effective words) took 0.2s, 495925 effective words/s
INFO - 2023-11-30 15:36:51,265: EPOCH 8: training on 191080 raw words (115613 effective words) took 0.2s, 498912 effective words/s
INFO - 2023-11-30 15:36:51,513: EPOCH 9: training on 191080 raw words (115706 effective words) took 0.2s, 471593 effective words/s
INFO - 2023-11-30 15:36:51,774: EPOCH 10: training on 191080 raw words (115695 effective words) took 0.3s, 448344 effective words/s
INFO - 2023-11-30 15:36:52,005: EPOCH 11: training on 191080 raw words (115735 effective words) took 0.2s, 506038 effective words/s
INFO - 2023-11-30 15:36:52,286: EPOCH 12: training on 191080 raw words (115607 effective words) took 0.3s, 416073 effective words/s
INFO - 2023-11-30 15:36:52,524: EPOCH 13: training on 191080 raw words (115717 effective words) took 0.2s, 491493 effective words/s
INFO - 2023-11-30 15:36:52,756: EPOCH 14: training on 191080 raw words (115743 effective words) took 0.2s, 503471 effective words/s
INFO - 2023-11-30 15:36:52,986: EPOCH 15: training on 191080 raw words (115664 effective words) took 0.2s, 506772 effective words/s
INFO - 2023-11-30 15:36:53,218: EPOCH 16: training on 191080 raw words (115940 effective words) took 0.2s, 505430 effective words/s
INFO - 2023-11-30 15:36:53,449: EPOCH 17: training on 191080 raw words (115806 effective words) took 0.2s, 505585 effective words/s
INFO - 2023-11-30 15:36:53,682: EPOCH 18: training on 191080 raw words (115665 effective words) took 0.2s, 500732 effective words/s
INFO - 2023-11-30 15:36:53,910: EPOCH 19: training on 191080 raw words (115474 effective words) took 0.2s, 512112 effective words/s
INFO - 2023-11-30 15:36:53,910: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313518 effective words) took 4.8s, 485345 effective words/s', 'datetime': '2023-11-30T15:36:53.910613', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:53,910: collecting all words and their counts
INFO - 2023-11-30 15:36:53,911: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:36:53,936: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:36:53,936: Updating model with new vocabulary
INFO - 2023-11-30 15:36:53,948: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:36:53.948569', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:53,963: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:36:53,963: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:36:53,963: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115697.3212315594 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:36:53.963736', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:53,986: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:36:53,986: updating layer weights
INFO - 2023-11-30 15:36:53,987: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:36:53.987186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:36:53,987: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:36:53,987: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:36:53.987359', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:54,215: EPOCH 0: training on 191080 raw words (115662 effective words) took 0.2s, 512329 effective words/s
INFO - 2023-11-30 15:36:54,459: EPOCH 1: training on 191080 raw words (115740 effective words) took 0.2s, 478520 effective words/s
INFO - 2023-11-30 15:36:54,688: EPOCH 2: training on 191080 raw words (115867 effective words) took 0.2s, 511163 effective words/s
INFO - 2023-11-30 15:36:54,975: EPOCH 3: training on 191080 raw words (115573 effective words) took 0.3s, 405594 effective words/s
INFO - 2023-11-30 15:36:55,204: EPOCH 4: training on 191080 raw words (115559 effective words) took 0.2s, 509962 effective words/s
INFO - 2023-11-30 15:36:55,424: EPOCH 5: training on 191080 raw words (115456 effective words) took 0.2s, 530763 effective words/s
INFO - 2023-11-30 15:36:55,655: EPOCH 6: training on 191080 raw words (115745 effective words) took 0.2s, 505735 effective words/s
INFO - 2023-11-30 15:36:55,879: EPOCH 7: training on 191080 raw words (115637 effective words) took 0.2s, 520880 effective words/s
INFO - 2023-11-30 15:36:56,104: EPOCH 8: training on 191080 raw words (115885 effective words) took 0.2s, 522452 effective words/s
INFO - 2023-11-30 15:36:56,322: EPOCH 9: training on 191080 raw words (115651 effective words) took 0.2s, 534229 effective words/s
INFO - 2023-11-30 15:36:56,569: EPOCH 10: training on 191080 raw words (116026 effective words) took 0.2s, 474915 effective words/s
INFO - 2023-11-30 15:36:56,822: EPOCH 11: training on 191080 raw words (115610 effective words) took 0.2s, 490074 effective words/s
INFO - 2023-11-30 15:36:57,129: EPOCH 12: training on 191080 raw words (115615 effective words) took 0.3s, 380375 effective words/s
INFO - 2023-11-30 15:36:57,420: EPOCH 13: training on 191080 raw words (115621 effective words) took 0.3s, 400443 effective words/s
INFO - 2023-11-30 15:36:57,707: EPOCH 14: training on 191080 raw words (115720 effective words) took 0.3s, 407907 effective words/s
INFO - 2023-11-30 15:36:57,989: EPOCH 15: training on 191080 raw words (115693 effective words) took 0.3s, 415605 effective words/s
INFO - 2023-11-30 15:36:58,273: EPOCH 16: training on 191080 raw words (115566 effective words) took 0.3s, 410881 effective words/s
INFO - 2023-11-30 15:36:58,560: EPOCH 17: training on 191080 raw words (115775 effective words) took 0.3s, 406997 effective words/s
INFO - 2023-11-30 15:36:58,914: EPOCH 18: training on 191080 raw words (115446 effective words) took 0.4s, 329611 effective words/s
INFO - 2023-11-30 15:36:59,214: EPOCH 19: training on 191080 raw words (115595 effective words) took 0.3s, 388687 effective words/s
INFO - 2023-11-30 15:36:59,214: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313442 effective words) took 5.2s, 442564 effective words/s', 'datetime': '2023-11-30T15:36:59.214814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:59,215: collecting all words and their counts
INFO - 2023-11-30 15:36:59,215: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:36:59,250: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:36:59,250: Updating model with new vocabulary
INFO - 2023-11-30 15:36:59,269: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:36:59.269372', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:59,289: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:36:59,289: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:36:59,289: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115557.7535791597 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:36:59.289726', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:36:59,321: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:36:59,321: updating layer weights
INFO - 2023-11-30 15:36:59,322: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:36:59.322096', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:36:59,322: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:36:59,322: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:36:59.322544', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:36:59,644: EPOCH 0: training on 191080 raw words (115477 effective words) took 0.3s, 361450 effective words/s
INFO - 2023-11-30 15:36:59,948: EPOCH 1: training on 191080 raw words (115622 effective words) took 0.3s, 384753 effective words/s
INFO - 2023-11-30 15:37:00,246: EPOCH 2: training on 191080 raw words (115263 effective words) took 0.3s, 390066 effective words/s
INFO - 2023-11-30 15:37:00,572: EPOCH 3: training on 191080 raw words (115422 effective words) took 0.3s, 357332 effective words/s
INFO - 2023-11-30 15:37:00,877: EPOCH 4: training on 191080 raw words (115478 effective words) took 0.3s, 382310 effective words/s
INFO - 2023-11-30 15:37:01,178: EPOCH 5: training on 191080 raw words (115616 effective words) took 0.3s, 387373 effective words/s
INFO - 2023-11-30 15:37:01,482: EPOCH 6: training on 191080 raw words (115562 effective words) took 0.3s, 383429 effective words/s
INFO - 2023-11-30 15:37:01,783: EPOCH 7: training on 191080 raw words (115640 effective words) took 0.3s, 388427 effective words/s
INFO - 2023-11-30 15:37:02,084: EPOCH 8: training on 191080 raw words (115554 effective words) took 0.3s, 419913 effective words/s
INFO - 2023-11-30 15:37:02,385: EPOCH 9: training on 191080 raw words (115573 effective words) took 0.3s, 388677 effective words/s
INFO - 2023-11-30 15:37:02,686: EPOCH 10: training on 191080 raw words (115402 effective words) took 0.3s, 386744 effective words/s
INFO - 2023-11-30 15:37:03,026: EPOCH 11: training on 191080 raw words (115430 effective words) took 0.3s, 342228 effective words/s
INFO - 2023-11-30 15:37:03,347: EPOCH 12: training on 191080 raw words (115732 effective words) took 0.3s, 363656 effective words/s
INFO - 2023-11-30 15:37:03,664: EPOCH 13: training on 191080 raw words (115419 effective words) took 0.3s, 368622 effective words/s
INFO - 2023-11-30 15:37:03,982: EPOCH 14: training on 191080 raw words (115646 effective words) took 0.3s, 366534 effective words/s
INFO - 2023-11-30 15:37:04,300: EPOCH 15: training on 191080 raw words (115412 effective words) took 0.3s, 366972 effective words/s
INFO - 2023-11-30 15:37:04,614: EPOCH 16: training on 191080 raw words (115321 effective words) took 0.3s, 369481 effective words/s
INFO - 2023-11-30 15:37:04,935: EPOCH 17: training on 191080 raw words (115696 effective words) took 0.3s, 363852 effective words/s
INFO - 2023-11-30 15:37:05,274: EPOCH 18: training on 191080 raw words (115606 effective words) took 0.3s, 344089 effective words/s
INFO - 2023-11-30 15:37:05,587: EPOCH 19: training on 191080 raw words (115517 effective words) took 0.3s, 372891 effective words/s
INFO - 2023-11-30 15:37:05,588: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310388 effective words) took 6.3s, 368760 effective words/s', 'datetime': '2023-11-30T15:37:05.588009', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:05,588: collecting all words and their counts
INFO - 2023-11-30 15:37:05,588: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:05,625: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:05,625: Updating model with new vocabulary
INFO - 2023-11-30 15:37:05,643: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:05.643754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:05,666: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:05,666: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:37:05,666: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115599.33027266554 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:37:05.666703', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:05,703: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:05,703: updating layer weights
INFO - 2023-11-30 15:37:05,703: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:05.703854', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:05,704: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:05,704: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:05.704588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:05,990: EPOCH 0: training on 191080 raw words (115733 effective words) took 0.3s, 411014 effective words/s
INFO - 2023-11-30 15:37:06,262: EPOCH 1: training on 191080 raw words (115637 effective words) took 0.3s, 429287 effective words/s
INFO - 2023-11-30 15:37:06,541: EPOCH 2: training on 191080 raw words (115617 effective words) took 0.3s, 419148 effective words/s
INFO - 2023-11-30 15:37:06,803: EPOCH 3: training on 191080 raw words (115569 effective words) took 0.3s, 445118 effective words/s
INFO - 2023-11-30 15:37:07,071: EPOCH 4: training on 191080 raw words (115500 effective words) took 0.3s, 435722 effective words/s
INFO - 2023-11-30 15:37:07,337: EPOCH 5: training on 191080 raw words (115738 effective words) took 0.3s, 440566 effective words/s
INFO - 2023-11-30 15:37:07,603: EPOCH 6: training on 191080 raw words (115434 effective words) took 0.3s, 438757 effective words/s
INFO - 2023-11-30 15:37:07,876: EPOCH 7: training on 191080 raw words (115797 effective words) took 0.3s, 429356 effective words/s
INFO - 2023-11-30 15:37:08,187: EPOCH 8: training on 191080 raw words (115773 effective words) took 0.3s, 375589 effective words/s
INFO - 2023-11-30 15:37:08,463: EPOCH 9: training on 191080 raw words (115650 effective words) took 0.3s, 422408 effective words/s
INFO - 2023-11-30 15:37:08,783: EPOCH 10: training on 191080 raw words (115478 effective words) took 0.3s, 363619 effective words/s
INFO - 2023-11-30 15:37:09,086: EPOCH 11: training on 191080 raw words (115578 effective words) took 0.3s, 385744 effective words/s
INFO - 2023-11-30 15:37:09,354: EPOCH 12: training on 191080 raw words (115475 effective words) took 0.3s, 435640 effective words/s
INFO - 2023-11-30 15:37:09,623: EPOCH 13: training on 191080 raw words (115490 effective words) took 0.3s, 433764 effective words/s
INFO - 2023-11-30 15:37:09,884: EPOCH 14: training on 191080 raw words (115608 effective words) took 0.2s, 489934 effective words/s
INFO - 2023-11-30 15:37:10,151: EPOCH 15: training on 191080 raw words (115537 effective words) took 0.3s, 436696 effective words/s
INFO - 2023-11-30 15:37:10,464: EPOCH 16: training on 191080 raw words (115555 effective words) took 0.3s, 372867 effective words/s
INFO - 2023-11-30 15:37:10,763: EPOCH 17: training on 191080 raw words (115604 effective words) took 0.3s, 391262 effective words/s
INFO - 2023-11-30 15:37:11,044: EPOCH 18: training on 191080 raw words (115677 effective words) took 0.3s, 415421 effective words/s
INFO - 2023-11-30 15:37:11,309: EPOCH 19: training on 191080 raw words (115744 effective words) took 0.3s, 440982 effective words/s
INFO - 2023-11-30 15:37:11,310: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312194 effective words) took 5.6s, 412506 effective words/s', 'datetime': '2023-11-30T15:37:11.310258', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:11,310: collecting all words and their counts
INFO - 2023-11-30 15:37:11,310: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:11,347: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:11,348: Updating model with new vocabulary
INFO - 2023-11-30 15:37:11,364: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:11.364230', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:11,384: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:11,384: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:11,384: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115304.6227881166 word corpus (60.3%% of prior 191080)', 'datetime': '2023-11-30T15:37:11.384750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:11,417: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:11,418: updating layer weights
INFO - 2023-11-30 15:37:11,418: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:11.418397', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:11,418: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:11,418: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:11.418696', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:11,722: EPOCH 0: training on 191080 raw words (115286 effective words) took 0.3s, 412902 effective words/s
INFO - 2023-11-30 15:37:12,003: EPOCH 1: training on 191080 raw words (115479 effective words) took 0.3s, 415355 effective words/s
INFO - 2023-11-30 15:37:12,386: EPOCH 2: training on 191080 raw words (115604 effective words) took 0.4s, 303936 effective words/s
INFO - 2023-11-30 15:37:12,697: EPOCH 3: training on 191080 raw words (115287 effective words) took 0.3s, 374837 effective words/s
INFO - 2023-11-30 15:37:12,954: EPOCH 4: training on 191080 raw words (115312 effective words) took 0.3s, 454304 effective words/s
INFO - 2023-11-30 15:37:13,197: EPOCH 5: training on 191080 raw words (115030 effective words) took 0.2s, 476660 effective words/s
INFO - 2023-11-30 15:37:13,446: EPOCH 6: training on 191080 raw words (115412 effective words) took 0.2s, 468070 effective words/s
INFO - 2023-11-30 15:37:13,678: EPOCH 7: training on 191080 raw words (115213 effective words) took 0.2s, 502263 effective words/s
INFO - 2023-11-30 15:37:13,915: EPOCH 8: training on 191080 raw words (115313 effective words) took 0.2s, 491650 effective words/s
INFO - 2023-11-30 15:37:14,155: EPOCH 9: training on 191080 raw words (115290 effective words) took 0.2s, 485628 effective words/s
INFO - 2023-11-30 15:37:14,401: EPOCH 10: training on 191080 raw words (115132 effective words) took 0.2s, 472257 effective words/s
INFO - 2023-11-30 15:37:14,647: EPOCH 11: training on 191080 raw words (115297 effective words) took 0.2s, 473323 effective words/s
INFO - 2023-11-30 15:37:14,909: EPOCH 12: training on 191080 raw words (115273 effective words) took 0.3s, 443745 effective words/s
INFO - 2023-11-30 15:37:15,162: EPOCH 13: training on 191080 raw words (115445 effective words) took 0.3s, 461325 effective words/s
INFO - 2023-11-30 15:37:15,420: EPOCH 14: training on 191080 raw words (115245 effective words) took 0.3s, 450403 effective words/s
INFO - 2023-11-30 15:37:15,691: EPOCH 15: training on 191080 raw words (115288 effective words) took 0.3s, 429931 effective words/s
INFO - 2023-11-30 15:37:15,969: EPOCH 16: training on 191080 raw words (114992 effective words) took 0.3s, 417965 effective words/s
INFO - 2023-11-30 15:37:16,240: EPOCH 17: training on 191080 raw words (115138 effective words) took 0.3s, 436546 effective words/s
INFO - 2023-11-30 15:37:16,515: EPOCH 18: training on 191080 raw words (115362 effective words) took 0.3s, 422603 effective words/s
INFO - 2023-11-30 15:37:16,754: EPOCH 19: training on 191080 raw words (115383 effective words) took 0.2s, 498095 effective words/s
INFO - 2023-11-30 15:37:16,755: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2305781 effective words) took 5.3s, 432109 effective words/s', 'datetime': '2023-11-30T15:37:16.754979', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:16,755: collecting all words and their counts
INFO - 2023-11-30 15:37:16,755: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:16,782: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:16,782: Updating model with new vocabulary
INFO - 2023-11-30 15:37:16,795: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:16.795389', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:16,810: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:16,810: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:37:16,810: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115677.72031648763 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:37:16.810375', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:16,846: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:16,847: updating layer weights
INFO - 2023-11-30 15:37:16,847: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:16.847713', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:16,847: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:16,848: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:16.848011', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:17,078: EPOCH 0: training on 191080 raw words (115549 effective words) took 0.2s, 507267 effective words/s
INFO - 2023-11-30 15:37:17,312: EPOCH 1: training on 191080 raw words (115663 effective words) took 0.2s, 499336 effective words/s
INFO - 2023-11-30 15:37:17,596: EPOCH 2: training on 191080 raw words (115746 effective words) took 0.3s, 411082 effective words/s
INFO - 2023-11-30 15:37:17,828: EPOCH 3: training on 191080 raw words (115662 effective words) took 0.2s, 503536 effective words/s
INFO - 2023-11-30 15:37:18,066: EPOCH 4: training on 191080 raw words (115493 effective words) took 0.2s, 489187 effective words/s
INFO - 2023-11-30 15:37:18,284: EPOCH 5: training on 191080 raw words (115722 effective words) took 0.2s, 537279 effective words/s
INFO - 2023-11-30 15:37:18,514: EPOCH 6: training on 191080 raw words (115685 effective words) took 0.2s, 508859 effective words/s
INFO - 2023-11-30 15:37:18,803: EPOCH 7: training on 191080 raw words (115559 effective words) took 0.3s, 402674 effective words/s
INFO - 2023-11-30 15:37:19,102: EPOCH 8: training on 191080 raw words (115662 effective words) took 0.3s, 392554 effective words/s
INFO - 2023-11-30 15:37:19,401: EPOCH 9: training on 191080 raw words (115816 effective words) took 0.3s, 390623 effective words/s
INFO - 2023-11-30 15:37:19,678: EPOCH 10: training on 191080 raw words (115771 effective words) took 0.3s, 422214 effective words/s
INFO - 2023-11-30 15:37:19,951: EPOCH 11: training on 191080 raw words (115472 effective words) took 0.3s, 429244 effective words/s
INFO - 2023-11-30 15:37:20,187: EPOCH 12: training on 191080 raw words (115752 effective words) took 0.2s, 494551 effective words/s
INFO - 2023-11-30 15:37:20,443: EPOCH 13: training on 191080 raw words (115476 effective words) took 0.3s, 457081 effective words/s
INFO - 2023-11-30 15:37:20,702: EPOCH 14: training on 191080 raw words (115507 effective words) took 0.3s, 449449 effective words/s
INFO - 2023-11-30 15:37:20,936: EPOCH 15: training on 191080 raw words (115616 effective words) took 0.2s, 500643 effective words/s
INFO - 2023-11-30 15:37:21,172: EPOCH 16: training on 191080 raw words (115566 effective words) took 0.2s, 493975 effective words/s
INFO - 2023-11-30 15:37:21,409: EPOCH 17: training on 191080 raw words (115533 effective words) took 0.2s, 491201 effective words/s
INFO - 2023-11-30 15:37:21,678: EPOCH 18: training on 191080 raw words (115712 effective words) took 0.3s, 435500 effective words/s
INFO - 2023-11-30 15:37:21,979: EPOCH 19: training on 191080 raw words (115631 effective words) took 0.3s, 386943 effective words/s
INFO - 2023-11-30 15:37:21,979: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312593 effective words) took 5.1s, 450655 effective words/s', 'datetime': '2023-11-30T15:37:21.979775', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:21,979: collecting all words and their counts
INFO - 2023-11-30 15:37:21,980: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:22,022: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:22,023: Updating model with new vocabulary
INFO - 2023-11-30 15:37:22,043: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:22.043600', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:22,069: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:22,070: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:22,070: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115578.35091756345 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:37:22.070523', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:22,098: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:22,098: updating layer weights
INFO - 2023-11-30 15:37:22,099: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:22.099193', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:22,099: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:22,099: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:22.099527', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:22,359: EPOCH 0: training on 191080 raw words (115457 effective words) took 0.3s, 448462 effective words/s
INFO - 2023-11-30 15:37:22,638: EPOCH 1: training on 191080 raw words (115652 effective words) took 0.3s, 418148 effective words/s
INFO - 2023-11-30 15:37:22,955: EPOCH 2: training on 191080 raw words (115665 effective words) took 0.3s, 368432 effective words/s
INFO - 2023-11-30 15:37:23,246: EPOCH 3: training on 191080 raw words (115669 effective words) took 0.3s, 401578 effective words/s
INFO - 2023-11-30 15:37:23,558: EPOCH 4: training on 191080 raw words (115349 effective words) took 0.3s, 374040 effective words/s
INFO - 2023-11-30 15:37:23,907: EPOCH 5: training on 191080 raw words (115482 effective words) took 0.3s, 334036 effective words/s
INFO - 2023-11-30 15:37:24,267: EPOCH 6: training on 191080 raw words (115568 effective words) took 0.4s, 323309 effective words/s
INFO - 2023-11-30 15:37:24,562: EPOCH 7: training on 191080 raw words (115667 effective words) took 0.3s, 395810 effective words/s
INFO - 2023-11-30 15:37:24,944: EPOCH 8: training on 191080 raw words (115377 effective words) took 0.4s, 304336 effective words/s
INFO - 2023-11-30 15:37:25,240: EPOCH 9: training on 191080 raw words (115573 effective words) took 0.3s, 395144 effective words/s
INFO - 2023-11-30 15:37:25,526: EPOCH 10: training on 191080 raw words (115567 effective words) took 0.3s, 407622 effective words/s
INFO - 2023-11-30 15:37:25,802: EPOCH 11: training on 191080 raw words (115456 effective words) took 0.3s, 423845 effective words/s
INFO - 2023-11-30 15:37:26,072: EPOCH 12: training on 191080 raw words (115598 effective words) took 0.2s, 469534 effective words/s
INFO - 2023-11-30 15:37:26,337: EPOCH 13: training on 191080 raw words (115969 effective words) took 0.3s, 441507 effective words/s
INFO - 2023-11-30 15:37:26,572: EPOCH 14: training on 191080 raw words (115753 effective words) took 0.2s, 497642 effective words/s
INFO - 2023-11-30 15:37:26,811: EPOCH 15: training on 191080 raw words (115670 effective words) took 0.2s, 488845 effective words/s
INFO - 2023-11-30 15:37:27,057: EPOCH 16: training on 191080 raw words (115621 effective words) took 0.2s, 475813 effective words/s
INFO - 2023-11-30 15:37:27,311: EPOCH 17: training on 191080 raw words (115776 effective words) took 0.3s, 460785 effective words/s
INFO - 2023-11-30 15:37:27,579: EPOCH 18: training on 191080 raw words (115584 effective words) took 0.3s, 435962 effective words/s
INFO - 2023-11-30 15:37:27,854: EPOCH 19: training on 191080 raw words (115257 effective words) took 0.3s, 430268 effective words/s
INFO - 2023-11-30 15:37:27,854: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2311710 effective words) took 5.8s, 401699 effective words/s', 'datetime': '2023-11-30T15:37:27.854512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:27,854: collecting all words and their counts
INFO - 2023-11-30 15:37:27,854: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:27,889: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:27,889: Updating model with new vocabulary
INFO - 2023-11-30 15:37:27,907: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:27.907633', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:27,925: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:27,925: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:27,925: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115589.79608862792 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:37:27.925922', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:27,954: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:27,954: updating layer weights
INFO - 2023-11-30 15:37:27,955: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:27.955251', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:27,955: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:27,955: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:27.955639', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:28,212: EPOCH 0: training on 191080 raw words (115548 effective words) took 0.3s, 455966 effective words/s
INFO - 2023-11-30 15:37:28,478: EPOCH 1: training on 191080 raw words (115470 effective words) took 0.3s, 439262 effective words/s
INFO - 2023-11-30 15:37:28,739: EPOCH 2: training on 191080 raw words (115389 effective words) took 0.3s, 446088 effective words/s
INFO - 2023-11-30 15:37:29,026: EPOCH 3: training on 191080 raw words (115529 effective words) took 0.3s, 407089 effective words/s
INFO - 2023-11-30 15:37:29,370: EPOCH 4: training on 191080 raw words (115705 effective words) took 0.3s, 339230 effective words/s
INFO - 2023-11-30 15:37:29,723: EPOCH 5: training on 191080 raw words (115577 effective words) took 0.3s, 331672 effective words/s
INFO - 2023-11-30 15:37:30,085: EPOCH 6: training on 191080 raw words (115614 effective words) took 0.4s, 322298 effective words/s
INFO - 2023-11-30 15:37:30,407: EPOCH 7: training on 191080 raw words (115574 effective words) took 0.3s, 363852 effective words/s
INFO - 2023-11-30 15:37:30,752: EPOCH 8: training on 191080 raw words (115467 effective words) took 0.3s, 336908 effective words/s
INFO - 2023-11-30 15:37:31,116: EPOCH 9: training on 191080 raw words (115446 effective words) took 0.4s, 320740 effective words/s
INFO - 2023-11-30 15:37:31,441: EPOCH 10: training on 191080 raw words (115631 effective words) took 0.3s, 359119 effective words/s
INFO - 2023-11-30 15:37:31,795: EPOCH 11: training on 191080 raw words (115565 effective words) took 0.4s, 329365 effective words/s
INFO - 2023-11-30 15:37:32,157: EPOCH 12: training on 191080 raw words (115639 effective words) took 0.4s, 322786 effective words/s
INFO - 2023-11-30 15:37:32,533: EPOCH 13: training on 191080 raw words (115502 effective words) took 0.4s, 309597 effective words/s
INFO - 2023-11-30 15:37:32,936: EPOCH 14: training on 191080 raw words (115251 effective words) took 0.4s, 288772 effective words/s
INFO - 2023-11-30 15:37:33,234: EPOCH 15: training on 191080 raw words (115530 effective words) took 0.3s, 391677 effective words/s
INFO - 2023-11-30 15:37:33,585: EPOCH 16: training on 191080 raw words (115566 effective words) took 0.3s, 331505 effective words/s
INFO - 2023-11-30 15:37:33,950: EPOCH 17: training on 191080 raw words (115604 effective words) took 0.4s, 319989 effective words/s
INFO - 2023-11-30 15:37:34,336: EPOCH 18: training on 191080 raw words (115711 effective words) took 0.4s, 302619 effective words/s
INFO - 2023-11-30 15:37:34,700: EPOCH 19: training on 191080 raw words (115615 effective words) took 0.4s, 320454 effective words/s
INFO - 2023-11-30 15:37:34,701: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310933 effective words) took 6.7s, 342592 effective words/s', 'datetime': '2023-11-30T15:37:34.701277', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:34,701: collecting all words and their counts
INFO - 2023-11-30 15:37:34,701: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:34,761: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:34,761: Updating model with new vocabulary
INFO - 2023-11-30 15:37:34,785: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:34.785460', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:34,820: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:34,821: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:37:34,821: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115485.9509491169 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:37:34.821738', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:34,861: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:34,861: updating layer weights
INFO - 2023-11-30 15:37:34,862: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:34.862012', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:34,862: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:34,862: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:34.862434', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:35,248: EPOCH 0: training on 191080 raw words (115269 effective words) took 0.4s, 300815 effective words/s
INFO - 2023-11-30 15:37:35,696: EPOCH 1: training on 191080 raw words (115745 effective words) took 0.4s, 260187 effective words/s
INFO - 2023-11-30 15:37:36,189: EPOCH 2: training on 191080 raw words (115433 effective words) took 0.5s, 236738 effective words/s
INFO - 2023-11-30 15:37:36,552: EPOCH 3: training on 191080 raw words (115633 effective words) took 0.4s, 322160 effective words/s
INFO - 2023-11-30 15:37:36,859: EPOCH 4: training on 191080 raw words (115464 effective words) took 0.3s, 379723 effective words/s
INFO - 2023-11-30 15:37:37,097: EPOCH 5: training on 191080 raw words (115656 effective words) took 0.2s, 490509 effective words/s
INFO - 2023-11-30 15:37:37,348: EPOCH 6: training on 191080 raw words (115621 effective words) took 0.2s, 465594 effective words/s
INFO - 2023-11-30 15:37:37,632: EPOCH 7: training on 191080 raw words (115356 effective words) took 0.3s, 410317 effective words/s
INFO - 2023-11-30 15:37:37,900: EPOCH 8: training on 191080 raw words (115381 effective words) took 0.3s, 435859 effective words/s
INFO - 2023-11-30 15:37:38,170: EPOCH 9: training on 191080 raw words (115389 effective words) took 0.3s, 431122 effective words/s
INFO - 2023-11-30 15:37:38,416: EPOCH 10: training on 191080 raw words (115740 effective words) took 0.2s, 475831 effective words/s
INFO - 2023-11-30 15:37:38,663: EPOCH 11: training on 191080 raw words (115563 effective words) took 0.2s, 472028 effective words/s
INFO - 2023-11-30 15:37:38,900: EPOCH 12: training on 191080 raw words (115237 effective words) took 0.2s, 492616 effective words/s
INFO - 2023-11-30 15:37:39,156: EPOCH 13: training on 191080 raw words (115527 effective words) took 0.3s, 455127 effective words/s
INFO - 2023-11-30 15:37:39,424: EPOCH 14: training on 191080 raw words (115549 effective words) took 0.3s, 436334 effective words/s
INFO - 2023-11-30 15:37:39,677: EPOCH 15: training on 191080 raw words (115491 effective words) took 0.3s, 461323 effective words/s
INFO - 2023-11-30 15:37:39,943: EPOCH 16: training on 191080 raw words (115413 effective words) took 0.3s, 438702 effective words/s
INFO - 2023-11-30 15:37:40,191: EPOCH 17: training on 191080 raw words (115482 effective words) took 0.2s, 469624 effective words/s
INFO - 2023-11-30 15:37:40,512: EPOCH 18: training on 191080 raw words (115545 effective words) took 0.3s, 363418 effective words/s
INFO - 2023-11-30 15:37:40,873: EPOCH 19: training on 191080 raw words (115244 effective words) took 0.4s, 322242 effective words/s
INFO - 2023-11-30 15:37:40,874: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309738 effective words) took 6.0s, 384213 effective words/s', 'datetime': '2023-11-30T15:37:40.874277', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:40,874: collecting all words and their counts
INFO - 2023-11-30 15:37:40,875: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:40,922: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:40,923: Updating model with new vocabulary
INFO - 2023-11-30 15:37:40,938: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:40.938477', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:40,960: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:40,961: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:37:40,961: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115930.61723081704 word corpus (60.7%% of prior 191080)', 'datetime': '2023-11-30T15:37:40.961595', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:40,997: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:40,997: updating layer weights
INFO - 2023-11-30 15:37:40,998: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:40.998131', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:40,998: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:40,998: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:40.998445', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:41,288: EPOCH 0: training on 191080 raw words (116020 effective words) took 0.3s, 404724 effective words/s
INFO - 2023-11-30 15:37:41,605: EPOCH 1: training on 191080 raw words (116215 effective words) took 0.3s, 370956 effective words/s
INFO - 2023-11-30 15:37:41,889: EPOCH 2: training on 191080 raw words (116177 effective words) took 0.3s, 412880 effective words/s
INFO - 2023-11-30 15:37:42,142: EPOCH 3: training on 191080 raw words (115595 effective words) took 0.2s, 504341 effective words/s
INFO - 2023-11-30 15:37:42,391: EPOCH 4: training on 191080 raw words (116095 effective words) took 0.2s, 471296 effective words/s
INFO - 2023-11-30 15:37:42,650: EPOCH 5: training on 191080 raw words (115868 effective words) took 0.3s, 452196 effective words/s
INFO - 2023-11-30 15:37:42,964: EPOCH 6: training on 191080 raw words (116034 effective words) took 0.3s, 373166 effective words/s
INFO - 2023-11-30 15:37:43,202: EPOCH 7: training on 191080 raw words (115780 effective words) took 0.2s, 490706 effective words/s
INFO - 2023-11-30 15:37:43,457: EPOCH 8: training on 191080 raw words (115700 effective words) took 0.3s, 457431 effective words/s
INFO - 2023-11-30 15:37:43,722: EPOCH 9: training on 191080 raw words (116073 effective words) took 0.3s, 442776 effective words/s
INFO - 2023-11-30 15:37:44,012: EPOCH 10: training on 191080 raw words (115886 effective words) took 0.3s, 415533 effective words/s
INFO - 2023-11-30 15:37:44,254: EPOCH 11: training on 191080 raw words (115851 effective words) took 0.2s, 483605 effective words/s
INFO - 2023-11-30 15:37:44,506: EPOCH 12: training on 191080 raw words (115940 effective words) took 0.3s, 463353 effective words/s
INFO - 2023-11-30 15:37:44,757: EPOCH 13: training on 191080 raw words (115954 effective words) took 0.2s, 467091 effective words/s
INFO - 2023-11-30 15:37:44,995: EPOCH 14: training on 191080 raw words (116058 effective words) took 0.2s, 494487 effective words/s
INFO - 2023-11-30 15:37:45,236: EPOCH 15: training on 191080 raw words (116020 effective words) took 0.2s, 485439 effective words/s
INFO - 2023-11-30 15:37:45,477: EPOCH 16: training on 191080 raw words (115986 effective words) took 0.2s, 487117 effective words/s
INFO - 2023-11-30 15:37:45,701: EPOCH 17: training on 191080 raw words (116095 effective words) took 0.2s, 523405 effective words/s
INFO - 2023-11-30 15:37:45,968: EPOCH 18: training on 191080 raw words (116156 effective words) took 0.3s, 439232 effective words/s
INFO - 2023-11-30 15:37:46,259: EPOCH 19: training on 191080 raw words (115640 effective words) took 0.3s, 400836 effective words/s
INFO - 2023-11-30 15:37:46,259: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2319143 effective words) took 5.3s, 440794 effective words/s', 'datetime': '2023-11-30T15:37:46.259883', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:46,260: collecting all words and their counts
INFO - 2023-11-30 15:37:46,260: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:46,292: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:46,292: Updating model with new vocabulary
INFO - 2023-11-30 15:37:46,311: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:46.311915', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:46,339: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:46,339: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:46,339: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115748.60763000892 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:37:46.339807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:46,370: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:46,370: updating layer weights
INFO - 2023-11-30 15:37:46,371: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:46.371289', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:46,371: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:46,371: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:46.371640', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:46,635: EPOCH 0: training on 191080 raw words (115962 effective words) took 0.3s, 445059 effective words/s
INFO - 2023-11-30 15:37:46,888: EPOCH 1: training on 191080 raw words (115779 effective words) took 0.3s, 460867 effective words/s
INFO - 2023-11-30 15:37:47,164: EPOCH 2: training on 191080 raw words (115619 effective words) took 0.3s, 423675 effective words/s
INFO - 2023-11-30 15:37:47,437: EPOCH 3: training on 191080 raw words (115572 effective words) took 0.3s, 426331 effective words/s
INFO - 2023-11-30 15:37:47,794: EPOCH 4: training on 191080 raw words (115890 effective words) took 0.4s, 326703 effective words/s
INFO - 2023-11-30 15:37:48,087: EPOCH 5: training on 191080 raw words (115895 effective words) took 0.3s, 400204 effective words/s
INFO - 2023-11-30 15:37:48,388: EPOCH 6: training on 191080 raw words (115674 effective words) took 0.3s, 388001 effective words/s
INFO - 2023-11-30 15:37:48,654: EPOCH 7: training on 191080 raw words (115688 effective words) took 0.3s, 439738 effective words/s
INFO - 2023-11-30 15:37:48,901: EPOCH 8: training on 191080 raw words (115861 effective words) took 0.2s, 474129 effective words/s
INFO - 2023-11-30 15:37:49,147: EPOCH 9: training on 191080 raw words (115770 effective words) took 0.2s, 475855 effective words/s
INFO - 2023-11-30 15:37:49,395: EPOCH 10: training on 191080 raw words (115828 effective words) took 0.2s, 471016 effective words/s
INFO - 2023-11-30 15:37:49,659: EPOCH 11: training on 191080 raw words (115836 effective words) took 0.3s, 443610 effective words/s
INFO - 2023-11-30 15:37:49,915: EPOCH 12: training on 191080 raw words (115778 effective words) took 0.3s, 456866 effective words/s
INFO - 2023-11-30 15:37:50,170: EPOCH 13: training on 191080 raw words (115770 effective words) took 0.3s, 458221 effective words/s
INFO - 2023-11-30 15:37:50,424: EPOCH 14: training on 191080 raw words (115843 effective words) took 0.3s, 460504 effective words/s
INFO - 2023-11-30 15:37:50,687: EPOCH 15: training on 191080 raw words (115833 effective words) took 0.2s, 476876 effective words/s
INFO - 2023-11-30 15:37:50,953: EPOCH 16: training on 191080 raw words (115822 effective words) took 0.3s, 439926 effective words/s
INFO - 2023-11-30 15:37:51,197: EPOCH 17: training on 191080 raw words (115897 effective words) took 0.2s, 479569 effective words/s
INFO - 2023-11-30 15:37:51,478: EPOCH 18: training on 191080 raw words (115657 effective words) took 0.3s, 414910 effective words/s
INFO - 2023-11-30 15:37:51,711: EPOCH 19: training on 191080 raw words (115604 effective words) took 0.2s, 500336 effective words/s
INFO - 2023-11-30 15:37:51,711: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2315578 effective words) took 5.3s, 433619 effective words/s', 'datetime': '2023-11-30T15:37:51.711942', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:51,712: collecting all words and their counts
INFO - 2023-11-30 15:37:51,712: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:51,739: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:51,740: Updating model with new vocabulary
INFO - 2023-11-30 15:37:51,753: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:51.753691', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:51,769: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:51,769: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:51,769: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115947.57816057396 word corpus (60.7%% of prior 191080)', 'datetime': '2023-11-30T15:37:51.769785', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:51,795: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:51,795: updating layer weights
INFO - 2023-11-30 15:37:51,796: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:51.796190', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:51,796: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:51,796: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:51.796464', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:52,069: EPOCH 0: training on 191080 raw words (116046 effective words) took 0.3s, 428530 effective words/s
INFO - 2023-11-30 15:37:52,311: EPOCH 1: training on 191080 raw words (115771 effective words) took 0.2s, 515593 effective words/s
INFO - 2023-11-30 15:37:52,573: EPOCH 2: training on 191080 raw words (116022 effective words) took 0.3s, 446578 effective words/s
INFO - 2023-11-30 15:37:52,816: EPOCH 3: training on 191080 raw words (115878 effective words) took 0.2s, 483257 effective words/s
INFO - 2023-11-30 15:37:53,059: EPOCH 4: training on 191080 raw words (115753 effective words) took 0.2s, 479148 effective words/s
INFO - 2023-11-30 15:37:53,381: EPOCH 5: training on 191080 raw words (115849 effective words) took 0.3s, 363933 effective words/s
INFO - 2023-11-30 15:37:53,739: EPOCH 6: training on 191080 raw words (116091 effective words) took 0.4s, 327473 effective words/s
INFO - 2023-11-30 15:37:54,161: EPOCH 7: training on 191080 raw words (115995 effective words) took 0.4s, 277195 effective words/s
INFO - 2023-11-30 15:37:54,588: EPOCH 8: training on 191080 raw words (115916 effective words) took 0.4s, 273992 effective words/s
INFO - 2023-11-30 15:37:54,928: EPOCH 9: training on 191080 raw words (115867 effective words) took 0.3s, 343733 effective words/s
INFO - 2023-11-30 15:37:55,258: EPOCH 10: training on 191080 raw words (115819 effective words) took 0.3s, 355082 effective words/s
INFO - 2023-11-30 15:37:55,557: EPOCH 11: training on 191080 raw words (115989 effective words) took 0.3s, 392377 effective words/s
INFO - 2023-11-30 15:37:55,856: EPOCH 12: training on 191080 raw words (115770 effective words) took 0.3s, 391268 effective words/s
INFO - 2023-11-30 15:37:56,163: EPOCH 13: training on 191080 raw words (116013 effective words) took 0.3s, 380583 effective words/s
INFO - 2023-11-30 15:37:56,489: EPOCH 14: training on 191080 raw words (116012 effective words) took 0.3s, 359184 effective words/s
INFO - 2023-11-30 15:37:56,819: EPOCH 15: training on 191080 raw words (115940 effective words) took 0.3s, 355330 effective words/s
INFO - 2023-11-30 15:37:57,152: EPOCH 16: training on 191080 raw words (116037 effective words) took 0.3s, 351876 effective words/s
INFO - 2023-11-30 15:37:57,480: EPOCH 17: training on 191080 raw words (115668 effective words) took 0.3s, 356874 effective words/s
INFO - 2023-11-30 15:37:57,838: EPOCH 18: training on 191080 raw words (115837 effective words) took 0.4s, 325649 effective words/s
INFO - 2023-11-30 15:37:58,147: EPOCH 19: training on 191080 raw words (115931 effective words) took 0.3s, 379729 effective words/s
INFO - 2023-11-30 15:37:58,147: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2318204 effective words) took 6.4s, 365007 effective words/s', 'datetime': '2023-11-30T15:37:58.147723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:58,147: collecting all words and their counts
INFO - 2023-11-30 15:37:58,148: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:37:58,186: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:37:58,187: Updating model with new vocabulary
INFO - 2023-11-30 15:37:58,207: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:37:58.207495', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:58,233: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:37:58,233: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:37:58,234: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115372.2658158615 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:37:58.234154', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:37:58,276: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:37:58,276: updating layer weights
INFO - 2023-11-30 15:37:58,276: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:37:58.276878', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:37:58,277: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:37:58,277: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:37:58.277205', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:37:58,629: EPOCH 0: training on 191080 raw words (115418 effective words) took 0.3s, 331229 effective words/s
INFO - 2023-11-30 15:37:59,012: EPOCH 1: training on 191080 raw words (115375 effective words) took 0.4s, 304044 effective words/s
INFO - 2023-11-30 15:37:59,383: EPOCH 2: training on 191080 raw words (115284 effective words) took 0.4s, 313862 effective words/s
INFO - 2023-11-30 15:37:59,747: EPOCH 3: training on 191080 raw words (115250 effective words) took 0.4s, 319874 effective words/s
INFO - 2023-11-30 15:38:00,127: EPOCH 4: training on 191080 raw words (115175 effective words) took 0.4s, 306478 effective words/s
INFO - 2023-11-30 15:38:00,498: EPOCH 5: training on 191080 raw words (115237 effective words) took 0.4s, 313524 effective words/s
INFO - 2023-11-30 15:38:00,909: EPOCH 6: training on 191080 raw words (115646 effective words) took 0.4s, 283867 effective words/s
INFO - 2023-11-30 15:38:01,297: EPOCH 7: training on 191080 raw words (115316 effective words) took 0.4s, 300176 effective words/s
INFO - 2023-11-30 15:38:01,688: EPOCH 8: training on 191080 raw words (115192 effective words) took 0.4s, 297487 effective words/s
INFO - 2023-11-30 15:38:02,050: EPOCH 9: training on 191080 raw words (115576 effective words) took 0.4s, 321986 effective words/s
INFO - 2023-11-30 15:38:02,385: EPOCH 10: training on 191080 raw words (115509 effective words) took 0.3s, 348792 effective words/s
INFO - 2023-11-30 15:38:02,632: EPOCH 11: training on 191080 raw words (115212 effective words) took 0.2s, 486426 effective words/s
INFO - 2023-11-30 15:38:02,909: EPOCH 12: training on 191080 raw words (115411 effective words) took 0.3s, 419443 effective words/s
INFO - 2023-11-30 15:38:03,176: EPOCH 13: training on 191080 raw words (115328 effective words) took 0.3s, 437007 effective words/s
INFO - 2023-11-30 15:38:03,427: EPOCH 14: training on 191080 raw words (115279 effective words) took 0.2s, 463491 effective words/s
INFO - 2023-11-30 15:38:03,685: EPOCH 15: training on 191080 raw words (115307 effective words) took 0.3s, 452037 effective words/s
INFO - 2023-11-30 15:38:03,956: EPOCH 16: training on 191080 raw words (115318 effective words) took 0.3s, 428009 effective words/s
INFO - 2023-11-30 15:38:04,236: EPOCH 17: training on 191080 raw words (115421 effective words) took 0.3s, 416517 effective words/s
INFO - 2023-11-30 15:38:04,506: EPOCH 18: training on 191080 raw words (115685 effective words) took 0.3s, 432786 effective words/s
INFO - 2023-11-30 15:38:04,782: EPOCH 19: training on 191080 raw words (115219 effective words) took 0.3s, 420277 effective words/s
INFO - 2023-11-30 15:38:04,783: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2307158 effective words) took 6.5s, 354628 effective words/s', 'datetime': '2023-11-30T15:38:04.783207', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:04,783: collecting all words and their counts
INFO - 2023-11-30 15:38:04,783: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:04,820: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:04,820: Updating model with new vocabulary
INFO - 2023-11-30 15:38:04,837: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:04.837614', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:04,858: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:04,858: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:38:04,858: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115542.55224408126 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:38:04.858550', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:04,886: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:04,886: updating layer weights
INFO - 2023-11-30 15:38:04,887: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:04.887350', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:04,887: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:04,887: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:04.887592', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:05,205: EPOCH 0: training on 191080 raw words (115575 effective words) took 0.3s, 366682 effective words/s
INFO - 2023-11-30 15:38:05,471: EPOCH 1: training on 191080 raw words (115612 effective words) took 0.3s, 439903 effective words/s
INFO - 2023-11-30 15:38:05,712: EPOCH 2: training on 191080 raw words (115582 effective words) took 0.2s, 483004 effective words/s
INFO - 2023-11-30 15:38:05,961: EPOCH 3: training on 191080 raw words (115552 effective words) took 0.2s, 504928 effective words/s
INFO - 2023-11-30 15:38:06,203: EPOCH 4: training on 191080 raw words (115758 effective words) took 0.2s, 484042 effective words/s
INFO - 2023-11-30 15:38:06,438: EPOCH 5: training on 191080 raw words (115444 effective words) took 0.2s, 494915 effective words/s
INFO - 2023-11-30 15:38:06,679: EPOCH 6: training on 191080 raw words (115645 effective words) took 0.2s, 485970 effective words/s
INFO - 2023-11-30 15:38:06,947: EPOCH 7: training on 191080 raw words (115429 effective words) took 0.3s, 435815 effective words/s
INFO - 2023-11-30 15:38:07,193: EPOCH 8: training on 191080 raw words (115753 effective words) took 0.2s, 476232 effective words/s
INFO - 2023-11-30 15:38:07,430: EPOCH 9: training on 191080 raw words (115762 effective words) took 0.2s, 492367 effective words/s
INFO - 2023-11-30 15:38:07,707: EPOCH 10: training on 191080 raw words (115417 effective words) took 0.3s, 421952 effective words/s
INFO - 2023-11-30 15:38:07,974: EPOCH 11: training on 191080 raw words (115501 effective words) took 0.3s, 436205 effective words/s
INFO - 2023-11-30 15:38:08,239: EPOCH 12: training on 191080 raw words (115536 effective words) took 0.3s, 441191 effective words/s
INFO - 2023-11-30 15:38:08,498: EPOCH 13: training on 191080 raw words (115508 effective words) took 0.3s, 450472 effective words/s
INFO - 2023-11-30 15:38:08,738: EPOCH 14: training on 191080 raw words (115468 effective words) took 0.2s, 486157 effective words/s
INFO - 2023-11-30 15:38:08,998: EPOCH 15: training on 191080 raw words (115395 effective words) took 0.3s, 447587 effective words/s
INFO - 2023-11-30 15:38:09,234: EPOCH 16: training on 191080 raw words (115289 effective words) took 0.2s, 493643 effective words/s
INFO - 2023-11-30 15:38:09,473: EPOCH 17: training on 191080 raw words (115625 effective words) took 0.2s, 488552 effective words/s
INFO - 2023-11-30 15:38:09,735: EPOCH 18: training on 191080 raw words (115313 effective words) took 0.3s, 444245 effective words/s
INFO - 2023-11-30 15:38:09,974: EPOCH 19: training on 191080 raw words (115337 effective words) took 0.2s, 487386 effective words/s
INFO - 2023-11-30 15:38:09,974: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310501 effective words) took 5.1s, 454187 effective words/s', 'datetime': '2023-11-30T15:38:09.974828', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:09,975: collecting all words and their counts
INFO - 2023-11-30 15:38:09,975: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:10,002: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:10,002: Updating model with new vocabulary
INFO - 2023-11-30 15:38:10,015: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:10.015421', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:10,035: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:10,035: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:38:10,035: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115878.94818813514 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:38:10.035468', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:10,061: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:10,061: updating layer weights
INFO - 2023-11-30 15:38:10,062: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:10.062187', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:10,062: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:10,062: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:10.062637', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:10,307: EPOCH 0: training on 191080 raw words (115590 effective words) took 0.2s, 476482 effective words/s
INFO - 2023-11-30 15:38:10,558: EPOCH 1: training on 191080 raw words (116000 effective words) took 0.2s, 467591 effective words/s
INFO - 2023-11-30 15:38:10,866: EPOCH 2: training on 191080 raw words (115737 effective words) took 0.3s, 379482 effective words/s
INFO - 2023-11-30 15:38:11,136: EPOCH 3: training on 191080 raw words (116062 effective words) took 0.3s, 442115 effective words/s
INFO - 2023-11-30 15:38:11,384: EPOCH 4: training on 191080 raw words (115859 effective words) took 0.2s, 471379 effective words/s
INFO - 2023-11-30 15:38:11,642: EPOCH 5: training on 191080 raw words (115779 effective words) took 0.3s, 453602 effective words/s
INFO - 2023-11-30 15:38:11,894: EPOCH 6: training on 191080 raw words (115901 effective words) took 0.2s, 464147 effective words/s
INFO - 2023-11-30 15:38:12,145: EPOCH 7: training on 191080 raw words (115715 effective words) took 0.2s, 465285 effective words/s
INFO - 2023-11-30 15:38:12,406: EPOCH 8: training on 191080 raw words (115794 effective words) took 0.3s, 447844 effective words/s
INFO - 2023-11-30 15:38:12,659: EPOCH 9: training on 191080 raw words (115987 effective words) took 0.3s, 463586 effective words/s
INFO - 2023-11-30 15:38:12,905: EPOCH 10: training on 191080 raw words (115786 effective words) took 0.2s, 474630 effective words/s
INFO - 2023-11-30 15:38:13,150: EPOCH 11: training on 191080 raw words (115915 effective words) took 0.2s, 479145 effective words/s
INFO - 2023-11-30 15:38:13,403: EPOCH 12: training on 191080 raw words (115679 effective words) took 0.3s, 460479 effective words/s
INFO - 2023-11-30 15:38:13,650: EPOCH 13: training on 191080 raw words (115907 effective words) took 0.2s, 474235 effective words/s
INFO - 2023-11-30 15:38:13,896: EPOCH 14: training on 191080 raw words (115820 effective words) took 0.2s, 475098 effective words/s
INFO - 2023-11-30 15:38:14,146: EPOCH 15: training on 191080 raw words (115843 effective words) took 0.2s, 467569 effective words/s
INFO - 2023-11-30 15:38:14,397: EPOCH 16: training on 191080 raw words (115617 effective words) took 0.2s, 467524 effective words/s
INFO - 2023-11-30 15:38:14,640: EPOCH 17: training on 191080 raw words (115706 effective words) took 0.2s, 480646 effective words/s
INFO - 2023-11-30 15:38:14,886: EPOCH 18: training on 191080 raw words (115683 effective words) took 0.2s, 475963 effective words/s
INFO - 2023-11-30 15:38:15,131: EPOCH 19: training on 191080 raw words (115694 effective words) took 0.2s, 476773 effective words/s
INFO - 2023-11-30 15:38:15,131: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316074 effective words) took 5.1s, 456928 effective words/s', 'datetime': '2023-11-30T15:38:15.131601', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:15,131: collecting all words and their counts
INFO - 2023-11-30 15:38:15,132: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:15,159: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:15,159: Updating model with new vocabulary
INFO - 2023-11-30 15:38:15,173: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:15.173660', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:15,190: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:15,191: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:15,191: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115443.32412453656 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:38:15.191195', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:15,215: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:15,215: updating layer weights
INFO - 2023-11-30 15:38:15,215: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:15.215694', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:15,215: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:15,215: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:15.215973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:15,454: EPOCH 0: training on 191080 raw words (115423 effective words) took 0.2s, 490113 effective words/s
INFO - 2023-11-30 15:38:15,692: EPOCH 1: training on 191080 raw words (115575 effective words) took 0.2s, 489147 effective words/s
INFO - 2023-11-30 15:38:15,936: EPOCH 2: training on 191080 raw words (115459 effective words) took 0.2s, 479410 effective words/s
INFO - 2023-11-30 15:38:16,181: EPOCH 3: training on 191080 raw words (115502 effective words) took 0.2s, 476586 effective words/s
INFO - 2023-11-30 15:38:16,413: EPOCH 4: training on 191080 raw words (115450 effective words) took 0.2s, 501487 effective words/s
INFO - 2023-11-30 15:38:16,647: EPOCH 5: training on 191080 raw words (115579 effective words) took 0.2s, 500536 effective words/s
INFO - 2023-11-30 15:38:16,892: EPOCH 6: training on 191080 raw words (115661 effective words) took 0.2s, 475775 effective words/s
INFO - 2023-11-30 15:38:17,136: EPOCH 7: training on 191080 raw words (115337 effective words) took 0.2s, 478407 effective words/s
INFO - 2023-11-30 15:38:17,401: EPOCH 8: training on 191080 raw words (115436 effective words) took 0.3s, 440768 effective words/s
INFO - 2023-11-30 15:38:17,796: EPOCH 9: training on 191080 raw words (115395 effective words) took 0.4s, 294122 effective words/s
INFO - 2023-11-30 15:38:18,119: EPOCH 10: training on 191080 raw words (115452 effective words) took 0.3s, 361779 effective words/s
INFO - 2023-11-30 15:38:18,469: EPOCH 11: training on 191080 raw words (115410 effective words) took 0.3s, 332678 effective words/s
INFO - 2023-11-30 15:38:18,797: EPOCH 12: training on 191080 raw words (115452 effective words) took 0.3s, 355841 effective words/s
INFO - 2023-11-30 15:38:19,136: EPOCH 13: training on 191080 raw words (115789 effective words) took 0.3s, 344162 effective words/s
INFO - 2023-11-30 15:38:19,560: EPOCH 14: training on 191080 raw words (115732 effective words) took 0.4s, 275510 effective words/s
INFO - 2023-11-30 15:38:19,901: EPOCH 15: training on 191080 raw words (115563 effective words) took 0.3s, 341593 effective words/s
INFO - 2023-11-30 15:38:20,210: EPOCH 16: training on 191080 raw words (115604 effective words) took 0.3s, 378166 effective words/s
INFO - 2023-11-30 15:38:20,537: EPOCH 17: training on 191080 raw words (115395 effective words) took 0.3s, 356928 effective words/s
INFO - 2023-11-30 15:38:20,904: EPOCH 18: training on 191080 raw words (115524 effective words) took 0.4s, 317028 effective words/s
INFO - 2023-11-30 15:38:21,250: EPOCH 19: training on 191080 raw words (115299 effective words) took 0.3s, 336559 effective words/s
INFO - 2023-11-30 15:38:21,251: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310037 effective words) took 6.0s, 382778 effective words/s', 'datetime': '2023-11-30T15:38:21.251052', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:21,251: collecting all words and their counts
INFO - 2023-11-30 15:38:21,251: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:21,297: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:21,298: Updating model with new vocabulary
INFO - 2023-11-30 15:38:21,327: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:21.327791', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:21,354: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:21,354: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:38:21,354: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115623.24419834968 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:38:21.354754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:21,399: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:21,399: updating layer weights
INFO - 2023-11-30 15:38:21,399: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:21.399892', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:21,400: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:21,400: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:21.400137', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:21,829: EPOCH 0: training on 191080 raw words (115679 effective words) took 0.4s, 271702 effective words/s
INFO - 2023-11-30 15:38:22,264: EPOCH 1: training on 191080 raw words (115757 effective words) took 0.4s, 269159 effective words/s
INFO - 2023-11-30 15:38:22,780: EPOCH 2: training on 191080 raw words (115752 effective words) took 0.5s, 226132 effective words/s
INFO - 2023-11-30 15:38:23,137: EPOCH 3: training on 191080 raw words (115516 effective words) took 0.4s, 326020 effective words/s
INFO - 2023-11-30 15:38:23,512: EPOCH 4: training on 191080 raw words (115662 effective words) took 0.3s, 335250 effective words/s
INFO - 2023-11-30 15:38:23,958: EPOCH 5: training on 191080 raw words (115599 effective words) took 0.4s, 262045 effective words/s
INFO - 2023-11-30 15:38:24,425: EPOCH 6: training on 191080 raw words (115460 effective words) took 0.5s, 249557 effective words/s
INFO - 2023-11-30 15:38:24,821: EPOCH 7: training on 191080 raw words (115565 effective words) took 0.4s, 295070 effective words/s
INFO - 2023-11-30 15:38:25,225: EPOCH 8: training on 191080 raw words (115684 effective words) took 0.4s, 289249 effective words/s
INFO - 2023-11-30 15:38:25,667: EPOCH 9: training on 191080 raw words (115461 effective words) took 0.4s, 263868 effective words/s
INFO - 2023-11-30 15:38:26,079: EPOCH 10: training on 191080 raw words (115835 effective words) took 0.4s, 284194 effective words/s
INFO - 2023-11-30 15:38:26,440: EPOCH 11: training on 191080 raw words (115666 effective words) took 0.4s, 323395 effective words/s
INFO - 2023-11-30 15:38:26,693: EPOCH 12: training on 191080 raw words (115744 effective words) took 0.3s, 461765 effective words/s
INFO - 2023-11-30 15:38:26,959: EPOCH 13: training on 191080 raw words (115840 effective words) took 0.3s, 440745 effective words/s
INFO - 2023-11-30 15:38:27,199: EPOCH 14: training on 191080 raw words (115682 effective words) took 0.2s, 494296 effective words/s
INFO - 2023-11-30 15:38:27,433: EPOCH 15: training on 191080 raw words (115541 effective words) took 0.2s, 497834 effective words/s
INFO - 2023-11-30 15:38:27,668: EPOCH 16: training on 191080 raw words (115681 effective words) took 0.2s, 497975 effective words/s
INFO - 2023-11-30 15:38:27,914: EPOCH 17: training on 191080 raw words (115649 effective words) took 0.2s, 473749 effective words/s
INFO - 2023-11-30 15:38:28,162: EPOCH 18: training on 191080 raw words (115590 effective words) took 0.2s, 471461 effective words/s
INFO - 2023-11-30 15:38:28,410: EPOCH 19: training on 191080 raw words (115668 effective words) took 0.2s, 470648 effective words/s
INFO - 2023-11-30 15:38:28,410: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313031 effective words) took 7.0s, 329929 effective words/s', 'datetime': '2023-11-30T15:38:28.410941', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:28,411: collecting all words and their counts
INFO - 2023-11-30 15:38:28,411: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:28,437: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:28,437: Updating model with new vocabulary
INFO - 2023-11-30 15:38:28,449: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:28.449419', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:28,466: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:28,466: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:28,466: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115697.53328808476 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:38:28.466705', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:28,489: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:28,489: updating layer weights
INFO - 2023-11-30 15:38:28,490: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:28.490294', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:28,490: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:28,490: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:28.490563', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:28,717: EPOCH 0: training on 191080 raw words (115723 effective words) took 0.2s, 514858 effective words/s
INFO - 2023-11-30 15:38:28,947: EPOCH 1: training on 191080 raw words (115757 effective words) took 0.2s, 509750 effective words/s
INFO - 2023-11-30 15:38:29,199: EPOCH 2: training on 191080 raw words (115613 effective words) took 0.2s, 462935 effective words/s
INFO - 2023-11-30 15:38:29,426: EPOCH 3: training on 191080 raw words (115751 effective words) took 0.2s, 515999 effective words/s
INFO - 2023-11-30 15:38:29,671: EPOCH 4: training on 191080 raw words (115860 effective words) took 0.2s, 476432 effective words/s
INFO - 2023-11-30 15:38:29,912: EPOCH 5: training on 191080 raw words (115753 effective words) took 0.2s, 485846 effective words/s
INFO - 2023-11-30 15:38:30,152: EPOCH 6: training on 191080 raw words (115893 effective words) took 0.2s, 487345 effective words/s
INFO - 2023-11-30 15:38:30,385: EPOCH 7: training on 191080 raw words (115793 effective words) took 0.2s, 502381 effective words/s
INFO - 2023-11-30 15:38:30,638: EPOCH 8: training on 191080 raw words (115723 effective words) took 0.2s, 463295 effective words/s
INFO - 2023-11-30 15:38:30,876: EPOCH 9: training on 191080 raw words (115885 effective words) took 0.2s, 492721 effective words/s
INFO - 2023-11-30 15:38:31,151: EPOCH 10: training on 191080 raw words (115718 effective words) took 0.3s, 424514 effective words/s
INFO - 2023-11-30 15:38:31,408: EPOCH 11: training on 191080 raw words (115723 effective words) took 0.3s, 453747 effective words/s
INFO - 2023-11-30 15:38:31,684: EPOCH 12: training on 191080 raw words (115656 effective words) took 0.3s, 423884 effective words/s
INFO - 2023-11-30 15:38:31,960: EPOCH 13: training on 191080 raw words (115920 effective words) took 0.3s, 424709 effective words/s
INFO - 2023-11-30 15:38:32,211: EPOCH 14: training on 191080 raw words (115516 effective words) took 0.2s, 465550 effective words/s
INFO - 2023-11-30 15:38:32,469: EPOCH 15: training on 191080 raw words (115690 effective words) took 0.3s, 451129 effective words/s
INFO - 2023-11-30 15:38:32,733: EPOCH 16: training on 191080 raw words (115748 effective words) took 0.3s, 443946 effective words/s
INFO - 2023-11-30 15:38:33,011: EPOCH 17: training on 191080 raw words (115719 effective words) took 0.3s, 424129 effective words/s
INFO - 2023-11-30 15:38:33,259: EPOCH 18: training on 191080 raw words (115685 effective words) took 0.2s, 474236 effective words/s
INFO - 2023-11-30 15:38:33,497: EPOCH 19: training on 191080 raw words (115566 effective words) took 0.2s, 490008 effective words/s
INFO - 2023-11-30 15:38:33,497: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2314692 effective words) took 5.0s, 462283 effective words/s', 'datetime': '2023-11-30T15:38:33.497795', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:33,497: collecting all words and their counts
INFO - 2023-11-30 15:38:33,498: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:33,524: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:33,524: Updating model with new vocabulary
INFO - 2023-11-30 15:38:33,537: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:33.537436', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:33,555: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:33,555: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:33,555: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115470.76925126693 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:38:33.555796', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:33,582: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:33,583: updating layer weights
INFO - 2023-11-30 15:38:33,583: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:33.583511', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:33,583: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:33,583: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:33.583762', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:33,852: EPOCH 0: training on 191080 raw words (115354 effective words) took 0.3s, 433917 effective words/s
INFO - 2023-11-30 15:38:34,112: EPOCH 1: training on 191080 raw words (115281 effective words) took 0.3s, 446535 effective words/s
INFO - 2023-11-30 15:38:34,421: EPOCH 2: training on 191080 raw words (115230 effective words) took 0.3s, 376249 effective words/s
INFO - 2023-11-30 15:38:34,695: EPOCH 3: training on 191080 raw words (115429 effective words) took 0.3s, 424592 effective words/s
INFO - 2023-11-30 15:38:34,969: EPOCH 4: training on 191080 raw words (115281 effective words) took 0.3s, 425635 effective words/s
INFO - 2023-11-30 15:38:35,227: EPOCH 5: training on 191080 raw words (115651 effective words) took 0.3s, 451907 effective words/s
INFO - 2023-11-30 15:38:35,488: EPOCH 6: training on 191080 raw words (115434 effective words) took 0.3s, 445382 effective words/s
INFO - 2023-11-30 15:38:35,742: EPOCH 7: training on 191080 raw words (115523 effective words) took 0.3s, 459834 effective words/s
INFO - 2023-11-30 15:38:36,002: EPOCH 8: training on 191080 raw words (115446 effective words) took 0.3s, 448644 effective words/s
INFO - 2023-11-30 15:38:36,250: EPOCH 9: training on 191080 raw words (115473 effective words) took 0.2s, 470068 effective words/s
INFO - 2023-11-30 15:38:36,509: EPOCH 10: training on 191080 raw words (115462 effective words) took 0.3s, 449551 effective words/s
INFO - 2023-11-30 15:38:36,769: EPOCH 11: training on 191080 raw words (115484 effective words) took 0.3s, 448677 effective words/s
INFO - 2023-11-30 15:38:37,018: EPOCH 12: training on 191080 raw words (115401 effective words) took 0.2s, 469054 effective words/s
INFO - 2023-11-30 15:38:37,269: EPOCH 13: training on 191080 raw words (115337 effective words) took 0.2s, 464028 effective words/s
INFO - 2023-11-30 15:38:37,519: EPOCH 14: training on 191080 raw words (115336 effective words) took 0.2s, 467128 effective words/s
INFO - 2023-11-30 15:38:37,766: EPOCH 15: training on 191080 raw words (115518 effective words) took 0.2s, 471208 effective words/s
INFO - 2023-11-30 15:38:38,013: EPOCH 16: training on 191080 raw words (115354 effective words) took 0.2s, 472129 effective words/s
INFO - 2023-11-30 15:38:38,263: EPOCH 17: training on 191080 raw words (115604 effective words) took 0.2s, 467418 effective words/s
INFO - 2023-11-30 15:38:38,508: EPOCH 18: training on 191080 raw words (115422 effective words) took 0.2s, 474527 effective words/s
INFO - 2023-11-30 15:38:38,755: EPOCH 19: training on 191080 raw words (115285 effective words) took 0.2s, 472338 effective words/s
INFO - 2023-11-30 15:38:38,755: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308305 effective words) took 5.2s, 446327 effective words/s', 'datetime': '2023-11-30T15:38:38.755658', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:38,755: collecting all words and their counts
INFO - 2023-11-30 15:38:38,756: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:38,784: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:38,784: Updating model with new vocabulary
INFO - 2023-11-30 15:38:38,798: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:38.798345', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:38,815: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:38,815: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:38,815: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115495.95914875985 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:38:38.815620', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:38,842: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:38,842: updating layer weights
INFO - 2023-11-30 15:38:38,842: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:38.842849', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:38,843: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:38,843: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:38.843236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:39,075: EPOCH 0: training on 191080 raw words (115439 effective words) took 0.2s, 503071 effective words/s
INFO - 2023-11-30 15:38:39,314: EPOCH 1: training on 191080 raw words (115617 effective words) took 0.2s, 488891 effective words/s
INFO - 2023-11-30 15:38:39,567: EPOCH 2: training on 191080 raw words (115392 effective words) took 0.3s, 460298 effective words/s
INFO - 2023-11-30 15:38:39,820: EPOCH 3: training on 191080 raw words (115548 effective words) took 0.3s, 460846 effective words/s
INFO - 2023-11-30 15:38:40,062: EPOCH 4: training on 191080 raw words (115431 effective words) took 0.2s, 483032 effective words/s
INFO - 2023-11-30 15:38:40,306: EPOCH 5: training on 191080 raw words (115502 effective words) took 0.2s, 478004 effective words/s
INFO - 2023-11-30 15:38:40,546: EPOCH 6: training on 191080 raw words (115529 effective words) took 0.2s, 486436 effective words/s
INFO - 2023-11-30 15:38:40,785: EPOCH 7: training on 191080 raw words (115478 effective words) took 0.2s, 488425 effective words/s
INFO - 2023-11-30 15:38:41,045: EPOCH 8: training on 191080 raw words (115566 effective words) took 0.3s, 448796 effective words/s
INFO - 2023-11-30 15:38:41,290: EPOCH 9: training on 191080 raw words (115432 effective words) took 0.2s, 476027 effective words/s
INFO - 2023-11-30 15:38:41,541: EPOCH 10: training on 191080 raw words (115621 effective words) took 0.2s, 465912 effective words/s
INFO - 2023-11-30 15:38:41,813: EPOCH 11: training on 191080 raw words (115601 effective words) took 0.3s, 428830 effective words/s
INFO - 2023-11-30 15:38:42,127: EPOCH 12: training on 191080 raw words (115431 effective words) took 0.3s, 370777 effective words/s
INFO - 2023-11-30 15:38:42,454: EPOCH 13: training on 191080 raw words (115567 effective words) took 0.3s, 356689 effective words/s
INFO - 2023-11-30 15:38:42,763: EPOCH 14: training on 191080 raw words (115574 effective words) took 0.3s, 377086 effective words/s
INFO - 2023-11-30 15:38:43,078: EPOCH 15: training on 191080 raw words (115489 effective words) took 0.3s, 370309 effective words/s
INFO - 2023-11-30 15:38:43,395: EPOCH 16: training on 191080 raw words (115472 effective words) took 0.3s, 367885 effective words/s
INFO - 2023-11-30 15:38:43,715: EPOCH 17: training on 191080 raw words (115303 effective words) took 0.3s, 364084 effective words/s
INFO - 2023-11-30 15:38:44,057: EPOCH 18: training on 191080 raw words (115296 effective words) took 0.3s, 340521 effective words/s
INFO - 2023-11-30 15:38:44,386: EPOCH 19: training on 191080 raw words (115589 effective words) took 0.3s, 354364 effective words/s
INFO - 2023-11-30 15:38:44,387: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309877 effective words) took 5.5s, 416680 effective words/s', 'datetime': '2023-11-30T15:38:44.387022', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:44,389: collecting all words and their counts
INFO - 2023-11-30 15:38:44,390: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:44,429: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:44,430: Updating model with new vocabulary
INFO - 2023-11-30 15:38:44,446: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:44.446330', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:44,466: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:44,467: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:44,467: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115626.08822080842 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:38:44.467425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:44,499: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:44,499: updating layer weights
INFO - 2023-11-30 15:38:44,500: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:44.500064', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:44,500: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:44,500: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:44.500379', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:44,843: EPOCH 0: training on 191080 raw words (115713 effective words) took 0.3s, 340069 effective words/s
INFO - 2023-11-30 15:38:45,185: EPOCH 1: training on 191080 raw words (115749 effective words) took 0.3s, 342892 effective words/s
INFO - 2023-11-30 15:38:45,570: EPOCH 2: training on 191080 raw words (115582 effective words) took 0.4s, 302584 effective words/s
INFO - 2023-11-30 15:38:45,964: EPOCH 3: training on 191080 raw words (115535 effective words) took 0.4s, 306966 effective words/s
INFO - 2023-11-30 15:38:46,241: EPOCH 4: training on 191080 raw words (115569 effective words) took 0.3s, 421918 effective words/s
INFO - 2023-11-30 15:38:46,492: EPOCH 5: training on 191080 raw words (115509 effective words) took 0.2s, 463057 effective words/s
INFO - 2023-11-30 15:38:46,758: EPOCH 6: training on 191080 raw words (115677 effective words) took 0.3s, 439627 effective words/s
INFO - 2023-11-30 15:38:47,008: EPOCH 7: training on 191080 raw words (115707 effective words) took 0.2s, 466705 effective words/s
INFO - 2023-11-30 15:38:47,302: EPOCH 8: training on 191080 raw words (115782 effective words) took 0.3s, 396931 effective words/s
INFO - 2023-11-30 15:38:47,590: EPOCH 9: training on 191080 raw words (115609 effective words) took 0.3s, 430125 effective words/s
INFO - 2023-11-30 15:38:47,899: EPOCH 10: training on 191080 raw words (115778 effective words) took 0.3s, 377199 effective words/s
INFO - 2023-11-30 15:38:48,244: EPOCH 11: training on 191080 raw words (115458 effective words) took 0.3s, 338573 effective words/s
INFO - 2023-11-30 15:38:48,596: EPOCH 12: training on 191080 raw words (115544 effective words) took 0.3s, 331071 effective words/s
INFO - 2023-11-30 15:38:48,949: EPOCH 13: training on 191080 raw words (115747 effective words) took 0.4s, 330484 effective words/s
INFO - 2023-11-30 15:38:49,299: EPOCH 14: training on 191080 raw words (115641 effective words) took 0.3s, 333562 effective words/s
INFO - 2023-11-30 15:38:49,656: EPOCH 15: training on 191080 raw words (115650 effective words) took 0.4s, 328064 effective words/s
INFO - 2023-11-30 15:38:49,970: EPOCH 16: training on 191080 raw words (115638 effective words) took 0.3s, 371837 effective words/s
INFO - 2023-11-30 15:38:50,223: EPOCH 17: training on 191080 raw words (115703 effective words) took 0.3s, 462406 effective words/s
INFO - 2023-11-30 15:38:50,482: EPOCH 18: training on 191080 raw words (115707 effective words) took 0.3s, 450621 effective words/s
INFO - 2023-11-30 15:38:50,731: EPOCH 19: training on 191080 raw words (115460 effective words) took 0.2s, 468810 effective words/s
INFO - 2023-11-30 15:38:50,731: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312758 effective words) took 6.2s, 371157 effective words/s', 'datetime': '2023-11-30T15:38:50.731764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:50,731: collecting all words and their counts
INFO - 2023-11-30 15:38:50,732: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:50,763: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:50,763: Updating model with new vocabulary
INFO - 2023-11-30 15:38:50,781: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:50.781873', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:50,802: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:50,803: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:38:50,803: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115821.87185116738 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:38:50.803532', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:50,838: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:50,838: updating layer weights
INFO - 2023-11-30 15:38:50,839: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:50.839417', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:50,839: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:50,839: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:50.839913', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:51,127: EPOCH 0: training on 191080 raw words (115772 effective words) took 0.3s, 406233 effective words/s
INFO - 2023-11-30 15:38:51,397: EPOCH 1: training on 191080 raw words (115949 effective words) took 0.3s, 434744 effective words/s
INFO - 2023-11-30 15:38:51,670: EPOCH 2: training on 191080 raw words (115871 effective words) took 0.3s, 428111 effective words/s
INFO - 2023-11-30 15:38:51,939: EPOCH 3: training on 191080 raw words (115704 effective words) took 0.3s, 434595 effective words/s
INFO - 2023-11-30 15:38:52,204: EPOCH 4: training on 191080 raw words (116026 effective words) took 0.3s, 442422 effective words/s
INFO - 2023-11-30 15:38:52,495: EPOCH 5: training on 191080 raw words (115575 effective words) took 0.3s, 401871 effective words/s
INFO - 2023-11-30 15:38:52,750: EPOCH 6: training on 191080 raw words (115687 effective words) took 0.3s, 457542 effective words/s
INFO - 2023-11-30 15:38:52,980: EPOCH 7: training on 191080 raw words (115793 effective words) took 0.2s, 509234 effective words/s
INFO - 2023-11-30 15:38:53,242: EPOCH 8: training on 191080 raw words (115634 effective words) took 0.3s, 446231 effective words/s
INFO - 2023-11-30 15:38:53,485: EPOCH 9: training on 191080 raw words (115804 effective words) took 0.2s, 483776 effective words/s
INFO - 2023-11-30 15:38:53,721: EPOCH 10: training on 191080 raw words (115892 effective words) took 0.2s, 494955 effective words/s
INFO - 2023-11-30 15:38:53,967: EPOCH 11: training on 191080 raw words (115870 effective words) took 0.2s, 477244 effective words/s
INFO - 2023-11-30 15:38:54,207: EPOCH 12: training on 191080 raw words (115874 effective words) took 0.2s, 487468 effective words/s
INFO - 2023-11-30 15:38:54,474: EPOCH 13: training on 191080 raw words (115608 effective words) took 0.3s, 435825 effective words/s
INFO - 2023-11-30 15:38:54,766: EPOCH 14: training on 191080 raw words (116027 effective words) took 0.3s, 401645 effective words/s
INFO - 2023-11-30 15:38:55,022: EPOCH 15: training on 191080 raw words (115806 effective words) took 0.3s, 456061 effective words/s
INFO - 2023-11-30 15:38:55,267: EPOCH 16: training on 191080 raw words (116057 effective words) took 0.2s, 479576 effective words/s
INFO - 2023-11-30 15:38:55,514: EPOCH 17: training on 191080 raw words (115803 effective words) took 0.2s, 472461 effective words/s
INFO - 2023-11-30 15:38:55,759: EPOCH 18: training on 191080 raw words (115893 effective words) took 0.2s, 478449 effective words/s
INFO - 2023-11-30 15:38:56,013: EPOCH 19: training on 191080 raw words (115632 effective words) took 0.3s, 460327 effective words/s
INFO - 2023-11-30 15:38:56,013: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316277 effective words) took 5.2s, 447713 effective words/s', 'datetime': '2023-11-30T15:38:56.013745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:56,013: collecting all words and their counts
INFO - 2023-11-30 15:38:56,014: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:38:56,044: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:38:56,044: Updating model with new vocabulary
INFO - 2023-11-30 15:38:56,060: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:38:56.060398', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:56,079: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:38:56,079: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:38:56,080: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115765.64227737603 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:38:56.080065', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:38:56,109: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:38:56,109: updating layer weights
INFO - 2023-11-30 15:38:56,110: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:38:56.110398', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:38:56,110: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:38:56,110: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:38:56.110770', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:38:56,422: EPOCH 0: training on 191080 raw words (115553 effective words) took 0.3s, 374768 effective words/s
INFO - 2023-11-30 15:38:56,684: EPOCH 1: training on 191080 raw words (115727 effective words) took 0.3s, 446494 effective words/s
INFO - 2023-11-30 15:38:56,965: EPOCH 2: training on 191080 raw words (115889 effective words) took 0.3s, 417127 effective words/s
INFO - 2023-11-30 15:38:57,207: EPOCH 3: training on 191080 raw words (115409 effective words) took 0.2s, 481633 effective words/s
INFO - 2023-11-30 15:38:57,458: EPOCH 4: training on 191080 raw words (115788 effective words) took 0.2s, 464432 effective words/s
INFO - 2023-11-30 15:38:57,689: EPOCH 5: training on 191080 raw words (115661 effective words) took 0.2s, 506131 effective words/s
INFO - 2023-11-30 15:38:57,922: EPOCH 6: training on 191080 raw words (115884 effective words) took 0.2s, 502617 effective words/s
INFO - 2023-11-30 15:38:58,157: EPOCH 7: training on 191080 raw words (115936 effective words) took 0.2s, 499833 effective words/s
INFO - 2023-11-30 15:38:58,391: EPOCH 8: training on 191080 raw words (115985 effective words) took 0.2s, 499746 effective words/s
INFO - 2023-11-30 15:38:58,628: EPOCH 9: training on 191080 raw words (115587 effective words) took 0.2s, 494050 effective words/s
INFO - 2023-11-30 15:38:58,858: EPOCH 10: training on 191080 raw words (115932 effective words) took 0.2s, 508430 effective words/s
INFO - 2023-11-30 15:38:59,087: EPOCH 11: training on 191080 raw words (115863 effective words) took 0.2s, 548821 effective words/s
INFO - 2023-11-30 15:38:59,325: EPOCH 12: training on 191080 raw words (115783 effective words) took 0.2s, 492094 effective words/s
INFO - 2023-11-30 15:38:59,565: EPOCH 13: training on 191080 raw words (115692 effective words) took 0.2s, 487851 effective words/s
INFO - 2023-11-30 15:38:59,797: EPOCH 14: training on 191080 raw words (115709 effective words) took 0.2s, 503741 effective words/s
INFO - 2023-11-30 15:39:00,028: EPOCH 15: training on 191080 raw words (115786 effective words) took 0.2s, 505218 effective words/s
INFO - 2023-11-30 15:39:00,259: EPOCH 16: training on 191080 raw words (115768 effective words) took 0.2s, 508801 effective words/s
INFO - 2023-11-30 15:39:00,492: EPOCH 17: training on 191080 raw words (115760 effective words) took 0.2s, 502269 effective words/s
INFO - 2023-11-30 15:39:00,716: EPOCH 18: training on 191080 raw words (115667 effective words) took 0.2s, 520854 effective words/s
INFO - 2023-11-30 15:39:00,945: EPOCH 19: training on 191080 raw words (115765 effective words) took 0.2s, 510011 effective words/s
INFO - 2023-11-30 15:39:00,945: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2315144 effective words) took 4.8s, 478846 effective words/s', 'datetime': '2023-11-30T15:39:00.945774', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:00,946: collecting all words and their counts
INFO - 2023-11-30 15:39:00,946: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:00,972: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:00,972: Updating model with new vocabulary
INFO - 2023-11-30 15:39:00,984: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:00.984479', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:00,999: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:01,000: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:01,000: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115656.3421720078 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:39:01.000257', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:01,025: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:01,025: updating layer weights
INFO - 2023-11-30 15:39:01,025: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:01.025891', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:01,026: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:01,026: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:01.026137', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:01,256: EPOCH 0: training on 191080 raw words (115571 effective words) took 0.2s, 507060 effective words/s
INFO - 2023-11-30 15:39:01,503: EPOCH 1: training on 191080 raw words (115610 effective words) took 0.2s, 473387 effective words/s
INFO - 2023-11-30 15:39:01,726: EPOCH 2: training on 191080 raw words (115700 effective words) took 0.2s, 523341 effective words/s
INFO - 2023-11-30 15:39:01,955: EPOCH 3: training on 191080 raw words (115678 effective words) took 0.2s, 508837 effective words/s
INFO - 2023-11-30 15:39:02,199: EPOCH 4: training on 191080 raw words (115665 effective words) took 0.2s, 479936 effective words/s
INFO - 2023-11-30 15:39:02,437: EPOCH 5: training on 191080 raw words (115693 effective words) took 0.2s, 490019 effective words/s
INFO - 2023-11-30 15:39:02,708: EPOCH 6: training on 191080 raw words (115604 effective words) took 0.3s, 430535 effective words/s
INFO - 2023-11-30 15:39:02,950: EPOCH 7: training on 191080 raw words (115702 effective words) took 0.2s, 483032 effective words/s
INFO - 2023-11-30 15:39:03,199: EPOCH 8: training on 191080 raw words (115836 effective words) took 0.2s, 469963 effective words/s
INFO - 2023-11-30 15:39:03,438: EPOCH 9: training on 191080 raw words (115618 effective words) took 0.2s, 489009 effective words/s
INFO - 2023-11-30 15:39:03,718: EPOCH 10: training on 191080 raw words (115840 effective words) took 0.3s, 417080 effective words/s
INFO - 2023-11-30 15:39:03,938: EPOCH 11: training on 191080 raw words (115656 effective words) took 0.2s, 529900 effective words/s
INFO - 2023-11-30 15:39:04,168: EPOCH 12: training on 191080 raw words (115617 effective words) took 0.2s, 507625 effective words/s
INFO - 2023-11-30 15:39:04,394: EPOCH 13: training on 191080 raw words (115933 effective words) took 0.2s, 520038 effective words/s
INFO - 2023-11-30 15:39:04,626: EPOCH 14: training on 191080 raw words (115560 effective words) took 0.2s, 501933 effective words/s
INFO - 2023-11-30 15:39:04,877: EPOCH 15: training on 191080 raw words (115681 effective words) took 0.2s, 465807 effective words/s
INFO - 2023-11-30 15:39:05,099: EPOCH 16: training on 191080 raw words (115662 effective words) took 0.2s, 526262 effective words/s
INFO - 2023-11-30 15:39:05,323: EPOCH 17: training on 191080 raw words (115738 effective words) took 0.2s, 523671 effective words/s
INFO - 2023-11-30 15:39:05,559: EPOCH 18: training on 191080 raw words (115673 effective words) took 0.2s, 496229 effective words/s
INFO - 2023-11-30 15:39:05,782: EPOCH 19: training on 191080 raw words (115657 effective words) took 0.2s, 526006 effective words/s
INFO - 2023-11-30 15:39:05,782: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313694 effective words) took 4.8s, 486434 effective words/s', 'datetime': '2023-11-30T15:39:05.782722', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:05,782: collecting all words and their counts
INFO - 2023-11-30 15:39:05,783: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:05,809: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:05,809: Updating model with new vocabulary
INFO - 2023-11-30 15:39:05,822: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:05.822462', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:05,838: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:05,838: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:05,838: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115441.25314145877 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:39:05.838597', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:05,863: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:05,864: updating layer weights
INFO - 2023-11-30 15:39:05,864: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:05.864462', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:05,864: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:05,864: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:05.864745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:06,113: EPOCH 0: training on 191080 raw words (115173 effective words) took 0.2s, 468126 effective words/s
INFO - 2023-11-30 15:39:06,346: EPOCH 1: training on 191080 raw words (115342 effective words) took 0.2s, 500198 effective words/s
INFO - 2023-11-30 15:39:06,644: EPOCH 2: training on 191080 raw words (115533 effective words) took 0.3s, 390826 effective words/s
INFO - 2023-11-30 15:39:06,890: EPOCH 3: training on 191080 raw words (115461 effective words) took 0.2s, 473422 effective words/s
INFO - 2023-11-30 15:39:07,127: EPOCH 4: training on 191080 raw words (115419 effective words) took 0.2s, 492287 effective words/s
INFO - 2023-11-30 15:39:07,364: EPOCH 5: training on 191080 raw words (115364 effective words) took 0.2s, 490550 effective words/s
INFO - 2023-11-30 15:39:07,628: EPOCH 6: training on 191080 raw words (115488 effective words) took 0.3s, 442243 effective words/s
INFO - 2023-11-30 15:39:07,860: EPOCH 7: training on 191080 raw words (115336 effective words) took 0.2s, 501859 effective words/s
INFO - 2023-11-30 15:39:08,090: EPOCH 8: training on 191080 raw words (115349 effective words) took 0.2s, 505598 effective words/s
INFO - 2023-11-30 15:39:08,323: EPOCH 9: training on 191080 raw words (115442 effective words) took 0.2s, 500287 effective words/s
INFO - 2023-11-30 15:39:08,559: EPOCH 10: training on 191080 raw words (115415 effective words) took 0.2s, 494368 effective words/s
INFO - 2023-11-30 15:39:08,797: EPOCH 11: training on 191080 raw words (115481 effective words) took 0.2s, 489445 effective words/s
INFO - 2023-11-30 15:39:09,107: EPOCH 12: training on 191080 raw words (115227 effective words) took 0.3s, 374485 effective words/s
INFO - 2023-11-30 15:39:09,441: EPOCH 13: training on 191080 raw words (115179 effective words) took 0.3s, 347973 effective words/s
INFO - 2023-11-30 15:39:09,769: EPOCH 14: training on 191080 raw words (115416 effective words) took 0.3s, 355297 effective words/s
INFO - 2023-11-30 15:39:10,122: EPOCH 15: training on 191080 raw words (115223 effective words) took 0.3s, 330597 effective words/s
INFO - 2023-11-30 15:39:10,495: EPOCH 16: training on 191080 raw words (115532 effective words) took 0.4s, 312647 effective words/s
INFO - 2023-11-30 15:39:10,849: EPOCH 17: training on 191080 raw words (115388 effective words) took 0.4s, 328797 effective words/s
INFO - 2023-11-30 15:39:11,214: EPOCH 18: training on 191080 raw words (115570 effective words) took 0.4s, 320043 effective words/s
INFO - 2023-11-30 15:39:11,594: EPOCH 19: training on 191080 raw words (115232 effective words) took 0.4s, 305927 effective words/s
INFO - 2023-11-30 15:39:11,594: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2307570 effective words) took 5.7s, 402744 effective words/s', 'datetime': '2023-11-30T15:39:11.594526', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:11,594: collecting all words and their counts
INFO - 2023-11-30 15:39:11,595: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:11,634: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:11,634: Updating model with new vocabulary
INFO - 2023-11-30 15:39:11,654: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:11.654211', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:11,678: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:11,678: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:11,678: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115532.30002862954 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:39:11.678784', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:11,715: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:11,715: updating layer weights
INFO - 2023-11-30 15:39:11,716: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:11.716083', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:11,716: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:11,716: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:11.716418', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:12,111: EPOCH 0: training on 191080 raw words (115716 effective words) took 0.4s, 295238 effective words/s
INFO - 2023-11-30 15:39:12,525: EPOCH 1: training on 191080 raw words (115533 effective words) took 0.4s, 281767 effective words/s
INFO - 2023-11-30 15:39:12,928: EPOCH 2: training on 191080 raw words (115396 effective words) took 0.4s, 288816 effective words/s
INFO - 2023-11-30 15:39:13,298: EPOCH 3: training on 191080 raw words (115289 effective words) took 0.4s, 314318 effective words/s
INFO - 2023-11-30 15:39:13,684: EPOCH 4: training on 191080 raw words (115417 effective words) took 0.4s, 302202 effective words/s
INFO - 2023-11-30 15:39:14,151: EPOCH 5: training on 191080 raw words (115703 effective words) took 0.5s, 256570 effective words/s
INFO - 2023-11-30 15:39:14,582: EPOCH 6: training on 191080 raw words (115619 effective words) took 0.4s, 271484 effective words/s
INFO - 2023-11-30 15:39:14,987: EPOCH 7: training on 191080 raw words (115266 effective words) took 0.4s, 287282 effective words/s
INFO - 2023-11-30 15:39:15,308: EPOCH 8: training on 191080 raw words (115388 effective words) took 0.3s, 363243 effective words/s
INFO - 2023-11-30 15:39:15,626: EPOCH 9: training on 191080 raw words (115759 effective words) took 0.3s, 367598 effective words/s
INFO - 2023-11-30 15:39:15,969: EPOCH 10: training on 191080 raw words (115527 effective words) took 0.3s, 339438 effective words/s
INFO - 2023-11-30 15:39:16,282: EPOCH 11: training on 191080 raw words (115798 effective words) took 0.3s, 373455 effective words/s
INFO - 2023-11-30 15:39:16,591: EPOCH 12: training on 191080 raw words (115600 effective words) took 0.3s, 378712 effective words/s
INFO - 2023-11-30 15:39:16,935: EPOCH 13: training on 191080 raw words (115512 effective words) took 0.3s, 339240 effective words/s
INFO - 2023-11-30 15:39:17,370: EPOCH 14: training on 191080 raw words (115650 effective words) took 0.4s, 268262 effective words/s
INFO - 2023-11-30 15:39:17,719: EPOCH 15: training on 191080 raw words (115496 effective words) took 0.3s, 334490 effective words/s
INFO - 2023-11-30 15:39:18,028: EPOCH 16: training on 191080 raw words (115471 effective words) took 0.3s, 378003 effective words/s
INFO - 2023-11-30 15:39:18,296: EPOCH 17: training on 191080 raw words (115613 effective words) took 0.3s, 435917 effective words/s
INFO - 2023-11-30 15:39:18,580: EPOCH 18: training on 191080 raw words (115415 effective words) took 0.3s, 410840 effective words/s
INFO - 2023-11-30 15:39:18,850: EPOCH 19: training on 191080 raw words (115464 effective words) took 0.3s, 432229 effective words/s
INFO - 2023-11-30 15:39:18,850: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310632 effective words) took 7.1s, 323881 effective words/s', 'datetime': '2023-11-30T15:39:18.850818', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:18,851: collecting all words and their counts
INFO - 2023-11-30 15:39:18,851: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:18,917: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:18,917: Updating model with new vocabulary
INFO - 2023-11-30 15:39:18,935: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:18.935674', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:18,960: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:18,960: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:18,961: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115868.3902442957 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:39:18.961040', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:19,002: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:19,002: updating layer weights
INFO - 2023-11-30 15:39:19,003: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:19.003269', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:19,003: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:19,003: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:19.003697', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:19,351: EPOCH 0: training on 191080 raw words (115988 effective words) took 0.3s, 336522 effective words/s
INFO - 2023-11-30 15:39:19,675: EPOCH 1: training on 191080 raw words (115901 effective words) took 0.3s, 362777 effective words/s
INFO - 2023-11-30 15:39:20,001: EPOCH 2: training on 191080 raw words (115974 effective words) took 0.3s, 359276 effective words/s
INFO - 2023-11-30 15:39:20,346: EPOCH 3: training on 191080 raw words (115838 effective words) took 0.3s, 338519 effective words/s
INFO - 2023-11-30 15:39:20,675: EPOCH 4: training on 191080 raw words (115990 effective words) took 0.3s, 356055 effective words/s
INFO - 2023-11-30 15:39:20,996: EPOCH 5: training on 191080 raw words (116083 effective words) took 0.3s, 365866 effective words/s
INFO - 2023-11-30 15:39:21,325: EPOCH 6: training on 191080 raw words (115698 effective words) took 0.3s, 355142 effective words/s
INFO - 2023-11-30 15:39:21,641: EPOCH 7: training on 191080 raw words (115717 effective words) took 0.3s, 369369 effective words/s
INFO - 2023-11-30 15:39:21,965: EPOCH 8: training on 191080 raw words (115740 effective words) took 0.3s, 360463 effective words/s
INFO - 2023-11-30 15:39:22,294: EPOCH 9: training on 191080 raw words (116113 effective words) took 0.3s, 356286 effective words/s
INFO - 2023-11-30 15:39:22,650: EPOCH 10: training on 191080 raw words (115946 effective words) took 0.4s, 328129 effective words/s
INFO - 2023-11-30 15:39:22,974: EPOCH 11: training on 191080 raw words (115840 effective words) took 0.3s, 361480 effective words/s
INFO - 2023-11-30 15:39:23,304: EPOCH 12: training on 191080 raw words (115986 effective words) took 0.3s, 354850 effective words/s
INFO - 2023-11-30 15:39:23,611: EPOCH 13: training on 191080 raw words (116086 effective words) took 0.3s, 381811 effective words/s
INFO - 2023-11-30 15:39:23,908: EPOCH 14: training on 191080 raw words (115822 effective words) took 0.3s, 393810 effective words/s
INFO - 2023-11-30 15:39:24,138: EPOCH 15: training on 191080 raw words (115802 effective words) took 0.2s, 508719 effective words/s
INFO - 2023-11-30 15:39:24,364: EPOCH 16: training on 191080 raw words (116036 effective words) took 0.2s, 518584 effective words/s
INFO - 2023-11-30 15:39:24,597: EPOCH 17: training on 191080 raw words (115887 effective words) took 0.2s, 502310 effective words/s
INFO - 2023-11-30 15:39:24,825: EPOCH 18: training on 191080 raw words (115790 effective words) took 0.2s, 512594 effective words/s
INFO - 2023-11-30 15:39:25,090: EPOCH 19: training on 191080 raw words (116157 effective words) took 0.3s, 442248 effective words/s
INFO - 2023-11-30 15:39:25,091: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2318394 effective words) took 6.1s, 380866 effective words/s', 'datetime': '2023-11-30T15:39:25.091054', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:25,091: collecting all words and their counts
INFO - 2023-11-30 15:39:25,091: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:25,119: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:25,119: Updating model with new vocabulary
INFO - 2023-11-30 15:39:25,132: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:25.132912', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:25,149: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:25,149: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:25,149: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115584.96210089156 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:39:25.149431', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:25,176: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:25,176: updating layer weights
INFO - 2023-11-30 15:39:25,177: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:25.177129', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:25,177: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:25,177: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:25.177407', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:25,473: EPOCH 0: training on 191080 raw words (115569 effective words) took 0.3s, 393858 effective words/s
INFO - 2023-11-30 15:39:25,708: EPOCH 1: training on 191080 raw words (115654 effective words) took 0.2s, 498527 effective words/s
INFO - 2023-11-30 15:39:25,942: EPOCH 2: training on 191080 raw words (115507 effective words) took 0.2s, 499288 effective words/s
INFO - 2023-11-30 15:39:26,172: EPOCH 3: training on 191080 raw words (115560 effective words) took 0.2s, 506657 effective words/s
INFO - 2023-11-30 15:39:26,417: EPOCH 4: training on 191080 raw words (115572 effective words) took 0.2s, 477713 effective words/s
INFO - 2023-11-30 15:39:26,673: EPOCH 5: training on 191080 raw words (115575 effective words) took 0.3s, 455921 effective words/s
INFO - 2023-11-30 15:39:26,913: EPOCH 6: training on 191080 raw words (115534 effective words) took 0.2s, 486637 effective words/s
INFO - 2023-11-30 15:39:27,142: EPOCH 7: training on 191080 raw words (115424 effective words) took 0.2s, 508497 effective words/s
INFO - 2023-11-30 15:39:27,362: EPOCH 8: training on 191080 raw words (115613 effective words) took 0.2s, 531844 effective words/s
INFO - 2023-11-30 15:39:27,593: EPOCH 9: training on 191080 raw words (115679 effective words) took 0.2s, 505573 effective words/s
INFO - 2023-11-30 15:39:27,832: EPOCH 10: training on 191080 raw words (115440 effective words) took 0.2s, 488892 effective words/s
INFO - 2023-11-30 15:39:28,071: EPOCH 11: training on 191080 raw words (115754 effective words) took 0.2s, 488325 effective words/s
INFO - 2023-11-30 15:39:28,302: EPOCH 12: training on 191080 raw words (115385 effective words) took 0.2s, 504942 effective words/s
INFO - 2023-11-30 15:39:28,567: EPOCH 13: training on 191080 raw words (115769 effective words) took 0.3s, 440485 effective words/s
INFO - 2023-11-30 15:39:28,822: EPOCH 14: training on 191080 raw words (115714 effective words) took 0.3s, 458441 effective words/s
INFO - 2023-11-30 15:39:29,074: EPOCH 15: training on 191080 raw words (115762 effective words) took 0.2s, 463726 effective words/s
INFO - 2023-11-30 15:39:29,308: EPOCH 16: training on 191080 raw words (115516 effective words) took 0.2s, 501128 effective words/s
INFO - 2023-11-30 15:39:29,569: EPOCH 17: training on 191080 raw words (115705 effective words) took 0.3s, 447944 effective words/s
INFO - 2023-11-30 15:39:29,798: EPOCH 18: training on 191080 raw words (115426 effective words) took 0.2s, 509993 effective words/s
INFO - 2023-11-30 15:39:30,028: EPOCH 19: training on 191080 raw words (115799 effective words) took 0.2s, 507813 effective words/s
INFO - 2023-11-30 15:39:30,028: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2311957 effective words) took 4.9s, 476561 effective words/s', 'datetime': '2023-11-30T15:39:30.028871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:30,029: collecting all words and their counts
INFO - 2023-11-30 15:39:30,029: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:30,056: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:30,056: Updating model with new vocabulary
INFO - 2023-11-30 15:39:30,073: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:30.072969', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:30,090: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:30,091: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:39:30,091: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115504.82687398916 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:39:30.091311', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:30,117: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:30,117: updating layer weights
INFO - 2023-11-30 15:39:30,118: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:30.118454', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:30,118: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:30,118: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:30.118818', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:30,359: EPOCH 0: training on 191080 raw words (115443 effective words) took 0.2s, 485656 effective words/s
INFO - 2023-11-30 15:39:30,606: EPOCH 1: training on 191080 raw words (115406 effective words) took 0.2s, 473349 effective words/s
INFO - 2023-11-30 15:39:30,848: EPOCH 2: training on 191080 raw words (115325 effective words) took 0.2s, 482227 effective words/s
INFO - 2023-11-30 15:39:31,088: EPOCH 3: training on 191080 raw words (115536 effective words) took 0.2s, 485622 effective words/s
INFO - 2023-11-30 15:39:31,324: EPOCH 4: training on 191080 raw words (115438 effective words) took 0.2s, 493794 effective words/s
INFO - 2023-11-30 15:39:31,559: EPOCH 5: training on 191080 raw words (115398 effective words) took 0.2s, 494957 effective words/s
INFO - 2023-11-30 15:39:31,805: EPOCH 6: training on 191080 raw words (115639 effective words) took 0.2s, 476448 effective words/s
INFO - 2023-11-30 15:39:32,054: EPOCH 7: training on 191080 raw words (115298 effective words) took 0.2s, 468006 effective words/s
INFO - 2023-11-30 15:39:32,297: EPOCH 8: training on 191080 raw words (115474 effective words) took 0.2s, 479153 effective words/s
INFO - 2023-11-30 15:39:32,551: EPOCH 9: training on 191080 raw words (115639 effective words) took 0.3s, 459657 effective words/s
INFO - 2023-11-30 15:39:32,821: EPOCH 10: training on 191080 raw words (115548 effective words) took 0.3s, 432457 effective words/s
INFO - 2023-11-30 15:39:33,074: EPOCH 11: training on 191080 raw words (115622 effective words) took 0.2s, 472933 effective words/s
INFO - 2023-11-30 15:39:33,314: EPOCH 12: training on 191080 raw words (115572 effective words) took 0.2s, 486187 effective words/s
INFO - 2023-11-30 15:39:33,558: EPOCH 13: training on 191080 raw words (115627 effective words) took 0.2s, 478262 effective words/s
INFO - 2023-11-30 15:39:33,805: EPOCH 14: training on 191080 raw words (115328 effective words) took 0.2s, 472175 effective words/s
INFO - 2023-11-30 15:39:34,048: EPOCH 15: training on 191080 raw words (115541 effective words) took 0.2s, 480472 effective words/s
INFO - 2023-11-30 15:39:34,284: EPOCH 16: training on 191080 raw words (115492 effective words) took 0.2s, 494432 effective words/s
INFO - 2023-11-30 15:39:34,527: EPOCH 17: training on 191080 raw words (115656 effective words) took 0.2s, 480460 effective words/s
INFO - 2023-11-30 15:39:34,776: EPOCH 18: training on 191080 raw words (115519 effective words) took 0.2s, 467880 effective words/s
INFO - 2023-11-30 15:39:35,014: EPOCH 19: training on 191080 raw words (115192 effective words) took 0.2s, 489913 effective words/s
INFO - 2023-11-30 15:39:35,014: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309693 effective words) took 4.9s, 471822 effective words/s', 'datetime': '2023-11-30T15:39:35.014227', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:35,014: collecting all words and their counts
INFO - 2023-11-30 15:39:35,014: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:35,041: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:35,042: Updating model with new vocabulary
INFO - 2023-11-30 15:39:35,054: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:35.054879', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:35,069: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:35,070: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:39:35,070: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115795.23954004448 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:39:35.070255', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:35,094: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:35,094: updating layer weights
INFO - 2023-11-30 15:39:35,094: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:35.094843', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:35,095: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:35,095: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:35.095144', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:35,319: EPOCH 0: training on 191080 raw words (115638 effective words) took 0.2s, 569667 effective words/s
INFO - 2023-11-30 15:39:35,560: EPOCH 1: training on 191080 raw words (115806 effective words) took 0.2s, 486038 effective words/s
INFO - 2023-11-30 15:39:35,791: EPOCH 2: training on 191080 raw words (115794 effective words) took 0.2s, 508293 effective words/s
INFO - 2023-11-30 15:39:36,021: EPOCH 3: training on 191080 raw words (115722 effective words) took 0.2s, 508188 effective words/s
INFO - 2023-11-30 15:39:36,262: EPOCH 4: training on 191080 raw words (115815 effective words) took 0.2s, 485493 effective words/s
INFO - 2023-11-30 15:39:36,498: EPOCH 5: training on 191080 raw words (115752 effective words) took 0.2s, 496064 effective words/s
INFO - 2023-11-30 15:39:36,735: EPOCH 6: training on 191080 raw words (115908 effective words) took 0.2s, 495627 effective words/s
INFO - 2023-11-30 15:39:36,965: EPOCH 7: training on 191080 raw words (115748 effective words) took 0.2s, 508418 effective words/s
INFO - 2023-11-30 15:39:37,207: EPOCH 8: training on 191080 raw words (115772 effective words) took 0.2s, 482669 effective words/s
INFO - 2023-11-30 15:39:37,439: EPOCH 9: training on 191080 raw words (115885 effective words) took 0.2s, 504025 effective words/s
INFO - 2023-11-30 15:39:37,709: EPOCH 10: training on 191080 raw words (115669 effective words) took 0.3s, 431630 effective words/s
INFO - 2023-11-30 15:39:37,975: EPOCH 11: training on 191080 raw words (115991 effective words) took 0.3s, 440576 effective words/s
INFO - 2023-11-30 15:39:38,252: EPOCH 12: training on 191080 raw words (116011 effective words) took 0.3s, 423429 effective words/s
INFO - 2023-11-30 15:39:38,577: EPOCH 13: training on 191080 raw words (116047 effective words) took 0.3s, 359335 effective words/s
INFO - 2023-11-30 15:39:38,894: EPOCH 14: training on 191080 raw words (115668 effective words) took 0.3s, 368264 effective words/s
INFO - 2023-11-30 15:39:39,191: EPOCH 15: training on 191080 raw words (115860 effective words) took 0.3s, 395651 effective words/s
INFO - 2023-11-30 15:39:39,474: EPOCH 16: training on 191080 raw words (115883 effective words) took 0.3s, 413494 effective words/s
INFO - 2023-11-30 15:39:39,770: EPOCH 17: training on 191080 raw words (115926 effective words) took 0.3s, 396353 effective words/s
INFO - 2023-11-30 15:39:40,079: EPOCH 18: training on 191080 raw words (115623 effective words) took 0.3s, 377453 effective words/s
INFO - 2023-11-30 15:39:40,372: EPOCH 19: training on 191080 raw words (115825 effective words) took 0.3s, 399782 effective words/s
INFO - 2023-11-30 15:39:40,372: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316343 effective words) took 5.3s, 438905 effective words/s', 'datetime': '2023-11-30T15:39:40.372847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:40,373: collecting all words and their counts
INFO - 2023-11-30 15:39:40,373: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:40,409: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:40,409: Updating model with new vocabulary
INFO - 2023-11-30 15:39:40,426: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:40.426245', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:40,448: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:40,448: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:39:40,448: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115676.3051978496 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:39:40.448760', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:40,481: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:40,481: updating layer weights
INFO - 2023-11-30 15:39:40,482: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:40.482210', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:40,482: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:40,482: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:40.482848', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:40,787: EPOCH 0: training on 191080 raw words (115518 effective words) took 0.3s, 382711 effective words/s
INFO - 2023-11-30 15:39:41,092: EPOCH 1: training on 191080 raw words (115427 effective words) took 0.3s, 382548 effective words/s
INFO - 2023-11-30 15:39:41,407: EPOCH 2: training on 191080 raw words (115609 effective words) took 0.3s, 369818 effective words/s
INFO - 2023-11-30 15:39:41,721: EPOCH 3: training on 191080 raw words (115621 effective words) took 0.3s, 372014 effective words/s
INFO - 2023-11-30 15:39:42,031: EPOCH 4: training on 191080 raw words (115756 effective words) took 0.3s, 376771 effective words/s
INFO - 2023-11-30 15:39:42,342: EPOCH 5: training on 191080 raw words (115562 effective words) took 0.3s, 375503 effective words/s
INFO - 2023-11-30 15:39:42,647: EPOCH 6: training on 191080 raw words (115471 effective words) took 0.3s, 382996 effective words/s
INFO - 2023-11-30 15:39:42,958: EPOCH 7: training on 191080 raw words (115794 effective words) took 0.3s, 375092 effective words/s
INFO - 2023-11-30 15:39:43,270: EPOCH 8: training on 191080 raw words (115509 effective words) took 0.3s, 374428 effective words/s
INFO - 2023-11-30 15:39:43,626: EPOCH 9: training on 191080 raw words (115632 effective words) took 0.4s, 327322 effective words/s
INFO - 2023-11-30 15:39:43,997: EPOCH 10: training on 191080 raw words (115809 effective words) took 0.4s, 314239 effective words/s
INFO - 2023-11-30 15:39:44,310: EPOCH 11: training on 191080 raw words (115905 effective words) took 0.3s, 373950 effective words/s
INFO - 2023-11-30 15:39:44,646: EPOCH 12: training on 191080 raw words (115775 effective words) took 0.3s, 347661 effective words/s
INFO - 2023-11-30 15:39:44,957: EPOCH 13: training on 191080 raw words (115429 effective words) took 0.3s, 374927 effective words/s
INFO - 2023-11-30 15:39:45,278: EPOCH 14: training on 191080 raw words (115676 effective words) took 0.3s, 364588 effective words/s
INFO - 2023-11-30 15:39:45,600: EPOCH 15: training on 191080 raw words (115713 effective words) took 0.3s, 362118 effective words/s
INFO - 2023-11-30 15:39:45,941: EPOCH 16: training on 191080 raw words (115482 effective words) took 0.3s, 342205 effective words/s
INFO - 2023-11-30 15:39:46,255: EPOCH 17: training on 191080 raw words (115640 effective words) took 0.3s, 372274 effective words/s
INFO - 2023-11-30 15:39:46,584: EPOCH 18: training on 191080 raw words (115607 effective words) took 0.3s, 354892 effective words/s
INFO - 2023-11-30 15:39:46,905: EPOCH 19: training on 191080 raw words (115933 effective words) took 0.3s, 364773 effective words/s
INFO - 2023-11-30 15:39:46,905: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312868 effective words) took 6.4s, 360129 effective words/s', 'datetime': '2023-11-30T15:39:46.905469', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:46,905: collecting all words and their counts
INFO - 2023-11-30 15:39:46,905: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:46,942: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:46,942: Updating model with new vocabulary
INFO - 2023-11-30 15:39:46,959: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:46.959342', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:46,981: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:46,981: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:39:46,981: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115916.0539707536 word corpus (60.7%% of prior 191080)', 'datetime': '2023-11-30T15:39:46.981575', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:47,020: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:47,021: updating layer weights
INFO - 2023-11-30 15:39:47,021: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:47.021669', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:47,021: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:47,022: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:47.022005', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:47,303: EPOCH 0: training on 191080 raw words (115879 effective words) took 0.3s, 417700 effective words/s
INFO - 2023-11-30 15:39:47,586: EPOCH 1: training on 191080 raw words (115967 effective words) took 0.3s, 413168 effective words/s
INFO - 2023-11-30 15:39:47,853: EPOCH 2: training on 191080 raw words (115712 effective words) took 0.3s, 438890 effective words/s
INFO - 2023-11-30 15:39:48,141: EPOCH 3: training on 191080 raw words (116043 effective words) took 0.3s, 406781 effective words/s
INFO - 2023-11-30 15:39:48,467: EPOCH 4: training on 191080 raw words (115833 effective words) took 0.3s, 359251 effective words/s
INFO - 2023-11-30 15:39:48,742: EPOCH 5: training on 191080 raw words (115864 effective words) took 0.3s, 442066 effective words/s
INFO - 2023-11-30 15:39:49,007: EPOCH 6: training on 191080 raw words (115844 effective words) took 0.3s, 442313 effective words/s
INFO - 2023-11-30 15:39:49,286: EPOCH 7: training on 191080 raw words (115809 effective words) took 0.3s, 419959 effective words/s
INFO - 2023-11-30 15:39:49,568: EPOCH 8: training on 191080 raw words (116023 effective words) took 0.3s, 417085 effective words/s
INFO - 2023-11-30 15:39:49,837: EPOCH 9: training on 191080 raw words (115986 effective words) took 0.3s, 436026 effective words/s
INFO - 2023-11-30 15:39:50,102: EPOCH 10: training on 191080 raw words (115956 effective words) took 0.3s, 443644 effective words/s
INFO - 2023-11-30 15:39:50,374: EPOCH 11: training on 191080 raw words (116057 effective words) took 0.3s, 430617 effective words/s
INFO - 2023-11-30 15:39:50,626: EPOCH 12: training on 191080 raw words (115776 effective words) took 0.2s, 465520 effective words/s
INFO - 2023-11-30 15:39:50,855: EPOCH 13: training on 191080 raw words (115935 effective words) took 0.2s, 510721 effective words/s
INFO - 2023-11-30 15:39:51,099: EPOCH 14: training on 191080 raw words (115791 effective words) took 0.2s, 479696 effective words/s
INFO - 2023-11-30 15:39:51,323: EPOCH 15: training on 191080 raw words (116083 effective words) took 0.2s, 522620 effective words/s
INFO - 2023-11-30 15:39:51,546: EPOCH 16: training on 191080 raw words (116082 effective words) took 0.2s, 526909 effective words/s
INFO - 2023-11-30 15:39:51,766: EPOCH 17: training on 191080 raw words (115913 effective words) took 0.2s, 531836 effective words/s
INFO - 2023-11-30 15:39:51,980: EPOCH 18: training on 191080 raw words (115929 effective words) took 0.2s, 546059 effective words/s
INFO - 2023-11-30 15:39:52,207: EPOCH 19: training on 191080 raw words (116020 effective words) took 0.2s, 517755 effective words/s
INFO - 2023-11-30 15:39:52,207: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2318502 effective words) took 5.2s, 447134 effective words/s', 'datetime': '2023-11-30T15:39:52.207416', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:52,207: collecting all words and their counts
INFO - 2023-11-30 15:39:52,207: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:52,234: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:52,235: Updating model with new vocabulary
INFO - 2023-11-30 15:39:52,247: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:52.247264', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:52,262: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:52,263: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:39:52,263: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115490.66107937461 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:39:52.263245', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:52,287: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:52,287: updating layer weights
INFO - 2023-11-30 15:39:52,287: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:52.287902', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:52,288: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:52,288: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:52.288139', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:52,518: EPOCH 0: training on 191080 raw words (115352 effective words) took 0.2s, 505554 effective words/s
INFO - 2023-11-30 15:39:52,787: EPOCH 1: training on 191080 raw words (115489 effective words) took 0.3s, 433838 effective words/s
INFO - 2023-11-30 15:39:53,018: EPOCH 2: training on 191080 raw words (115413 effective words) took 0.2s, 503775 effective words/s
INFO - 2023-11-30 15:39:53,265: EPOCH 3: training on 191080 raw words (115761 effective words) took 0.2s, 472985 effective words/s
INFO - 2023-11-30 15:39:53,504: EPOCH 4: training on 191080 raw words (115170 effective words) took 0.2s, 486764 effective words/s
INFO - 2023-11-30 15:39:53,763: EPOCH 5: training on 191080 raw words (115548 effective words) took 0.3s, 450120 effective words/s
INFO - 2023-11-30 15:39:53,998: EPOCH 6: training on 191080 raw words (115461 effective words) took 0.2s, 533988 effective words/s
INFO - 2023-11-30 15:39:54,227: EPOCH 7: training on 191080 raw words (115530 effective words) took 0.2s, 509802 effective words/s
INFO - 2023-11-30 15:39:54,458: EPOCH 8: training on 191080 raw words (115580 effective words) took 0.2s, 504476 effective words/s
INFO - 2023-11-30 15:39:54,690: EPOCH 9: training on 191080 raw words (115567 effective words) took 0.2s, 502853 effective words/s
INFO - 2023-11-30 15:39:54,927: EPOCH 10: training on 191080 raw words (115276 effective words) took 0.2s, 491246 effective words/s
INFO - 2023-11-30 15:39:55,160: EPOCH 11: training on 191080 raw words (115545 effective words) took 0.2s, 500615 effective words/s
INFO - 2023-11-30 15:39:55,390: EPOCH 12: training on 191080 raw words (115587 effective words) took 0.2s, 508319 effective words/s
INFO - 2023-11-30 15:39:55,621: EPOCH 13: training on 191080 raw words (115367 effective words) took 0.2s, 504051 effective words/s
INFO - 2023-11-30 15:39:55,869: EPOCH 14: training on 191080 raw words (115593 effective words) took 0.2s, 470686 effective words/s
INFO - 2023-11-30 15:39:56,166: EPOCH 15: training on 191080 raw words (115457 effective words) took 0.3s, 392732 effective words/s
INFO - 2023-11-30 15:39:56,409: EPOCH 16: training on 191080 raw words (115473 effective words) took 0.2s, 482464 effective words/s
INFO - 2023-11-30 15:39:56,651: EPOCH 17: training on 191080 raw words (115675 effective words) took 0.2s, 483358 effective words/s
INFO - 2023-11-30 15:39:56,893: EPOCH 18: training on 191080 raw words (115612 effective words) took 0.2s, 483167 effective words/s
INFO - 2023-11-30 15:39:57,134: EPOCH 19: training on 191080 raw words (115558 effective words) took 0.2s, 527477 effective words/s
INFO - 2023-11-30 15:39:57,134: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310014 effective words) took 4.8s, 476670 effective words/s', 'datetime': '2023-11-30T15:39:57.134414', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:57,134: collecting all words and their counts
INFO - 2023-11-30 15:39:57,134: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:39:57,162: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:39:57,162: Updating model with new vocabulary
INFO - 2023-11-30 15:39:57,174: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:39:57.174763', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:57,190: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:39:57,190: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:39:57,191: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115675.93442067655 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:39:57.190980', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:39:57,221: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:39:57,221: updating layer weights
INFO - 2023-11-30 15:39:57,222: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:39:57.222054', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:39:57,222: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:39:57,222: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:39:57.222346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:39:57,449: EPOCH 0: training on 191080 raw words (115701 effective words) took 0.2s, 514432 effective words/s
INFO - 2023-11-30 15:39:57,708: EPOCH 1: training on 191080 raw words (115790 effective words) took 0.3s, 452483 effective words/s
INFO - 2023-11-30 15:39:57,968: EPOCH 2: training on 191080 raw words (115852 effective words) took 0.3s, 450646 effective words/s
INFO - 2023-11-30 15:39:58,223: EPOCH 3: training on 191080 raw words (115584 effective words) took 0.3s, 457053 effective words/s
INFO - 2023-11-30 15:39:58,456: EPOCH 4: training on 191080 raw words (115922 effective words) took 0.2s, 503884 effective words/s
INFO - 2023-11-30 15:39:58,747: EPOCH 5: training on 191080 raw words (115825 effective words) took 0.3s, 401711 effective words/s
INFO - 2023-11-30 15:39:59,085: EPOCH 6: training on 191080 raw words (115676 effective words) took 0.3s, 349051 effective words/s
INFO - 2023-11-30 15:39:59,390: EPOCH 7: training on 191080 raw words (115870 effective words) took 0.3s, 381978 effective words/s
INFO - 2023-11-30 15:39:59,683: EPOCH 8: training on 191080 raw words (115740 effective words) took 0.3s, 399486 effective words/s
INFO - 2023-11-30 15:39:59,983: EPOCH 9: training on 191080 raw words (115493 effective words) took 0.3s, 388472 effective words/s
INFO - 2023-11-30 15:40:00,275: EPOCH 10: training on 191080 raw words (115542 effective words) took 0.3s, 400217 effective words/s
INFO - 2023-11-30 15:40:00,520: EPOCH 11: training on 191080 raw words (115680 effective words) took 0.2s, 477825 effective words/s
INFO - 2023-11-30 15:40:00,778: EPOCH 12: training on 191080 raw words (115635 effective words) took 0.3s, 451629 effective words/s
INFO - 2023-11-30 15:40:01,046: EPOCH 13: training on 191080 raw words (115681 effective words) took 0.3s, 436523 effective words/s
INFO - 2023-11-30 15:40:01,292: EPOCH 14: training on 191080 raw words (115460 effective words) took 0.2s, 474697 effective words/s
INFO - 2023-11-30 15:40:01,530: EPOCH 15: training on 191080 raw words (115631 effective words) took 0.2s, 517709 effective words/s
INFO - 2023-11-30 15:40:01,813: EPOCH 16: training on 191080 raw words (115808 effective words) took 0.3s, 413599 effective words/s
INFO - 2023-11-30 15:40:02,056: EPOCH 17: training on 191080 raw words (115773 effective words) took 0.2s, 482089 effective words/s
INFO - 2023-11-30 15:40:02,314: EPOCH 18: training on 191080 raw words (115659 effective words) took 0.3s, 451908 effective words/s
INFO - 2023-11-30 15:40:02,629: EPOCH 19: training on 191080 raw words (115649 effective words) took 0.3s, 370770 effective words/s
INFO - 2023-11-30 15:40:02,630: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313971 effective words) took 5.4s, 427909 effective words/s', 'datetime': '2023-11-30T15:40:02.630135', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:02,630: collecting all words and their counts
INFO - 2023-11-30 15:40:02,630: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:02,674: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:02,675: Updating model with new vocabulary
INFO - 2023-11-30 15:40:02,699: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:02.699754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:02,725: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:02,725: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:02,725: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115442.74293979837 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:40:02.725853', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:02,761: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:02,761: updating layer weights
INFO - 2023-11-30 15:40:02,761: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:02.761735', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:02,761: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:02,762: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:02.762027', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:03,087: EPOCH 0: training on 191080 raw words (115145 effective words) took 0.3s, 357158 effective words/s
INFO - 2023-11-30 15:40:03,475: EPOCH 1: training on 191080 raw words (115420 effective words) took 0.4s, 299804 effective words/s
INFO - 2023-11-30 15:40:03,816: EPOCH 2: training on 191080 raw words (115146 effective words) took 0.3s, 341031 effective words/s
INFO - 2023-11-30 15:40:04,133: EPOCH 3: training on 191080 raw words (115570 effective words) took 0.3s, 367767 effective words/s
INFO - 2023-11-30 15:40:04,447: EPOCH 4: training on 191080 raw words (115339 effective words) took 0.3s, 370324 effective words/s
INFO - 2023-11-30 15:40:04,731: EPOCH 5: training on 191080 raw words (115413 effective words) took 0.3s, 410208 effective words/s
INFO - 2023-11-30 15:40:05,129: EPOCH 6: training on 191080 raw words (115549 effective words) took 0.4s, 292409 effective words/s
INFO - 2023-11-30 15:40:05,456: EPOCH 7: training on 191080 raw words (115664 effective words) took 0.3s, 356999 effective words/s
INFO - 2023-11-30 15:40:05,828: EPOCH 8: training on 191080 raw words (115539 effective words) took 0.4s, 313130 effective words/s
INFO - 2023-11-30 15:40:06,174: EPOCH 9: training on 191080 raw words (115541 effective words) took 0.3s, 337310 effective words/s
INFO - 2023-11-30 15:40:06,568: EPOCH 10: training on 191080 raw words (115513 effective words) took 0.4s, 295597 effective words/s
INFO - 2023-11-30 15:40:06,910: EPOCH 11: training on 191080 raw words (115531 effective words) took 0.3s, 341188 effective words/s
INFO - 2023-11-30 15:40:07,277: EPOCH 12: training on 191080 raw words (115560 effective words) took 0.4s, 318451 effective words/s
INFO - 2023-11-30 15:40:07,630: EPOCH 13: training on 191080 raw words (115456 effective words) took 0.3s, 329908 effective words/s
INFO - 2023-11-30 15:40:07,993: EPOCH 14: training on 191080 raw words (115664 effective words) took 0.4s, 321218 effective words/s
INFO - 2023-11-30 15:40:08,361: EPOCH 15: training on 191080 raw words (115363 effective words) took 0.4s, 317210 effective words/s
INFO - 2023-11-30 15:40:08,759: EPOCH 16: training on 191080 raw words (115506 effective words) took 0.4s, 293060 effective words/s
INFO - 2023-11-30 15:40:09,145: EPOCH 17: training on 191080 raw words (115618 effective words) took 0.4s, 302427 effective words/s
INFO - 2023-11-30 15:40:09,540: EPOCH 18: training on 191080 raw words (115478 effective words) took 0.4s, 294887 effective words/s
INFO - 2023-11-30 15:40:09,919: EPOCH 19: training on 191080 raw words (115683 effective words) took 0.4s, 308515 effective words/s
INFO - 2023-11-30 15:40:09,919: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309698 effective words) took 7.2s, 322686 effective words/s', 'datetime': '2023-11-30T15:40:09.919922', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:09,920: collecting all words and their counts
INFO - 2023-11-30 15:40:09,920: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:09,964: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:09,964: Updating model with new vocabulary
INFO - 2023-11-30 15:40:09,991: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:09.991390', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:10,016: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:10,016: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:10,017: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115635.23294986544 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:40:10.017139', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:10,059: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:10,059: updating layer weights
INFO - 2023-11-30 15:40:10,060: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:10.060821', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:10,061: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:10,061: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:10.061369', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:10,466: EPOCH 0: training on 191080 raw words (115628 effective words) took 0.4s, 289214 effective words/s
INFO - 2023-11-30 15:40:10,887: EPOCH 1: training on 191080 raw words (115485 effective words) took 0.4s, 276802 effective words/s
INFO - 2023-11-30 15:40:11,254: EPOCH 2: training on 191080 raw words (115592 effective words) took 0.4s, 318365 effective words/s
INFO - 2023-11-30 15:40:11,526: EPOCH 3: training on 191080 raw words (115640 effective words) took 0.3s, 430334 effective words/s
INFO - 2023-11-30 15:40:11,819: EPOCH 4: training on 191080 raw words (115668 effective words) took 0.3s, 397609 effective words/s
INFO - 2023-11-30 15:40:12,098: EPOCH 5: training on 191080 raw words (115640 effective words) took 0.3s, 420168 effective words/s
INFO - 2023-11-30 15:40:12,370: EPOCH 6: training on 191080 raw words (115646 effective words) took 0.3s, 429338 effective words/s
INFO - 2023-11-30 15:40:12,639: EPOCH 7: training on 191080 raw words (115667 effective words) took 0.3s, 432800 effective words/s
INFO - 2023-11-30 15:40:12,901: EPOCH 8: training on 191080 raw words (115622 effective words) took 0.3s, 447729 effective words/s
INFO - 2023-11-30 15:40:13,169: EPOCH 9: training on 191080 raw words (115552 effective words) took 0.3s, 441261 effective words/s
INFO - 2023-11-30 15:40:13,516: EPOCH 10: training on 191080 raw words (115841 effective words) took 0.3s, 337323 effective words/s
INFO - 2023-11-30 15:40:13,792: EPOCH 11: training on 191080 raw words (115858 effective words) took 0.3s, 422846 effective words/s
INFO - 2023-11-30 15:40:14,060: EPOCH 12: training on 191080 raw words (115782 effective words) took 0.3s, 436723 effective words/s
INFO - 2023-11-30 15:40:14,328: EPOCH 13: training on 191080 raw words (115482 effective words) took 0.3s, 435177 effective words/s
INFO - 2023-11-30 15:40:14,595: EPOCH 14: training on 191080 raw words (115592 effective words) took 0.3s, 440003 effective words/s
INFO - 2023-11-30 15:40:14,857: EPOCH 15: training on 191080 raw words (115470 effective words) took 0.3s, 445059 effective words/s
INFO - 2023-11-30 15:40:15,109: EPOCH 16: training on 191080 raw words (115732 effective words) took 0.2s, 465079 effective words/s
INFO - 2023-11-30 15:40:15,354: EPOCH 17: training on 191080 raw words (115736 effective words) took 0.2s, 477510 effective words/s
INFO - 2023-11-30 15:40:15,613: EPOCH 18: training on 191080 raw words (115476 effective words) took 0.3s, 451831 effective words/s
INFO - 2023-11-30 15:40:15,871: EPOCH 19: training on 191080 raw words (115742 effective words) took 0.3s, 452932 effective words/s
INFO - 2023-11-30 15:40:15,872: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312851 effective words) took 5.8s, 398030 effective words/s', 'datetime': '2023-11-30T15:40:15.872315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:15,872: collecting all words and their counts
INFO - 2023-11-30 15:40:15,872: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:15,901: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:15,901: Updating model with new vocabulary
INFO - 2023-11-30 15:40:15,915: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:15.915092', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:15,938: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:15,938: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:15,938: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115607.47662323379 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:40:15.938846', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:15,963: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:15,963: updating layer weights
INFO - 2023-11-30 15:40:15,964: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:15.964226', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:15,964: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:15,964: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:15.964472', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:16,215: EPOCH 0: training on 191080 raw words (115789 effective words) took 0.2s, 465061 effective words/s
INFO - 2023-11-30 15:40:16,481: EPOCH 1: training on 191080 raw words (115662 effective words) took 0.3s, 440863 effective words/s
INFO - 2023-11-30 15:40:16,738: EPOCH 2: training on 191080 raw words (115550 effective words) took 0.3s, 452470 effective words/s
INFO - 2023-11-30 15:40:16,991: EPOCH 3: training on 191080 raw words (115394 effective words) took 0.2s, 461837 effective words/s
INFO - 2023-11-30 15:40:17,248: EPOCH 4: training on 191080 raw words (115578 effective words) took 0.3s, 455341 effective words/s
INFO - 2023-11-30 15:40:17,507: EPOCH 5: training on 191080 raw words (115835 effective words) took 0.3s, 450470 effective words/s
INFO - 2023-11-30 15:40:17,764: EPOCH 6: training on 191080 raw words (115643 effective words) took 0.3s, 455264 effective words/s
INFO - 2023-11-30 15:40:18,020: EPOCH 7: training on 191080 raw words (115515 effective words) took 0.3s, 456551 effective words/s
INFO - 2023-11-30 15:40:18,272: EPOCH 8: training on 191080 raw words (115749 effective words) took 0.2s, 470393 effective words/s
INFO - 2023-11-30 15:40:18,533: EPOCH 9: training on 191080 raw words (115503 effective words) took 0.3s, 446734 effective words/s
INFO - 2023-11-30 15:40:18,787: EPOCH 10: training on 191080 raw words (115575 effective words) took 0.3s, 459534 effective words/s
INFO - 2023-11-30 15:40:19,042: EPOCH 11: training on 191080 raw words (115786 effective words) took 0.3s, 459039 effective words/s
INFO - 2023-11-30 15:40:19,304: EPOCH 12: training on 191080 raw words (115498 effective words) took 0.3s, 444111 effective words/s
INFO - 2023-11-30 15:40:19,590: EPOCH 13: training on 191080 raw words (115700 effective words) took 0.3s, 408513 effective words/s
INFO - 2023-11-30 15:40:19,860: EPOCH 14: training on 191080 raw words (115710 effective words) took 0.3s, 434175 effective words/s
INFO - 2023-11-30 15:40:20,135: EPOCH 15: training on 191080 raw words (115689 effective words) took 0.3s, 424891 effective words/s
INFO - 2023-11-30 15:40:20,419: EPOCH 16: training on 191080 raw words (115660 effective words) took 0.3s, 412490 effective words/s
INFO - 2023-11-30 15:40:20,727: EPOCH 17: training on 191080 raw words (115843 effective words) took 0.3s, 379916 effective words/s
INFO - 2023-11-30 15:40:20,998: EPOCH 18: training on 191080 raw words (115513 effective words) took 0.3s, 429947 effective words/s
INFO - 2023-11-30 15:40:21,273: EPOCH 19: training on 191080 raw words (115494 effective words) took 0.3s, 424370 effective words/s
INFO - 2023-11-30 15:40:21,273: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312686 effective words) took 5.3s, 435630 effective words/s', 'datetime': '2023-11-30T15:40:21.273417', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:21,273: collecting all words and their counts
INFO - 2023-11-30 15:40:21,273: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:21,308: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:21,308: Updating model with new vocabulary
INFO - 2023-11-30 15:40:21,324: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:21.324236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:21,345: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:21,345: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:21,345: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115677.7717942535 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:40:21.345684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:21,374: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:21,374: updating layer weights
INFO - 2023-11-30 15:40:21,375: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:21.375471', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:21,375: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:21,375: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:21.375801', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:21,647: EPOCH 0: training on 191080 raw words (115679 effective words) took 0.3s, 429539 effective words/s
INFO - 2023-11-30 15:40:21,912: EPOCH 1: training on 191080 raw words (115828 effective words) took 0.3s, 443420 effective words/s
INFO - 2023-11-30 15:40:22,192: EPOCH 2: training on 191080 raw words (115581 effective words) took 0.3s, 417214 effective words/s
INFO - 2023-11-30 15:40:22,462: EPOCH 3: training on 191080 raw words (115665 effective words) took 0.3s, 432772 effective words/s
INFO - 2023-11-30 15:40:22,735: EPOCH 4: training on 191080 raw words (115586 effective words) took 0.3s, 428637 effective words/s
INFO - 2023-11-30 15:40:23,017: EPOCH 5: training on 191080 raw words (115658 effective words) took 0.3s, 413243 effective words/s
INFO - 2023-11-30 15:40:23,281: EPOCH 6: training on 191080 raw words (115508 effective words) took 0.3s, 441964 effective words/s
INFO - 2023-11-30 15:40:23,552: EPOCH 7: training on 191080 raw words (115711 effective words) took 0.3s, 430568 effective words/s
INFO - 2023-11-30 15:40:23,839: EPOCH 8: training on 191080 raw words (115471 effective words) took 0.3s, 406079 effective words/s
INFO - 2023-11-30 15:40:24,107: EPOCH 9: training on 191080 raw words (115716 effective words) took 0.3s, 436514 effective words/s
INFO - 2023-11-30 15:40:24,364: EPOCH 10: training on 191080 raw words (115705 effective words) took 0.3s, 455448 effective words/s
INFO - 2023-11-30 15:40:24,604: EPOCH 11: training on 191080 raw words (115769 effective words) took 0.2s, 487983 effective words/s
INFO - 2023-11-30 15:40:24,854: EPOCH 12: training on 191080 raw words (115679 effective words) took 0.2s, 466486 effective words/s
INFO - 2023-11-30 15:40:25,096: EPOCH 13: training on 191080 raw words (115825 effective words) took 0.2s, 484646 effective words/s
INFO - 2023-11-30 15:40:25,342: EPOCH 14: training on 191080 raw words (115656 effective words) took 0.2s, 475743 effective words/s
INFO - 2023-11-30 15:40:25,603: EPOCH 15: training on 191080 raw words (115628 effective words) took 0.3s, 447435 effective words/s
INFO - 2023-11-30 15:40:25,868: EPOCH 16: training on 191080 raw words (115686 effective words) took 0.3s, 440996 effective words/s
INFO - 2023-11-30 15:40:26,142: EPOCH 17: training on 191080 raw words (115967 effective words) took 0.3s, 427368 effective words/s
INFO - 2023-11-30 15:40:26,420: EPOCH 18: training on 191080 raw words (115511 effective words) took 0.3s, 421213 effective words/s
INFO - 2023-11-30 15:40:26,785: EPOCH 19: training on 191080 raw words (115676 effective words) took 0.4s, 320060 effective words/s
INFO - 2023-11-30 15:40:26,785: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313505 effective words) took 5.4s, 427661 effective words/s', 'datetime': '2023-11-30T15:40:26.785616', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:26,785: collecting all words and their counts
INFO - 2023-11-30 15:40:26,786: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:26,828: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:26,828: Updating model with new vocabulary
INFO - 2023-11-30 15:40:26,848: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:26.848887', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:26,872: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:26,872: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:26,873: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115499.58609353742 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:40:26.873213', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:26,911: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:26,911: updating layer weights
INFO - 2023-11-30 15:40:26,912: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:26.912296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:26,912: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:26,912: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:26.912642', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:27,269: EPOCH 0: training on 191080 raw words (115521 effective words) took 0.4s, 326677 effective words/s
INFO - 2023-11-30 15:40:27,624: EPOCH 1: training on 191080 raw words (115371 effective words) took 0.4s, 327758 effective words/s
INFO - 2023-11-30 15:40:27,978: EPOCH 2: training on 191080 raw words (115327 effective words) took 0.4s, 329466 effective words/s
INFO - 2023-11-30 15:40:28,318: EPOCH 3: training on 191080 raw words (115515 effective words) took 0.3s, 342476 effective words/s
INFO - 2023-11-30 15:40:28,641: EPOCH 4: training on 191080 raw words (115624 effective words) took 0.3s, 360779 effective words/s
INFO - 2023-11-30 15:40:28,964: EPOCH 5: training on 191080 raw words (115634 effective words) took 0.3s, 362709 effective words/s
INFO - 2023-11-30 15:40:29,288: EPOCH 6: training on 191080 raw words (115670 effective words) took 0.3s, 359973 effective words/s
INFO - 2023-11-30 15:40:29,617: EPOCH 7: training on 191080 raw words (115543 effective words) took 0.3s, 354434 effective words/s
INFO - 2023-11-30 15:40:29,948: EPOCH 8: training on 191080 raw words (115510 effective words) took 0.3s, 352609 effective words/s
INFO - 2023-11-30 15:40:30,276: EPOCH 9: training on 191080 raw words (115623 effective words) took 0.3s, 356220 effective words/s
INFO - 2023-11-30 15:40:30,610: EPOCH 10: training on 191080 raw words (115740 effective words) took 0.3s, 349420 effective words/s
INFO - 2023-11-30 15:40:30,953: EPOCH 11: training on 191080 raw words (115224 effective words) took 0.3s, 338913 effective words/s
INFO - 2023-11-30 15:40:31,288: EPOCH 12: training on 191080 raw words (115331 effective words) took 0.3s, 348413 effective words/s
INFO - 2023-11-30 15:40:31,624: EPOCH 13: training on 191080 raw words (115641 effective words) took 0.3s, 347713 effective words/s
INFO - 2023-11-30 15:40:31,952: EPOCH 14: training on 191080 raw words (115370 effective words) took 0.3s, 355170 effective words/s
INFO - 2023-11-30 15:40:32,285: EPOCH 15: training on 191080 raw words (115511 effective words) took 0.3s, 351007 effective words/s
INFO - 2023-11-30 15:40:32,626: EPOCH 16: training on 191080 raw words (115563 effective words) took 0.3s, 341510 effective words/s
INFO - 2023-11-30 15:40:33,014: EPOCH 17: training on 191080 raw words (115405 effective words) took 0.4s, 300026 effective words/s
INFO - 2023-11-30 15:40:33,355: EPOCH 18: training on 191080 raw words (115582 effective words) took 0.3s, 341681 effective words/s
INFO - 2023-11-30 15:40:33,728: EPOCH 19: training on 191080 raw words (115611 effective words) took 0.4s, 312829 effective words/s
INFO - 2023-11-30 15:40:33,728: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310316 effective words) took 6.8s, 338952 effective words/s', 'datetime': '2023-11-30T15:40:33.728869', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:33,729: collecting all words and their counts
INFO - 2023-11-30 15:40:33,729: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:33,769: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:33,769: Updating model with new vocabulary
INFO - 2023-11-30 15:40:33,788: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:33.788911', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:33,813: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:33,814: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:40:33,814: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115383.7469475943 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:40:33.814392', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:33,851: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:33,851: updating layer weights
INFO - 2023-11-30 15:40:33,852: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:33.852865', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:33,853: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:33,853: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:33.853313', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:34,182: EPOCH 0: training on 191080 raw words (115485 effective words) took 0.3s, 357980 effective words/s
INFO - 2023-11-30 15:40:34,515: EPOCH 1: training on 191080 raw words (115360 effective words) took 0.3s, 349695 effective words/s
INFO - 2023-11-30 15:40:34,842: EPOCH 2: training on 191080 raw words (115509 effective words) took 0.3s, 357002 effective words/s
INFO - 2023-11-30 15:40:35,183: EPOCH 3: training on 191080 raw words (115381 effective words) took 0.3s, 342065 effective words/s
INFO - 2023-11-30 15:40:35,497: EPOCH 4: training on 191080 raw words (115513 effective words) took 0.3s, 372397 effective words/s
INFO - 2023-11-30 15:40:35,742: EPOCH 5: training on 191080 raw words (115486 effective words) took 0.2s, 475311 effective words/s
INFO - 2023-11-30 15:40:35,989: EPOCH 6: training on 191080 raw words (115411 effective words) took 0.2s, 472476 effective words/s
INFO - 2023-11-30 15:40:36,234: EPOCH 7: training on 191080 raw words (115510 effective words) took 0.2s, 475162 effective words/s
INFO - 2023-11-30 15:40:36,512: EPOCH 8: training on 191080 raw words (115461 effective words) took 0.3s, 419521 effective words/s
INFO - 2023-11-30 15:40:36,773: EPOCH 9: training on 191080 raw words (115512 effective words) took 0.3s, 447842 effective words/s
INFO - 2023-11-30 15:40:37,019: EPOCH 10: training on 191080 raw words (115417 effective words) took 0.2s, 474386 effective words/s
INFO - 2023-11-30 15:40:37,267: EPOCH 11: training on 191080 raw words (115266 effective words) took 0.2s, 470023 effective words/s
INFO - 2023-11-30 15:40:37,513: EPOCH 12: training on 191080 raw words (115470 effective words) took 0.2s, 474357 effective words/s
INFO - 2023-11-30 15:40:37,754: EPOCH 13: training on 191080 raw words (115245 effective words) took 0.2s, 483777 effective words/s
INFO - 2023-11-30 15:40:37,999: EPOCH 14: training on 191080 raw words (115535 effective words) took 0.2s, 474999 effective words/s
INFO - 2023-11-30 15:40:38,239: EPOCH 15: training on 191080 raw words (115179 effective words) took 0.2s, 485679 effective words/s
INFO - 2023-11-30 15:40:38,485: EPOCH 16: training on 191080 raw words (115492 effective words) took 0.2s, 473993 effective words/s
INFO - 2023-11-30 15:40:38,726: EPOCH 17: training on 191080 raw words (115345 effective words) took 0.2s, 483027 effective words/s
INFO - 2023-11-30 15:40:38,977: EPOCH 18: training on 191080 raw words (115524 effective words) took 0.2s, 467505 effective words/s
INFO - 2023-11-30 15:40:39,225: EPOCH 19: training on 191080 raw words (115509 effective words) took 0.2s, 469333 effective words/s
INFO - 2023-11-30 15:40:39,226: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308610 effective words) took 5.4s, 429691 effective words/s', 'datetime': '2023-11-30T15:40:39.226205', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:39,226: collecting all words and their counts
INFO - 2023-11-30 15:40:39,226: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:39,255: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:39,255: Updating model with new vocabulary
INFO - 2023-11-30 15:40:39,272: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:39.272533', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:39,290: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:39,290: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:39,290: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115414.41419835902 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:40:39.290494', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:39,320: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:39,320: updating layer weights
INFO - 2023-11-30 15:40:39,321: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:39.321700', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:39,322: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:39,322: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:39.322348', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:39,597: EPOCH 0: training on 191080 raw words (115506 effective words) took 0.3s, 424506 effective words/s
INFO - 2023-11-30 15:40:39,859: EPOCH 1: training on 191080 raw words (115274 effective words) took 0.3s, 443590 effective words/s
INFO - 2023-11-30 15:40:40,128: EPOCH 2: training on 191080 raw words (115286 effective words) took 0.3s, 433441 effective words/s
INFO - 2023-11-30 15:40:40,399: EPOCH 3: training on 191080 raw words (115755 effective words) took 0.3s, 430156 effective words/s
INFO - 2023-11-30 15:40:40,679: EPOCH 4: training on 191080 raw words (115437 effective words) took 0.3s, 417552 effective words/s
INFO - 2023-11-30 15:40:40,965: EPOCH 5: training on 191080 raw words (115414 effective words) took 0.3s, 407404 effective words/s
INFO - 2023-11-30 15:40:41,230: EPOCH 6: training on 191080 raw words (115568 effective words) took 0.3s, 439683 effective words/s
INFO - 2023-11-30 15:40:41,496: EPOCH 7: training on 191080 raw words (115269 effective words) took 0.3s, 437097 effective words/s
INFO - 2023-11-30 15:40:41,823: EPOCH 8: training on 191080 raw words (115414 effective words) took 0.3s, 356300 effective words/s
INFO - 2023-11-30 15:40:42,090: EPOCH 9: training on 191080 raw words (115334 effective words) took 0.3s, 436612 effective words/s
INFO - 2023-11-30 15:40:42,415: EPOCH 10: training on 191080 raw words (115444 effective words) took 0.3s, 357283 effective words/s
INFO - 2023-11-30 15:40:42,720: EPOCH 11: training on 191080 raw words (115483 effective words) took 0.3s, 380932 effective words/s
INFO - 2023-11-30 15:40:43,016: EPOCH 12: training on 191080 raw words (115335 effective words) took 0.3s, 393908 effective words/s
INFO - 2023-11-30 15:40:43,277: EPOCH 13: training on 191080 raw words (115305 effective words) took 0.3s, 446922 effective words/s
INFO - 2023-11-30 15:40:43,600: EPOCH 14: training on 191080 raw words (115313 effective words) took 0.3s, 359641 effective words/s
INFO - 2023-11-30 15:40:43,916: EPOCH 15: training on 191080 raw words (115294 effective words) took 0.3s, 368053 effective words/s
INFO - 2023-11-30 15:40:44,177: EPOCH 16: training on 191080 raw words (115509 effective words) took 0.3s, 446013 effective words/s
INFO - 2023-11-30 15:40:44,445: EPOCH 17: training on 191080 raw words (115243 effective words) took 0.3s, 434917 effective words/s
INFO - 2023-11-30 15:40:44,717: EPOCH 18: training on 191080 raw words (115564 effective words) took 0.3s, 429557 effective words/s
INFO - 2023-11-30 15:40:45,009: EPOCH 19: training on 191080 raw words (115487 effective words) took 0.3s, 398210 effective words/s
INFO - 2023-11-30 15:40:45,009: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308234 effective words) took 5.7s, 405890 effective words/s', 'datetime': '2023-11-30T15:40:45.009390', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:45,009: collecting all words and their counts
INFO - 2023-11-30 15:40:45,009: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:45,038: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:45,038: Updating model with new vocabulary
INFO - 2023-11-30 15:40:45,053: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:45.053415', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:45,072: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:45,072: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:45,072: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115583.89457044873 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:40:45.072837', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:45,100: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:45,100: updating layer weights
INFO - 2023-11-30 15:40:45,100: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:45.100657', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:45,100: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:45,100: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:45.100846', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:45,357: EPOCH 0: training on 191080 raw words (115629 effective words) took 0.3s, 454182 effective words/s
INFO - 2023-11-30 15:40:45,619: EPOCH 1: training on 191080 raw words (115535 effective words) took 0.3s, 445146 effective words/s
INFO - 2023-11-30 15:40:45,875: EPOCH 2: training on 191080 raw words (115704 effective words) took 0.3s, 457151 effective words/s
INFO - 2023-11-30 15:40:46,133: EPOCH 3: training on 191080 raw words (115590 effective words) took 0.3s, 452633 effective words/s
INFO - 2023-11-30 15:40:46,399: EPOCH 4: training on 191080 raw words (115314 effective words) took 0.3s, 436377 effective words/s
INFO - 2023-11-30 15:40:46,709: EPOCH 5: training on 191080 raw words (115562 effective words) took 0.3s, 376784 effective words/s
INFO - 2023-11-30 15:40:46,984: EPOCH 6: training on 191080 raw words (115625 effective words) took 0.3s, 424628 effective words/s
INFO - 2023-11-30 15:40:47,237: EPOCH 7: training on 191080 raw words (115473 effective words) took 0.3s, 461578 effective words/s
INFO - 2023-11-30 15:40:47,488: EPOCH 8: training on 191080 raw words (115550 effective words) took 0.2s, 463760 effective words/s
INFO - 2023-11-30 15:40:47,757: EPOCH 9: training on 191080 raw words (115578 effective words) took 0.3s, 434238 effective words/s
INFO - 2023-11-30 15:40:48,045: EPOCH 10: training on 191080 raw words (115645 effective words) took 0.3s, 406423 effective words/s
INFO - 2023-11-30 15:40:48,295: EPOCH 11: training on 191080 raw words (115524 effective words) took 0.2s, 467547 effective words/s
INFO - 2023-11-30 15:40:48,553: EPOCH 12: training on 191080 raw words (115902 effective words) took 0.3s, 455039 effective words/s
INFO - 2023-11-30 15:40:48,817: EPOCH 13: training on 191080 raw words (115507 effective words) took 0.3s, 441116 effective words/s
INFO - 2023-11-30 15:40:49,081: EPOCH 14: training on 191080 raw words (115333 effective words) took 0.3s, 441075 effective words/s
INFO - 2023-11-30 15:40:49,332: EPOCH 15: training on 191080 raw words (115356 effective words) took 0.2s, 463766 effective words/s
INFO - 2023-11-30 15:40:49,591: EPOCH 16: training on 191080 raw words (115478 effective words) took 0.3s, 450351 effective words/s
INFO - 2023-11-30 15:40:49,891: EPOCH 17: training on 191080 raw words (115515 effective words) took 0.3s, 388746 effective words/s
INFO - 2023-11-30 15:40:50,148: EPOCH 18: training on 191080 raw words (115539 effective words) took 0.3s, 453911 effective words/s
INFO - 2023-11-30 15:40:50,406: EPOCH 19: training on 191080 raw words (115629 effective words) took 0.3s, 453715 effective words/s
INFO - 2023-11-30 15:40:50,406: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310988 effective words) took 5.3s, 435558 effective words/s', 'datetime': '2023-11-30T15:40:50.406752', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:50,406: collecting all words and their counts
INFO - 2023-11-30 15:40:50,407: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:50,437: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:50,437: Updating model with new vocabulary
INFO - 2023-11-30 15:40:50,452: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:50.452154', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:50,468: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:50,468: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:40:50,469: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115484.27219466296 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:40:50.469135', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:50,494: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:50,494: updating layer weights
INFO - 2023-11-30 15:40:50,494: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:50.494824', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:50,495: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:50,495: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:50.495396', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:50,834: EPOCH 0: training on 191080 raw words (115367 effective words) took 0.3s, 342832 effective words/s
INFO - 2023-11-30 15:40:51,216: EPOCH 1: training on 191080 raw words (115479 effective words) took 0.4s, 305590 effective words/s
INFO - 2023-11-30 15:40:51,570: EPOCH 2: training on 191080 raw words (115446 effective words) took 0.4s, 329559 effective words/s
INFO - 2023-11-30 15:40:51,976: EPOCH 3: training on 191080 raw words (115359 effective words) took 0.4s, 286600 effective words/s
INFO - 2023-11-30 15:40:52,350: EPOCH 4: training on 191080 raw words (115461 effective words) took 0.4s, 311363 effective words/s
INFO - 2023-11-30 15:40:52,705: EPOCH 5: training on 191080 raw words (115305 effective words) took 0.4s, 327752 effective words/s
INFO - 2023-11-30 15:40:53,058: EPOCH 6: training on 191080 raw words (115602 effective words) took 0.3s, 330723 effective words/s
INFO - 2023-11-30 15:40:53,431: EPOCH 7: training on 191080 raw words (115316 effective words) took 0.4s, 311848 effective words/s
INFO - 2023-11-30 15:40:53,883: EPOCH 8: training on 191080 raw words (115529 effective words) took 0.4s, 259353 effective words/s
INFO - 2023-11-30 15:40:54,280: EPOCH 9: training on 191080 raw words (115627 effective words) took 0.4s, 313831 effective words/s
INFO - 2023-11-30 15:40:54,733: EPOCH 10: training on 191080 raw words (115453 effective words) took 0.4s, 256626 effective words/s
INFO - 2023-11-30 15:40:55,124: EPOCH 11: training on 191080 raw words (115333 effective words) took 0.4s, 298092 effective words/s
INFO - 2023-11-30 15:40:55,502: EPOCH 12: training on 191080 raw words (115468 effective words) took 0.4s, 308655 effective words/s
INFO - 2023-11-30 15:40:55,921: EPOCH 13: training on 191080 raw words (115318 effective words) took 0.4s, 277640 effective words/s
INFO - 2023-11-30 15:40:56,324: EPOCH 14: training on 191080 raw words (115600 effective words) took 0.4s, 288843 effective words/s
INFO - 2023-11-30 15:40:56,708: EPOCH 15: training on 191080 raw words (115502 effective words) took 0.4s, 304561 effective words/s
INFO - 2023-11-30 15:40:57,211: EPOCH 16: training on 191080 raw words (115354 effective words) took 0.5s, 231336 effective words/s
INFO - 2023-11-30 15:40:57,615: EPOCH 17: training on 191080 raw words (115442 effective words) took 0.4s, 288222 effective words/s
INFO - 2023-11-30 15:40:58,037: EPOCH 18: training on 191080 raw words (115520 effective words) took 0.4s, 276135 effective words/s
INFO - 2023-11-30 15:40:58,493: EPOCH 19: training on 191080 raw words (115424 effective words) took 0.5s, 255504 effective words/s
INFO - 2023-11-30 15:40:58,494: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308905 effective words) took 8.0s, 288661 effective words/s', 'datetime': '2023-11-30T15:40:58.494291', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:58,494: collecting all words and their counts
INFO - 2023-11-30 15:40:58,494: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:40:58,543: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:40:58,543: Updating model with new vocabulary
INFO - 2023-11-30 15:40:58,565: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:40:58.565655', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:58,591: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:40:58,592: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:40:58,592: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115847.34378489514 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:40:58.592390', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:40:58,636: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:40:58,636: updating layer weights
INFO - 2023-11-30 15:40:58,636: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:40:58.636646', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:40:58,636: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:40:58,637: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:40:58.637012', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:40:59,026: EPOCH 0: training on 191080 raw words (115984 effective words) took 0.4s, 300976 effective words/s
INFO - 2023-11-30 15:40:59,485: EPOCH 1: training on 191080 raw words (115689 effective words) took 0.5s, 254439 effective words/s
INFO - 2023-11-30 15:40:59,777: EPOCH 2: training on 191080 raw words (115837 effective words) took 0.3s, 401596 effective words/s
INFO - 2023-11-30 15:41:00,030: EPOCH 3: training on 191080 raw words (115567 effective words) took 0.3s, 460564 effective words/s
INFO - 2023-11-30 15:41:00,288: EPOCH 4: training on 191080 raw words (115826 effective words) took 0.3s, 454879 effective words/s
INFO - 2023-11-30 15:41:00,552: EPOCH 5: training on 191080 raw words (115900 effective words) took 0.3s, 443145 effective words/s
INFO - 2023-11-30 15:41:00,802: EPOCH 6: training on 191080 raw words (115997 effective words) took 0.2s, 469718 effective words/s
INFO - 2023-11-30 15:41:01,055: EPOCH 7: training on 191080 raw words (115956 effective words) took 0.3s, 463799 effective words/s
INFO - 2023-11-30 15:41:01,312: EPOCH 8: training on 191080 raw words (115844 effective words) took 0.3s, 455627 effective words/s
INFO - 2023-11-30 15:41:01,572: EPOCH 9: training on 191080 raw words (115834 effective words) took 0.3s, 448104 effective words/s
INFO - 2023-11-30 15:41:01,837: EPOCH 10: training on 191080 raw words (115761 effective words) took 0.3s, 441799 effective words/s
INFO - 2023-11-30 15:41:02,099: EPOCH 11: training on 191080 raw words (115763 effective words) took 0.3s, 447298 effective words/s
INFO - 2023-11-30 15:41:02,360: EPOCH 12: training on 191080 raw words (115712 effective words) took 0.3s, 449000 effective words/s
INFO - 2023-11-30 15:41:02,630: EPOCH 13: training on 191080 raw words (116036 effective words) took 0.3s, 435791 effective words/s
INFO - 2023-11-30 15:41:02,886: EPOCH 14: training on 191080 raw words (115902 effective words) took 0.3s, 457882 effective words/s
INFO - 2023-11-30 15:41:03,138: EPOCH 15: training on 191080 raw words (116057 effective words) took 0.2s, 465794 effective words/s
INFO - 2023-11-30 15:41:03,458: EPOCH 16: training on 191080 raw words (115629 effective words) took 0.3s, 363507 effective words/s
INFO - 2023-11-30 15:41:03,808: EPOCH 17: training on 191080 raw words (115882 effective words) took 0.3s, 334475 effective words/s
INFO - 2023-11-30 15:41:04,065: EPOCH 18: training on 191080 raw words (115763 effective words) took 0.3s, 455292 effective words/s
INFO - 2023-11-30 15:41:04,330: EPOCH 19: training on 191080 raw words (115768 effective words) took 0.3s, 440761 effective words/s
INFO - 2023-11-30 15:41:04,330: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316707 effective words) took 5.7s, 406901 effective words/s', 'datetime': '2023-11-30T15:41:04.330758', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:04,331: collecting all words and their counts
INFO - 2023-11-30 15:41:04,331: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:04,380: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:04,380: Updating model with new vocabulary
INFO - 2023-11-30 15:41:04,394: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:04.394496', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:04,410: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:04,410: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-30 15:41:04,411: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115660.11672857251 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:41:04.411110', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:04,448: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:04,448: updating layer weights
INFO - 2023-11-30 15:41:04,449: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:04.448997', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:04,449: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:04,449: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:04.449344', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:04,727: EPOCH 0: training on 191080 raw words (115711 effective words) took 0.3s, 426806 effective words/s
INFO - 2023-11-30 15:41:05,001: EPOCH 1: training on 191080 raw words (115669 effective words) took 0.3s, 426719 effective words/s
INFO - 2023-11-30 15:41:05,262: EPOCH 2: training on 191080 raw words (115650 effective words) took 0.3s, 446379 effective words/s
INFO - 2023-11-30 15:41:05,536: EPOCH 3: training on 191080 raw words (115478 effective words) took 0.3s, 425415 effective words/s
INFO - 2023-11-30 15:41:05,797: EPOCH 4: training on 191080 raw words (115564 effective words) took 0.3s, 448114 effective words/s
INFO - 2023-11-30 15:41:06,070: EPOCH 5: training on 191080 raw words (115474 effective words) took 0.3s, 426353 effective words/s
INFO - 2023-11-30 15:41:06,347: EPOCH 6: training on 191080 raw words (115778 effective words) took 0.3s, 422198 effective words/s
INFO - 2023-11-30 15:41:06,674: EPOCH 7: training on 191080 raw words (115886 effective words) took 0.3s, 357145 effective words/s
INFO - 2023-11-30 15:41:06,937: EPOCH 8: training on 191080 raw words (115704 effective words) took 0.3s, 445465 effective words/s
INFO - 2023-11-30 15:41:07,208: EPOCH 9: training on 191080 raw words (115914 effective words) took 0.3s, 431006 effective words/s
INFO - 2023-11-30 15:41:07,489: EPOCH 10: training on 191080 raw words (115930 effective words) took 0.3s, 417887 effective words/s
INFO - 2023-11-30 15:41:07,753: EPOCH 11: training on 191080 raw words (115623 effective words) took 0.3s, 441942 effective words/s
INFO - 2023-11-30 15:41:08,021: EPOCH 12: training on 191080 raw words (115999 effective words) took 0.3s, 436440 effective words/s
INFO - 2023-11-30 15:41:08,279: EPOCH 13: training on 191080 raw words (115683 effective words) took 0.3s, 453259 effective words/s
INFO - 2023-11-30 15:41:08,574: EPOCH 14: training on 191080 raw words (115796 effective words) took 0.3s, 395607 effective words/s
INFO - 2023-11-30 15:41:08,862: EPOCH 15: training on 191080 raw words (115425 effective words) took 0.3s, 403676 effective words/s
INFO - 2023-11-30 15:41:09,133: EPOCH 16: training on 191080 raw words (115759 effective words) took 0.3s, 431709 effective words/s
INFO - 2023-11-30 15:41:09,408: EPOCH 17: training on 191080 raw words (115518 effective words) took 0.3s, 428716 effective words/s
INFO - 2023-11-30 15:41:09,697: EPOCH 18: training on 191080 raw words (115709 effective words) took 0.3s, 404280 effective words/s
INFO - 2023-11-30 15:41:09,964: EPOCH 19: training on 191080 raw words (115547 effective words) took 0.3s, 436655 effective words/s
INFO - 2023-11-30 15:41:09,965: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313817 effective words) took 5.5s, 419511 effective words/s', 'datetime': '2023-11-30T15:41:09.964993', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:09,965: collecting all words and their counts
INFO - 2023-11-30 15:41:09,965: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:09,993: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:09,993: Updating model with new vocabulary
INFO - 2023-11-30 15:41:10,007: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:10.007234', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:10,024: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:10,024: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:41:10,024: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115559.96457423917 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:41:10.024688', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:10,050: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:10,050: updating layer weights
INFO - 2023-11-30 15:41:10,051: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:10.051365', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:10,051: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:10,052: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:10.052020', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:10,305: EPOCH 0: training on 191080 raw words (115655 effective words) took 0.3s, 460214 effective words/s
INFO - 2023-11-30 15:41:10,607: EPOCH 1: training on 191080 raw words (115595 effective words) took 0.3s, 385953 effective words/s
INFO - 2023-11-30 15:41:10,863: EPOCH 2: training on 191080 raw words (115385 effective words) took 0.3s, 456291 effective words/s
INFO - 2023-11-30 15:41:11,124: EPOCH 3: training on 191080 raw words (115574 effective words) took 0.3s, 446466 effective words/s
INFO - 2023-11-30 15:41:11,378: EPOCH 4: training on 191080 raw words (115437 effective words) took 0.3s, 459730 effective words/s
INFO - 2023-11-30 15:41:11,648: EPOCH 5: training on 191080 raw words (115581 effective words) took 0.3s, 431473 effective words/s
INFO - 2023-11-30 15:41:11,964: EPOCH 6: training on 191080 raw words (115529 effective words) took 0.3s, 368473 effective words/s
INFO - 2023-11-30 15:41:12,232: EPOCH 7: training on 191080 raw words (115700 effective words) took 0.3s, 436220 effective words/s
INFO - 2023-11-30 15:41:12,490: EPOCH 8: training on 191080 raw words (115647 effective words) took 0.3s, 452764 effective words/s
INFO - 2023-11-30 15:41:12,806: EPOCH 9: training on 191080 raw words (115554 effective words) took 0.3s, 368547 effective words/s
INFO - 2023-11-30 15:41:13,143: EPOCH 10: training on 191080 raw words (115548 effective words) took 0.3s, 346335 effective words/s
INFO - 2023-11-30 15:41:13,438: EPOCH 11: training on 191080 raw words (115846 effective words) took 0.3s, 396183 effective words/s
INFO - 2023-11-30 15:41:13,685: EPOCH 12: training on 191080 raw words (115661 effective words) took 0.2s, 474810 effective words/s
INFO - 2023-11-30 15:41:14,009: EPOCH 13: training on 191080 raw words (115715 effective words) took 0.3s, 360055 effective words/s
INFO - 2023-11-30 15:41:14,294: EPOCH 14: training on 191080 raw words (115565 effective words) took 0.3s, 408679 effective words/s
INFO - 2023-11-30 15:41:14,558: EPOCH 15: training on 191080 raw words (115651 effective words) took 0.3s, 441609 effective words/s
INFO - 2023-11-30 15:41:14,859: EPOCH 16: training on 191080 raw words (115506 effective words) took 0.3s, 387174 effective words/s
INFO - 2023-11-30 15:41:15,227: EPOCH 17: training on 191080 raw words (115651 effective words) took 0.4s, 317971 effective words/s
INFO - 2023-11-30 15:41:15,567: EPOCH 18: training on 191080 raw words (115589 effective words) took 0.3s, 343452 effective words/s
INFO - 2023-11-30 15:41:15,954: EPOCH 19: training on 191080 raw words (115666 effective words) took 0.4s, 301151 effective words/s
INFO - 2023-11-30 15:41:15,954: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312055 effective words) took 5.9s, 391700 effective words/s', 'datetime': '2023-11-30T15:41:15.954815', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:15,955: collecting all words and their counts
INFO - 2023-11-30 15:41:15,955: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:16,006: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:16,007: Updating model with new vocabulary
INFO - 2023-11-30 15:41:16,029: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:16.029124', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:16,062: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:16,063: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:41:16,063: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115888.9780409366 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:41:16.063606', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:16,105: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:16,105: updating layer weights
INFO - 2023-11-30 15:41:16,106: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:16.106454', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:16,106: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:16,106: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:16.106960', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:16,564: EPOCH 0: training on 191080 raw words (116192 effective words) took 0.5s, 257849 effective words/s
INFO - 2023-11-30 15:41:17,022: EPOCH 1: training on 191080 raw words (115797 effective words) took 0.5s, 255200 effective words/s
INFO - 2023-11-30 15:41:17,450: EPOCH 2: training on 191080 raw words (116013 effective words) took 0.4s, 283484 effective words/s
INFO - 2023-11-30 15:41:17,842: EPOCH 3: training on 191080 raw words (116083 effective words) took 0.4s, 299097 effective words/s
INFO - 2023-11-30 15:41:18,254: EPOCH 4: training on 191080 raw words (115925 effective words) took 0.4s, 283857 effective words/s
INFO - 2023-11-30 15:41:18,710: EPOCH 5: training on 191080 raw words (115793 effective words) took 0.5s, 256488 effective words/s
INFO - 2023-11-30 15:41:19,146: EPOCH 6: training on 191080 raw words (116236 effective words) took 0.4s, 269369 effective words/s
INFO - 2023-11-30 15:41:19,597: EPOCH 7: training on 191080 raw words (115937 effective words) took 0.4s, 259446 effective words/s
INFO - 2023-11-30 15:41:20,056: EPOCH 8: training on 191080 raw words (116083 effective words) took 0.5s, 255357 effective words/s
INFO - 2023-11-30 15:41:20,510: EPOCH 9: training on 191080 raw words (116034 effective words) took 0.4s, 257972 effective words/s
INFO - 2023-11-30 15:41:20,958: EPOCH 10: training on 191080 raw words (116092 effective words) took 0.4s, 260859 effective words/s
INFO - 2023-11-30 15:41:21,454: EPOCH 11: training on 191080 raw words (116056 effective words) took 0.5s, 236473 effective words/s
INFO - 2023-11-30 15:41:21,974: EPOCH 12: training on 191080 raw words (115881 effective words) took 0.5s, 224470 effective words/s
INFO - 2023-11-30 15:41:22,528: EPOCH 13: training on 191080 raw words (115953 effective words) took 0.5s, 211261 effective words/s
INFO - 2023-11-30 15:41:23,041: EPOCH 14: training on 191080 raw words (115780 effective words) took 0.5s, 227470 effective words/s
INFO - 2023-11-30 15:41:23,463: EPOCH 15: training on 191080 raw words (115898 effective words) took 0.4s, 277462 effective words/s
INFO - 2023-11-30 15:41:23,840: EPOCH 16: training on 191080 raw words (115737 effective words) took 0.4s, 309702 effective words/s
INFO - 2023-11-30 15:41:24,130: EPOCH 17: training on 191080 raw words (115765 effective words) took 0.3s, 404804 effective words/s
INFO - 2023-11-30 15:41:24,401: EPOCH 18: training on 191080 raw words (115938 effective words) took 0.3s, 431986 effective words/s
INFO - 2023-11-30 15:41:24,695: EPOCH 19: training on 191080 raw words (115791 effective words) took 0.3s, 397488 effective words/s
INFO - 2023-11-30 15:41:24,695: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2318984 effective words) took 8.6s, 270022 effective words/s', 'datetime': '2023-11-30T15:41:24.695335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:24,695: collecting all words and their counts
INFO - 2023-11-30 15:41:24,695: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:24,725: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:24,725: Updating model with new vocabulary
INFO - 2023-11-30 15:41:24,739: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:24.739074', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:24,756: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:24,757: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:41:24,757: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115787.74322910322 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:41:24.757140', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:24,782: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:24,782: updating layer weights
INFO - 2023-11-30 15:41:24,783: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:24.783185', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:24,783: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:24,783: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:24.783486', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:25,056: EPOCH 0: training on 191080 raw words (115744 effective words) took 0.3s, 427199 effective words/s
INFO - 2023-11-30 15:41:25,363: EPOCH 1: training on 191080 raw words (115730 effective words) took 0.3s, 382070 effective words/s
INFO - 2023-11-30 15:41:25,679: EPOCH 2: training on 191080 raw words (115920 effective words) took 0.3s, 370059 effective words/s
INFO - 2023-11-30 15:41:25,961: EPOCH 3: training on 191080 raw words (115710 effective words) took 0.3s, 415545 effective words/s
INFO - 2023-11-30 15:41:26,283: EPOCH 4: training on 191080 raw words (115770 effective words) took 0.3s, 363017 effective words/s
INFO - 2023-11-30 15:41:26,627: EPOCH 5: training on 191080 raw words (115574 effective words) took 0.3s, 341994 effective words/s
INFO - 2023-11-30 15:41:26,930: EPOCH 6: training on 191080 raw words (115863 effective words) took 0.3s, 385637 effective words/s
INFO - 2023-11-30 15:41:27,208: EPOCH 7: training on 191080 raw words (115947 effective words) took 0.3s, 422099 effective words/s
INFO - 2023-11-30 15:41:27,523: EPOCH 8: training on 191080 raw words (115713 effective words) took 0.3s, 371150 effective words/s
INFO - 2023-11-30 15:41:27,794: EPOCH 9: training on 191080 raw words (115994 effective words) took 0.3s, 433202 effective words/s
INFO - 2023-11-30 15:41:28,083: EPOCH 10: training on 191080 raw words (115720 effective words) took 0.3s, 404544 effective words/s
INFO - 2023-11-30 15:41:28,428: EPOCH 11: training on 191080 raw words (115689 effective words) took 0.3s, 337877 effective words/s
INFO - 2023-11-30 15:41:28,695: EPOCH 12: training on 191080 raw words (115890 effective words) took 0.3s, 439608 effective words/s
INFO - 2023-11-30 15:41:28,988: EPOCH 13: training on 191080 raw words (115830 effective words) took 0.3s, 397628 effective words/s
INFO - 2023-11-30 15:41:29,306: EPOCH 14: training on 191080 raw words (115568 effective words) took 0.3s, 369464 effective words/s
INFO - 2023-11-30 15:41:29,690: EPOCH 15: training on 191080 raw words (115772 effective words) took 0.4s, 311145 effective words/s
INFO - 2023-11-30 15:41:30,018: EPOCH 16: training on 191080 raw words (115816 effective words) took 0.3s, 357787 effective words/s
INFO - 2023-11-30 15:41:30,299: EPOCH 17: training on 191080 raw words (115652 effective words) took 0.3s, 415730 effective words/s
INFO - 2023-11-30 15:41:30,613: EPOCH 18: training on 191080 raw words (115539 effective words) took 0.3s, 370015 effective words/s
INFO - 2023-11-30 15:41:30,882: EPOCH 19: training on 191080 raw words (115769 effective words) took 0.3s, 435414 effective words/s
INFO - 2023-11-30 15:41:30,883: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2315210 effective words) took 6.1s, 379582 effective words/s', 'datetime': '2023-11-30T15:41:30.882994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:30,883: collecting all words and their counts
INFO - 2023-11-30 15:41:30,883: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:30,913: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:30,913: Updating model with new vocabulary
INFO - 2023-11-30 15:41:30,929: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:30.929512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:30,951: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:30,951: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:41:30,951: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115354.20133156146 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:41:30.951950', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:30,985: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:30,985: updating layer weights
INFO - 2023-11-30 15:41:30,986: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:30.985997', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:30,986: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:30,986: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:30.986276', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:31,293: EPOCH 0: training on 191080 raw words (115433 effective words) took 0.3s, 380509 effective words/s
INFO - 2023-11-30 15:41:31,567: EPOCH 1: training on 191080 raw words (115250 effective words) took 0.3s, 424158 effective words/s
INFO - 2023-11-30 15:41:31,843: EPOCH 2: training on 191080 raw words (115439 effective words) took 0.3s, 422938 effective words/s
INFO - 2023-11-30 15:41:32,137: EPOCH 3: training on 191080 raw words (115431 effective words) took 0.3s, 396514 effective words/s
INFO - 2023-11-30 15:41:32,410: EPOCH 4: training on 191080 raw words (115397 effective words) took 0.3s, 426816 effective words/s
INFO - 2023-11-30 15:41:32,693: EPOCH 5: training on 191080 raw words (115557 effective words) took 0.3s, 413044 effective words/s
INFO - 2023-11-30 15:41:33,002: EPOCH 6: training on 191080 raw words (115495 effective words) took 0.3s, 376924 effective words/s
INFO - 2023-11-30 15:41:33,312: EPOCH 7: training on 191080 raw words (115291 effective words) took 0.3s, 375460 effective words/s
INFO - 2023-11-30 15:41:33,591: EPOCH 8: training on 191080 raw words (115470 effective words) took 0.3s, 417690 effective words/s
INFO - 2023-11-30 15:41:33,877: EPOCH 9: training on 191080 raw words (115412 effective words) took 0.3s, 407358 effective words/s
INFO - 2023-11-30 15:41:34,201: EPOCH 10: training on 191080 raw words (115345 effective words) took 0.3s, 376358 effective words/s
INFO - 2023-11-30 15:41:34,497: EPOCH 11: training on 191080 raw words (115440 effective words) took 0.3s, 394371 effective words/s
INFO - 2023-11-30 15:41:34,799: EPOCH 12: training on 191080 raw words (115460 effective words) took 0.3s, 386376 effective words/s
INFO - 2023-11-30 15:41:35,118: EPOCH 13: training on 191080 raw words (115406 effective words) took 0.3s, 363926 effective words/s
INFO - 2023-11-30 15:41:35,504: EPOCH 14: training on 191080 raw words (115636 effective words) took 0.4s, 302046 effective words/s
INFO - 2023-11-30 15:41:35,802: EPOCH 15: training on 191080 raw words (115360 effective words) took 0.3s, 390878 effective words/s
INFO - 2023-11-30 15:41:36,139: EPOCH 16: training on 191080 raw words (115335 effective words) took 0.3s, 344640 effective words/s
INFO - 2023-11-30 15:41:36,446: EPOCH 17: training on 191080 raw words (115297 effective words) took 0.3s, 379942 effective words/s
INFO - 2023-11-30 15:41:36,724: EPOCH 18: training on 191080 raw words (115494 effective words) took 0.3s, 420173 effective words/s
INFO - 2023-11-30 15:41:37,009: EPOCH 19: training on 191080 raw words (115557 effective words) took 0.3s, 408793 effective words/s
INFO - 2023-11-30 15:41:37,009: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308505 effective words) took 6.0s, 383246 effective words/s', 'datetime': '2023-11-30T15:41:37.009951', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:37,010: collecting all words and their counts
INFO - 2023-11-30 15:41:37,010: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:37,036: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:37,037: Updating model with new vocabulary
INFO - 2023-11-30 15:41:37,050: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:37.050197', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:37,066: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:37,066: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:41:37,066: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115779.2156677251 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:41:37.066618', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:37,094: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:37,094: updating layer weights
INFO - 2023-11-30 15:41:37,094: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:37.094814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:37,095: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:37,095: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:37.095121', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:37,444: EPOCH 0: training on 191080 raw words (115868 effective words) took 0.3s, 333942 effective words/s
INFO - 2023-11-30 15:41:37,778: EPOCH 1: training on 191080 raw words (115838 effective words) took 0.3s, 349398 effective words/s
INFO - 2023-11-30 15:41:38,039: EPOCH 2: training on 191080 raw words (115671 effective words) took 0.3s, 449614 effective words/s
INFO - 2023-11-30 15:41:38,402: EPOCH 3: training on 191080 raw words (115648 effective words) took 0.4s, 320814 effective words/s
INFO - 2023-11-30 15:41:38,686: EPOCH 4: training on 191080 raw words (115717 effective words) took 0.3s, 411826 effective words/s
INFO - 2023-11-30 15:41:39,029: EPOCH 5: training on 191080 raw words (115554 effective words) took 0.3s, 338922 effective words/s
INFO - 2023-11-30 15:41:39,373: EPOCH 6: training on 191080 raw words (115708 effective words) took 0.3s, 340087 effective words/s
INFO - 2023-11-30 15:41:39,719: EPOCH 7: training on 191080 raw words (115823 effective words) took 0.3s, 355203 effective words/s
INFO - 2023-11-30 15:41:40,069: EPOCH 8: training on 191080 raw words (115832 effective words) took 0.3s, 333971 effective words/s
INFO - 2023-11-30 15:41:40,489: EPOCH 9: training on 191080 raw words (115780 effective words) took 0.4s, 278327 effective words/s
INFO - 2023-11-30 15:41:40,850: EPOCH 10: training on 191080 raw words (115797 effective words) took 0.4s, 323960 effective words/s
INFO - 2023-11-30 15:41:41,229: EPOCH 11: training on 191080 raw words (115728 effective words) took 0.4s, 308410 effective words/s
INFO - 2023-11-30 15:41:41,588: EPOCH 12: training on 191080 raw words (115945 effective words) took 0.4s, 326435 effective words/s
INFO - 2023-11-30 15:41:41,987: EPOCH 13: training on 191080 raw words (115910 effective words) took 0.4s, 293293 effective words/s
INFO - 2023-11-30 15:41:42,353: EPOCH 14: training on 191080 raw words (115732 effective words) took 0.4s, 318980 effective words/s
INFO - 2023-11-30 15:41:42,736: EPOCH 15: training on 191080 raw words (115854 effective words) took 0.4s, 304481 effective words/s
INFO - 2023-11-30 15:41:43,164: EPOCH 16: training on 191080 raw words (115672 effective words) took 0.4s, 272603 effective words/s
INFO - 2023-11-30 15:41:43,634: EPOCH 17: training on 191080 raw words (115897 effective words) took 0.5s, 248362 effective words/s
INFO - 2023-11-30 15:41:44,121: EPOCH 18: training on 191080 raw words (115889 effective words) took 0.5s, 239999 effective words/s
INFO - 2023-11-30 15:41:44,549: EPOCH 19: training on 191080 raw words (115621 effective words) took 0.4s, 274492 effective words/s
INFO - 2023-11-30 15:41:44,550: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2315484 effective words) took 7.5s, 310607 effective words/s', 'datetime': '2023-11-30T15:41:44.550014', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:44,550: collecting all words and their counts
INFO - 2023-11-30 15:41:44,550: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:44,597: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:44,597: Updating model with new vocabulary
INFO - 2023-11-30 15:41:44,624: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:44.624114', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:44,668: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:44,669: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:41:44,669: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115458.3660635123 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:41:44.669261', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:44,706: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:44,706: updating layer weights
INFO - 2023-11-30 15:41:44,707: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:44.707142', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:44,707: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:44,707: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:44.707520', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:45,049: EPOCH 0: training on 191080 raw words (115371 effective words) took 0.3s, 340702 effective words/s
INFO - 2023-11-30 15:41:45,466: EPOCH 1: training on 191080 raw words (115623 effective words) took 0.4s, 279791 effective words/s
INFO - 2023-11-30 15:41:45,906: EPOCH 2: training on 191080 raw words (115426 effective words) took 0.4s, 264474 effective words/s
INFO - 2023-11-30 15:41:46,336: EPOCH 3: training on 191080 raw words (115541 effective words) took 0.4s, 270847 effective words/s
INFO - 2023-11-30 15:41:46,877: EPOCH 4: training on 191080 raw words (115531 effective words) took 0.5s, 214867 effective words/s
INFO - 2023-11-30 15:41:47,394: EPOCH 5: training on 191080 raw words (115384 effective words) took 0.5s, 224819 effective words/s
INFO - 2023-11-30 15:41:47,874: EPOCH 6: training on 191080 raw words (115505 effective words) took 0.5s, 243074 effective words/s
INFO - 2023-11-30 15:41:48,254: EPOCH 7: training on 191080 raw words (115366 effective words) took 0.4s, 306593 effective words/s
INFO - 2023-11-30 15:41:48,591: EPOCH 8: training on 191080 raw words (115285 effective words) took 0.3s, 345000 effective words/s
INFO - 2023-11-30 15:41:48,948: EPOCH 9: training on 191080 raw words (115290 effective words) took 0.4s, 325755 effective words/s
INFO - 2023-11-30 15:41:49,289: EPOCH 10: training on 191080 raw words (115447 effective words) took 0.3s, 341677 effective words/s
INFO - 2023-11-30 15:41:49,559: EPOCH 11: training on 191080 raw words (115535 effective words) took 0.3s, 432689 effective words/s
INFO - 2023-11-30 15:41:49,862: EPOCH 12: training on 191080 raw words (115456 effective words) took 0.3s, 384796 effective words/s
INFO - 2023-11-30 15:41:50,222: EPOCH 13: training on 191080 raw words (115190 effective words) took 0.4s, 321717 effective words/s
INFO - 2023-11-30 15:41:50,534: EPOCH 14: training on 191080 raw words (115620 effective words) took 0.3s, 373666 effective words/s
INFO - 2023-11-30 15:41:50,839: EPOCH 15: training on 191080 raw words (115697 effective words) took 0.3s, 382757 effective words/s
INFO - 2023-11-30 15:41:51,199: EPOCH 16: training on 191080 raw words (115345 effective words) took 0.4s, 323166 effective words/s
INFO - 2023-11-30 15:41:51,520: EPOCH 17: training on 191080 raw words (115511 effective words) took 0.3s, 362284 effective words/s
INFO - 2023-11-30 15:41:51,835: EPOCH 18: training on 191080 raw words (115498 effective words) took 0.3s, 370545 effective words/s
INFO - 2023-11-30 15:41:52,182: EPOCH 19: training on 191080 raw words (115463 effective words) took 0.3s, 336079 effective words/s
INFO - 2023-11-30 15:41:52,182: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309084 effective words) took 7.5s, 308905 effective words/s', 'datetime': '2023-11-30T15:41:52.182771', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:52,182: collecting all words and their counts
INFO - 2023-11-30 15:41:52,183: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:52,215: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:52,216: Updating model with new vocabulary
INFO - 2023-11-30 15:41:52,232: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:52.232067', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:52,252: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:52,252: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:41:52,252: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115521.14877177174 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:41:52.252569', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:52,285: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:52,285: updating layer weights
INFO - 2023-11-30 15:41:52,286: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:52.286151', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:52,286: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:52,286: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:52.286687', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:52,565: EPOCH 0: training on 191080 raw words (115624 effective words) took 0.3s, 418973 effective words/s
INFO - 2023-11-30 15:41:52,852: EPOCH 1: training on 191080 raw words (115542 effective words) took 0.3s, 406178 effective words/s
INFO - 2023-11-30 15:41:53,156: EPOCH 2: training on 191080 raw words (115641 effective words) took 0.3s, 384416 effective words/s
INFO - 2023-11-30 15:41:53,457: EPOCH 3: training on 191080 raw words (115596 effective words) took 0.3s, 388342 effective words/s
INFO - 2023-11-30 15:41:53,846: EPOCH 4: training on 191080 raw words (115443 effective words) took 0.4s, 299275 effective words/s
INFO - 2023-11-30 15:41:54,162: EPOCH 5: training on 191080 raw words (115404 effective words) took 0.3s, 367866 effective words/s
INFO - 2023-11-30 15:41:54,470: EPOCH 6: training on 191080 raw words (115630 effective words) took 0.3s, 378557 effective words/s
INFO - 2023-11-30 15:41:54,819: EPOCH 7: training on 191080 raw words (115428 effective words) took 0.3s, 334192 effective words/s
INFO - 2023-11-30 15:41:55,183: EPOCH 8: training on 191080 raw words (115688 effective words) took 0.4s, 320301 effective words/s
INFO - 2023-11-30 15:41:55,499: EPOCH 9: training on 191080 raw words (115598 effective words) took 0.3s, 369925 effective words/s
INFO - 2023-11-30 15:41:55,826: EPOCH 10: training on 191080 raw words (115761 effective words) took 0.3s, 357174 effective words/s
INFO - 2023-11-30 15:41:56,124: EPOCH 11: training on 191080 raw words (115588 effective words) took 0.3s, 391461 effective words/s
INFO - 2023-11-30 15:41:56,415: EPOCH 12: training on 191080 raw words (115478 effective words) took 0.3s, 401394 effective words/s
INFO - 2023-11-30 15:41:56,716: EPOCH 13: training on 191080 raw words (115353 effective words) took 0.3s, 385696 effective words/s
INFO - 2023-11-30 15:41:57,020: EPOCH 14: training on 191080 raw words (115700 effective words) took 0.3s, 385028 effective words/s
INFO - 2023-11-30 15:41:57,300: EPOCH 15: training on 191080 raw words (115600 effective words) took 0.3s, 417279 effective words/s
INFO - 2023-11-30 15:41:57,588: EPOCH 16: training on 191080 raw words (115353 effective words) took 0.3s, 404904 effective words/s
INFO - 2023-11-30 15:41:57,906: EPOCH 17: training on 191080 raw words (115728 effective words) took 0.3s, 366420 effective words/s
INFO - 2023-11-30 15:41:58,199: EPOCH 18: training on 191080 raw words (115524 effective words) took 0.3s, 398172 effective words/s
INFO - 2023-11-30 15:41:58,481: EPOCH 19: training on 191080 raw words (115137 effective words) took 0.3s, 412275 effective words/s
INFO - 2023-11-30 15:41:58,481: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310816 effective words) took 6.2s, 373046 effective words/s', 'datetime': '2023-11-30T15:41:58.481346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:58,481: collecting all words and their counts
INFO - 2023-11-30 15:41:58,481: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:41:58,517: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:41:58,517: Updating model with new vocabulary
INFO - 2023-11-30 15:41:58,536: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:41:58.536573', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:58,560: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:41:58,561: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:41:58,561: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115936.6292845167 word corpus (60.7%% of prior 191080)', 'datetime': '2023-11-30T15:41:58.561748', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:41:58,596: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:41:58,596: updating layer weights
INFO - 2023-11-30 15:41:58,596: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:41:58.596841', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:41:58,597: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:41:58,597: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:41:58.597171', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:41:58,918: EPOCH 0: training on 191080 raw words (115680 effective words) took 0.3s, 362786 effective words/s
INFO - 2023-11-30 15:41:59,243: EPOCH 1: training on 191080 raw words (116110 effective words) took 0.3s, 360886 effective words/s
INFO - 2023-11-30 15:41:59,534: EPOCH 2: training on 191080 raw words (115934 effective words) took 0.3s, 401318 effective words/s
INFO - 2023-11-30 15:41:59,813: EPOCH 3: training on 191080 raw words (116104 effective words) took 0.3s, 419636 effective words/s
INFO - 2023-11-30 15:42:00,088: EPOCH 4: training on 191080 raw words (116044 effective words) took 0.3s, 456370 effective words/s
INFO - 2023-11-30 15:42:00,380: EPOCH 5: training on 191080 raw words (115958 effective words) took 0.3s, 400396 effective words/s
INFO - 2023-11-30 15:42:00,663: EPOCH 6: training on 191080 raw words (115748 effective words) took 0.3s, 414356 effective words/s
INFO - 2023-11-30 15:42:00,952: EPOCH 7: training on 191080 raw words (115746 effective words) took 0.3s, 404922 effective words/s
INFO - 2023-11-30 15:42:01,222: EPOCH 8: training on 191080 raw words (115965 effective words) took 0.3s, 434281 effective words/s
INFO - 2023-11-30 15:42:01,543: EPOCH 9: training on 191080 raw words (115955 effective words) took 0.3s, 364603 effective words/s
INFO - 2023-11-30 15:42:01,841: EPOCH 10: training on 191080 raw words (115890 effective words) took 0.3s, 392462 effective words/s
INFO - 2023-11-30 15:42:02,116: EPOCH 11: training on 191080 raw words (115831 effective words) took 0.3s, 454760 effective words/s
INFO - 2023-11-30 15:42:02,403: EPOCH 12: training on 191080 raw words (116118 effective words) took 0.3s, 408552 effective words/s
INFO - 2023-11-30 15:42:02,692: EPOCH 13: training on 191080 raw words (116035 effective words) took 0.3s, 405539 effective words/s
INFO - 2023-11-30 15:42:03,030: EPOCH 14: training on 191080 raw words (116042 effective words) took 0.3s, 346800 effective words/s
INFO - 2023-11-30 15:42:03,439: EPOCH 15: training on 191080 raw words (115955 effective words) took 0.4s, 285423 effective words/s
INFO - 2023-11-30 15:42:03,905: EPOCH 16: training on 191080 raw words (116300 effective words) took 0.5s, 251043 effective words/s
INFO - 2023-11-30 15:42:04,322: EPOCH 17: training on 191080 raw words (116070 effective words) took 0.4s, 281716 effective words/s
INFO - 2023-11-30 15:42:04,751: EPOCH 18: training on 191080 raw words (116023 effective words) took 0.4s, 273060 effective words/s
INFO - 2023-11-30 15:42:05,189: EPOCH 19: training on 191080 raw words (115822 effective words) took 0.4s, 266680 effective words/s
INFO - 2023-11-30 15:42:05,189: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2319330 effective words) took 6.6s, 351840 effective words/s', 'datetime': '2023-11-30T15:42:05.189323', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:05,189: collecting all words and their counts
INFO - 2023-11-30 15:42:05,189: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:05,230: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:05,230: Updating model with new vocabulary
INFO - 2023-11-30 15:42:05,250: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:05.250554', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:05,285: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:05,285: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:42:05,286: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115220.21747798324 word corpus (60.3%% of prior 191080)', 'datetime': '2023-11-30T15:42:05.286211', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:05,335: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:05,335: updating layer weights
INFO - 2023-11-30 15:42:05,336: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:05.336021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:05,336: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:05,336: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:05.336482', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:05,686: EPOCH 0: training on 191080 raw words (115334 effective words) took 0.3s, 332620 effective words/s
INFO - 2023-11-30 15:42:06,156: EPOCH 1: training on 191080 raw words (115101 effective words) took 0.5s, 250490 effective words/s
INFO - 2023-11-30 15:42:06,591: EPOCH 2: training on 191080 raw words (115158 effective words) took 0.4s, 267462 effective words/s
INFO - 2023-11-30 15:42:07,024: EPOCH 3: training on 191080 raw words (115172 effective words) took 0.4s, 268425 effective words/s
INFO - 2023-11-30 15:42:07,430: EPOCH 4: training on 191080 raw words (115362 effective words) took 0.4s, 287055 effective words/s
INFO - 2023-11-30 15:42:07,887: EPOCH 5: training on 191080 raw words (114973 effective words) took 0.5s, 253311 effective words/s
INFO - 2023-11-30 15:42:08,282: EPOCH 6: training on 191080 raw words (115157 effective words) took 0.4s, 295214 effective words/s
INFO - 2023-11-30 15:42:08,824: EPOCH 7: training on 191080 raw words (115258 effective words) took 0.5s, 214172 effective words/s
INFO - 2023-11-30 15:42:09,266: EPOCH 8: training on 191080 raw words (115382 effective words) took 0.4s, 263292 effective words/s
INFO - 2023-11-30 15:42:09,741: EPOCH 9: training on 191080 raw words (115364 effective words) took 0.5s, 244535 effective words/s
INFO - 2023-11-30 15:42:10,275: EPOCH 10: training on 191080 raw words (115315 effective words) took 0.5s, 217649 effective words/s
INFO - 2023-11-30 15:42:10,737: EPOCH 11: training on 191080 raw words (115225 effective words) took 0.5s, 251395 effective words/s
INFO - 2023-11-30 15:42:11,233: EPOCH 12: training on 191080 raw words (115134 effective words) took 0.5s, 234679 effective words/s
INFO - 2023-11-30 15:42:11,861: EPOCH 13: training on 191080 raw words (115172 effective words) took 0.6s, 185654 effective words/s
INFO - 2023-11-30 15:42:12,248: EPOCH 14: training on 191080 raw words (115405 effective words) took 0.4s, 302251 effective words/s
INFO - 2023-11-30 15:42:12,542: EPOCH 15: training on 191080 raw words (115197 effective words) took 0.3s, 411571 effective words/s
INFO - 2023-11-30 15:42:12,832: EPOCH 16: training on 191080 raw words (115113 effective words) took 0.3s, 402344 effective words/s
INFO - 2023-11-30 15:42:13,133: EPOCH 17: training on 191080 raw words (115154 effective words) took 0.3s, 385824 effective words/s
INFO - 2023-11-30 15:42:13,419: EPOCH 18: training on 191080 raw words (115380 effective words) took 0.3s, 407833 effective words/s
INFO - 2023-11-30 15:42:13,718: EPOCH 19: training on 191080 raw words (115288 effective words) took 0.3s, 389030 effective words/s
INFO - 2023-11-30 15:42:13,719: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2304644 effective words) took 8.4s, 274933 effective words/s', 'datetime': '2023-11-30T15:42:13.719212', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:13,719: collecting all words and their counts
INFO - 2023-11-30 15:42:13,719: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:13,758: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:13,758: Updating model with new vocabulary
INFO - 2023-11-30 15:42:13,784: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:13.784316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:13,811: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:13,811: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:42:13,811: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115440.66139493886 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:42:13.811820', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:13,845: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:13,845: updating layer weights
INFO - 2023-11-30 15:42:13,845: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:13.845869', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:13,846: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:13,846: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:13.846170', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:14,173: EPOCH 0: training on 191080 raw words (115372 effective words) took 0.3s, 354666 effective words/s
INFO - 2023-11-30 15:42:14,531: EPOCH 1: training on 191080 raw words (115499 effective words) took 0.4s, 325795 effective words/s
INFO - 2023-11-30 15:42:14,855: EPOCH 2: training on 191080 raw words (115473 effective words) took 0.3s, 359401 effective words/s
INFO - 2023-11-30 15:42:15,181: EPOCH 3: training on 191080 raw words (115328 effective words) took 0.3s, 365386 effective words/s
INFO - 2023-11-30 15:42:15,507: EPOCH 4: training on 191080 raw words (115522 effective words) took 0.3s, 358482 effective words/s
INFO - 2023-11-30 15:42:15,794: EPOCH 5: training on 191080 raw words (115400 effective words) took 0.3s, 405990 effective words/s
INFO - 2023-11-30 15:42:16,099: EPOCH 6: training on 191080 raw words (115453 effective words) took 0.3s, 381903 effective words/s
INFO - 2023-11-30 15:42:16,440: EPOCH 7: training on 191080 raw words (115311 effective words) took 0.3s, 340732 effective words/s
INFO - 2023-11-30 15:42:16,865: EPOCH 8: training on 191080 raw words (115403 effective words) took 0.4s, 273148 effective words/s
INFO - 2023-11-30 15:42:17,234: EPOCH 9: training on 191080 raw words (115181 effective words) took 0.4s, 315753 effective words/s
INFO - 2023-11-30 15:42:17,534: EPOCH 10: training on 191080 raw words (115367 effective words) took 0.3s, 388312 effective words/s
INFO - 2023-11-30 15:42:17,825: EPOCH 11: training on 191080 raw words (115774 effective words) took 0.3s, 400730 effective words/s
INFO - 2023-11-30 15:42:18,139: EPOCH 12: training on 191080 raw words (115257 effective words) took 0.3s, 370585 effective words/s
INFO - 2023-11-30 15:42:18,433: EPOCH 13: training on 191080 raw words (115383 effective words) took 0.3s, 395653 effective words/s
INFO - 2023-11-30 15:42:18,728: EPOCH 14: training on 191080 raw words (115234 effective words) took 0.3s, 394555 effective words/s
INFO - 2023-11-30 15:42:19,062: EPOCH 15: training on 191080 raw words (115340 effective words) took 0.3s, 349953 effective words/s
INFO - 2023-11-30 15:42:19,398: EPOCH 16: training on 191080 raw words (115293 effective words) took 0.3s, 345113 effective words/s
INFO - 2023-11-30 15:42:19,691: EPOCH 17: training on 191080 raw words (115495 effective words) took 0.3s, 398827 effective words/s
INFO - 2023-11-30 15:42:19,991: EPOCH 18: training on 191080 raw words (115609 effective words) took 0.3s, 388972 effective words/s
INFO - 2023-11-30 15:42:20,272: EPOCH 19: training on 191080 raw words (115492 effective words) took 0.3s, 415617 effective words/s
INFO - 2023-11-30 15:42:20,273: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308186 effective words) took 6.4s, 359152 effective words/s', 'datetime': '2023-11-30T15:42:20.273068', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:20,273: collecting all words and their counts
INFO - 2023-11-30 15:42:20,273: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:20,302: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:20,302: Updating model with new vocabulary
INFO - 2023-11-30 15:42:20,317: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:20.317171', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:20,340: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:20,341: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:42:20,341: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115534.80203406097 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:42:20.341509', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:20,369: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:20,369: updating layer weights
INFO - 2023-11-30 15:42:20,370: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:20.370286', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:20,370: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:20,370: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:20.370555', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:20,661: EPOCH 0: training on 191080 raw words (115438 effective words) took 0.3s, 399612 effective words/s
INFO - 2023-11-30 15:42:20,929: EPOCH 1: training on 191080 raw words (115587 effective words) took 0.3s, 435779 effective words/s
INFO - 2023-11-30 15:42:21,200: EPOCH 2: training on 191080 raw words (115625 effective words) took 0.3s, 432747 effective words/s
INFO - 2023-11-30 15:42:21,493: EPOCH 3: training on 191080 raw words (115484 effective words) took 0.3s, 396784 effective words/s
INFO - 2023-11-30 15:42:21,845: EPOCH 4: training on 191080 raw words (115442 effective words) took 0.3s, 331687 effective words/s
INFO - 2023-11-30 15:42:22,226: EPOCH 5: training on 191080 raw words (115551 effective words) took 0.4s, 306097 effective words/s
INFO - 2023-11-30 15:42:22,563: EPOCH 6: training on 191080 raw words (115419 effective words) took 0.3s, 345388 effective words/s
INFO - 2023-11-30 15:42:22,845: EPOCH 7: training on 191080 raw words (115468 effective words) took 0.3s, 413999 effective words/s
INFO - 2023-11-30 15:42:23,122: EPOCH 8: training on 191080 raw words (115373 effective words) took 0.3s, 422457 effective words/s
INFO - 2023-11-30 15:42:23,381: EPOCH 9: training on 191080 raw words (115494 effective words) took 0.3s, 448843 effective words/s
INFO - 2023-11-30 15:42:23,761: EPOCH 10: training on 191080 raw words (115411 effective words) took 0.4s, 305839 effective words/s
INFO - 2023-11-30 15:42:24,018: EPOCH 11: training on 191080 raw words (115686 effective words) took 0.3s, 456089 effective words/s
INFO - 2023-11-30 15:42:24,267: EPOCH 12: training on 191080 raw words (115572 effective words) took 0.2s, 469842 effective words/s
INFO - 2023-11-30 15:42:24,556: EPOCH 13: training on 191080 raw words (115393 effective words) took 0.3s, 402344 effective words/s
INFO - 2023-11-30 15:42:24,902: EPOCH 14: training on 191080 raw words (115480 effective words) took 0.3s, 336648 effective words/s
INFO - 2023-11-30 15:42:25,229: EPOCH 15: training on 191080 raw words (115473 effective words) took 0.3s, 355679 effective words/s
INFO - 2023-11-30 15:42:25,509: EPOCH 16: training on 191080 raw words (115656 effective words) took 0.3s, 416475 effective words/s
INFO - 2023-11-30 15:42:25,793: EPOCH 17: training on 191080 raw words (115650 effective words) took 0.3s, 413275 effective words/s
INFO - 2023-11-30 15:42:26,097: EPOCH 18: training on 191080 raw words (115421 effective words) took 0.3s, 383501 effective words/s
INFO - 2023-11-30 15:42:26,393: EPOCH 19: training on 191080 raw words (115672 effective words) took 0.3s, 394584 effective words/s
INFO - 2023-11-30 15:42:26,394: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310295 effective words) took 6.0s, 383558 effective words/s', 'datetime': '2023-11-30T15:42:26.394028', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:26,394: collecting all words and their counts
INFO - 2023-11-30 15:42:26,394: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:26,435: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:26,435: Updating model with new vocabulary
INFO - 2023-11-30 15:42:26,452: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:26.452119', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:26,475: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:26,475: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:42:26,475: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115853.97044929765 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:42:26.475740', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:26,507: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:26,507: updating layer weights
INFO - 2023-11-30 15:42:26,508: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:26.508494', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:26,508: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:26,508: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:26.508837', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:26,855: EPOCH 0: training on 191080 raw words (115728 effective words) took 0.3s, 337021 effective words/s
INFO - 2023-11-30 15:42:27,169: EPOCH 1: training on 191080 raw words (116032 effective words) took 0.3s, 372738 effective words/s
INFO - 2023-11-30 15:42:27,529: EPOCH 2: training on 191080 raw words (116198 effective words) took 0.4s, 325321 effective words/s
INFO - 2023-11-30 15:42:27,940: EPOCH 3: training on 191080 raw words (115940 effective words) took 0.4s, 284721 effective words/s
INFO - 2023-11-30 15:42:28,372: EPOCH 4: training on 191080 raw words (115852 effective words) took 0.4s, 270357 effective words/s
INFO - 2023-11-30 15:42:28,776: EPOCH 5: training on 191080 raw words (115787 effective words) took 0.4s, 289472 effective words/s
INFO - 2023-11-30 15:42:29,248: EPOCH 6: training on 191080 raw words (115821 effective words) took 0.5s, 248039 effective words/s
INFO - 2023-11-30 15:42:29,681: EPOCH 7: training on 191080 raw words (115715 effective words) took 0.4s, 269964 effective words/s
INFO - 2023-11-30 15:42:30,115: EPOCH 8: training on 191080 raw words (115837 effective words) took 0.4s, 269347 effective words/s
INFO - 2023-11-30 15:42:30,549: EPOCH 9: training on 191080 raw words (116008 effective words) took 0.4s, 270123 effective words/s
INFO - 2023-11-30 15:42:30,987: EPOCH 10: training on 191080 raw words (115653 effective words) took 0.4s, 266165 effective words/s
INFO - 2023-11-30 15:42:31,387: EPOCH 11: training on 191080 raw words (116002 effective words) took 0.4s, 291928 effective words/s
INFO - 2023-11-30 15:42:31,848: EPOCH 12: training on 191080 raw words (115873 effective words) took 0.5s, 253272 effective words/s
INFO - 2023-11-30 15:42:32,289: EPOCH 13: training on 191080 raw words (115655 effective words) took 0.4s, 264967 effective words/s
INFO - 2023-11-30 15:42:32,733: EPOCH 14: training on 191080 raw words (116002 effective words) took 0.4s, 262855 effective words/s
INFO - 2023-11-30 15:42:33,175: EPOCH 15: training on 191080 raw words (115951 effective words) took 0.4s, 264563 effective words/s
INFO - 2023-11-30 15:42:33,661: EPOCH 16: training on 191080 raw words (115586 effective words) took 0.5s, 240325 effective words/s
INFO - 2023-11-30 15:42:34,128: EPOCH 17: training on 191080 raw words (115778 effective words) took 0.5s, 250411 effective words/s
INFO - 2023-11-30 15:42:34,622: EPOCH 18: training on 191080 raw words (115789 effective words) took 0.5s, 247521 effective words/s
INFO - 2023-11-30 15:42:35,080: EPOCH 19: training on 191080 raw words (116093 effective words) took 0.4s, 273410 effective words/s
INFO - 2023-11-30 15:42:35,080: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2317300 effective words) took 8.6s, 270355 effective words/s', 'datetime': '2023-11-30T15:42:35.080380', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:35,080: collecting all words and their counts
INFO - 2023-11-30 15:42:35,080: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:35,136: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:35,136: Updating model with new vocabulary
INFO - 2023-11-30 15:42:35,158: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:35.158803', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:35,189: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:35,189: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:42:35,190: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115836.89854134695 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:42:35.189982', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:35,234: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:35,235: updating layer weights
INFO - 2023-11-30 15:42:35,235: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:35.235542', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:35,235: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:35,235: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:35.235926', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:35,709: EPOCH 0: training on 191080 raw words (115742 effective words) took 0.5s, 246555 effective words/s
INFO - 2023-11-30 15:42:36,162: EPOCH 1: training on 191080 raw words (115821 effective words) took 0.4s, 258339 effective words/s
INFO - 2023-11-30 15:42:36,470: EPOCH 2: training on 191080 raw words (116023 effective words) took 0.3s, 381167 effective words/s
INFO - 2023-11-30 15:42:36,742: EPOCH 3: training on 191080 raw words (115619 effective words) took 0.3s, 429727 effective words/s
INFO - 2023-11-30 15:42:37,145: EPOCH 4: training on 191080 raw words (115830 effective words) took 0.4s, 291012 effective words/s
INFO - 2023-11-30 15:42:37,463: EPOCH 5: training on 191080 raw words (115646 effective words) took 0.3s, 367279 effective words/s
INFO - 2023-11-30 15:42:37,756: EPOCH 6: training on 191080 raw words (115976 effective words) took 0.3s, 400458 effective words/s
INFO - 2023-11-30 15:42:38,017: EPOCH 7: training on 191080 raw words (115865 effective words) took 0.3s, 447090 effective words/s
INFO - 2023-11-30 15:42:38,279: EPOCH 8: training on 191080 raw words (115707 effective words) took 0.3s, 447809 effective words/s
INFO - 2023-11-30 15:42:38,557: EPOCH 9: training on 191080 raw words (115662 effective words) took 0.3s, 419461 effective words/s
INFO - 2023-11-30 15:42:38,817: EPOCH 10: training on 191080 raw words (115853 effective words) took 0.3s, 451781 effective words/s
INFO - 2023-11-30 15:42:39,079: EPOCH 11: training on 191080 raw words (116000 effective words) took 0.3s, 447286 effective words/s
INFO - 2023-11-30 15:42:39,392: EPOCH 12: training on 191080 raw words (115868 effective words) took 0.3s, 372905 effective words/s
INFO - 2023-11-30 15:42:39,703: EPOCH 13: training on 191080 raw words (115934 effective words) took 0.3s, 376696 effective words/s
INFO - 2023-11-30 15:42:39,973: EPOCH 14: training on 191080 raw words (115906 effective words) took 0.3s, 434347 effective words/s
INFO - 2023-11-30 15:42:40,339: EPOCH 15: training on 191080 raw words (116048 effective words) took 0.4s, 318893 effective words/s
INFO - 2023-11-30 15:42:40,679: EPOCH 16: training on 191080 raw words (115933 effective words) took 0.3s, 343575 effective words/s
INFO - 2023-11-30 15:42:40,962: EPOCH 17: training on 191080 raw words (115865 effective words) took 0.3s, 414437 effective words/s
INFO - 2023-11-30 15:42:41,224: EPOCH 18: training on 191080 raw words (115746 effective words) took 0.3s, 446565 effective words/s
INFO - 2023-11-30 15:42:41,484: EPOCH 19: training on 191080 raw words (115765 effective words) took 0.3s, 450856 effective words/s
INFO - 2023-11-30 15:42:41,484: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316809 effective words) took 6.2s, 370785 effective words/s', 'datetime': '2023-11-30T15:42:41.484515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:41,484: collecting all words and their counts
INFO - 2023-11-30 15:42:41,484: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:41,518: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:41,518: Updating model with new vocabulary
INFO - 2023-11-30 15:42:41,537: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:41.537017', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:41,553: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:41,554: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:42:41,554: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115663.48614418198 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:42:41.554258', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:41,581: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:41,582: updating layer weights
INFO - 2023-11-30 15:42:41,582: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:41.582570', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:41,582: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:41,582: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:41.582866', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:41,889: EPOCH 0: training on 191080 raw words (115623 effective words) took 0.3s, 379916 effective words/s
INFO - 2023-11-30 15:42:42,165: EPOCH 1: training on 191080 raw words (115668 effective words) took 0.3s, 423459 effective words/s
INFO - 2023-11-30 15:42:42,469: EPOCH 2: training on 191080 raw words (115433 effective words) took 0.3s, 382756 effective words/s
INFO - 2023-11-30 15:42:42,854: EPOCH 3: training on 191080 raw words (115656 effective words) took 0.4s, 302260 effective words/s
INFO - 2023-11-30 15:42:43,225: EPOCH 4: training on 191080 raw words (115558 effective words) took 0.4s, 313857 effective words/s
INFO - 2023-11-30 15:42:43,584: EPOCH 5: training on 191080 raw words (115545 effective words) took 0.4s, 324879 effective words/s
INFO - 2023-11-30 15:42:43,912: EPOCH 6: training on 191080 raw words (115559 effective words) took 0.3s, 354651 effective words/s
INFO - 2023-11-30 15:42:44,224: EPOCH 7: training on 191080 raw words (115473 effective words) took 0.3s, 395464 effective words/s
INFO - 2023-11-30 15:42:44,629: EPOCH 8: training on 191080 raw words (115543 effective words) took 0.4s, 287509 effective words/s
INFO - 2023-11-30 15:42:45,008: EPOCH 9: training on 191080 raw words (115780 effective words) took 0.4s, 310721 effective words/s
INFO - 2023-11-30 15:42:45,358: EPOCH 10: training on 191080 raw words (115607 effective words) took 0.3s, 333104 effective words/s
INFO - 2023-11-30 15:42:45,634: EPOCH 11: training on 191080 raw words (115543 effective words) took 0.3s, 423380 effective words/s
INFO - 2023-11-30 15:42:45,903: EPOCH 12: training on 191080 raw words (115534 effective words) took 0.3s, 433709 effective words/s
INFO - 2023-11-30 15:42:46,222: EPOCH 13: training on 191080 raw words (115611 effective words) took 0.3s, 365282 effective words/s
INFO - 2023-11-30 15:42:46,490: EPOCH 14: training on 191080 raw words (115765 effective words) took 0.3s, 435821 effective words/s
INFO - 2023-11-30 15:42:46,809: EPOCH 15: training on 191080 raw words (115597 effective words) took 0.3s, 365027 effective words/s
INFO - 2023-11-30 15:42:47,081: EPOCH 16: training on 191080 raw words (115493 effective words) took 0.3s, 428593 effective words/s
INFO - 2023-11-30 15:42:47,365: EPOCH 17: training on 191080 raw words (115716 effective words) took 0.3s, 411257 effective words/s
INFO - 2023-11-30 15:42:47,632: EPOCH 18: training on 191080 raw words (115531 effective words) took 0.3s, 437967 effective words/s
INFO - 2023-11-30 15:42:47,918: EPOCH 19: training on 191080 raw words (115555 effective words) took 0.3s, 407557 effective words/s
INFO - 2023-11-30 15:42:47,918: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2311790 effective words) took 6.3s, 364882 effective words/s', 'datetime': '2023-11-30T15:42:47.918720', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:47,918: collecting all words and their counts
INFO - 2023-11-30 15:42:47,919: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:47,948: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:47,949: Updating model with new vocabulary
INFO - 2023-11-30 15:42:47,962: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:47.962259', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:47,978: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:47,979: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:42:47,979: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115809.70262648846 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:42:47.979363', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:48,007: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:48,008: updating layer weights
INFO - 2023-11-30 15:42:48,008: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:48.008685', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:48,008: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:48,009: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:48.009036', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:48,323: EPOCH 0: training on 191080 raw words (115954 effective words) took 0.3s, 372224 effective words/s
INFO - 2023-11-30 15:42:48,614: EPOCH 1: training on 191080 raw words (115844 effective words) took 0.3s, 401437 effective words/s
INFO - 2023-11-30 15:42:48,880: EPOCH 2: training on 191080 raw words (115701 effective words) took 0.3s, 439426 effective words/s
INFO - 2023-11-30 15:42:49,167: EPOCH 3: training on 191080 raw words (115780 effective words) took 0.3s, 407796 effective words/s
INFO - 2023-11-30 15:42:49,488: EPOCH 4: training on 191080 raw words (115874 effective words) took 0.3s, 364108 effective words/s
INFO - 2023-11-30 15:42:49,768: EPOCH 5: training on 191080 raw words (115478 effective words) took 0.3s, 416479 effective words/s
INFO - 2023-11-30 15:42:50,038: EPOCH 6: training on 191080 raw words (115503 effective words) took 0.3s, 430770 effective words/s
INFO - 2023-11-30 15:42:50,327: EPOCH 7: training on 191080 raw words (115702 effective words) took 0.3s, 403768 effective words/s
INFO - 2023-11-30 15:42:50,646: EPOCH 8: training on 191080 raw words (115647 effective words) took 0.3s, 366370 effective words/s
INFO - 2023-11-30 15:42:50,927: EPOCH 9: training on 191080 raw words (115766 effective words) took 0.3s, 417045 effective words/s
INFO - 2023-11-30 15:42:51,211: EPOCH 10: training on 191080 raw words (115821 effective words) took 0.3s, 412066 effective words/s
INFO - 2023-11-30 15:42:51,494: EPOCH 11: training on 191080 raw words (115732 effective words) took 0.3s, 412133 effective words/s
INFO - 2023-11-30 15:42:51,819: EPOCH 12: training on 191080 raw words (115871 effective words) took 0.3s, 360697 effective words/s
INFO - 2023-11-30 15:42:52,138: EPOCH 13: training on 191080 raw words (115762 effective words) took 0.3s, 366752 effective words/s
INFO - 2023-11-30 15:42:52,605: EPOCH 14: training on 191080 raw words (115721 effective words) took 0.5s, 249202 effective words/s
INFO - 2023-11-30 15:42:52,965: EPOCH 15: training on 191080 raw words (115877 effective words) took 0.4s, 326657 effective words/s
INFO - 2023-11-30 15:42:53,291: EPOCH 16: training on 191080 raw words (115725 effective words) took 0.3s, 357701 effective words/s
INFO - 2023-11-30 15:42:53,617: EPOCH 17: training on 191080 raw words (115943 effective words) took 0.3s, 359310 effective words/s
INFO - 2023-11-30 15:42:53,953: EPOCH 18: training on 191080 raw words (115623 effective words) took 0.3s, 347896 effective words/s
INFO - 2023-11-30 15:42:54,281: EPOCH 19: training on 191080 raw words (115675 effective words) took 0.3s, 356355 effective words/s
INFO - 2023-11-30 15:42:54,281: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2314999 effective words) took 6.3s, 369072 effective words/s', 'datetime': '2023-11-30T15:42:54.281658', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:54,281: collecting all words and their counts
INFO - 2023-11-30 15:42:54,282: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:42:54,320: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:42:54,320: Updating model with new vocabulary
INFO - 2023-11-30 15:42:54,334: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:42:54.334482', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:54,356: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:42:54,357: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:42:54,357: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115610.26456509248 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:42:54.357504', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:42:54,400: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:42:54,400: updating layer weights
INFO - 2023-11-30 15:42:54,400: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:42:54.400639', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:42:54,400: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:42:54,400: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:42:54.400842', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:42:54,833: EPOCH 0: training on 191080 raw words (115741 effective words) took 0.4s, 269419 effective words/s
INFO - 2023-11-30 15:42:55,225: EPOCH 1: training on 191080 raw words (115691 effective words) took 0.4s, 297508 effective words/s
INFO - 2023-11-30 15:42:55,652: EPOCH 2: training on 191080 raw words (115489 effective words) took 0.4s, 278349 effective words/s
INFO - 2023-11-30 15:42:56,045: EPOCH 3: training on 191080 raw words (115922 effective words) took 0.4s, 297429 effective words/s
INFO - 2023-11-30 15:42:56,415: EPOCH 4: training on 191080 raw words (115520 effective words) took 0.4s, 314687 effective words/s
INFO - 2023-11-30 15:42:56,823: EPOCH 5: training on 191080 raw words (115539 effective words) took 0.4s, 285677 effective words/s
INFO - 2023-11-30 15:42:57,255: EPOCH 6: training on 191080 raw words (115614 effective words) took 0.4s, 273611 effective words/s
INFO - 2023-11-30 15:42:57,671: EPOCH 7: training on 191080 raw words (115777 effective words) took 0.4s, 280734 effective words/s
INFO - 2023-11-30 15:42:58,071: EPOCH 8: training on 191080 raw words (116015 effective words) took 0.4s, 314027 effective words/s
INFO - 2023-11-30 15:42:58,488: EPOCH 9: training on 191080 raw words (115675 effective words) took 0.4s, 279752 effective words/s
INFO - 2023-11-30 15:42:58,976: EPOCH 10: training on 191080 raw words (115373 effective words) took 0.5s, 238012 effective words/s
INFO - 2023-11-30 15:42:59,409: EPOCH 11: training on 191080 raw words (115646 effective words) took 0.4s, 268910 effective words/s
INFO - 2023-11-30 15:42:59,862: EPOCH 12: training on 191080 raw words (115427 effective words) took 0.4s, 256874 effective words/s
INFO - 2023-11-30 15:43:00,242: EPOCH 13: training on 191080 raw words (115765 effective words) took 0.4s, 307410 effective words/s
INFO - 2023-11-30 15:43:00,576: EPOCH 14: training on 191080 raw words (115723 effective words) took 0.3s, 350489 effective words/s
INFO - 2023-11-30 15:43:00,883: EPOCH 15: training on 191080 raw words (115591 effective words) took 0.3s, 379370 effective words/s
INFO - 2023-11-30 15:43:01,150: EPOCH 16: training on 191080 raw words (115899 effective words) took 0.3s, 438403 effective words/s
INFO - 2023-11-30 15:43:01,437: EPOCH 17: training on 191080 raw words (115589 effective words) took 0.3s, 406153 effective words/s
INFO - 2023-11-30 15:43:01,720: EPOCH 18: training on 191080 raw words (115443 effective words) took 0.3s, 410655 effective words/s
INFO - 2023-11-30 15:43:02,025: EPOCH 19: training on 191080 raw words (115575 effective words) took 0.3s, 382406 effective words/s
INFO - 2023-11-30 15:43:02,026: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313014 effective words) took 7.6s, 303347 effective words/s', 'datetime': '2023-11-30T15:43:02.025959', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:02,026: collecting all words and their counts
INFO - 2023-11-30 15:43:02,026: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:02,077: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:02,077: Updating model with new vocabulary
INFO - 2023-11-30 15:43:02,092: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:02.092491', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:02,112: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:02,112: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:43:02,113: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115476.90888177928 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:43:02.113052', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:02,141: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:02,142: updating layer weights
INFO - 2023-11-30 15:43:02,142: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:02.142462', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:02,142: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:02,142: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:02.142773', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:02,419: EPOCH 0: training on 191080 raw words (115409 effective words) took 0.3s, 421266 effective words/s
INFO - 2023-11-30 15:43:02,671: EPOCH 1: training on 191080 raw words (115301 effective words) took 0.3s, 460955 effective words/s
INFO - 2023-11-30 15:43:02,928: EPOCH 2: training on 191080 raw words (115461 effective words) took 0.3s, 454592 effective words/s
INFO - 2023-11-30 15:43:03,205: EPOCH 3: training on 191080 raw words (115470 effective words) took 0.3s, 421689 effective words/s
INFO - 2023-11-30 15:43:03,459: EPOCH 4: training on 191080 raw words (115713 effective words) took 0.3s, 462218 effective words/s
INFO - 2023-11-30 15:43:03,714: EPOCH 5: training on 191080 raw words (115546 effective words) took 0.3s, 456932 effective words/s
INFO - 2023-11-30 15:43:03,967: EPOCH 6: training on 191080 raw words (115496 effective words) took 0.3s, 460749 effective words/s
INFO - 2023-11-30 15:43:04,222: EPOCH 7: training on 191080 raw words (115528 effective words) took 0.3s, 459561 effective words/s
INFO - 2023-11-30 15:43:04,474: EPOCH 8: training on 191080 raw words (115518 effective words) took 0.2s, 462473 effective words/s
INFO - 2023-11-30 15:43:04,728: EPOCH 9: training on 191080 raw words (115501 effective words) took 0.3s, 458892 effective words/s
INFO - 2023-11-30 15:43:05,001: EPOCH 10: training on 191080 raw words (115829 effective words) took 0.3s, 429447 effective words/s
INFO - 2023-11-30 15:43:05,303: EPOCH 11: training on 191080 raw words (115495 effective words) took 0.3s, 386817 effective words/s
INFO - 2023-11-30 15:43:05,560: EPOCH 12: training on 191080 raw words (115518 effective words) took 0.3s, 453089 effective words/s
INFO - 2023-11-30 15:43:05,835: EPOCH 13: training on 191080 raw words (115400 effective words) took 0.3s, 424468 effective words/s
INFO - 2023-11-30 15:43:06,107: EPOCH 14: training on 191080 raw words (115313 effective words) took 0.3s, 427961 effective words/s
INFO - 2023-11-30 15:43:06,375: EPOCH 15: training on 191080 raw words (115375 effective words) took 0.3s, 436090 effective words/s
INFO - 2023-11-30 15:43:06,646: EPOCH 16: training on 191080 raw words (115576 effective words) took 0.3s, 430382 effective words/s
INFO - 2023-11-30 15:43:06,901: EPOCH 17: training on 191080 raw words (115579 effective words) took 0.3s, 459242 effective words/s
INFO - 2023-11-30 15:43:07,153: EPOCH 18: training on 191080 raw words (115387 effective words) took 0.2s, 463293 effective words/s
INFO - 2023-11-30 15:43:07,436: EPOCH 19: training on 191080 raw words (115686 effective words) took 0.3s, 412769 effective words/s
INFO - 2023-11-30 15:43:07,436: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310101 effective words) took 5.3s, 436393 effective words/s', 'datetime': '2023-11-30T15:43:07.436545', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:07,436: collecting all words and their counts
INFO - 2023-11-30 15:43:07,437: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:07,469: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:07,469: Updating model with new vocabulary
INFO - 2023-11-30 15:43:07,482: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:07.482529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:07,499: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:07,499: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:43:07,499: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115446.07814131881 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:43:07.499769', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:07,529: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:07,529: updating layer weights
INFO - 2023-11-30 15:43:07,529: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:07.529860', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:07,530: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:07,530: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:07.530161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:07,788: EPOCH 0: training on 191080 raw words (115345 effective words) took 0.3s, 451267 effective words/s
INFO - 2023-11-30 15:43:08,049: EPOCH 1: training on 191080 raw words (115519 effective words) took 0.3s, 446827 effective words/s
INFO - 2023-11-30 15:43:08,325: EPOCH 2: training on 191080 raw words (115495 effective words) took 0.3s, 423215 effective words/s
INFO - 2023-11-30 15:43:08,628: EPOCH 3: training on 191080 raw words (115591 effective words) took 0.3s, 384413 effective words/s
INFO - 2023-11-30 15:43:08,893: EPOCH 4: training on 191080 raw words (115549 effective words) took 0.3s, 439941 effective words/s
INFO - 2023-11-30 15:43:09,167: EPOCH 5: training on 191080 raw words (115651 effective words) took 0.3s, 426599 effective words/s
INFO - 2023-11-30 15:43:09,432: EPOCH 6: training on 191080 raw words (115413 effective words) took 0.3s, 438731 effective words/s
INFO - 2023-11-30 15:43:09,743: EPOCH 7: training on 191080 raw words (115481 effective words) took 0.3s, 375629 effective words/s
INFO - 2023-11-30 15:43:10,003: EPOCH 8: training on 191080 raw words (115607 effective words) took 0.3s, 449928 effective words/s
INFO - 2023-11-30 15:43:10,259: EPOCH 9: training on 191080 raw words (115408 effective words) took 0.3s, 454552 effective words/s
INFO - 2023-11-30 15:43:10,523: EPOCH 10: training on 191080 raw words (115339 effective words) took 0.3s, 440785 effective words/s
INFO - 2023-11-30 15:43:10,795: EPOCH 11: training on 191080 raw words (115526 effective words) took 0.3s, 429230 effective words/s
INFO - 2023-11-30 15:43:11,054: EPOCH 12: training on 191080 raw words (115382 effective words) took 0.3s, 450404 effective words/s
INFO - 2023-11-30 15:43:11,307: EPOCH 13: training on 191080 raw words (115486 effective words) took 0.3s, 460478 effective words/s
INFO - 2023-11-30 15:43:11,590: EPOCH 14: training on 191080 raw words (115612 effective words) took 0.3s, 412184 effective words/s
INFO - 2023-11-30 15:43:11,859: EPOCH 15: training on 191080 raw words (115421 effective words) took 0.3s, 433851 effective words/s
INFO - 2023-11-30 15:43:12,125: EPOCH 16: training on 191080 raw words (115476 effective words) took 0.3s, 438967 effective words/s
INFO - 2023-11-30 15:43:12,385: EPOCH 17: training on 191080 raw words (115434 effective words) took 0.3s, 447947 effective words/s
INFO - 2023-11-30 15:43:12,673: EPOCH 18: training on 191080 raw words (115186 effective words) took 0.3s, 403525 effective words/s
INFO - 2023-11-30 15:43:12,932: EPOCH 19: training on 191080 raw words (115548 effective words) took 0.3s, 452670 effective words/s
INFO - 2023-11-30 15:43:12,932: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2309469 effective words) took 5.4s, 427524 effective words/s', 'datetime': '2023-11-30T15:43:12.932273', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:12,932: collecting all words and their counts
INFO - 2023-11-30 15:43:12,932: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:12,961: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:12,961: Updating model with new vocabulary
INFO - 2023-11-30 15:43:12,976: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:12.976448', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:12,995: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:12,995: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:43:12,995: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115886.64828026676 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:43:12.995649', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:13,029: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:13,030: updating layer weights
INFO - 2023-11-30 15:43:13,030: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:13.030573', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:13,030: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:13,030: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:13.030849', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:13,286: EPOCH 0: training on 191080 raw words (115762 effective words) took 0.3s, 456810 effective words/s
INFO - 2023-11-30 15:43:13,555: EPOCH 1: training on 191080 raw words (115960 effective words) took 0.3s, 436184 effective words/s
INFO - 2023-11-30 15:43:13,882: EPOCH 2: training on 191080 raw words (115898 effective words) took 0.3s, 357138 effective words/s
INFO - 2023-11-30 15:43:14,142: EPOCH 3: training on 191080 raw words (115789 effective words) took 0.3s, 450269 effective words/s
INFO - 2023-11-30 15:43:14,403: EPOCH 4: training on 191080 raw words (115616 effective words) took 0.3s, 447283 effective words/s
INFO - 2023-11-30 15:43:14,677: EPOCH 5: training on 191080 raw words (115870 effective words) took 0.3s, 426631 effective words/s
INFO - 2023-11-30 15:43:14,941: EPOCH 6: training on 191080 raw words (115906 effective words) took 0.3s, 444077 effective words/s
INFO - 2023-11-30 15:43:15,228: EPOCH 7: training on 191080 raw words (115942 effective words) took 0.3s, 407672 effective words/s
INFO - 2023-11-30 15:43:15,484: EPOCH 8: training on 191080 raw words (115791 effective words) took 0.3s, 456880 effective words/s
INFO - 2023-11-30 15:43:15,851: EPOCH 9: training on 191080 raw words (115665 effective words) took 0.4s, 317156 effective words/s
INFO - 2023-11-30 15:43:16,216: EPOCH 10: training on 191080 raw words (115996 effective words) took 0.4s, 321529 effective words/s
INFO - 2023-11-30 15:43:16,591: EPOCH 11: training on 191080 raw words (115942 effective words) took 0.4s, 312071 effective words/s
INFO - 2023-11-30 15:43:16,947: EPOCH 12: training on 191080 raw words (115920 effective words) took 0.4s, 328857 effective words/s
INFO - 2023-11-30 15:43:17,302: EPOCH 13: training on 191080 raw words (115873 effective words) took 0.4s, 329264 effective words/s
INFO - 2023-11-30 15:43:17,635: EPOCH 14: training on 191080 raw words (115795 effective words) took 0.3s, 351839 effective words/s
INFO - 2023-11-30 15:43:17,998: EPOCH 15: training on 191080 raw words (116014 effective words) took 0.4s, 322341 effective words/s
INFO - 2023-11-30 15:43:18,394: EPOCH 16: training on 191080 raw words (115802 effective words) took 0.4s, 295363 effective words/s
INFO - 2023-11-30 15:43:18,761: EPOCH 17: training on 191080 raw words (115965 effective words) took 0.3s, 333579 effective words/s
INFO - 2023-11-30 15:43:19,186: EPOCH 18: training on 191080 raw words (115945 effective words) took 0.4s, 275147 effective words/s
INFO - 2023-11-30 15:43:19,574: EPOCH 19: training on 191080 raw words (115816 effective words) took 0.4s, 300994 effective words/s
INFO - 2023-11-30 15:43:19,574: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2317267 effective words) took 6.5s, 354112 effective words/s', 'datetime': '2023-11-30T15:43:19.574883', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:19,575: collecting all words and their counts
INFO - 2023-11-30 15:43:19,575: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:19,616: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:19,617: Updating model with new vocabulary
INFO - 2023-11-30 15:43:19,636: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:19.635946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:19,671: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:19,671: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:43:19,671: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115484.06527868359 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:43:19.671612', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:19,710: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:19,711: updating layer weights
INFO - 2023-11-30 15:43:19,711: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:19.711558', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:19,712: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:19,712: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:19.712509', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:20,155: EPOCH 0: training on 191080 raw words (115491 effective words) took 0.4s, 262736 effective words/s
INFO - 2023-11-30 15:43:20,636: EPOCH 1: training on 191080 raw words (115475 effective words) took 0.5s, 242109 effective words/s
INFO - 2023-11-30 15:43:21,093: EPOCH 2: training on 191080 raw words (115253 effective words) took 0.5s, 254513 effective words/s
INFO - 2023-11-30 15:43:21,519: EPOCH 3: training on 191080 raw words (115421 effective words) took 0.4s, 273072 effective words/s
INFO - 2023-11-30 15:43:21,921: EPOCH 4: training on 191080 raw words (115376 effective words) took 0.4s, 296966 effective words/s
INFO - 2023-11-30 15:43:22,432: EPOCH 5: training on 191080 raw words (115400 effective words) took 0.5s, 227489 effective words/s
INFO - 2023-11-30 15:43:22,846: EPOCH 6: training on 191080 raw words (115531 effective words) took 0.4s, 282179 effective words/s
INFO - 2023-11-30 15:43:23,261: EPOCH 7: training on 191080 raw words (115433 effective words) took 0.4s, 280844 effective words/s
INFO - 2023-11-30 15:43:23,683: EPOCH 8: training on 191080 raw words (115443 effective words) took 0.4s, 277020 effective words/s
INFO - 2023-11-30 15:43:24,103: EPOCH 9: training on 191080 raw words (115025 effective words) took 0.4s, 276105 effective words/s
INFO - 2023-11-30 15:43:24,550: EPOCH 10: training on 191080 raw words (115519 effective words) took 0.4s, 260580 effective words/s
INFO - 2023-11-30 15:43:24,896: EPOCH 11: training on 191080 raw words (115351 effective words) took 0.3s, 337985 effective words/s
INFO - 2023-11-30 15:43:25,233: EPOCH 12: training on 191080 raw words (115422 effective words) took 0.3s, 346072 effective words/s
INFO - 2023-11-30 15:43:25,624: EPOCH 13: training on 191080 raw words (115704 effective words) took 0.4s, 299144 effective words/s
INFO - 2023-11-30 15:43:25,952: EPOCH 14: training on 191080 raw words (115221 effective words) took 0.3s, 354567 effective words/s
INFO - 2023-11-30 15:43:26,285: EPOCH 15: training on 191080 raw words (115221 effective words) took 0.3s, 348796 effective words/s
INFO - 2023-11-30 15:43:26,677: EPOCH 16: training on 191080 raw words (115434 effective words) took 0.4s, 297126 effective words/s
INFO - 2023-11-30 15:43:26,993: EPOCH 17: training on 191080 raw words (115266 effective words) took 0.3s, 368692 effective words/s
INFO - 2023-11-30 15:43:27,322: EPOCH 18: training on 191080 raw words (115390 effective words) took 0.3s, 353575 effective words/s
INFO - 2023-11-30 15:43:27,645: EPOCH 19: training on 191080 raw words (115552 effective words) took 0.3s, 360813 effective words/s
INFO - 2023-11-30 15:43:27,646: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2307928 effective words) took 7.9s, 290915 effective words/s', 'datetime': '2023-11-30T15:43:27.646188', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:27,646: collecting all words and their counts
INFO - 2023-11-30 15:43:27,646: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:27,674: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:27,675: Updating model with new vocabulary
INFO - 2023-11-30 15:43:27,692: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:27.692430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:27,710: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:27,711: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:43:27,711: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115513.13945950608 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:43:27.711449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:27,737: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:27,737: updating layer weights
INFO - 2023-11-30 15:43:27,738: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:27.738081', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:27,738: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:27,738: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:27.738342', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:27,985: EPOCH 0: training on 191080 raw words (115587 effective words) took 0.2s, 473124 effective words/s
INFO - 2023-11-30 15:43:28,237: EPOCH 1: training on 191080 raw words (115400 effective words) took 0.2s, 461651 effective words/s
INFO - 2023-11-30 15:43:28,510: EPOCH 2: training on 191080 raw words (115456 effective words) took 0.3s, 426920 effective words/s
INFO - 2023-11-30 15:43:28,775: EPOCH 3: training on 191080 raw words (115419 effective words) took 0.3s, 441691 effective words/s
INFO - 2023-11-30 15:43:29,029: EPOCH 4: training on 191080 raw words (115608 effective words) took 0.3s, 458543 effective words/s
INFO - 2023-11-30 15:43:29,302: EPOCH 5: training on 191080 raw words (115570 effective words) took 0.3s, 427312 effective words/s
INFO - 2023-11-30 15:43:29,572: EPOCH 6: training on 191080 raw words (115542 effective words) took 0.3s, 432175 effective words/s
INFO - 2023-11-30 15:43:29,824: EPOCH 7: training on 191080 raw words (115494 effective words) took 0.2s, 462804 effective words/s
INFO - 2023-11-30 15:43:30,138: EPOCH 8: training on 191080 raw words (115653 effective words) took 0.3s, 370561 effective words/s
INFO - 2023-11-30 15:43:30,400: EPOCH 9: training on 191080 raw words (115397 effective words) took 0.3s, 444512 effective words/s
INFO - 2023-11-30 15:43:30,746: EPOCH 10: training on 191080 raw words (115613 effective words) took 0.3s, 336998 effective words/s
INFO - 2023-11-30 15:43:31,005: EPOCH 11: training on 191080 raw words (115662 effective words) took 0.3s, 451600 effective words/s
INFO - 2023-11-30 15:43:31,268: EPOCH 12: training on 191080 raw words (115484 effective words) took 0.3s, 443694 effective words/s
INFO - 2023-11-30 15:43:31,613: EPOCH 13: training on 191080 raw words (115317 effective words) took 0.3s, 337395 effective words/s
INFO - 2023-11-30 15:43:31,867: EPOCH 14: training on 191080 raw words (115489 effective words) took 0.3s, 460569 effective words/s
INFO - 2023-11-30 15:43:32,128: EPOCH 15: training on 191080 raw words (115650 effective words) took 0.3s, 446379 effective words/s
INFO - 2023-11-30 15:43:32,393: EPOCH 16: training on 191080 raw words (115580 effective words) took 0.3s, 440689 effective words/s
INFO - 2023-11-30 15:43:32,662: EPOCH 17: training on 191080 raw words (115350 effective words) took 0.3s, 433918 effective words/s
INFO - 2023-11-30 15:43:32,920: EPOCH 18: training on 191080 raw words (115759 effective words) took 0.3s, 453008 effective words/s
INFO - 2023-11-30 15:43:33,196: EPOCH 19: training on 191080 raw words (115635 effective words) took 0.3s, 422108 effective words/s
INFO - 2023-11-30 15:43:33,196: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310665 effective words) took 5.5s, 423331 effective words/s', 'datetime': '2023-11-30T15:43:33.196905', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:33,197: collecting all words and their counts
INFO - 2023-11-30 15:43:33,197: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:33,225: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:33,226: Updating model with new vocabulary
INFO - 2023-11-30 15:43:33,239: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:33.239615', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:33,255: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:33,255: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:43:33,255: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115694.72555739751 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:43:33.255758', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:33,288: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:33,288: updating layer weights
INFO - 2023-11-30 15:43:33,289: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:33.289222', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:33,289: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:33,289: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:33.289713', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:33,577: EPOCH 0: training on 191080 raw words (115763 effective words) took 0.3s, 405376 effective words/s
INFO - 2023-11-30 15:43:33,839: EPOCH 1: training on 191080 raw words (115570 effective words) took 0.3s, 446462 effective words/s
INFO - 2023-11-30 15:43:34,127: EPOCH 2: training on 191080 raw words (115696 effective words) took 0.3s, 404923 effective words/s
INFO - 2023-11-30 15:43:34,389: EPOCH 3: training on 191080 raw words (115603 effective words) took 0.3s, 446522 effective words/s
INFO - 2023-11-30 15:43:34,658: EPOCH 4: training on 191080 raw words (115743 effective words) took 0.3s, 433170 effective words/s
INFO - 2023-11-30 15:43:34,922: EPOCH 5: training on 191080 raw words (115614 effective words) took 0.3s, 441113 effective words/s
INFO - 2023-11-30 15:43:35,187: EPOCH 6: training on 191080 raw words (115754 effective words) took 0.3s, 441265 effective words/s
INFO - 2023-11-30 15:43:35,466: EPOCH 7: training on 191080 raw words (115520 effective words) took 0.3s, 418182 effective words/s
INFO - 2023-11-30 15:43:35,755: EPOCH 8: training on 191080 raw words (115559 effective words) took 0.3s, 404594 effective words/s
INFO - 2023-11-30 15:43:36,020: EPOCH 9: training on 191080 raw words (115640 effective words) took 0.3s, 440453 effective words/s
INFO - 2023-11-30 15:43:36,285: EPOCH 10: training on 191080 raw words (115707 effective words) took 0.3s, 439911 effective words/s
INFO - 2023-11-30 15:43:36,566: EPOCH 11: training on 191080 raw words (115670 effective words) took 0.3s, 416165 effective words/s
INFO - 2023-11-30 15:43:36,900: EPOCH 12: training on 191080 raw words (115549 effective words) took 0.3s, 349242 effective words/s
INFO - 2023-11-30 15:43:37,176: EPOCH 13: training on 191080 raw words (115563 effective words) took 0.3s, 421964 effective words/s
INFO - 2023-11-30 15:43:37,445: EPOCH 14: training on 191080 raw words (115574 effective words) took 0.3s, 434160 effective words/s
INFO - 2023-11-30 15:43:37,711: EPOCH 15: training on 191080 raw words (115784 effective words) took 0.3s, 439401 effective words/s
INFO - 2023-11-30 15:43:37,980: EPOCH 16: training on 191080 raw words (115671 effective words) took 0.3s, 433977 effective words/s
INFO - 2023-11-30 15:43:38,247: EPOCH 17: training on 191080 raw words (115882 effective words) took 0.3s, 439501 effective words/s
INFO - 2023-11-30 15:43:38,505: EPOCH 18: training on 191080 raw words (115769 effective words) took 0.3s, 453245 effective words/s
INFO - 2023-11-30 15:43:38,819: EPOCH 19: training on 191080 raw words (115729 effective words) took 0.3s, 371852 effective words/s
INFO - 2023-11-30 15:43:38,819: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313360 effective words) took 5.5s, 418356 effective words/s', 'datetime': '2023-11-30T15:43:38.819515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:38,819: collecting all words and their counts
INFO - 2023-11-30 15:43:38,820: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:38,851: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:38,851: Updating model with new vocabulary
INFO - 2023-11-30 15:43:38,872: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:38.872084', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:38,889: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:38,889: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:43:38,889: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115689.76035547371 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:43:38.889754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:38,932: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:38,932: updating layer weights
INFO - 2023-11-30 15:43:38,932: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:38.932880', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:38,933: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:38,933: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:38.933170', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:39,197: EPOCH 0: training on 191080 raw words (115577 effective words) took 0.3s, 441785 effective words/s
INFO - 2023-11-30 15:43:39,458: EPOCH 1: training on 191080 raw words (115692 effective words) took 0.3s, 447928 effective words/s
INFO - 2023-11-30 15:43:39,716: EPOCH 2: training on 191080 raw words (115907 effective words) took 0.3s, 452608 effective words/s
INFO - 2023-11-30 15:43:39,984: EPOCH 3: training on 191080 raw words (115671 effective words) took 0.3s, 435626 effective words/s
INFO - 2023-11-30 15:43:40,255: EPOCH 4: training on 191080 raw words (115946 effective words) took 0.3s, 431814 effective words/s
INFO - 2023-11-30 15:43:40,515: EPOCH 5: training on 191080 raw words (115760 effective words) took 0.3s, 449686 effective words/s
INFO - 2023-11-30 15:43:40,789: EPOCH 6: training on 191080 raw words (115708 effective words) took 0.3s, 427396 effective words/s
INFO - 2023-11-30 15:43:41,054: EPOCH 7: training on 191080 raw words (115384 effective words) took 0.3s, 439187 effective words/s
INFO - 2023-11-30 15:43:41,328: EPOCH 8: training on 191080 raw words (115868 effective words) took 0.3s, 427467 effective words/s
INFO - 2023-11-30 15:43:41,612: EPOCH 9: training on 191080 raw words (115739 effective words) took 0.3s, 410869 effective words/s
INFO - 2023-11-30 15:43:41,914: EPOCH 10: training on 191080 raw words (115722 effective words) took 0.3s, 387549 effective words/s
INFO - 2023-11-30 15:43:42,185: EPOCH 11: training on 191080 raw words (115669 effective words) took 0.3s, 438451 effective words/s
INFO - 2023-11-30 15:43:42,456: EPOCH 12: training on 191080 raw words (115735 effective words) took 0.3s, 431174 effective words/s
INFO - 2023-11-30 15:43:42,726: EPOCH 13: training on 191080 raw words (115585 effective words) took 0.3s, 431855 effective words/s
INFO - 2023-11-30 15:43:43,048: EPOCH 14: training on 191080 raw words (115389 effective words) took 0.3s, 361674 effective words/s
INFO - 2023-11-30 15:43:43,318: EPOCH 15: training on 191080 raw words (115740 effective words) took 0.3s, 432862 effective words/s
INFO - 2023-11-30 15:43:43,580: EPOCH 16: training on 191080 raw words (115805 effective words) took 0.3s, 447748 effective words/s
INFO - 2023-11-30 15:43:43,864: EPOCH 17: training on 191080 raw words (115688 effective words) took 0.3s, 410495 effective words/s
INFO - 2023-11-30 15:43:44,128: EPOCH 18: training on 191080 raw words (115622 effective words) took 0.3s, 442678 effective words/s
INFO - 2023-11-30 15:43:44,434: EPOCH 19: training on 191080 raw words (115722 effective words) took 0.3s, 381178 effective words/s
INFO - 2023-11-30 15:43:44,435: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313929 effective words) took 5.5s, 420586 effective words/s', 'datetime': '2023-11-30T15:43:44.434981', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:44,435: collecting all words and their counts
INFO - 2023-11-30 15:43:44,435: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:44,466: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:44,466: Updating model with new vocabulary
INFO - 2023-11-30 15:43:44,486: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:44.486448', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:44,508: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:44,508: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:43:44,508: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115754.45223439392 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:43:44.508736', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:44,535: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:44,535: updating layer weights
INFO - 2023-11-30 15:43:44,536: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:44.536045', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:44,536: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:44,536: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:44.536401', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:44,814: EPOCH 0: training on 191080 raw words (115716 effective words) took 0.3s, 418944 effective words/s
INFO - 2023-11-30 15:43:45,151: EPOCH 1: training on 191080 raw words (115573 effective words) took 0.3s, 346415 effective words/s
INFO - 2023-11-30 15:43:45,452: EPOCH 2: training on 191080 raw words (115677 effective words) took 0.3s, 387679 effective words/s
INFO - 2023-11-30 15:43:45,725: EPOCH 3: training on 191080 raw words (115972 effective words) took 0.3s, 428496 effective words/s
INFO - 2023-11-30 15:43:46,071: EPOCH 4: training on 191080 raw words (115681 effective words) took 0.3s, 337744 effective words/s
INFO - 2023-11-30 15:43:46,429: EPOCH 5: training on 191080 raw words (115775 effective words) took 0.4s, 326103 effective words/s
INFO - 2023-11-30 15:43:46,786: EPOCH 6: training on 191080 raw words (115885 effective words) took 0.4s, 327553 effective words/s
INFO - 2023-11-30 15:43:47,202: EPOCH 7: training on 191080 raw words (115736 effective words) took 0.4s, 280482 effective words/s
INFO - 2023-11-30 15:43:47,594: EPOCH 8: training on 191080 raw words (115762 effective words) took 0.4s, 298666 effective words/s
INFO - 2023-11-30 15:43:47,958: EPOCH 9: training on 191080 raw words (115941 effective words) took 0.4s, 321021 effective words/s
INFO - 2023-11-30 15:43:48,326: EPOCH 10: training on 191080 raw words (115645 effective words) took 0.4s, 317569 effective words/s
INFO - 2023-11-30 15:43:48,788: EPOCH 11: training on 191080 raw words (115487 effective words) took 0.5s, 252091 effective words/s
INFO - 2023-11-30 15:43:49,156: EPOCH 12: training on 191080 raw words (115786 effective words) took 0.4s, 318263 effective words/s
INFO - 2023-11-30 15:43:49,572: EPOCH 13: training on 191080 raw words (115908 effective words) took 0.4s, 281114 effective words/s
INFO - 2023-11-30 15:43:49,959: EPOCH 14: training on 191080 raw words (115717 effective words) took 0.4s, 301704 effective words/s
INFO - 2023-11-30 15:43:50,331: EPOCH 15: training on 191080 raw words (115803 effective words) took 0.4s, 314681 effective words/s
INFO - 2023-11-30 15:43:50,802: EPOCH 16: training on 191080 raw words (115731 effective words) took 0.5s, 248619 effective words/s
INFO - 2023-11-30 15:43:51,206: EPOCH 17: training on 191080 raw words (115746 effective words) took 0.4s, 288442 effective words/s
INFO - 2023-11-30 15:43:51,604: EPOCH 18: training on 191080 raw words (115604 effective words) took 0.4s, 293413 effective words/s
INFO - 2023-11-30 15:43:52,071: EPOCH 19: training on 191080 raw words (115778 effective words) took 0.5s, 250613 effective words/s
INFO - 2023-11-30 15:43:52,071: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2314923 effective words) took 7.5s, 307213 effective words/s', 'datetime': '2023-11-30T15:43:52.071832', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:52,072: collecting all words and their counts
INFO - 2023-11-30 15:43:52,072: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:52,125: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:52,126: Updating model with new vocabulary
INFO - 2023-11-30 15:43:52,155: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:52.155060', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:52,187: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:52,188: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:43:52,188: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115403.55395178084 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:43:52.188200', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:52,238: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:52,238: updating layer weights
INFO - 2023-11-30 15:43:52,239: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:52.239294', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:52,239: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:52,239: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:52.239830', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:52,646: EPOCH 0: training on 191080 raw words (115596 effective words) took 0.4s, 287178 effective words/s
INFO - 2023-11-30 15:43:53,052: EPOCH 1: training on 191080 raw words (115247 effective words) took 0.4s, 286424 effective words/s
INFO - 2023-11-30 15:43:53,493: EPOCH 2: training on 191080 raw words (115262 effective words) took 0.4s, 263904 effective words/s
INFO - 2023-11-30 15:43:53,940: EPOCH 3: training on 191080 raw words (115323 effective words) took 0.4s, 259676 effective words/s
INFO - 2023-11-30 15:43:54,358: EPOCH 4: training on 191080 raw words (115351 effective words) took 0.4s, 279048 effective words/s
INFO - 2023-11-30 15:43:54,730: EPOCH 5: training on 191080 raw words (115352 effective words) took 0.4s, 313353 effective words/s
INFO - 2023-11-30 15:43:55,112: EPOCH 6: training on 191080 raw words (115355 effective words) took 0.4s, 318164 effective words/s
INFO - 2023-11-30 15:43:55,492: EPOCH 7: training on 191080 raw words (115256 effective words) took 0.4s, 306923 effective words/s
INFO - 2023-11-30 15:43:55,892: EPOCH 8: training on 191080 raw words (115258 effective words) took 0.4s, 292128 effective words/s
INFO - 2023-11-30 15:43:56,362: EPOCH 9: training on 191080 raw words (115159 effective words) took 0.5s, 247591 effective words/s
INFO - 2023-11-30 15:43:56,838: EPOCH 10: training on 191080 raw words (115333 effective words) took 0.5s, 244455 effective words/s
INFO - 2023-11-30 15:43:57,275: EPOCH 11: training on 191080 raw words (115509 effective words) took 0.4s, 266895 effective words/s
INFO - 2023-11-30 15:43:57,676: EPOCH 12: training on 191080 raw words (115203 effective words) took 0.4s, 290660 effective words/s
INFO - 2023-11-30 15:43:57,969: EPOCH 13: training on 191080 raw words (115203 effective words) took 0.3s, 398347 effective words/s
INFO - 2023-11-30 15:43:58,222: EPOCH 14: training on 191080 raw words (115429 effective words) took 0.3s, 459712 effective words/s
INFO - 2023-11-30 15:43:58,485: EPOCH 15: training on 191080 raw words (115499 effective words) took 0.3s, 443419 effective words/s
INFO - 2023-11-30 15:43:58,762: EPOCH 16: training on 191080 raw words (115413 effective words) took 0.3s, 421703 effective words/s
INFO - 2023-11-30 15:43:59,080: EPOCH 17: training on 191080 raw words (115285 effective words) took 0.3s, 365454 effective words/s
INFO - 2023-11-30 15:43:59,439: EPOCH 18: training on 191080 raw words (115598 effective words) took 0.4s, 324365 effective words/s
INFO - 2023-11-30 15:43:59,729: EPOCH 19: training on 191080 raw words (115401 effective words) took 0.3s, 401481 effective words/s
INFO - 2023-11-30 15:43:59,730: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2307032 effective words) took 7.5s, 308016 effective words/s', 'datetime': '2023-11-30T15:43:59.730001', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:43:59,730: collecting all words and their counts
INFO - 2023-11-30 15:43:59,730: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:43:59,770: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:43:59,770: Updating model with new vocabulary
INFO - 2023-11-30 15:43:59,788: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:43:59.788621', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:59,813: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:43:59,814: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:43:59,814: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115735.37485565786 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:43:59.814306', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:43:59,843: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:43:59,843: updating layer weights
INFO - 2023-11-30 15:43:59,844: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:43:59.844350', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:43:59,844: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:43:59,844: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:43:59.844609', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:00,155: EPOCH 0: training on 191080 raw words (115671 effective words) took 0.3s, 376447 effective words/s
INFO - 2023-11-30 15:44:00,479: EPOCH 1: training on 191080 raw words (115679 effective words) took 0.3s, 360712 effective words/s
INFO - 2023-11-30 15:44:00,804: EPOCH 2: training on 191080 raw words (115574 effective words) took 0.3s, 357704 effective words/s
INFO - 2023-11-30 15:44:01,154: EPOCH 3: training on 191080 raw words (115680 effective words) took 0.3s, 333149 effective words/s
INFO - 2023-11-30 15:44:01,444: EPOCH 4: training on 191080 raw words (115628 effective words) took 0.3s, 403716 effective words/s
INFO - 2023-11-30 15:44:01,721: EPOCH 5: training on 191080 raw words (115574 effective words) took 0.3s, 420560 effective words/s
INFO - 2023-11-30 15:44:02,036: EPOCH 6: training on 191080 raw words (115689 effective words) took 0.3s, 370193 effective words/s
INFO - 2023-11-30 15:44:02,468: EPOCH 7: training on 191080 raw words (115742 effective words) took 0.4s, 270252 effective words/s
INFO - 2023-11-30 15:44:02,832: EPOCH 8: training on 191080 raw words (115751 effective words) took 0.4s, 319891 effective words/s
INFO - 2023-11-30 15:44:03,183: EPOCH 9: training on 191080 raw words (115792 effective words) took 0.3s, 332924 effective words/s
INFO - 2023-11-30 15:44:03,524: EPOCH 10: training on 191080 raw words (115792 effective words) took 0.3s, 344221 effective words/s
INFO - 2023-11-30 15:44:03,807: EPOCH 11: training on 191080 raw words (115501 effective words) took 0.3s, 410884 effective words/s
INFO - 2023-11-30 15:44:04,095: EPOCH 12: training on 191080 raw words (115707 effective words) took 0.3s, 405445 effective words/s
INFO - 2023-11-30 15:44:04,386: EPOCH 13: training on 191080 raw words (115672 effective words) took 0.3s, 405006 effective words/s
INFO - 2023-11-30 15:44:04,671: EPOCH 14: training on 191080 raw words (115676 effective words) took 0.3s, 409097 effective words/s
INFO - 2023-11-30 15:44:05,082: EPOCH 15: training on 191080 raw words (115821 effective words) took 0.4s, 284596 effective words/s
INFO - 2023-11-30 15:44:05,398: EPOCH 16: training on 191080 raw words (115592 effective words) took 0.3s, 368464 effective words/s
INFO - 2023-11-30 15:44:05,773: EPOCH 17: training on 191080 raw words (115848 effective words) took 0.4s, 311295 effective words/s
INFO - 2023-11-30 15:44:06,117: EPOCH 18: training on 191080 raw words (115885 effective words) took 0.3s, 339425 effective words/s
INFO - 2023-11-30 15:44:06,397: EPOCH 19: training on 191080 raw words (115715 effective words) took 0.3s, 418085 effective words/s
INFO - 2023-11-30 15:44:06,397: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313989 effective words) took 6.6s, 353143 effective words/s', 'datetime': '2023-11-30T15:44:06.397303', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:06,397: collecting all words and their counts
INFO - 2023-11-30 15:44:06,397: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:06,433: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:06,433: Updating model with new vocabulary
INFO - 2023-11-30 15:44:06,450: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:06.449992', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:06,478: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:06,479: sample=0.001 downsamples 31 most-common words
INFO - 2023-11-30 15:44:06,479: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115845.83866135839 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:44:06.479485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:06,519: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:06,519: updating layer weights
INFO - 2023-11-30 15:44:06,520: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:06.520535', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:06,520: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:06,521: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:06.521108', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:06,889: EPOCH 0: training on 191080 raw words (115851 effective words) took 0.4s, 316859 effective words/s
INFO - 2023-11-30 15:44:07,226: EPOCH 1: training on 191080 raw words (115744 effective words) took 0.3s, 346434 effective words/s
INFO - 2023-11-30 15:44:07,576: EPOCH 2: training on 191080 raw words (116200 effective words) took 0.3s, 335013 effective words/s
INFO - 2023-11-30 15:44:07,856: EPOCH 3: training on 191080 raw words (115698 effective words) took 0.3s, 416798 effective words/s
INFO - 2023-11-30 15:44:08,126: EPOCH 4: training on 191080 raw words (115733 effective words) took 0.3s, 433370 effective words/s
INFO - 2023-11-30 15:44:08,417: EPOCH 5: training on 191080 raw words (115832 effective words) took 0.3s, 402605 effective words/s
INFO - 2023-11-30 15:44:08,710: EPOCH 6: training on 191080 raw words (115804 effective words) took 0.3s, 399012 effective words/s
INFO - 2023-11-30 15:44:08,994: EPOCH 7: training on 191080 raw words (115876 effective words) took 0.3s, 410785 effective words/s
INFO - 2023-11-30 15:44:09,276: EPOCH 8: training on 191080 raw words (115923 effective words) took 0.3s, 416608 effective words/s
INFO - 2023-11-30 15:44:09,582: EPOCH 9: training on 191080 raw words (115692 effective words) took 0.3s, 381629 effective words/s
INFO - 2023-11-30 15:44:09,842: EPOCH 10: training on 191080 raw words (115817 effective words) took 0.3s, 449378 effective words/s
INFO - 2023-11-30 15:44:10,137: EPOCH 11: training on 191080 raw words (115825 effective words) took 0.3s, 395678 effective words/s
INFO - 2023-11-30 15:44:10,407: EPOCH 12: training on 191080 raw words (115718 effective words) took 0.3s, 432995 effective words/s
INFO - 2023-11-30 15:44:10,670: EPOCH 13: training on 191080 raw words (115590 effective words) took 0.3s, 443799 effective words/s
INFO - 2023-11-30 15:44:10,940: EPOCH 14: training on 191080 raw words (116001 effective words) took 0.3s, 434287 effective words/s
INFO - 2023-11-30 15:44:11,198: EPOCH 15: training on 191080 raw words (115611 effective words) took 0.3s, 450923 effective words/s
INFO - 2023-11-30 15:44:11,461: EPOCH 16: training on 191080 raw words (115834 effective words) took 0.3s, 446849 effective words/s
INFO - 2023-11-30 15:44:11,769: EPOCH 17: training on 191080 raw words (115777 effective words) took 0.3s, 377814 effective words/s
INFO - 2023-11-30 15:44:12,055: EPOCH 18: training on 191080 raw words (115830 effective words) took 0.3s, 410243 effective words/s
INFO - 2023-11-30 15:44:12,380: EPOCH 19: training on 191080 raw words (115665 effective words) took 0.3s, 359052 effective words/s
INFO - 2023-11-30 15:44:12,380: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2316021 effective words) took 5.9s, 395258 effective words/s', 'datetime': '2023-11-30T15:44:12.380745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:12,381: collecting all words and their counts
INFO - 2023-11-30 15:44:12,381: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:12,418: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:12,418: Updating model with new vocabulary
INFO - 2023-11-30 15:44:12,437: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:12.437280', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:12,461: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:12,462: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:44:12,462: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115542.01526857825 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:44:12.462453', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:12,504: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:12,504: updating layer weights
INFO - 2023-11-30 15:44:12,504: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:12.504699', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:12,504: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:12,505: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:12.505011', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:12,916: EPOCH 0: training on 191080 raw words (115435 effective words) took 0.4s, 283182 effective words/s
INFO - 2023-11-30 15:44:13,250: EPOCH 1: training on 191080 raw words (115472 effective words) took 0.3s, 348671 effective words/s
INFO - 2023-11-30 15:44:13,689: EPOCH 2: training on 191080 raw words (115871 effective words) took 0.4s, 265813 effective words/s
INFO - 2023-11-30 15:44:14,099: EPOCH 3: training on 191080 raw words (115639 effective words) took 0.4s, 285035 effective words/s
INFO - 2023-11-30 15:44:14,437: EPOCH 4: training on 191080 raw words (115418 effective words) took 0.3s, 344305 effective words/s
INFO - 2023-11-30 15:44:14,795: EPOCH 5: training on 191080 raw words (115615 effective words) took 0.4s, 325566 effective words/s
INFO - 2023-11-30 15:44:15,200: EPOCH 6: training on 191080 raw words (115581 effective words) took 0.4s, 288145 effective words/s
INFO - 2023-11-30 15:44:15,556: EPOCH 7: training on 191080 raw words (115898 effective words) took 0.4s, 328721 effective words/s
INFO - 2023-11-30 15:44:15,908: EPOCH 8: training on 191080 raw words (115440 effective words) took 0.3s, 336971 effective words/s
INFO - 2023-11-30 15:44:16,264: EPOCH 9: training on 191080 raw words (115547 effective words) took 0.4s, 326831 effective words/s
INFO - 2023-11-30 15:44:16,621: EPOCH 10: training on 191080 raw words (115643 effective words) took 0.4s, 327317 effective words/s
INFO - 2023-11-30 15:44:16,989: EPOCH 11: training on 191080 raw words (115295 effective words) took 0.4s, 316540 effective words/s
INFO - 2023-11-30 15:44:17,355: EPOCH 12: training on 191080 raw words (115445 effective words) took 0.4s, 318336 effective words/s
INFO - 2023-11-30 15:44:17,717: EPOCH 13: training on 191080 raw words (115630 effective words) took 0.4s, 322669 effective words/s
INFO - 2023-11-30 15:44:18,057: EPOCH 14: training on 191080 raw words (115530 effective words) took 0.3s, 342759 effective words/s
INFO - 2023-11-30 15:44:18,405: EPOCH 15: training on 191080 raw words (115474 effective words) took 0.3s, 335728 effective words/s
INFO - 2023-11-30 15:44:18,736: EPOCH 16: training on 191080 raw words (115358 effective words) took 0.3s, 351396 effective words/s
INFO - 2023-11-30 15:44:19,118: EPOCH 17: training on 191080 raw words (115532 effective words) took 0.4s, 305329 effective words/s
INFO - 2023-11-30 15:44:19,453: EPOCH 18: training on 191080 raw words (115508 effective words) took 0.3s, 347741 effective words/s
INFO - 2023-11-30 15:44:19,789: EPOCH 19: training on 191080 raw words (115524 effective words) took 0.3s, 346484 effective words/s
INFO - 2023-11-30 15:44:19,790: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310855 effective words) took 7.3s, 317201 effective words/s', 'datetime': '2023-11-30T15:44:19.790346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:19,790: collecting all words and their counts
INFO - 2023-11-30 15:44:19,791: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:19,829: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:19,829: Updating model with new vocabulary
INFO - 2023-11-30 15:44:19,847: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:19.847761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:19,870: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:19,870: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:44:19,871: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115270.31989210704 word corpus (60.3%% of prior 191080)', 'datetime': '2023-11-30T15:44:19.871203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:19,906: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:19,906: updating layer weights
INFO - 2023-11-30 15:44:19,906: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:19.906867', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:19,907: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:19,907: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:19.907169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:20,220: EPOCH 0: training on 191080 raw words (115404 effective words) took 0.3s, 372641 effective words/s
INFO - 2023-11-30 15:44:20,534: EPOCH 1: training on 191080 raw words (115138 effective words) took 0.3s, 370782 effective words/s
INFO - 2023-11-30 15:44:20,851: EPOCH 2: training on 191080 raw words (115144 effective words) took 0.3s, 366233 effective words/s
INFO - 2023-11-30 15:44:21,134: EPOCH 3: training on 191080 raw words (115340 effective words) took 0.3s, 413889 effective words/s
INFO - 2023-11-30 15:44:21,423: EPOCH 4: training on 191080 raw words (115422 effective words) took 0.3s, 403038 effective words/s
INFO - 2023-11-30 15:44:21,655: EPOCH 5: training on 191080 raw words (115349 effective words) took 0.2s, 502163 effective words/s
INFO - 2023-11-30 15:44:21,885: EPOCH 6: training on 191080 raw words (115283 effective words) took 0.2s, 504258 effective words/s
INFO - 2023-11-30 15:44:22,122: EPOCH 7: training on 191080 raw words (115231 effective words) took 0.2s, 491801 effective words/s
INFO - 2023-11-30 15:44:22,364: EPOCH 8: training on 191080 raw words (115072 effective words) took 0.2s, 481342 effective words/s
INFO - 2023-11-30 15:44:22,626: EPOCH 9: training on 191080 raw words (115118 effective words) took 0.3s, 443656 effective words/s
INFO - 2023-11-30 15:44:22,870: EPOCH 10: training on 191080 raw words (115113 effective words) took 0.2s, 477294 effective words/s
INFO - 2023-11-30 15:44:23,111: EPOCH 11: training on 191080 raw words (115305 effective words) took 0.2s, 482826 effective words/s
INFO - 2023-11-30 15:44:23,354: EPOCH 12: training on 191080 raw words (115599 effective words) took 0.2s, 481908 effective words/s
INFO - 2023-11-30 15:44:23,601: EPOCH 13: training on 191080 raw words (115181 effective words) took 0.2s, 472591 effective words/s
INFO - 2023-11-30 15:44:23,848: EPOCH 14: training on 191080 raw words (115008 effective words) took 0.2s, 468914 effective words/s
INFO - 2023-11-30 15:44:24,088: EPOCH 15: training on 191080 raw words (115290 effective words) took 0.2s, 486973 effective words/s
INFO - 2023-11-30 15:44:24,319: EPOCH 16: training on 191080 raw words (115050 effective words) took 0.2s, 502298 effective words/s
INFO - 2023-11-30 15:44:24,552: EPOCH 17: training on 191080 raw words (115332 effective words) took 0.2s, 499826 effective words/s
INFO - 2023-11-30 15:44:24,787: EPOCH 18: training on 191080 raw words (115317 effective words) took 0.2s, 495496 effective words/s
INFO - 2023-11-30 15:44:25,025: EPOCH 19: training on 191080 raw words (115359 effective words) took 0.2s, 489678 effective words/s
INFO - 2023-11-30 15:44:25,025: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2305055 effective words) took 5.1s, 450350 effective words/s', 'datetime': '2023-11-30T15:44:25.025670', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:25,025: collecting all words and their counts
INFO - 2023-11-30 15:44:25,026: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:25,052: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:25,053: Updating model with new vocabulary
INFO - 2023-11-30 15:44:25,066: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:25.065955', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:25,081: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:25,081: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:44:25,081: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115560.41378286049 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:44:25.081828', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:25,106: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:25,106: updating layer weights
INFO - 2023-11-30 15:44:25,107: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:25.107210', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:25,107: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:25,107: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:25.107472', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:25,351: EPOCH 0: training on 191080 raw words (115848 effective words) took 0.2s, 479316 effective words/s
INFO - 2023-11-30 15:44:25,627: EPOCH 1: training on 191080 raw words (115708 effective words) took 0.3s, 421668 effective words/s
INFO - 2023-11-30 15:44:25,872: EPOCH 2: training on 191080 raw words (115584 effective words) took 0.2s, 477410 effective words/s
INFO - 2023-11-30 15:44:26,162: EPOCH 3: training on 191080 raw words (115519 effective words) took 0.3s, 401392 effective words/s
INFO - 2023-11-30 15:44:26,413: EPOCH 4: training on 191080 raw words (115496 effective words) took 0.2s, 463672 effective words/s
INFO - 2023-11-30 15:44:26,686: EPOCH 5: training on 191080 raw words (115628 effective words) took 0.3s, 428337 effective words/s
INFO - 2023-11-30 15:44:26,991: EPOCH 6: training on 191080 raw words (115543 effective words) took 0.3s, 383058 effective words/s
INFO - 2023-11-30 15:44:27,234: EPOCH 7: training on 191080 raw words (115498 effective words) took 0.2s, 480114 effective words/s
INFO - 2023-11-30 15:44:27,477: EPOCH 8: training on 191080 raw words (115643 effective words) took 0.2s, 480836 effective words/s
INFO - 2023-11-30 15:44:27,724: EPOCH 9: training on 191080 raw words (115695 effective words) took 0.2s, 471755 effective words/s
INFO - 2023-11-30 15:44:27,969: EPOCH 10: training on 191080 raw words (115671 effective words) took 0.2s, 476902 effective words/s
INFO - 2023-11-30 15:44:28,228: EPOCH 11: training on 191080 raw words (115499 effective words) took 0.3s, 451783 effective words/s
INFO - 2023-11-30 15:44:28,486: EPOCH 12: training on 191080 raw words (115755 effective words) took 0.3s, 452337 effective words/s
INFO - 2023-11-30 15:44:28,750: EPOCH 13: training on 191080 raw words (115426 effective words) took 0.3s, 441230 effective words/s
INFO - 2023-11-30 15:44:29,011: EPOCH 14: training on 191080 raw words (115545 effective words) took 0.3s, 445858 effective words/s
INFO - 2023-11-30 15:44:29,282: EPOCH 15: training on 191080 raw words (115605 effective words) took 0.3s, 432448 effective words/s
INFO - 2023-11-30 15:44:29,550: EPOCH 16: training on 191080 raw words (115488 effective words) took 0.3s, 434480 effective words/s
INFO - 2023-11-30 15:44:29,823: EPOCH 17: training on 191080 raw words (115679 effective words) took 0.3s, 427776 effective words/s
INFO - 2023-11-30 15:44:30,123: EPOCH 18: training on 191080 raw words (115644 effective words) took 0.3s, 389993 effective words/s
INFO - 2023-11-30 15:44:30,418: EPOCH 19: training on 191080 raw words (115560 effective words) took 0.3s, 394115 effective words/s
INFO - 2023-11-30 15:44:30,419: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2312034 effective words) took 5.3s, 435282 effective words/s', 'datetime': '2023-11-30T15:44:30.419186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:30,419: collecting all words and their counts
INFO - 2023-11-30 15:44:30,419: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:30,452: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:30,453: Updating model with new vocabulary
INFO - 2023-11-30 15:44:30,467: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:30.467142', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:30,487: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:30,488: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:44:30,488: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115412.82603442098 word corpus (60.4%% of prior 191080)', 'datetime': '2023-11-30T15:44:30.488768', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:30,520: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:30,520: updating layer weights
INFO - 2023-11-30 15:44:30,521: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:30.521704', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:30,521: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:30,522: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:30.522072', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:30,799: EPOCH 0: training on 191080 raw words (115661 effective words) took 0.3s, 422776 effective words/s
INFO - 2023-11-30 15:44:31,068: EPOCH 1: training on 191080 raw words (115525 effective words) took 0.3s, 433930 effective words/s
INFO - 2023-11-30 15:44:31,370: EPOCH 2: training on 191080 raw words (115187 effective words) took 0.3s, 385811 effective words/s
INFO - 2023-11-30 15:44:31,643: EPOCH 3: training on 191080 raw words (115328 effective words) took 0.3s, 427078 effective words/s
INFO - 2023-11-30 15:44:31,901: EPOCH 4: training on 191080 raw words (115369 effective words) took 0.3s, 450903 effective words/s
INFO - 2023-11-30 15:44:32,159: EPOCH 5: training on 191080 raw words (115436 effective words) took 0.3s, 453431 effective words/s
INFO - 2023-11-30 15:44:32,411: EPOCH 6: training on 191080 raw words (115623 effective words) took 0.2s, 463745 effective words/s
INFO - 2023-11-30 15:44:32,675: EPOCH 7: training on 191080 raw words (115446 effective words) took 0.3s, 441630 effective words/s
INFO - 2023-11-30 15:44:32,983: EPOCH 8: training on 191080 raw words (115444 effective words) took 0.3s, 377573 effective words/s
INFO - 2023-11-30 15:44:33,238: EPOCH 9: training on 191080 raw words (115480 effective words) took 0.3s, 460041 effective words/s
INFO - 2023-11-30 15:44:33,487: EPOCH 10: training on 191080 raw words (115540 effective words) took 0.2s, 468338 effective words/s
INFO - 2023-11-30 15:44:33,737: EPOCH 11: training on 191080 raw words (115559 effective words) took 0.2s, 468048 effective words/s
INFO - 2023-11-30 15:44:33,980: EPOCH 12: training on 191080 raw words (115300 effective words) took 0.2s, 479652 effective words/s
INFO - 2023-11-30 15:44:34,228: EPOCH 13: training on 191080 raw words (115456 effective words) took 0.2s, 468540 effective words/s
INFO - 2023-11-30 15:44:34,468: EPOCH 14: training on 191080 raw words (115378 effective words) took 0.2s, 486968 effective words/s
INFO - 2023-11-30 15:44:34,702: EPOCH 15: training on 191080 raw words (115379 effective words) took 0.2s, 500626 effective words/s
INFO - 2023-11-30 15:44:34,955: EPOCH 16: training on 191080 raw words (115413 effective words) took 0.3s, 460183 effective words/s
INFO - 2023-11-30 15:44:35,193: EPOCH 17: training on 191080 raw words (115366 effective words) took 0.2s, 489227 effective words/s
INFO - 2023-11-30 15:44:35,427: EPOCH 18: training on 191080 raw words (115303 effective words) took 0.2s, 498494 effective words/s
INFO - 2023-11-30 15:44:35,666: EPOCH 19: training on 191080 raw words (115345 effective words) took 0.2s, 488525 effective words/s
INFO - 2023-11-30 15:44:35,666: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2308538 effective words) took 5.1s, 448757 effective words/s', 'datetime': '2023-11-30T15:44:35.666594', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:35,666: collecting all words and their counts
INFO - 2023-11-30 15:44:35,666: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:35,695: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:35,695: Updating model with new vocabulary
INFO - 2023-11-30 15:44:35,708: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:35.708620', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:35,724: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:35,724: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:44:35,724: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115712.67953472397 word corpus (60.6%% of prior 191080)', 'datetime': '2023-11-30T15:44:35.724739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:35,750: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:35,750: updating layer weights
INFO - 2023-11-30 15:44:35,751: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:35.751372', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:35,751: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:35,751: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:35.751653', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:35,999: EPOCH 0: training on 191080 raw words (115723 effective words) took 0.2s, 472296 effective words/s
INFO - 2023-11-30 15:44:36,248: EPOCH 1: training on 191080 raw words (115787 effective words) took 0.2s, 468923 effective words/s
INFO - 2023-11-30 15:44:36,584: EPOCH 2: training on 191080 raw words (115720 effective words) took 0.3s, 346546 effective words/s
INFO - 2023-11-30 15:44:36,918: EPOCH 3: training on 191080 raw words (115640 effective words) took 0.3s, 349980 effective words/s
INFO - 2023-11-30 15:44:37,254: EPOCH 4: training on 191080 raw words (115962 effective words) took 0.3s, 349746 effective words/s
INFO - 2023-11-30 15:44:37,593: EPOCH 5: training on 191080 raw words (115723 effective words) took 0.3s, 362677 effective words/s
INFO - 2023-11-30 15:44:37,929: EPOCH 6: training on 191080 raw words (115997 effective words) took 0.3s, 347813 effective words/s
INFO - 2023-11-30 15:44:38,287: EPOCH 7: training on 191080 raw words (115911 effective words) took 0.4s, 327412 effective words/s
INFO - 2023-11-30 15:44:38,649: EPOCH 8: training on 191080 raw words (115646 effective words) took 0.4s, 322016 effective words/s
INFO - 2023-11-30 15:44:39,008: EPOCH 9: training on 191080 raw words (115772 effective words) took 0.4s, 325540 effective words/s
INFO - 2023-11-30 15:44:39,433: EPOCH 10: training on 191080 raw words (115650 effective words) took 0.4s, 273712 effective words/s
INFO - 2023-11-30 15:44:39,813: EPOCH 11: training on 191080 raw words (115650 effective words) took 0.4s, 307662 effective words/s
INFO - 2023-11-30 15:44:40,193: EPOCH 12: training on 191080 raw words (115822 effective words) took 0.4s, 307387 effective words/s
INFO - 2023-11-30 15:44:40,572: EPOCH 13: training on 191080 raw words (115723 effective words) took 0.4s, 309143 effective words/s
INFO - 2023-11-30 15:44:40,957: EPOCH 14: training on 191080 raw words (115687 effective words) took 0.4s, 303262 effective words/s
INFO - 2023-11-30 15:44:41,334: EPOCH 15: training on 191080 raw words (115882 effective words) took 0.4s, 309968 effective words/s
INFO - 2023-11-30 15:44:41,703: EPOCH 16: training on 191080 raw words (115720 effective words) took 0.4s, 316047 effective words/s
INFO - 2023-11-30 15:44:42,086: EPOCH 17: training on 191080 raw words (115675 effective words) took 0.4s, 305649 effective words/s
INFO - 2023-11-30 15:44:42,498: EPOCH 18: training on 191080 raw words (115670 effective words) took 0.4s, 301765 effective words/s
INFO - 2023-11-30 15:44:42,884: EPOCH 19: training on 191080 raw words (115644 effective words) took 0.4s, 303137 effective words/s
INFO - 2023-11-30 15:44:42,884: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2315004 effective words) took 7.1s, 324545 effective words/s', 'datetime': '2023-11-30T15:44:42.884876', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:42,885: collecting all words and their counts
INFO - 2023-11-30 15:44:42,885: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:42,928: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:42,928: Updating model with new vocabulary
INFO - 2023-11-30 15:44:42,947: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:42.947385', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:42,980: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:42,981: sample=0.001 downsamples 32 most-common words
INFO - 2023-11-30 15:44:42,981: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115515.81719631405 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:44:42.981640', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:43,038: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:43,038: updating layer weights
INFO - 2023-11-30 15:44:43,039: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:43.039359', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:43,039: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:43,039: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:43.039746', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:43,431: EPOCH 0: training on 191080 raw words (115528 effective words) took 0.4s, 298290 effective words/s
INFO - 2023-11-30 15:44:43,793: EPOCH 1: training on 191080 raw words (115413 effective words) took 0.4s, 323222 effective words/s
INFO - 2023-11-30 15:44:44,163: EPOCH 2: training on 191080 raw words (115344 effective words) took 0.4s, 314675 effective words/s
INFO - 2023-11-30 15:44:44,541: EPOCH 3: training on 191080 raw words (115557 effective words) took 0.4s, 308671 effective words/s
INFO - 2023-11-30 15:44:44,921: EPOCH 4: training on 191080 raw words (115455 effective words) took 0.4s, 306920 effective words/s
INFO - 2023-11-30 15:44:45,296: EPOCH 5: training on 191080 raw words (115402 effective words) took 0.4s, 311002 effective words/s
INFO - 2023-11-30 15:44:45,545: EPOCH 6: training on 191080 raw words (115443 effective words) took 0.2s, 466497 effective words/s
INFO - 2023-11-30 15:44:45,790: EPOCH 7: training on 191080 raw words (115320 effective words) took 0.2s, 475589 effective words/s
INFO - 2023-11-30 15:44:46,047: EPOCH 8: training on 191080 raw words (115824 effective words) took 0.3s, 458098 effective words/s
INFO - 2023-11-30 15:44:46,295: EPOCH 9: training on 191080 raw words (115586 effective words) took 0.2s, 471820 effective words/s
INFO - 2023-11-30 15:44:46,532: EPOCH 10: training on 191080 raw words (115558 effective words) took 0.2s, 491658 effective words/s
INFO - 2023-11-30 15:44:46,803: EPOCH 11: training on 191080 raw words (115583 effective words) took 0.3s, 432123 effective words/s
INFO - 2023-11-30 15:44:47,140: EPOCH 12: training on 191080 raw words (115534 effective words) took 0.3s, 345768 effective words/s
INFO - 2023-11-30 15:44:47,415: EPOCH 13: training on 191080 raw words (115480 effective words) took 0.3s, 422774 effective words/s
INFO - 2023-11-30 15:44:47,665: EPOCH 14: training on 191080 raw words (115615 effective words) took 0.2s, 469364 effective words/s
INFO - 2023-11-30 15:44:47,918: EPOCH 15: training on 191080 raw words (115304 effective words) took 0.3s, 459895 effective words/s
INFO - 2023-11-30 15:44:48,163: EPOCH 16: training on 191080 raw words (115503 effective words) took 0.2s, 475814 effective words/s
INFO - 2023-11-30 15:44:48,413: EPOCH 17: training on 191080 raw words (115633 effective words) took 0.2s, 467605 effective words/s
INFO - 2023-11-30 15:44:48,655: EPOCH 18: training on 191080 raw words (115581 effective words) took 0.2s, 482358 effective words/s
INFO - 2023-11-30 15:44:48,955: EPOCH 19: training on 191080 raw words (115592 effective words) took 0.3s, 389135 effective words/s
INFO - 2023-11-30 15:44:48,956: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2310255 effective words) took 5.9s, 390516 effective words/s', 'datetime': '2023-11-30T15:44:48.956059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:48,956: collecting all words and their counts
INFO - 2023-11-30 15:44:48,956: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-30 15:44:48,988: collected 4777 word types from a corpus of 191080 raw words and 4777 sentences
INFO - 2023-11-30 15:44:48,988: Updating model with new vocabulary
INFO - 2023-11-30 15:44:49,006: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 4777) and increased the count of 4777 pre-existing words (100.00% of original 4777)', 'datetime': '2023-11-30T15:44:49.006814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:49,029: deleting the raw counts dictionary of 4777 items
INFO - 2023-11-30 15:44:49,029: sample=0.001 downsamples 33 most-common words
INFO - 2023-11-30 15:44:49,029: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 115665.33247192421 word corpus (60.5%% of prior 191080)', 'datetime': '2023-11-30T15:44:49.029625', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-30 15:44:49,057: estimated required memory for 4777 words and 128 dimensions: 7280148 bytes
INFO - 2023-11-30 15:44:49,057: updating layer weights
INFO - 2023-11-30 15:44:49,058: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-30T15:44:49.058550', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-30 15:44:49,058: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-30 15:44:49,058: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4777 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-30T15:44:49.058843', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:49,337: EPOCH 0: training on 191080 raw words (115792 effective words) took 0.3s, 422518 effective words/s
INFO - 2023-11-30 15:44:49,655: EPOCH 1: training on 191080 raw words (115634 effective words) took 0.3s, 367647 effective words/s
INFO - 2023-11-30 15:44:49,979: EPOCH 2: training on 191080 raw words (115780 effective words) took 0.3s, 362173 effective words/s
INFO - 2023-11-30 15:44:50,284: EPOCH 3: training on 191080 raw words (115613 effective words) took 0.3s, 383737 effective words/s
INFO - 2023-11-30 15:44:50,598: EPOCH 4: training on 191080 raw words (115629 effective words) took 0.3s, 376958 effective words/s
INFO - 2023-11-30 15:44:50,864: EPOCH 5: training on 191080 raw words (115779 effective words) took 0.3s, 441416 effective words/s
INFO - 2023-11-30 15:44:51,122: EPOCH 6: training on 191080 raw words (115766 effective words) took 0.3s, 452896 effective words/s
INFO - 2023-11-30 15:44:51,397: EPOCH 7: training on 191080 raw words (115553 effective words) took 0.3s, 424436 effective words/s
INFO - 2023-11-30 15:44:51,654: EPOCH 8: training on 191080 raw words (115729 effective words) took 0.3s, 455680 effective words/s
INFO - 2023-11-30 15:44:51,942: EPOCH 9: training on 191080 raw words (115637 effective words) took 0.3s, 404860 effective words/s
INFO - 2023-11-30 15:44:52,196: EPOCH 10: training on 191080 raw words (115715 effective words) took 0.3s, 460051 effective words/s
INFO - 2023-11-30 15:44:52,474: EPOCH 11: training on 191080 raw words (115555 effective words) took 0.3s, 419425 effective words/s
INFO - 2023-11-30 15:44:52,737: EPOCH 12: training on 191080 raw words (115504 effective words) took 0.3s, 444157 effective words/s
INFO - 2023-11-30 15:44:53,017: EPOCH 13: training on 191080 raw words (115625 effective words) took 0.3s, 417087 effective words/s
INFO - 2023-11-30 15:44:53,333: EPOCH 14: training on 191080 raw words (116023 effective words) took 0.3s, 369253 effective words/s
INFO - 2023-11-30 15:44:53,592: EPOCH 15: training on 191080 raw words (115535 effective words) took 0.3s, 451051 effective words/s
INFO - 2023-11-30 15:44:53,847: EPOCH 16: training on 191080 raw words (115511 effective words) took 0.3s, 456045 effective words/s
INFO - 2023-11-30 15:44:54,106: EPOCH 17: training on 191080 raw words (115640 effective words) took 0.3s, 450880 effective words/s
INFO - 2023-11-30 15:44:54,383: EPOCH 18: training on 191080 raw words (115538 effective words) took 0.3s, 420715 effective words/s
INFO - 2023-11-30 15:44:54,665: EPOCH 19: training on 191080 raw words (115715 effective words) took 0.3s, 414909 effective words/s
INFO - 2023-11-30 15:44:54,665: Word2Vec lifecycle event {'msg': 'training on 3821600 raw words (2313273 effective words) took 5.6s, 412601 effective words/s', 'datetime': '2023-11-30T15:44:54.665538', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-30 15:44:54,672: storing 4777x128 projection weights into POS.txt
