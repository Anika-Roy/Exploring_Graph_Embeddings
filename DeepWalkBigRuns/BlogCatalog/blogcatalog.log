INFO - 2023-11-27 13:05:11,391: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-27T13:05:11.380312', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-27 13:05:11,391: collecting all words and their counts
INFO - 2023-11-27 13:05:11,391: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:05:11,453: PROGRESS: at sentence #10000, processed 400000 words, keeping 10303 word types
INFO - 2023-11-27 13:05:11,455: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:05:11,455: Creating a fresh vocabulary
INFO - 2023-11-27 13:05:11,476: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 10312 unique words (100.00% of original 10312, drops 0)', 'datetime': '2023-11-27T13:05:11.476563', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:11,476: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 412480 word corpus (100.00% of original 412480, drops 0)', 'datetime': '2023-11-27T13:05:11.476753', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:11,509: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:05:11,510: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:05:11,510: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403550.97629778157 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:05:11.510776', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:11,565: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:05:11,565: resetting layer weights
INFO - 2023-11-27 13:05:11,569: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-27T13:05:11.569807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-27 13:05:11,569: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:05:11.569979', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:05:12,420: EPOCH 0: training on 412480 raw words (403566 effective words) took 0.8s, 490912 effective words/s
INFO - 2023-11-27 13:05:13,262: EPOCH 1: training on 412480 raw words (403544 effective words) took 0.8s, 480524 effective words/s
INFO - 2023-11-27 13:05:14,193: EPOCH 2: training on 412480 raw words (403615 effective words) took 0.9s, 434363 effective words/s
INFO - 2023-11-27 13:05:15,034: EPOCH 3: training on 412480 raw words (403605 effective words) took 0.8s, 480935 effective words/s
INFO - 2023-11-27 13:05:15,846: EPOCH 4: training on 412480 raw words (403630 effective words) took 0.8s, 498381 effective words/s
INFO - 2023-11-27 13:05:16,717: EPOCH 5: training on 412480 raw words (403592 effective words) took 0.9s, 464364 effective words/s
INFO - 2023-11-27 13:05:17,544: EPOCH 6: training on 412480 raw words (403560 effective words) took 0.8s, 489507 effective words/s
INFO - 2023-11-27 13:05:18,411: EPOCH 7: training on 412480 raw words (403700 effective words) took 0.9s, 466337 effective words/s
INFO - 2023-11-27 13:05:19,296: EPOCH 8: training on 412480 raw words (403529 effective words) took 0.9s, 457146 effective words/s
INFO - 2023-11-27 13:05:20,149: EPOCH 9: training on 412480 raw words (403539 effective words) took 0.9s, 474132 effective words/s
INFO - 2023-11-27 13:05:20,963: EPOCH 10: training on 412480 raw words (403564 effective words) took 0.8s, 497228 effective words/s
INFO - 2023-11-27 13:05:21,811: EPOCH 11: training on 412480 raw words (403546 effective words) took 0.8s, 476827 effective words/s
INFO - 2023-11-27 13:05:22,662: EPOCH 12: training on 412480 raw words (403445 effective words) took 0.8s, 475282 effective words/s
INFO - 2023-11-27 13:05:23,523: EPOCH 13: training on 412480 raw words (403675 effective words) took 0.9s, 470372 effective words/s
INFO - 2023-11-27 13:05:24,542: EPOCH 14 - PROGRESS: at 100.00% examples, 396707 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:05:24,542: EPOCH 14: training on 412480 raw words (403662 effective words) took 1.0s, 396610 effective words/s
INFO - 2023-11-27 13:05:25,548: EPOCH 15 - PROGRESS: at 97.58% examples, 392523 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:05:25,655: EPOCH 15: training on 412480 raw words (403540 effective words) took 1.1s, 363495 effective words/s
INFO - 2023-11-27 13:05:26,664: EPOCH 16 - PROGRESS: at 87.88% examples, 352356 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:05:26,742: EPOCH 16: training on 412480 raw words (403558 effective words) took 1.1s, 371983 effective words/s
INFO - 2023-11-27 13:05:27,751: EPOCH 17 - PROGRESS: at 92.73% examples, 371710 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:05:27,843: EPOCH 17: training on 412480 raw words (403480 effective words) took 1.1s, 367299 effective words/s
INFO - 2023-11-27 13:05:28,848: EPOCH 18 - PROGRESS: at 82.43% examples, 331891 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:05:28,980: EPOCH 18: training on 412480 raw words (403518 effective words) took 1.1s, 355892 effective words/s
INFO - 2023-11-27 13:05:29,986: EPOCH 19 - PROGRESS: at 87.28% examples, 351619 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:05:30,087: EPOCH 19: training on 412480 raw words (403554 effective words) took 1.1s, 366068 effective words/s
INFO - 2023-11-27 13:05:30,087: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071422 effective words) took 18.5s, 435878 effective words/s', 'datetime': '2023-11-27T13:05:30.087723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:05:30,087: collecting all words and their counts
INFO - 2023-11-27 13:05:30,088: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:05:30,184: PROGRESS: at sentence #10000, processed 400000 words, keeping 10297 word types
INFO - 2023-11-27 13:05:30,186: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:05:30,187: Updating model with new vocabulary
INFO - 2023-11-27 13:05:30,222: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:05:30.222754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:30,269: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:05:30,269: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:05:30,269: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403678.2383642935 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:05:30.269488', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:30,353: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:05:30,353: updating layer weights
INFO - 2023-11-27 13:05:30,355: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:05:30.355218', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:05:30,355: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:05:30,355: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:05:30.355469', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:05:31,410: EPOCH 0 - PROGRESS: at 75.16% examples, 288352 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:05:31,617: EPOCH 0: training on 412480 raw words (403751 effective words) took 1.3s, 320678 effective words/s
INFO - 2023-11-27 13:05:32,648: EPOCH 1 - PROGRESS: at 75.16% examples, 294935 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:05:32,857: EPOCH 1: training on 412480 raw words (403757 effective words) took 1.2s, 326211 effective words/s
INFO - 2023-11-27 13:05:33,930: EPOCH 2 - PROGRESS: at 75.16% examples, 283270 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:05:34,112: EPOCH 2: training on 412480 raw words (403632 effective words) took 1.3s, 322089 effective words/s
INFO - 2023-11-27 13:05:35,146: EPOCH 3 - PROGRESS: at 75.16% examples, 294255 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:05:35,356: EPOCH 3: training on 412480 raw words (403729 effective words) took 1.2s, 325370 effective words/s
INFO - 2023-11-27 13:05:36,360: EPOCH 4 - PROGRESS: at 80.00% examples, 322813 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:05:36,458: EPOCH 4: training on 412480 raw words (403624 effective words) took 1.1s, 367670 effective words/s
INFO - 2023-11-27 13:05:37,329: EPOCH 5: training on 412480 raw words (403583 effective words) took 0.9s, 464346 effective words/s
INFO - 2023-11-27 13:05:38,246: EPOCH 6: training on 412480 raw words (403644 effective words) took 0.9s, 440949 effective words/s
INFO - 2023-11-27 13:05:39,121: EPOCH 7: training on 412480 raw words (403655 effective words) took 0.9s, 462763 effective words/s
INFO - 2023-11-27 13:05:40,073: EPOCH 8: training on 412480 raw words (403860 effective words) took 1.0s, 424910 effective words/s
INFO - 2023-11-27 13:05:40,928: EPOCH 9: training on 412480 raw words (403714 effective words) took 0.9s, 473492 effective words/s
INFO - 2023-11-27 13:05:41,784: EPOCH 10: training on 412480 raw words (403772 effective words) took 0.9s, 472213 effective words/s
INFO - 2023-11-27 13:05:42,675: EPOCH 11: training on 412480 raw words (403646 effective words) took 0.9s, 454271 effective words/s
INFO - 2023-11-27 13:05:43,556: EPOCH 12: training on 412480 raw words (403559 effective words) took 0.9s, 459225 effective words/s
INFO - 2023-11-27 13:05:44,417: EPOCH 13: training on 412480 raw words (403693 effective words) took 0.9s, 469623 effective words/s
INFO - 2023-11-27 13:05:45,300: EPOCH 14: training on 412480 raw words (403812 effective words) took 0.9s, 458793 effective words/s
INFO - 2023-11-27 13:05:46,131: EPOCH 15: training on 412480 raw words (403754 effective words) took 0.8s, 486608 effective words/s
INFO - 2023-11-27 13:05:47,016: EPOCH 16: training on 412480 raw words (403627 effective words) took 0.9s, 457313 effective words/s
INFO - 2023-11-27 13:05:47,887: EPOCH 17: training on 412480 raw words (403585 effective words) took 0.9s, 464820 effective words/s
INFO - 2023-11-27 13:05:48,790: EPOCH 18: training on 412480 raw words (403649 effective words) took 0.9s, 447782 effective words/s
INFO - 2023-11-27 13:05:49,659: EPOCH 19: training on 412480 raw words (403544 effective words) took 0.9s, 465755 effective words/s
INFO - 2023-11-27 13:05:49,660: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073590 effective words) took 19.3s, 418223 effective words/s', 'datetime': '2023-11-27T13:05:49.660079', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:05:49,660: collecting all words and their counts
INFO - 2023-11-27 13:05:49,660: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:05:49,716: PROGRESS: at sentence #10000, processed 400000 words, keeping 10307 word types
INFO - 2023-11-27 13:05:49,718: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:05:49,718: Updating model with new vocabulary
INFO - 2023-11-27 13:05:49,743: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:05:49.743336', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:49,773: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:05:49,773: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:05:49,773: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403733.2736901526 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:05:49.773967', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:05:49,822: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:05:49,822: updating layer weights
INFO - 2023-11-27 13:05:49,823: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:05:49.823430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:05:49,823: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:05:49,823: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:05:49.823591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:05:50,634: EPOCH 0: training on 412480 raw words (403780 effective words) took 0.8s, 499301 effective words/s
INFO - 2023-11-27 13:05:51,495: EPOCH 1: training on 412480 raw words (403668 effective words) took 0.9s, 469581 effective words/s
INFO - 2023-11-27 13:05:52,326: EPOCH 2: training on 412480 raw words (403736 effective words) took 0.8s, 487142 effective words/s
INFO - 2023-11-27 13:05:53,188: EPOCH 3: training on 412480 raw words (403687 effective words) took 0.9s, 469700 effective words/s
INFO - 2023-11-27 13:05:54,049: EPOCH 4: training on 412480 raw words (403865 effective words) took 0.9s, 470183 effective words/s
INFO - 2023-11-27 13:05:54,906: EPOCH 5: training on 412480 raw words (403844 effective words) took 0.9s, 473257 effective words/s
INFO - 2023-11-27 13:05:55,766: EPOCH 6: training on 412480 raw words (403695 effective words) took 0.9s, 471005 effective words/s
INFO - 2023-11-27 13:05:56,739: EPOCH 7: training on 412480 raw words (403832 effective words) took 1.0s, 416015 effective words/s
INFO - 2023-11-27 13:05:57,821: EPOCH 8 - PROGRESS: at 100.00% examples, 373968 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:05:57,821: EPOCH 8: training on 412480 raw words (403647 effective words) took 1.1s, 373869 effective words/s
INFO - 2023-11-27 13:05:58,879: EPOCH 9 - PROGRESS: at 100.00% examples, 382884 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:05:58,879: EPOCH 9: training on 412480 raw words (403766 effective words) took 1.1s, 382793 effective words/s
INFO - 2023-11-27 13:05:59,924: EPOCH 10 - PROGRESS: at 77.58% examples, 300433 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:06:00,010: EPOCH 10: training on 412480 raw words (403748 effective words) took 1.1s, 357558 effective words/s
INFO - 2023-11-27 13:06:01,110: EPOCH 11 - PROGRESS: at 100.00% examples, 368097 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:01,110: EPOCH 11: training on 412480 raw words (403719 effective words) took 1.1s, 368016 effective words/s
INFO - 2023-11-27 13:06:02,118: EPOCH 12 - PROGRESS: at 84.85% examples, 340879 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:06:02,230: EPOCH 12: training on 412480 raw words (403699 effective words) took 1.1s, 361490 effective words/s
INFO - 2023-11-27 13:06:03,212: EPOCH 13: training on 412480 raw words (403709 effective words) took 1.0s, 412201 effective words/s
INFO - 2023-11-27 13:06:04,233: EPOCH 14 - PROGRESS: at 100.00% examples, 396247 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:04,233: EPOCH 14: training on 412480 raw words (403771 effective words) took 1.0s, 396143 effective words/s
INFO - 2023-11-27 13:06:05,260: EPOCH 15 - PROGRESS: at 100.00% examples, 394089 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:05,261: EPOCH 15: training on 412480 raw words (403719 effective words) took 1.0s, 393995 effective words/s
INFO - 2023-11-27 13:06:06,282: EPOCH 16 - PROGRESS: at 100.00% examples, 396720 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:06,282: EPOCH 16: training on 412480 raw words (403673 effective words) took 1.0s, 396622 effective words/s
INFO - 2023-11-27 13:06:07,281: EPOCH 17: training on 412480 raw words (403577 effective words) took 1.0s, 404995 effective words/s
INFO - 2023-11-27 13:06:08,302: EPOCH 18 - PROGRESS: at 100.00% examples, 396501 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:08,302: EPOCH 18: training on 412480 raw words (403836 effective words) took 1.0s, 396386 effective words/s
INFO - 2023-11-27 13:06:09,325: EPOCH 19 - PROGRESS: at 100.00% examples, 395785 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:09,325: EPOCH 19: training on 412480 raw words (403713 effective words) took 1.0s, 395689 effective words/s
INFO - 2023-11-27 13:06:09,325: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074684 effective words) took 19.5s, 414048 effective words/s', 'datetime': '2023-11-27T13:06:09.325491', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:09,325: collecting all words and their counts
INFO - 2023-11-27 13:06:09,325: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:06:09,412: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:06:09,415: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:06:09,415: Updating model with new vocabulary
INFO - 2023-11-27 13:06:09,450: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:06:09.450364', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:09,494: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:06:09,494: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:06:09,494: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403907.19907910144 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:06:09.494811', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:09,564: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:06:09,564: updating layer weights
INFO - 2023-11-27 13:06:09,564: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:06:09.564918', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:06:09,565: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:06:09,565: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:06:09.565112', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:10,604: EPOCH 0 - PROGRESS: at 100.00% examples, 389543 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:10,604: EPOCH 0: training on 412480 raw words (403862 effective words) took 1.0s, 389444 effective words/s
INFO - 2023-11-27 13:06:11,672: EPOCH 1 - PROGRESS: at 100.00% examples, 379227 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:11,672: EPOCH 1: training on 412480 raw words (403926 effective words) took 1.1s, 379135 effective words/s
INFO - 2023-11-27 13:06:12,677: EPOCH 2 - PROGRESS: at 92.73% examples, 373599 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:06:12,777: EPOCH 2: training on 412480 raw words (403985 effective words) took 1.1s, 366301 effective words/s
INFO - 2023-11-27 13:06:13,835: EPOCH 3 - PROGRESS: at 100.00% examples, 383068 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:13,835: EPOCH 3: training on 412480 raw words (403975 effective words) took 1.1s, 382976 effective words/s
INFO - 2023-11-27 13:06:14,908: EPOCH 4 - PROGRESS: at 100.00% examples, 376993 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:14,909: EPOCH 4: training on 412480 raw words (403825 effective words) took 1.1s, 376855 effective words/s
INFO - 2023-11-27 13:06:15,983: EPOCH 5 - PROGRESS: at 100.00% examples, 376959 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:15,984: EPOCH 5: training on 412480 raw words (403911 effective words) took 1.1s, 376873 effective words/s
INFO - 2023-11-27 13:06:16,996: EPOCH 6 - PROGRESS: at 100.00% examples, 400204 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:16,996: EPOCH 6: training on 412480 raw words (404078 effective words) took 1.0s, 400108 effective words/s
INFO - 2023-11-27 13:06:18,030: EPOCH 7 - PROGRESS: at 100.00% examples, 391807 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:18,030: EPOCH 7: training on 412480 raw words (403910 effective words) took 1.0s, 391724 effective words/s
INFO - 2023-11-27 13:06:19,078: EPOCH 8 - PROGRESS: at 100.00% examples, 386340 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:19,078: EPOCH 8: training on 412480 raw words (403891 effective words) took 1.0s, 386251 effective words/s
INFO - 2023-11-27 13:06:20,130: EPOCH 9 - PROGRESS: at 100.00% examples, 385060 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:20,130: EPOCH 9: training on 412480 raw words (403800 effective words) took 1.0s, 384973 effective words/s
INFO - 2023-11-27 13:06:21,186: EPOCH 10 - PROGRESS: at 100.00% examples, 383398 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:21,186: EPOCH 10: training on 412480 raw words (403856 effective words) took 1.1s, 383309 effective words/s
INFO - 2023-11-27 13:06:22,244: EPOCH 11 - PROGRESS: at 100.00% examples, 383153 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:22,244: EPOCH 11: training on 412480 raw words (403827 effective words) took 1.1s, 383062 effective words/s
INFO - 2023-11-27 13:06:23,294: EPOCH 12 - PROGRESS: at 100.00% examples, 385677 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:23,295: EPOCH 12: training on 412480 raw words (403988 effective words) took 1.0s, 385568 effective words/s
INFO - 2023-11-27 13:06:24,339: EPOCH 13 - PROGRESS: at 100.00% examples, 388007 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:24,339: EPOCH 13: training on 412480 raw words (404080 effective words) took 1.0s, 387917 effective words/s
INFO - 2023-11-27 13:06:25,343: EPOCH 14 - PROGRESS: at 97.58% examples, 393654 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:06:25,418: EPOCH 14: training on 412480 raw words (403905 effective words) took 1.1s, 375204 effective words/s
INFO - 2023-11-27 13:06:26,467: EPOCH 15 - PROGRESS: at 100.00% examples, 386437 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:26,467: EPOCH 15: training on 412480 raw words (403782 effective words) took 1.0s, 386348 effective words/s
INFO - 2023-11-27 13:06:27,498: EPOCH 16 - PROGRESS: at 100.00% examples, 393184 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:27,498: EPOCH 16: training on 412480 raw words (404011 effective words) took 1.0s, 393093 effective words/s
INFO - 2023-11-27 13:06:28,544: EPOCH 17 - PROGRESS: at 100.00% examples, 387055 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:28,544: EPOCH 17: training on 412480 raw words (403896 effective words) took 1.0s, 386966 effective words/s
INFO - 2023-11-27 13:06:29,567: EPOCH 18 - PROGRESS: at 100.00% examples, 395876 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:29,567: EPOCH 18: training on 412480 raw words (403958 effective words) took 1.0s, 395765 effective words/s
INFO - 2023-11-27 13:06:30,623: EPOCH 19 - PROGRESS: at 100.00% examples, 383445 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:30,624: EPOCH 19: training on 412480 raw words (403941 effective words) took 1.1s, 383358 effective words/s
INFO - 2023-11-27 13:06:30,624: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8078407 effective words) took 21.1s, 383608 effective words/s', 'datetime': '2023-11-27T13:06:30.624227', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:30,624: collecting all words and their counts
INFO - 2023-11-27 13:06:30,624: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:06:30,717: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:06:30,719: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:06:30,719: Updating model with new vocabulary
INFO - 2023-11-27 13:06:30,756: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:06:30.756771', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:30,816: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:06:30,816: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:06:30,816: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403733.63982715335 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:06:30.816454', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:30,904: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:06:30,904: updating layer weights
INFO - 2023-11-27 13:06:30,905: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:06:30.905202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:06:30,905: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:06:30,905: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:06:30.905435', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:31,917: EPOCH 0 - PROGRESS: at 100.00% examples, 401558 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:31,917: EPOCH 0: training on 412480 raw words (403578 effective words) took 1.0s, 401461 effective words/s
INFO - 2023-11-27 13:06:32,938: EPOCH 1 - PROGRESS: at 100.00% examples, 396539 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:32,938: EPOCH 1: training on 412480 raw words (403834 effective words) took 1.0s, 396446 effective words/s
INFO - 2023-11-27 13:06:33,929: EPOCH 2: training on 412480 raw words (403739 effective words) took 1.0s, 408819 effective words/s
INFO - 2023-11-27 13:06:34,935: EPOCH 3 - PROGRESS: at 100.00% examples, 402170 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:34,935: EPOCH 3: training on 412480 raw words (403768 effective words) took 1.0s, 402067 effective words/s
INFO - 2023-11-27 13:06:35,949: EPOCH 4 - PROGRESS: at 100.00% examples, 399387 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:35,949: EPOCH 4: training on 412480 raw words (403852 effective words) took 1.0s, 399292 effective words/s
INFO - 2023-11-27 13:06:36,942: EPOCH 5: training on 412480 raw words (403720 effective words) took 1.0s, 407765 effective words/s
INFO - 2023-11-27 13:06:37,928: EPOCH 6: training on 412480 raw words (403869 effective words) took 1.0s, 410967 effective words/s
INFO - 2023-11-27 13:06:38,948: EPOCH 7 - PROGRESS: at 100.00% examples, 396435 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:38,949: EPOCH 7: training on 412480 raw words (403614 effective words) took 1.0s, 396326 effective words/s
INFO - 2023-11-27 13:06:39,966: EPOCH 8 - PROGRESS: at 100.00% examples, 398094 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:39,966: EPOCH 8: training on 412480 raw words (403743 effective words) took 1.0s, 397998 effective words/s
INFO - 2023-11-27 13:06:40,920: EPOCH 9: training on 412480 raw words (403790 effective words) took 1.0s, 424707 effective words/s
INFO - 2023-11-27 13:06:41,941: EPOCH 10 - PROGRESS: at 100.00% examples, 396546 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:41,941: EPOCH 10: training on 412480 raw words (403815 effective words) took 1.0s, 396443 effective words/s
INFO - 2023-11-27 13:06:42,956: EPOCH 11 - PROGRESS: at 100.00% examples, 398828 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:42,956: EPOCH 11: training on 412480 raw words (403869 effective words) took 1.0s, 398733 effective words/s
INFO - 2023-11-27 13:06:43,955: EPOCH 12: training on 412480 raw words (403710 effective words) took 1.0s, 405475 effective words/s
INFO - 2023-11-27 13:06:44,971: EPOCH 13 - PROGRESS: at 100.00% examples, 398594 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:44,971: EPOCH 13: training on 412480 raw words (403772 effective words) took 1.0s, 398494 effective words/s
INFO - 2023-11-27 13:06:45,956: EPOCH 14: training on 412480 raw words (403884 effective words) took 1.0s, 415081 effective words/s
INFO - 2023-11-27 13:06:46,918: EPOCH 15: training on 412480 raw words (403751 effective words) took 1.0s, 420624 effective words/s
INFO - 2023-11-27 13:06:47,947: EPOCH 16 - PROGRESS: at 100.00% examples, 393502 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:47,947: EPOCH 16: training on 412480 raw words (403700 effective words) took 1.0s, 393407 effective words/s
INFO - 2023-11-27 13:06:49,038: EPOCH 17 - PROGRESS: at 100.00% examples, 371067 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:49,038: EPOCH 17: training on 412480 raw words (403799 effective words) took 1.1s, 370977 effective words/s
INFO - 2023-11-27 13:06:50,064: EPOCH 18 - PROGRESS: at 100.00% examples, 394590 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:50,064: EPOCH 18: training on 412480 raw words (403748 effective words) took 1.0s, 394494 effective words/s
INFO - 2023-11-27 13:06:51,113: EPOCH 19 - PROGRESS: at 100.00% examples, 385784 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:51,113: EPOCH 19: training on 412480 raw words (403790 effective words) took 1.0s, 385694 effective words/s
INFO - 2023-11-27 13:06:51,113: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8075345 effective words) took 20.2s, 399603 effective words/s', 'datetime': '2023-11-27T13:06:51.113954', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:51,114: collecting all words and their counts
INFO - 2023-11-27 13:06:51,114: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:06:51,211: PROGRESS: at sentence #10000, processed 400000 words, keeping 10303 word types
INFO - 2023-11-27 13:06:51,214: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:06:51,214: Updating model with new vocabulary
INFO - 2023-11-27 13:06:51,248: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:06:51.248504', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:51,293: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:06:51,294: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:06:51,294: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403749.2498827555 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:06:51.294093', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:06:51,366: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:06:51,366: updating layer weights
INFO - 2023-11-27 13:06:51,366: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:06:51.366843', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:06:51,366: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:06:51,367: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:06:51.367074', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:06:52,430: EPOCH 0 - PROGRESS: at 100.00% examples, 381030 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:52,430: EPOCH 0: training on 412480 raw words (403823 effective words) took 1.1s, 380934 effective words/s
INFO - 2023-11-27 13:06:53,503: EPOCH 1 - PROGRESS: at 100.00% examples, 377245 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:53,504: EPOCH 1: training on 412480 raw words (403790 effective words) took 1.1s, 377158 effective words/s
INFO - 2023-11-27 13:06:54,553: EPOCH 2 - PROGRESS: at 100.00% examples, 385818 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:54,553: EPOCH 2: training on 412480 raw words (403716 effective words) took 1.0s, 385728 effective words/s
INFO - 2023-11-27 13:06:55,598: EPOCH 3 - PROGRESS: at 100.00% examples, 387291 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:55,598: EPOCH 3: training on 412480 raw words (403816 effective words) took 1.0s, 387199 effective words/s
INFO - 2023-11-27 13:06:56,650: EPOCH 4 - PROGRESS: at 100.00% examples, 384716 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:56,651: EPOCH 4: training on 412480 raw words (403596 effective words) took 1.0s, 384627 effective words/s
INFO - 2023-11-27 13:06:57,742: EPOCH 5 - PROGRESS: at 100.00% examples, 370611 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:57,742: EPOCH 5: training on 412480 raw words (403518 effective words) took 1.1s, 370529 effective words/s
INFO - 2023-11-27 13:06:58,767: EPOCH 6 - PROGRESS: at 100.00% examples, 394704 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:58,768: EPOCH 6: training on 412480 raw words (403640 effective words) took 1.0s, 394614 effective words/s
INFO - 2023-11-27 13:06:59,810: EPOCH 7 - PROGRESS: at 100.00% examples, 388495 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:06:59,810: EPOCH 7: training on 412480 raw words (403877 effective words) took 1.0s, 388404 effective words/s
INFO - 2023-11-27 13:07:00,887: EPOCH 8 - PROGRESS: at 100.00% examples, 375776 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:07:00,887: EPOCH 8: training on 412480 raw words (403765 effective words) took 1.1s, 375691 effective words/s
INFO - 2023-11-27 13:07:01,927: EPOCH 9 - PROGRESS: at 100.00% examples, 389172 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:07:01,928: EPOCH 9: training on 412480 raw words (403794 effective words) took 1.0s, 389081 effective words/s
INFO - 2023-11-27 13:07:02,940: EPOCH 10 - PROGRESS: at 80.00% examples, 319957 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:07:03,045: EPOCH 10: training on 412480 raw words (403759 effective words) took 1.1s, 362250 effective words/s
INFO - 2023-11-27 13:07:04,067: EPOCH 11 - PROGRESS: at 97.58% examples, 386500 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:07:04,117: EPOCH 11: training on 412480 raw words (403834 effective words) took 1.1s, 377528 effective words/s
INFO - 2023-11-27 13:07:05,030: EPOCH 12: training on 412480 raw words (403741 effective words) took 0.9s, 443260 effective words/s
INFO - 2023-11-27 13:07:05,925: EPOCH 13: training on 412480 raw words (403765 effective words) took 0.9s, 452495 effective words/s
INFO - 2023-11-27 13:07:06,801: EPOCH 14: training on 412480 raw words (403802 effective words) took 0.9s, 461545 effective words/s
INFO - 2023-11-27 13:07:07,714: EPOCH 15: training on 412480 raw words (403827 effective words) took 0.9s, 443955 effective words/s
INFO - 2023-11-27 13:07:08,697: EPOCH 16: training on 412480 raw words (403700 effective words) took 1.0s, 411466 effective words/s
INFO - 2023-11-27 13:07:09,713: EPOCH 17: training on 412480 raw words (403694 effective words) took 1.0s, 403802 effective words/s
INFO - 2023-11-27 13:07:10,679: EPOCH 18: training on 412480 raw words (403627 effective words) took 1.0s, 418664 effective words/s
INFO - 2023-11-27 13:07:11,590: EPOCH 19: training on 412480 raw words (403851 effective words) took 0.9s, 444564 effective words/s
INFO - 2023-11-27 13:07:11,590: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074935 effective words) took 20.2s, 399284 effective words/s', 'datetime': '2023-11-27T13:07:11.590684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:11,590: collecting all words and their counts
INFO - 2023-11-27 13:07:11,590: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:07:11,649: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:07:11,651: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:07:11,651: Updating model with new vocabulary
INFO - 2023-11-27 13:07:11,677: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:07:11.677121', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:11,711: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:07:11,711: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:07:11,711: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403563.201471643 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:07:11.711540', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:11,763: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:07:11,763: updating layer weights
INFO - 2023-11-27 13:07:11,764: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:07:11.763982', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:07:11,764: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:07:11,764: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:07:11.764155', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:12,608: EPOCH 0: training on 412480 raw words (403614 effective words) took 0.8s, 478983 effective words/s
INFO - 2023-11-27 13:07:13,488: EPOCH 1: training on 412480 raw words (403666 effective words) took 0.9s, 459757 effective words/s
INFO - 2023-11-27 13:07:14,501: EPOCH 2 - PROGRESS: at 97.58% examples, 389533 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:07:14,511: EPOCH 2: training on 412480 raw words (403445 effective words) took 1.0s, 395441 effective words/s
INFO - 2023-11-27 13:07:15,494: EPOCH 3: training on 412480 raw words (403557 effective words) took 1.0s, 411353 effective words/s
INFO - 2023-11-27 13:07:16,420: EPOCH 4: training on 412480 raw words (403533 effective words) took 0.9s, 437011 effective words/s
INFO - 2023-11-27 13:07:17,335: EPOCH 5: training on 412480 raw words (403679 effective words) took 0.9s, 443153 effective words/s
INFO - 2023-11-27 13:07:18,191: EPOCH 6: training on 412480 raw words (403595 effective words) took 0.9s, 473022 effective words/s
INFO - 2023-11-27 13:07:19,087: EPOCH 7: training on 412480 raw words (403680 effective words) took 0.9s, 451532 effective words/s
INFO - 2023-11-27 13:07:19,952: EPOCH 8: training on 412480 raw words (403544 effective words) took 0.9s, 467785 effective words/s
INFO - 2023-11-27 13:07:20,818: EPOCH 9: training on 412480 raw words (403545 effective words) took 0.9s, 466956 effective words/s
INFO - 2023-11-27 13:07:21,652: EPOCH 10: training on 412480 raw words (403548 effective words) took 0.8s, 484957 effective words/s
INFO - 2023-11-27 13:07:22,498: EPOCH 11: training on 412480 raw words (403435 effective words) took 0.8s, 478372 effective words/s
INFO - 2023-11-27 13:07:23,465: EPOCH 12: training on 412480 raw words (403598 effective words) took 1.0s, 418053 effective words/s
INFO - 2023-11-27 13:07:24,472: EPOCH 13 - PROGRESS: at 77.58% examples, 311904 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:07:24,559: EPOCH 13: training on 412480 raw words (403627 effective words) took 1.1s, 370028 effective words/s
INFO - 2023-11-27 13:07:25,641: EPOCH 14 - PROGRESS: at 100.00% examples, 373498 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:07:25,642: EPOCH 14: training on 412480 raw words (403477 effective words) took 1.1s, 373414 effective words/s
INFO - 2023-11-27 13:07:26,683: EPOCH 15 - PROGRESS: at 75.16% examples, 291839 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:07:26,876: EPOCH 15: training on 412480 raw words (403523 effective words) took 1.2s, 327414 effective words/s
INFO - 2023-11-27 13:07:27,879: EPOCH 16 - PROGRESS: at 97.58% examples, 393623 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:07:27,973: EPOCH 16: training on 412480 raw words (403651 effective words) took 1.1s, 368638 effective words/s
INFO - 2023-11-27 13:07:28,984: EPOCH 17 - PROGRESS: at 87.28% examples, 349127 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:07:29,111: EPOCH 17: training on 412480 raw words (403659 effective words) took 1.1s, 355494 effective words/s
INFO - 2023-11-27 13:07:30,119: EPOCH 18 - PROGRESS: at 75.16% examples, 301839 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:07:30,302: EPOCH 18: training on 412480 raw words (403699 effective words) took 1.2s, 339606 effective words/s
INFO - 2023-11-27 13:07:31,346: EPOCH 19 - PROGRESS: at 75.16% examples, 291274 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:07:31,544: EPOCH 19: training on 412480 raw words (403450 effective words) took 1.2s, 325589 effective words/s
INFO - 2023-11-27 13:07:31,544: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071525 effective words) took 19.8s, 408052 effective words/s', 'datetime': '2023-11-27T13:07:31.544852', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:31,545: collecting all words and their counts
INFO - 2023-11-27 13:07:31,545: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:07:31,646: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:07:31,649: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:07:31,649: Updating model with new vocabulary
INFO - 2023-11-27 13:07:31,696: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:07:31.696126', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:31,743: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:07:31,743: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:07:31,743: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403635.8674164957 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:07:31.743725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:31,830: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:07:31,830: updating layer weights
INFO - 2023-11-27 13:07:31,831: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:07:31.831254', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:07:31,831: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:07:31,831: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:07:31.831499', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:32,842: EPOCH 0 - PROGRESS: at 77.58% examples, 310479 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:07:32,992: EPOCH 0: training on 412480 raw words (403615 effective words) took 1.2s, 348500 effective words/s
INFO - 2023-11-27 13:07:34,007: EPOCH 1 - PROGRESS: at 95.15% examples, 379115 words/s, in_qsize 0, out_qsize 5
INFO - 2023-11-27 13:07:34,007: EPOCH 1: training on 412480 raw words (403575 effective words) took 1.0s, 398305 effective words/s
INFO - 2023-11-27 13:07:35,224: EPOCH 2 - PROGRESS: at 72.73% examples, 283445 words/s, in_qsize 12, out_qsize 0
INFO - 2023-11-27 13:07:35,519: EPOCH 2: training on 412480 raw words (403750 effective words) took 1.3s, 303321 effective words/s
INFO - 2023-11-27 13:07:36,521: EPOCH 3 - PROGRESS: at 60.61% examples, 244557 words/s, in_qsize 17, out_qsize 0
INFO - 2023-11-27 13:07:36,839: EPOCH 3: training on 412480 raw words (403648 effective words) took 1.3s, 306116 effective words/s
INFO - 2023-11-27 13:07:37,879: EPOCH 4 - PROGRESS: at 65.46% examples, 257362 words/s, in_qsize 15, out_qsize 0
INFO - 2023-11-27 13:07:38,308: EPOCH 4: training on 412480 raw words (403625 effective words) took 1.5s, 277235 effective words/s
INFO - 2023-11-27 13:07:39,350: EPOCH 5 - PROGRESS: at 55.76% examples, 216578 words/s, in_qsize 16, out_qsize 3
INFO - 2023-11-27 13:07:39,803: EPOCH 5: training on 412480 raw words (403733 effective words) took 1.5s, 270493 effective words/s
INFO - 2023-11-27 13:07:41,108: EPOCH 6 - PROGRESS: at 46.06% examples, 142766 words/s, in_qsize 13, out_qsize 4
INFO - 2023-11-27 13:07:41,877: EPOCH 6: training on 412480 raw words (403656 effective words) took 2.1s, 194839 effective words/s
INFO - 2023-11-27 13:07:43,836: EPOCH 7 - PROGRESS: at 92.73% examples, 371164 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:07:43,919: EPOCH 7: training on 412480 raw words (403549 effective words) took 1.1s, 369943 effective words/s
INFO - 2023-11-27 13:07:44,848: EPOCH 8: training on 412480 raw words (403531 effective words) took 0.9s, 442229 effective words/s
INFO - 2023-11-27 13:07:45,764: EPOCH 9: training on 412480 raw words (403667 effective words) took 0.9s, 441605 effective words/s
INFO - 2023-11-27 13:07:46,727: EPOCH 10: training on 412480 raw words (403527 effective words) took 1.0s, 419651 effective words/s
INFO - 2023-11-27 13:07:47,646: EPOCH 11: training on 412480 raw words (403578 effective words) took 0.9s, 440773 effective words/s
INFO - 2023-11-27 13:07:48,592: EPOCH 12: training on 412480 raw words (403582 effective words) took 0.9s, 427266 effective words/s
INFO - 2023-11-27 13:07:49,570: EPOCH 13: training on 412480 raw words (403618 effective words) took 1.0s, 413899 effective words/s
INFO - 2023-11-27 13:07:50,521: EPOCH 14: training on 412480 raw words (403785 effective words) took 0.9s, 425774 effective words/s
INFO - 2023-11-27 13:07:51,467: EPOCH 15: training on 412480 raw words (403807 effective words) took 0.9s, 427693 effective words/s
INFO - 2023-11-27 13:07:52,419: EPOCH 16: training on 412480 raw words (403706 effective words) took 0.9s, 425098 effective words/s
INFO - 2023-11-27 13:07:53,363: EPOCH 17: training on 412480 raw words (403497 effective words) took 0.9s, 428320 effective words/s
INFO - 2023-11-27 13:07:54,221: EPOCH 18: training on 412480 raw words (403625 effective words) took 0.9s, 471755 effective words/s
INFO - 2023-11-27 13:07:55,065: EPOCH 19: training on 412480 raw words (403614 effective words) took 0.8s, 479592 effective words/s
INFO - 2023-11-27 13:07:55,065: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072688 effective words) took 23.2s, 347454 effective words/s', 'datetime': '2023-11-27T13:07:55.065428', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:55,065: collecting all words and their counts
INFO - 2023-11-27 13:07:55,065: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:07:55,124: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:07:55,126: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:07:55,126: Updating model with new vocabulary
INFO - 2023-11-27 13:07:55,161: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:07:55.161370', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:55,194: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:07:55,194: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:07:55,194: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403440.50664662826 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:07:55.194750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:07:55,243: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:07:55,243: updating layer weights
INFO - 2023-11-27 13:07:55,244: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:07:55.244185', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:07:55,244: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:07:55,244: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:07:55.244348', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:07:56,074: EPOCH 0: training on 412480 raw words (403439 effective words) took 0.8s, 487236 effective words/s
INFO - 2023-11-27 13:07:56,972: EPOCH 1: training on 412480 raw words (403459 effective words) took 0.9s, 450015 effective words/s
INFO - 2023-11-27 13:07:57,863: EPOCH 2: training on 412480 raw words (403364 effective words) took 0.9s, 453872 effective words/s
INFO - 2023-11-27 13:07:58,667: EPOCH 3: training on 412480 raw words (403406 effective words) took 0.8s, 503254 effective words/s
INFO - 2023-11-27 13:07:59,501: EPOCH 4: training on 412480 raw words (403460 effective words) took 0.8s, 485007 effective words/s
INFO - 2023-11-27 13:08:00,330: EPOCH 5: training on 412480 raw words (403366 effective words) took 0.8s, 487611 effective words/s
INFO - 2023-11-27 13:08:01,121: EPOCH 6: training on 412480 raw words (403461 effective words) took 0.8s, 511329 effective words/s
INFO - 2023-11-27 13:08:01,943: EPOCH 7: training on 412480 raw words (403411 effective words) took 0.8s, 492174 effective words/s
INFO - 2023-11-27 13:08:02,816: EPOCH 8: training on 412480 raw words (403513 effective words) took 0.9s, 463132 effective words/s
INFO - 2023-11-27 13:08:03,814: EPOCH 9: training on 412480 raw words (403352 effective words) took 1.0s, 405144 effective words/s
INFO - 2023-11-27 13:08:04,864: EPOCH 10 - PROGRESS: at 100.00% examples, 384808 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:04,865: EPOCH 10: training on 412480 raw words (403402 effective words) took 1.0s, 384716 effective words/s
INFO - 2023-11-27 13:08:05,920: EPOCH 11 - PROGRESS: at 100.00% examples, 382963 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:05,920: EPOCH 11: training on 412480 raw words (403407 effective words) took 1.1s, 382873 effective words/s
INFO - 2023-11-27 13:08:06,923: EPOCH 12 - PROGRESS: at 80.00% examples, 322503 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:08:07,081: EPOCH 12: training on 412480 raw words (403305 effective words) took 1.2s, 348151 effective words/s
INFO - 2023-11-27 13:08:08,178: EPOCH 13 - PROGRESS: at 100.00% examples, 368774 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:08,178: EPOCH 13: training on 412480 raw words (403340 effective words) took 1.1s, 368693 effective words/s
INFO - 2023-11-27 13:08:09,200: EPOCH 14 - PROGRESS: at 80.00% examples, 316630 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:08:09,340: EPOCH 14: training on 412480 raw words (403409 effective words) took 1.2s, 347840 effective words/s
INFO - 2023-11-27 13:08:10,358: EPOCH 15 - PROGRESS: at 77.58% examples, 308280 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:08:10,562: EPOCH 15: training on 412480 raw words (403353 effective words) took 1.2s, 330930 effective words/s
INFO - 2023-11-27 13:08:11,571: EPOCH 16 - PROGRESS: at 65.46% examples, 262806 words/s, in_qsize 14, out_qsize 1
INFO - 2023-11-27 13:08:11,980: EPOCH 16: training on 412480 raw words (403524 effective words) took 1.4s, 285376 effective words/s
INFO - 2023-11-27 13:08:12,969: EPOCH 17: training on 412480 raw words (403566 effective words) took 1.0s, 409337 effective words/s
INFO - 2023-11-27 13:08:13,885: EPOCH 18: training on 412480 raw words (403516 effective words) took 0.9s, 441655 effective words/s
INFO - 2023-11-27 13:08:14,816: EPOCH 19: training on 412480 raw words (403383 effective words) took 0.9s, 433942 effective words/s
INFO - 2023-11-27 13:08:14,817: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8068436 effective words) took 19.6s, 412231 effective words/s', 'datetime': '2023-11-27T13:08:14.817027', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:14,817: collecting all words and their counts
INFO - 2023-11-27 13:08:14,817: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:08:14,876: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:08:14,878: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:08:14,878: Updating model with new vocabulary
INFO - 2023-11-27 13:08:14,907: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:08:14.907806', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:14,942: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:08:14,942: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:08:14,942: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403765.70725923905 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:08:14.942533', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:14,993: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:08:14,994: updating layer weights
INFO - 2023-11-27 13:08:14,994: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:08:14.994659', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:08:14,994: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:08:14,994: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:08:14.994831', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:15,919: EPOCH 0: training on 412480 raw words (403662 effective words) took 0.9s, 437306 effective words/s
INFO - 2023-11-27 13:08:16,933: EPOCH 1 - PROGRESS: at 100.00% examples, 398975 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:16,934: EPOCH 1: training on 412480 raw words (403715 effective words) took 1.0s, 398902 effective words/s
INFO - 2023-11-27 13:08:17,890: EPOCH 2: training on 412480 raw words (403837 effective words) took 1.0s, 422957 effective words/s
INFO - 2023-11-27 13:08:18,855: EPOCH 3: training on 412480 raw words (403776 effective words) took 1.0s, 419596 effective words/s
INFO - 2023-11-27 13:08:19,830: EPOCH 4: training on 412480 raw words (403772 effective words) took 1.0s, 419155 effective words/s
INFO - 2023-11-27 13:08:20,833: EPOCH 5 - PROGRESS: at 100.00% examples, 403394 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:20,833: EPOCH 5: training on 412480 raw words (403856 effective words) took 1.0s, 403319 effective words/s
INFO - 2023-11-27 13:08:21,809: EPOCH 6: training on 412480 raw words (403905 effective words) took 1.0s, 414786 effective words/s
INFO - 2023-11-27 13:08:22,756: EPOCH 7: training on 412480 raw words (403826 effective words) took 0.9s, 427368 effective words/s
INFO - 2023-11-27 13:08:23,702: EPOCH 8: training on 412480 raw words (403839 effective words) took 0.9s, 427960 effective words/s
INFO - 2023-11-27 13:08:24,582: EPOCH 9: training on 412480 raw words (403699 effective words) took 0.9s, 460093 effective words/s
INFO - 2023-11-27 13:08:25,493: EPOCH 10: training on 412480 raw words (403617 effective words) took 0.9s, 443755 effective words/s
INFO - 2023-11-27 13:08:26,418: EPOCH 11: training on 412480 raw words (403761 effective words) took 0.9s, 437664 effective words/s
INFO - 2023-11-27 13:08:27,500: EPOCH 12 - PROGRESS: at 100.00% examples, 374219 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:27,500: EPOCH 12: training on 412480 raw words (403830 effective words) took 1.1s, 374112 effective words/s
INFO - 2023-11-27 13:08:28,522: EPOCH 13 - PROGRESS: at 77.58% examples, 307595 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:08:28,677: EPOCH 13: training on 412480 raw words (403726 effective words) took 1.2s, 344112 effective words/s
INFO - 2023-11-27 13:08:29,683: EPOCH 14 - PROGRESS: at 89.70% examples, 360857 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:08:29,810: EPOCH 14: training on 412480 raw words (403841 effective words) took 1.1s, 357081 effective words/s
INFO - 2023-11-27 13:08:30,814: EPOCH 15 - PROGRESS: at 87.28% examples, 351846 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:08:30,929: EPOCH 15: training on 412480 raw words (403889 effective words) took 1.1s, 361542 effective words/s
INFO - 2023-11-27 13:08:31,933: EPOCH 16 - PROGRESS: at 80.00% examples, 322674 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:08:32,059: EPOCH 16: training on 412480 raw words (403741 effective words) took 1.1s, 358381 effective words/s
INFO - 2023-11-27 13:08:33,069: EPOCH 17 - PROGRESS: at 77.58% examples, 310647 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:08:33,226: EPOCH 17: training on 412480 raw words (403727 effective words) took 1.2s, 346655 effective words/s
INFO - 2023-11-27 13:08:34,234: EPOCH 18 - PROGRESS: at 75.16% examples, 301709 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:08:34,417: EPOCH 18: training on 412480 raw words (403773 effective words) took 1.2s, 339739 effective words/s
INFO - 2023-11-27 13:08:35,422: EPOCH 19 - PROGRESS: at 87.28% examples, 351437 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:08:35,535: EPOCH 19: training on 412480 raw words (403794 effective words) took 1.1s, 361931 effective words/s
INFO - 2023-11-27 13:08:35,535: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8075586 effective words) took 20.5s, 393155 effective words/s', 'datetime': '2023-11-27T13:08:35.535379', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:35,535: collecting all words and their counts
INFO - 2023-11-27 13:08:35,535: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:08:35,592: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:08:35,594: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:08:35,594: Updating model with new vocabulary
INFO - 2023-11-27 13:08:35,618: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:08:35.618541', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:35,652: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:08:35,652: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:08:35,653: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403701.46260247554 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:08:35.653087', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:35,705: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:08:35,706: updating layer weights
INFO - 2023-11-27 13:08:35,706: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:08:35.706532', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:08:35,706: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:08:35,706: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:08:35.706684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:36,537: EPOCH 0: training on 412480 raw words (403680 effective words) took 0.8s, 486840 effective words/s
INFO - 2023-11-27 13:08:37,442: EPOCH 1: training on 412480 raw words (403596 effective words) took 0.9s, 446716 effective words/s
INFO - 2023-11-27 13:08:38,269: EPOCH 2: training on 412480 raw words (403750 effective words) took 0.8s, 489851 effective words/s
INFO - 2023-11-27 13:08:39,091: EPOCH 3: training on 412480 raw words (403673 effective words) took 0.8s, 492250 effective words/s
INFO - 2023-11-27 13:08:39,949: EPOCH 4: training on 412480 raw words (403493 effective words) took 0.9s, 471730 effective words/s
INFO - 2023-11-27 13:08:40,737: EPOCH 5: training on 412480 raw words (403691 effective words) took 0.8s, 513374 effective words/s
INFO - 2023-11-27 13:08:41,585: EPOCH 6: training on 412480 raw words (403729 effective words) took 0.8s, 477367 effective words/s
INFO - 2023-11-27 13:08:42,424: EPOCH 7: training on 412480 raw words (403785 effective words) took 0.8s, 482384 effective words/s
INFO - 2023-11-27 13:08:43,249: EPOCH 8: training on 412480 raw words (403779 effective words) took 0.8s, 490476 effective words/s
INFO - 2023-11-27 13:08:44,109: EPOCH 9: training on 412480 raw words (403760 effective words) took 0.9s, 470345 effective words/s
INFO - 2023-11-27 13:08:44,935: EPOCH 10: training on 412480 raw words (403549 effective words) took 0.8s, 489732 effective words/s
INFO - 2023-11-27 13:08:45,763: EPOCH 11: training on 412480 raw words (403749 effective words) took 0.8s, 488623 effective words/s
INFO - 2023-11-27 13:08:46,831: EPOCH 12 - PROGRESS: at 100.00% examples, 378908 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:46,831: EPOCH 12: training on 412480 raw words (403677 effective words) took 1.1s, 378809 effective words/s
INFO - 2023-11-27 13:08:47,739: EPOCH 13: training on 412480 raw words (403710 effective words) took 0.9s, 445693 effective words/s
INFO - 2023-11-27 13:08:48,569: EPOCH 14: training on 412480 raw words (403732 effective words) took 0.8s, 487589 effective words/s
INFO - 2023-11-27 13:08:49,418: EPOCH 15: training on 412480 raw words (403783 effective words) took 0.8s, 476692 effective words/s
INFO - 2023-11-27 13:08:50,201: EPOCH 16: training on 412480 raw words (403674 effective words) took 0.8s, 517417 effective words/s
INFO - 2023-11-27 13:08:51,214: EPOCH 17 - PROGRESS: at 100.00% examples, 399251 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:51,214: EPOCH 17: training on 412480 raw words (403684 effective words) took 1.0s, 399158 effective words/s
INFO - 2023-11-27 13:08:52,275: EPOCH 18 - PROGRESS: at 100.00% examples, 381691 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:52,275: EPOCH 18: training on 412480 raw words (403592 effective words) took 1.1s, 381596 effective words/s
INFO - 2023-11-27 13:08:53,319: EPOCH 19 - PROGRESS: at 100.00% examples, 387890 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:08:53,319: EPOCH 19: training on 412480 raw words (403675 effective words) took 1.0s, 387802 effective words/s
INFO - 2023-11-27 13:08:53,319: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073761 effective words) took 17.6s, 458400 effective words/s', 'datetime': '2023-11-27T13:08:53.319674', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:53,319: collecting all words and their counts
INFO - 2023-11-27 13:08:53,320: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:08:53,404: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:08:53,407: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:08:53,407: Updating model with new vocabulary
INFO - 2023-11-27 13:08:53,438: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:08:53.438678', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:53,479: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:08:53,479: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:08:53,479: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403670.0790866694 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:08:53.479299', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:08:53,543: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:08:53,544: updating layer weights
INFO - 2023-11-27 13:08:53,544: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:08:53.544893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:08:53,545: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:08:53,545: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:08:53.545080', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:08:54,547: EPOCH 0 - PROGRESS: at 90.30% examples, 364234 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:08:54,657: EPOCH 0: training on 412480 raw words (403556 effective words) took 1.1s, 363505 effective words/s
INFO - 2023-11-27 13:08:55,663: EPOCH 1 - PROGRESS: at 82.43% examples, 331611 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:08:55,756: EPOCH 1: training on 412480 raw words (403758 effective words) took 1.1s, 368346 effective words/s
INFO - 2023-11-27 13:08:56,762: EPOCH 2 - PROGRESS: at 82.43% examples, 331514 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:08:56,919: EPOCH 2: training on 412480 raw words (403669 effective words) took 1.2s, 347733 effective words/s
INFO - 2023-11-27 13:08:57,957: EPOCH 3 - PROGRESS: at 80.00% examples, 312012 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:08:58,075: EPOCH 3: training on 412480 raw words (403866 effective words) took 1.2s, 350159 effective words/s
INFO - 2023-11-27 13:08:59,116: EPOCH 4 - PROGRESS: at 77.58% examples, 301709 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:08:59,250: EPOCH 4: training on 412480 raw words (403816 effective words) took 1.2s, 344317 effective words/s
INFO - 2023-11-27 13:09:00,196: EPOCH 5: training on 412480 raw words (403584 effective words) took 0.9s, 427866 effective words/s
INFO - 2023-11-27 13:09:01,065: EPOCH 6: training on 412480 raw words (403662 effective words) took 0.9s, 465578 effective words/s
INFO - 2023-11-27 13:09:01,946: EPOCH 7: training on 412480 raw words (403562 effective words) took 0.9s, 458864 effective words/s
INFO - 2023-11-27 13:09:02,826: EPOCH 8: training on 412480 raw words (403714 effective words) took 0.9s, 459995 effective words/s
INFO - 2023-11-27 13:09:03,713: EPOCH 9: training on 412480 raw words (403627 effective words) took 0.9s, 456434 effective words/s
INFO - 2023-11-27 13:09:04,573: EPOCH 10: training on 412480 raw words (403719 effective words) took 0.9s, 470583 effective words/s
INFO - 2023-11-27 13:09:05,454: EPOCH 11: training on 412480 raw words (403693 effective words) took 0.9s, 459480 effective words/s
INFO - 2023-11-27 13:09:06,367: EPOCH 12: training on 412480 raw words (403609 effective words) took 0.9s, 442973 effective words/s
INFO - 2023-11-27 13:09:07,221: EPOCH 13: training on 412480 raw words (403749 effective words) took 0.9s, 473558 effective words/s
INFO - 2023-11-27 13:09:08,096: EPOCH 14: training on 412480 raw words (403664 effective words) took 0.9s, 462423 effective words/s
INFO - 2023-11-27 13:09:08,968: EPOCH 15: training on 412480 raw words (403497 effective words) took 0.9s, 464145 effective words/s
INFO - 2023-11-27 13:09:09,821: EPOCH 16: training on 412480 raw words (403861 effective words) took 0.9s, 474834 effective words/s
INFO - 2023-11-27 13:09:10,718: EPOCH 17: training on 412480 raw words (403659 effective words) took 0.9s, 451250 effective words/s
INFO - 2023-11-27 13:09:11,584: EPOCH 18: training on 412480 raw words (403545 effective words) took 0.9s, 466764 effective words/s
INFO - 2023-11-27 13:09:12,414: EPOCH 19: training on 412480 raw words (403660 effective words) took 0.8s, 493849 effective words/s
INFO - 2023-11-27 13:09:12,414: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073470 effective words) took 18.9s, 427866 effective words/s', 'datetime': '2023-11-27T13:09:12.414290', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:12,414: collecting all words and their counts
INFO - 2023-11-27 13:09:12,414: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:09:12,473: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:09:12,475: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:09:12,475: Updating model with new vocabulary
INFO - 2023-11-27 13:09:12,501: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:09:12.501940', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:12,532: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:09:12,532: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:09:12,532: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403671.6778250452 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:09:12.532632', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:12,582: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:09:12,582: updating layer weights
INFO - 2023-11-27 13:09:12,582: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:09:12.582702', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:09:12,582: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:09:12,582: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:09:12.582860', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:13,431: EPOCH 0: training on 412480 raw words (403674 effective words) took 0.8s, 476699 effective words/s
INFO - 2023-11-27 13:09:14,269: EPOCH 1: training on 412480 raw words (403655 effective words) took 0.8s, 483149 effective words/s
INFO - 2023-11-27 13:09:15,241: EPOCH 2: training on 412480 raw words (403728 effective words) took 1.0s, 416162 effective words/s
INFO - 2023-11-27 13:09:16,275: EPOCH 3 - PROGRESS: at 100.00% examples, 391469 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:16,275: EPOCH 3: training on 412480 raw words (403711 effective words) took 1.0s, 391373 effective words/s
INFO - 2023-11-27 13:09:17,345: EPOCH 4 - PROGRESS: at 100.00% examples, 380510 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:17,345: EPOCH 4: training on 412480 raw words (403598 effective words) took 1.1s, 380430 effective words/s
INFO - 2023-11-27 13:09:18,400: EPOCH 5 - PROGRESS: at 100.00% examples, 383628 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:18,400: EPOCH 5: training on 412480 raw words (403785 effective words) took 1.1s, 383539 effective words/s
INFO - 2023-11-27 13:09:19,407: EPOCH 6 - PROGRESS: at 97.58% examples, 392176 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:09:19,508: EPOCH 6: training on 412480 raw words (403764 effective words) took 1.1s, 365262 effective words/s
INFO - 2023-11-27 13:09:20,552: EPOCH 7 - PROGRESS: at 100.00% examples, 387477 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:20,552: EPOCH 7: training on 412480 raw words (403581 effective words) took 1.0s, 387382 effective words/s
INFO - 2023-11-27 13:09:21,558: EPOCH 8 - PROGRESS: at 92.13% examples, 371167 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:09:21,682: EPOCH 8: training on 412480 raw words (403638 effective words) took 1.1s, 358394 effective words/s
INFO - 2023-11-27 13:09:22,690: EPOCH 9 - PROGRESS: at 97.58% examples, 391801 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:09:22,782: EPOCH 9: training on 412480 raw words (403605 effective words) took 1.1s, 367844 effective words/s
INFO - 2023-11-27 13:09:23,809: EPOCH 10 - PROGRESS: at 100.00% examples, 394011 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:23,809: EPOCH 10: training on 412480 raw words (403646 effective words) took 1.0s, 393932 effective words/s
INFO - 2023-11-27 13:09:24,643: EPOCH 11: training on 412480 raw words (403670 effective words) took 0.8s, 485209 effective words/s
INFO - 2023-11-27 13:09:25,484: EPOCH 12: training on 412480 raw words (403699 effective words) took 0.8s, 481170 effective words/s
INFO - 2023-11-27 13:09:26,311: EPOCH 13: training on 412480 raw words (403726 effective words) took 0.8s, 489525 effective words/s
INFO - 2023-11-27 13:09:27,182: EPOCH 14: training on 412480 raw words (403755 effective words) took 0.9s, 464820 effective words/s
INFO - 2023-11-27 13:09:28,130: EPOCH 15: training on 412480 raw words (403746 effective words) took 0.9s, 427094 effective words/s
INFO - 2023-11-27 13:09:28,966: EPOCH 16: training on 412480 raw words (403767 effective words) took 0.8s, 484428 effective words/s
INFO - 2023-11-27 13:09:29,776: EPOCH 17: training on 412480 raw words (403685 effective words) took 0.8s, 499401 effective words/s
INFO - 2023-11-27 13:09:30,588: EPOCH 18: training on 412480 raw words (403794 effective words) took 0.8s, 498166 effective words/s
INFO - 2023-11-27 13:09:31,428: EPOCH 19: training on 412480 raw words (403619 effective words) took 0.8s, 481589 effective words/s
INFO - 2023-11-27 13:09:31,429: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073846 effective words) took 18.8s, 428408 effective words/s', 'datetime': '2023-11-27T13:09:31.429070', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:31,429: collecting all words and their counts
INFO - 2023-11-27 13:09:31,429: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:09:31,497: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:09:31,499: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:09:31,499: Updating model with new vocabulary
INFO - 2023-11-27 13:09:31,523: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:09:31.523802', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:31,554: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:09:31,554: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:09:31,554: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403538.21645790274 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:09:31.554220', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:31,603: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:09:31,603: updating layer weights
INFO - 2023-11-27 13:09:31,604: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:09:31.604513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:09:31,604: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:09:31,604: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:09:31.604693', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:32,480: EPOCH 0: training on 412480 raw words (403587 effective words) took 0.9s, 462145 effective words/s
INFO - 2023-11-27 13:09:33,350: EPOCH 1: training on 412480 raw words (403664 effective words) took 0.9s, 464833 effective words/s
INFO - 2023-11-27 13:09:34,214: EPOCH 2: training on 412480 raw words (403564 effective words) took 0.9s, 468324 effective words/s
INFO - 2023-11-27 13:09:35,076: EPOCH 3: training on 412480 raw words (403538 effective words) took 0.9s, 469110 effective words/s
INFO - 2023-11-27 13:09:35,946: EPOCH 4: training on 412480 raw words (403510 effective words) took 0.9s, 464706 effective words/s
INFO - 2023-11-27 13:09:36,795: EPOCH 5: training on 412480 raw words (403649 effective words) took 0.8s, 476976 effective words/s
INFO - 2023-11-27 13:09:37,664: EPOCH 6: training on 412480 raw words (403763 effective words) took 0.9s, 465883 effective words/s
INFO - 2023-11-27 13:09:38,535: EPOCH 7: training on 412480 raw words (403479 effective words) took 0.9s, 464045 effective words/s
INFO - 2023-11-27 13:09:39,560: EPOCH 8 - PROGRESS: at 95.15% examples, 375644 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:09:39,631: EPOCH 8: training on 412480 raw words (403565 effective words) took 1.1s, 369010 effective words/s
INFO - 2023-11-27 13:09:40,721: EPOCH 9 - PROGRESS: at 100.00% examples, 375659 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:40,722: EPOCH 9: training on 412480 raw words (403622 effective words) took 1.1s, 375571 effective words/s
INFO - 2023-11-27 13:09:41,727: EPOCH 10 - PROGRESS: at 89.70% examples, 361125 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:09:41,863: EPOCH 10: training on 412480 raw words (403569 effective words) took 1.1s, 354265 effective words/s
INFO - 2023-11-27 13:09:42,965: EPOCH 11 - PROGRESS: at 100.00% examples, 367475 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:42,965: EPOCH 11: training on 412480 raw words (403596 effective words) took 1.1s, 367399 effective words/s
INFO - 2023-11-27 13:09:44,044: EPOCH 12 - PROGRESS: at 100.00% examples, 374674 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:09:44,044: EPOCH 12: training on 412480 raw words (403533 effective words) took 1.1s, 374593 effective words/s
INFO - 2023-11-27 13:09:45,060: EPOCH 13 - PROGRESS: at 97.58% examples, 388507 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:09:45,143: EPOCH 13: training on 412480 raw words (403522 effective words) took 1.1s, 368174 effective words/s
INFO - 2023-11-27 13:09:46,166: EPOCH 14 - PROGRESS: at 77.58% examples, 306808 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:09:46,319: EPOCH 14: training on 412480 raw words (403629 effective words) took 1.2s, 343878 effective words/s
INFO - 2023-11-27 13:09:47,325: EPOCH 15 - PROGRESS: at 75.16% examples, 302345 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:09:47,509: EPOCH 15: training on 412480 raw words (403566 effective words) took 1.2s, 340125 effective words/s
INFO - 2023-11-27 13:09:48,441: EPOCH 16: training on 412480 raw words (403490 effective words) took 0.9s, 433882 effective words/s
INFO - 2023-11-27 13:09:49,263: EPOCH 17: training on 412480 raw words (403623 effective words) took 0.8s, 492407 effective words/s
INFO - 2023-11-27 13:09:50,096: EPOCH 18: training on 412480 raw words (403611 effective words) took 0.8s, 489306 effective words/s
INFO - 2023-11-27 13:09:50,956: EPOCH 19: training on 412480 raw words (403717 effective words) took 0.9s, 470675 effective words/s
INFO - 2023-11-27 13:09:50,956: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071797 effective words) took 19.4s, 417108 effective words/s', 'datetime': '2023-11-27T13:09:50.956595', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:50,956: collecting all words and their counts
INFO - 2023-11-27 13:09:50,956: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:09:51,019: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:09:51,022: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:09:51,022: Updating model with new vocabulary
INFO - 2023-11-27 13:09:51,049: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:09:51.049052', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:51,084: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:09:51,084: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:09:51,084: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403659.7016124649 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:09:51.084725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:09:51,134: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:09:51,134: updating layer weights
INFO - 2023-11-27 13:09:51,134: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:09:51.134742', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:09:51,134: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:09:51,134: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:09:51.134908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:09:51,970: EPOCH 0: training on 412480 raw words (403727 effective words) took 0.8s, 484603 effective words/s
INFO - 2023-11-27 13:09:52,785: EPOCH 1: training on 412480 raw words (403694 effective words) took 0.8s, 496433 effective words/s
INFO - 2023-11-27 13:09:53,650: EPOCH 2: training on 412480 raw words (403784 effective words) took 0.9s, 467861 effective words/s
INFO - 2023-11-27 13:09:54,499: EPOCH 3: training on 412480 raw words (403694 effective words) took 0.8s, 476612 effective words/s
INFO - 2023-11-27 13:09:55,372: EPOCH 4: training on 412480 raw words (403757 effective words) took 0.9s, 463497 effective words/s
INFO - 2023-11-27 13:09:56,189: EPOCH 5: training on 412480 raw words (403668 effective words) took 0.8s, 495138 effective words/s
INFO - 2023-11-27 13:09:56,982: EPOCH 6: training on 412480 raw words (403749 effective words) took 0.8s, 510096 effective words/s
INFO - 2023-11-27 13:09:57,817: EPOCH 7: training on 412480 raw words (403552 effective words) took 0.8s, 484491 effective words/s
INFO - 2023-11-27 13:09:58,603: EPOCH 8: training on 412480 raw words (403650 effective words) took 0.8s, 515195 effective words/s
INFO - 2023-11-27 13:09:59,413: EPOCH 9: training on 412480 raw words (403532 effective words) took 0.8s, 498860 effective words/s
INFO - 2023-11-27 13:10:00,240: EPOCH 10: training on 412480 raw words (403676 effective words) took 0.8s, 489830 effective words/s
INFO - 2023-11-27 13:10:01,052: EPOCH 11: training on 412480 raw words (403543 effective words) took 0.8s, 497834 effective words/s
INFO - 2023-11-27 13:10:01,921: EPOCH 12: training on 412480 raw words (403581 effective words) took 0.9s, 465548 effective words/s
INFO - 2023-11-27 13:10:02,823: EPOCH 13: training on 412480 raw words (403568 effective words) took 0.9s, 448616 effective words/s
INFO - 2023-11-27 13:10:03,692: EPOCH 14: training on 412480 raw words (403605 effective words) took 0.9s, 465337 effective words/s
INFO - 2023-11-27 13:10:04,629: EPOCH 15: training on 412480 raw words (403653 effective words) took 0.9s, 431772 effective words/s
INFO - 2023-11-27 13:10:05,655: EPOCH 16 - PROGRESS: at 77.58% examples, 306294 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:10:05,800: EPOCH 16: training on 412480 raw words (403618 effective words) took 1.2s, 345775 effective words/s
INFO - 2023-11-27 13:10:06,810: EPOCH 17 - PROGRESS: at 82.43% examples, 330307 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:10:06,940: EPOCH 17: training on 412480 raw words (403714 effective words) took 1.1s, 354943 effective words/s
INFO - 2023-11-27 13:10:07,995: EPOCH 18 - PROGRESS: at 75.16% examples, 288222 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:10:08,180: EPOCH 18: training on 412480 raw words (403620 effective words) took 1.2s, 326138 effective words/s
INFO - 2023-11-27 13:10:09,270: EPOCH 19 - PROGRESS: at 100.00% examples, 371210 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:10:09,271: EPOCH 19: training on 412480 raw words (403604 effective words) took 1.1s, 371120 effective words/s
INFO - 2023-11-27 13:10:09,271: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072989 effective words) took 18.1s, 445130 effective words/s', 'datetime': '2023-11-27T13:10:09.271208', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:09,271: collecting all words and their counts
INFO - 2023-11-27 13:10:09,271: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:10:09,365: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:10:09,367: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:10:09,367: Updating model with new vocabulary
INFO - 2023-11-27 13:10:09,413: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:10:09.413632', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:09,469: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:10:09,470: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:10:09,470: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403601.97156969015 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:10:09.470424', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:09,545: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:10:09,546: updating layer weights
INFO - 2023-11-27 13:10:09,546: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:10:09.546622', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:10:09,546: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:10:09,546: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:10:09.546942', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:10,596: EPOCH 0 - PROGRESS: at 77.58% examples, 299392 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:10:10,760: EPOCH 0: training on 412480 raw words (403720 effective words) took 1.2s, 333567 effective words/s
INFO - 2023-11-27 13:10:11,795: EPOCH 1 - PROGRESS: at 75.16% examples, 293993 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:10:11,997: EPOCH 1: training on 412480 raw words (403777 effective words) took 1.2s, 327242 effective words/s
INFO - 2023-11-27 13:10:12,850: EPOCH 2: training on 412480 raw words (403565 effective words) took 0.9s, 473911 effective words/s
INFO - 2023-11-27 13:10:13,779: EPOCH 3: training on 412480 raw words (403703 effective words) took 0.9s, 435374 effective words/s
INFO - 2023-11-27 13:10:14,629: EPOCH 4: training on 412480 raw words (403480 effective words) took 0.8s, 476065 effective words/s
INFO - 2023-11-27 13:10:15,508: EPOCH 5: training on 412480 raw words (403492 effective words) took 0.9s, 460200 effective words/s
INFO - 2023-11-27 13:10:16,496: EPOCH 6: training on 412480 raw words (403714 effective words) took 1.0s, 409408 effective words/s
INFO - 2023-11-27 13:10:17,448: EPOCH 7: training on 412480 raw words (403553 effective words) took 0.9s, 425131 effective words/s
INFO - 2023-11-27 13:10:18,407: EPOCH 8: training on 412480 raw words (403525 effective words) took 0.9s, 426980 effective words/s
INFO - 2023-11-27 13:10:19,344: EPOCH 9: training on 412480 raw words (403544 effective words) took 0.9s, 431937 effective words/s
INFO - 2023-11-27 13:10:20,189: EPOCH 10: training on 412480 raw words (403577 effective words) took 0.8s, 478865 effective words/s
INFO - 2023-11-27 13:10:21,058: EPOCH 11: training on 412480 raw words (403717 effective words) took 0.9s, 465673 effective words/s
INFO - 2023-11-27 13:10:21,947: EPOCH 12: training on 412480 raw words (403455 effective words) took 0.9s, 454744 effective words/s
INFO - 2023-11-27 13:10:22,844: EPOCH 13: training on 412480 raw words (403529 effective words) took 0.9s, 450870 effective words/s
INFO - 2023-11-27 13:10:23,675: EPOCH 14: training on 412480 raw words (403603 effective words) took 0.8s, 486476 effective words/s
INFO - 2023-11-27 13:10:24,510: EPOCH 15: training on 412480 raw words (403594 effective words) took 0.8s, 484392 effective words/s
INFO - 2023-11-27 13:10:25,375: EPOCH 16: training on 412480 raw words (403598 effective words) took 0.9s, 468408 effective words/s
INFO - 2023-11-27 13:10:26,245: EPOCH 17: training on 412480 raw words (403577 effective words) took 0.9s, 465197 effective words/s
INFO - 2023-11-27 13:10:27,114: EPOCH 18: training on 412480 raw words (403752 effective words) took 0.9s, 465580 effective words/s
INFO - 2023-11-27 13:10:27,979: EPOCH 19: training on 412480 raw words (403590 effective words) took 0.9s, 467865 effective words/s
INFO - 2023-11-27 13:10:27,979: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072065 effective words) took 18.4s, 437931 effective words/s', 'datetime': '2023-11-27T13:10:27.979303', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:27,979: collecting all words and their counts
INFO - 2023-11-27 13:10:27,979: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:10:28,037: PROGRESS: at sentence #10000, processed 400000 words, keeping 10295 word types
INFO - 2023-11-27 13:10:28,039: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:10:28,039: Updating model with new vocabulary
INFO - 2023-11-27 13:10:28,065: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:10:28.065192', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:28,097: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:10:28,098: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:10:28,098: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403553.60582753574 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:10:28.098139', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:28,149: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:10:28,149: updating layer weights
INFO - 2023-11-27 13:10:28,150: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:10:28.150246', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:10:28,150: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:10:28,150: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:10:28.150468', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:29,132: EPOCH 0: training on 412480 raw words (403619 effective words) took 1.0s, 411799 effective words/s
INFO - 2023-11-27 13:10:30,185: EPOCH 1 - PROGRESS: at 100.00% examples, 384112 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:10:30,185: EPOCH 1: training on 412480 raw words (403499 effective words) took 1.1s, 384025 effective words/s
INFO - 2023-11-27 13:10:31,281: EPOCH 2 - PROGRESS: at 100.00% examples, 369061 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:10:31,281: EPOCH 2: training on 412480 raw words (403500 effective words) took 1.1s, 368976 effective words/s
INFO - 2023-11-27 13:10:32,337: EPOCH 3 - PROGRESS: at 77.58% examples, 297302 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:10:32,457: EPOCH 3: training on 412480 raw words (403547 effective words) took 1.2s, 343823 effective words/s
INFO - 2023-11-27 13:10:33,536: EPOCH 4 - PROGRESS: at 75.16% examples, 281903 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:10:33,740: EPOCH 4: training on 412480 raw words (403556 effective words) took 1.3s, 315233 effective words/s
INFO - 2023-11-27 13:10:34,767: EPOCH 5 - PROGRESS: at 77.58% examples, 305772 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:10:34,909: EPOCH 5: training on 412480 raw words (403626 effective words) took 1.2s, 345997 effective words/s
INFO - 2023-11-27 13:10:35,928: EPOCH 6 - PROGRESS: at 75.16% examples, 298526 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:10:36,139: EPOCH 6: training on 412480 raw words (403492 effective words) took 1.2s, 329068 effective words/s
INFO - 2023-11-27 13:10:37,011: EPOCH 7: training on 412480 raw words (403575 effective words) took 0.9s, 463991 effective words/s
INFO - 2023-11-27 13:10:37,840: EPOCH 8: training on 412480 raw words (403505 effective words) took 0.8s, 488080 effective words/s
INFO - 2023-11-27 13:10:38,711: EPOCH 9: training on 412480 raw words (403606 effective words) took 0.9s, 464547 effective words/s
INFO - 2023-11-27 13:10:39,560: EPOCH 10: training on 412480 raw words (403646 effective words) took 0.8s, 476501 effective words/s
INFO - 2023-11-27 13:10:40,398: EPOCH 11: training on 412480 raw words (403577 effective words) took 0.8s, 482792 effective words/s
INFO - 2023-11-27 13:10:41,232: EPOCH 12: training on 412480 raw words (403632 effective words) took 0.8s, 485372 effective words/s
INFO - 2023-11-27 13:10:42,078: EPOCH 13: training on 412480 raw words (403464 effective words) took 0.8s, 478118 effective words/s
INFO - 2023-11-27 13:10:42,908: EPOCH 14: training on 412480 raw words (403618 effective words) took 0.8s, 487473 effective words/s
INFO - 2023-11-27 13:10:43,758: EPOCH 15: training on 412480 raw words (403523 effective words) took 0.8s, 475746 effective words/s
INFO - 2023-11-27 13:10:44,627: EPOCH 16: training on 412480 raw words (403458 effective words) took 0.9s, 465035 effective words/s
INFO - 2023-11-27 13:10:45,481: EPOCH 17: training on 412480 raw words (403551 effective words) took 0.9s, 473523 effective words/s
INFO - 2023-11-27 13:10:46,314: EPOCH 18: training on 412480 raw words (403531 effective words) took 0.8s, 485842 effective words/s
INFO - 2023-11-27 13:10:47,149: EPOCH 19: training on 412480 raw words (403548 effective words) took 0.8s, 484777 effective words/s
INFO - 2023-11-27 13:10:47,149: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071073 effective words) took 19.0s, 424821 effective words/s', 'datetime': '2023-11-27T13:10:47.149274', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:47,149: collecting all words and their counts
INFO - 2023-11-27 13:10:47,149: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:10:47,208: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:10:47,210: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:10:47,210: Updating model with new vocabulary
INFO - 2023-11-27 13:10:47,235: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:10:47.235052', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:47,266: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:10:47,266: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:10:47,266: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403544.8485146058 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:10:47.266918', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:10:47,324: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:10:47,324: updating layer weights
INFO - 2023-11-27 13:10:47,325: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:10:47.325491', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:10:47,325: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:10:47,325: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:10:47.325679', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:10:48,217: EPOCH 0: training on 412480 raw words (403467 effective words) took 0.9s, 454698 effective words/s
INFO - 2023-11-27 13:10:49,131: EPOCH 1: training on 412480 raw words (403514 effective words) took 0.9s, 442836 effective words/s
INFO - 2023-11-27 13:10:50,151: EPOCH 2 - PROGRESS: at 100.00% examples, 396446 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:10:50,151: EPOCH 2: training on 412480 raw words (403548 effective words) took 1.0s, 396349 effective words/s
INFO - 2023-11-27 13:10:51,185: EPOCH 3 - PROGRESS: at 100.00% examples, 391153 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:10:51,185: EPOCH 3: training on 412480 raw words (403431 effective words) took 1.0s, 391075 effective words/s
INFO - 2023-11-27 13:10:52,198: EPOCH 4 - PROGRESS: at 77.58% examples, 309577 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:10:52,363: EPOCH 4: training on 412480 raw words (403483 effective words) took 1.2s, 342959 effective words/s
INFO - 2023-11-27 13:10:53,374: EPOCH 5 - PROGRESS: at 55.76% examples, 223237 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:10:53,688: EPOCH 5: training on 412480 raw words (403478 effective words) took 1.3s, 305178 effective words/s
INFO - 2023-11-27 13:10:54,691: EPOCH 6 - PROGRESS: at 84.85% examples, 342265 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:10:54,819: EPOCH 6: training on 412480 raw words (403570 effective words) took 1.1s, 357583 effective words/s
INFO - 2023-11-27 13:10:55,851: EPOCH 7 - PROGRESS: at 82.43% examples, 323017 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:10:55,956: EPOCH 7: training on 412480 raw words (403459 effective words) took 1.1s, 355541 effective words/s
INFO - 2023-11-27 13:10:56,961: EPOCH 8 - PROGRESS: at 94.55% examples, 380521 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:10:57,080: EPOCH 8: training on 412480 raw words (403640 effective words) took 1.1s, 359987 effective words/s
INFO - 2023-11-27 13:10:58,160: EPOCH 9 - PROGRESS: at 75.16% examples, 281249 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:10:58,366: EPOCH 9: training on 412480 raw words (403520 effective words) took 1.3s, 314186 effective words/s
INFO - 2023-11-27 13:10:59,376: EPOCH 10 - PROGRESS: at 65.46% examples, 262371 words/s, in_qsize 15, out_qsize 0
INFO - 2023-11-27 13:10:59,735: EPOCH 10: training on 412480 raw words (403514 effective words) took 1.4s, 295428 effective words/s
INFO - 2023-11-27 13:11:00,767: EPOCH 11 - PROGRESS: at 65.46% examples, 256622 words/s, in_qsize 15, out_qsize 0
INFO - 2023-11-27 13:11:01,140: EPOCH 11: training on 412480 raw words (403441 effective words) took 1.4s, 287691 effective words/s
INFO - 2023-11-27 13:11:02,073: EPOCH 12: training on 412480 raw words (403474 effective words) took 0.9s, 433613 effective words/s
INFO - 2023-11-27 13:11:03,001: EPOCH 13: training on 412480 raw words (403456 effective words) took 0.9s, 435510 effective words/s
INFO - 2023-11-27 13:11:03,981: EPOCH 14: training on 412480 raw words (403493 effective words) took 1.0s, 412730 effective words/s
INFO - 2023-11-27 13:11:04,881: EPOCH 15: training on 412480 raw words (403429 effective words) took 0.9s, 449902 effective words/s
INFO - 2023-11-27 13:11:05,731: EPOCH 16: training on 412480 raw words (403625 effective words) took 0.8s, 476100 effective words/s
INFO - 2023-11-27 13:11:06,583: EPOCH 17: training on 412480 raw words (403470 effective words) took 0.8s, 474769 effective words/s
INFO - 2023-11-27 13:11:07,471: EPOCH 18: training on 412480 raw words (403476 effective words) took 0.9s, 454885 effective words/s
INFO - 2023-11-27 13:11:08,347: EPOCH 19: training on 412480 raw words (403634 effective words) took 0.9s, 461807 effective words/s
INFO - 2023-11-27 13:11:08,348: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070122 effective words) took 21.0s, 383882 effective words/s', 'datetime': '2023-11-27T13:11:08.348126', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:08,348: collecting all words and their counts
INFO - 2023-11-27 13:11:08,348: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:11:08,414: PROGRESS: at sentence #10000, processed 400000 words, keeping 10303 word types
INFO - 2023-11-27 13:11:08,416: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:11:08,416: Updating model with new vocabulary
INFO - 2023-11-27 13:11:08,443: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:11:08.443089', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:08,473: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:11:08,473: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:11:08,473: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403688.5485123938 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:11:08.473972', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:08,524: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:11:08,524: updating layer weights
INFO - 2023-11-27 13:11:08,525: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:11:08.525490', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:11:08,525: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:11:08,525: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:11:08.525698', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:09,343: EPOCH 0: training on 412480 raw words (403757 effective words) took 0.8s, 495254 effective words/s
INFO - 2023-11-27 13:11:10,163: EPOCH 1: training on 412480 raw words (403696 effective words) took 0.8s, 493560 effective words/s
INFO - 2023-11-27 13:11:10,988: EPOCH 2: training on 412480 raw words (403674 effective words) took 0.8s, 490697 effective words/s
INFO - 2023-11-27 13:11:11,891: EPOCH 3: training on 412480 raw words (403479 effective words) took 0.9s, 447842 effective words/s
INFO - 2023-11-27 13:11:12,743: EPOCH 4: training on 412480 raw words (403628 effective words) took 0.8s, 475002 effective words/s
INFO - 2023-11-27 13:11:13,595: EPOCH 5: training on 412480 raw words (403643 effective words) took 0.9s, 474542 effective words/s
INFO - 2023-11-27 13:11:14,489: EPOCH 6: training on 412480 raw words (403631 effective words) took 0.9s, 453374 effective words/s
INFO - 2023-11-27 13:11:15,489: EPOCH 7: training on 412480 raw words (403640 effective words) took 1.0s, 404159 effective words/s
INFO - 2023-11-27 13:11:16,493: EPOCH 8 - PROGRESS: at 100.00% examples, 403071 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:11:16,493: EPOCH 8: training on 412480 raw words (403607 effective words) took 1.0s, 402970 effective words/s
INFO - 2023-11-27 13:11:17,506: EPOCH 9 - PROGRESS: at 97.58% examples, 390178 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:11:17,606: EPOCH 9: training on 412480 raw words (403769 effective words) took 1.1s, 363707 effective words/s
INFO - 2023-11-27 13:11:18,612: EPOCH 10 - PROGRESS: at 89.70% examples, 360814 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:11:18,790: EPOCH 10: training on 412480 raw words (403542 effective words) took 1.2s, 341631 effective words/s
INFO - 2023-11-27 13:11:19,819: EPOCH 11 - PROGRESS: at 77.58% examples, 305115 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:11:19,960: EPOCH 11: training on 412480 raw words (403655 effective words) took 1.2s, 346089 effective words/s
INFO - 2023-11-27 13:11:20,971: EPOCH 12 - PROGRESS: at 77.58% examples, 310410 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:11:21,124: EPOCH 12: training on 412480 raw words (403623 effective words) took 1.2s, 347555 effective words/s
INFO - 2023-11-27 13:11:22,132: EPOCH 13 - PROGRESS: at 87.28% examples, 350249 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:11:22,270: EPOCH 13: training on 412480 raw words (403655 effective words) took 1.1s, 353077 effective words/s
INFO - 2023-11-27 13:11:23,325: EPOCH 14 - PROGRESS: at 75.16% examples, 288131 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:11:23,498: EPOCH 14: training on 412480 raw words (403643 effective words) took 1.2s, 329255 effective words/s
INFO - 2023-11-27 13:11:24,524: EPOCH 15 - PROGRESS: at 80.00% examples, 315544 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:11:24,621: EPOCH 15: training on 412480 raw words (403628 effective words) took 1.1s, 360095 effective words/s
INFO - 2023-11-27 13:11:25,468: EPOCH 16: training on 412480 raw words (403576 effective words) took 0.8s, 478028 effective words/s
INFO - 2023-11-27 13:11:26,279: EPOCH 17: training on 412480 raw words (403676 effective words) took 0.8s, 499011 effective words/s
INFO - 2023-11-27 13:11:27,089: EPOCH 18: training on 412480 raw words (403708 effective words) took 0.8s, 499435 effective words/s
INFO - 2023-11-27 13:11:27,912: EPOCH 19: training on 412480 raw words (403695 effective words) took 0.8s, 491450 effective words/s
INFO - 2023-11-27 13:11:27,913: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072925 effective words) took 19.4s, 416404 effective words/s', 'datetime': '2023-11-27T13:11:27.912989', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:27,913: collecting all words and their counts
INFO - 2023-11-27 13:11:27,913: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:11:27,974: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:11:27,976: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:11:27,976: Updating model with new vocabulary
INFO - 2023-11-27 13:11:28,003: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:11:28.003250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:28,034: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:11:28,034: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:11:28,035: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403377.8352954952 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:11:28.034985', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:28,083: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:11:28,083: updating layer weights
INFO - 2023-11-27 13:11:28,083: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:11:28.083912', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:11:28,084: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:11:28,084: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:11:28.084062', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:28,972: EPOCH 0: training on 412480 raw words (403321 effective words) took 0.9s, 455056 effective words/s
INFO - 2023-11-27 13:11:29,845: EPOCH 1: training on 412480 raw words (403417 effective words) took 0.9s, 463563 effective words/s
INFO - 2023-11-27 13:11:30,756: EPOCH 2: training on 412480 raw words (403428 effective words) took 0.9s, 443578 effective words/s
INFO - 2023-11-27 13:11:31,609: EPOCH 3: training on 412480 raw words (403365 effective words) took 0.8s, 474816 effective words/s
INFO - 2023-11-27 13:11:32,443: EPOCH 4: training on 412480 raw words (403399 effective words) took 0.8s, 484986 effective words/s
INFO - 2023-11-27 13:11:33,275: EPOCH 5: training on 412480 raw words (403527 effective words) took 0.8s, 485740 effective words/s
INFO - 2023-11-27 13:11:34,144: EPOCH 6: training on 412480 raw words (403380 effective words) took 0.9s, 465483 effective words/s
INFO - 2023-11-27 13:11:35,019: EPOCH 7: training on 412480 raw words (403297 effective words) took 0.9s, 461634 effective words/s
INFO - 2023-11-27 13:11:35,906: EPOCH 8: training on 412480 raw words (403383 effective words) took 0.9s, 456274 effective words/s
INFO - 2023-11-27 13:11:36,765: EPOCH 9: training on 412480 raw words (403355 effective words) took 0.9s, 470541 effective words/s
INFO - 2023-11-27 13:11:37,619: EPOCH 10: training on 412480 raw words (403367 effective words) took 0.9s, 473516 effective words/s
INFO - 2023-11-27 13:11:38,513: EPOCH 11: training on 412480 raw words (403358 effective words) took 0.9s, 451811 effective words/s
INFO - 2023-11-27 13:11:39,434: EPOCH 12: training on 412480 raw words (403362 effective words) took 0.9s, 444048 effective words/s
INFO - 2023-11-27 13:11:40,482: EPOCH 13 - PROGRESS: at 100.00% examples, 385669 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:11:40,482: EPOCH 13: training on 412480 raw words (403346 effective words) took 1.0s, 385580 effective words/s
INFO - 2023-11-27 13:11:41,503: EPOCH 14 - PROGRESS: at 75.16% examples, 297672 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:11:41,735: EPOCH 14: training on 412480 raw words (403492 effective words) took 1.3s, 322570 effective words/s
INFO - 2023-11-27 13:11:42,768: EPOCH 15 - PROGRESS: at 77.58% examples, 304051 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:11:42,917: EPOCH 15: training on 412480 raw words (403254 effective words) took 1.2s, 342072 effective words/s
INFO - 2023-11-27 13:11:44,042: EPOCH 16 - PROGRESS: at 75.16% examples, 270430 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:11:44,229: EPOCH 16: training on 412480 raw words (403463 effective words) took 1.3s, 308295 effective words/s
INFO - 2023-11-27 13:11:45,242: EPOCH 17 - PROGRESS: at 77.58% examples, 309974 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:11:45,395: EPOCH 17: training on 412480 raw words (403456 effective words) took 1.2s, 346946 effective words/s
INFO - 2023-11-27 13:11:46,449: EPOCH 18 - PROGRESS: at 75.16% examples, 288530 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:11:46,663: EPOCH 18: training on 412480 raw words (403459 effective words) took 1.3s, 318813 effective words/s
INFO - 2023-11-27 13:11:47,700: EPOCH 19 - PROGRESS: at 75.16% examples, 293221 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:11:47,915: EPOCH 19: training on 412480 raw words (403276 effective words) took 1.2s, 322885 effective words/s
INFO - 2023-11-27 13:11:47,916: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8067705 effective words) took 19.8s, 406805 effective words/s', 'datetime': '2023-11-27T13:11:47.915991', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:47,916: collecting all words and their counts
INFO - 2023-11-27 13:11:47,916: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:11:48,004: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:11:48,008: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:11:48,008: Updating model with new vocabulary
INFO - 2023-11-27 13:11:48,054: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:11:48.054620', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:48,104: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:11:48,104: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:11:48,105: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403816.1798247935 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:11:48.105112', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:11:48,186: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:11:48,186: updating layer weights
INFO - 2023-11-27 13:11:48,187: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:11:48.187257', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:11:48,187: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:11:48,187: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:11:48.187466', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:11:49,169: EPOCH 0: training on 412480 raw words (403847 effective words) took 1.0s, 412225 effective words/s
INFO - 2023-11-27 13:11:49,975: EPOCH 1: training on 412480 raw words (403765 effective words) took 0.8s, 502488 effective words/s
INFO - 2023-11-27 13:11:50,794: EPOCH 2: training on 412480 raw words (403885 effective words) took 0.8s, 494655 effective words/s
INFO - 2023-11-27 13:11:51,639: EPOCH 3: training on 412480 raw words (403813 effective words) took 0.8s, 479311 effective words/s
INFO - 2023-11-27 13:11:52,602: EPOCH 4: training on 412480 raw words (403849 effective words) took 1.0s, 420025 effective words/s
INFO - 2023-11-27 13:11:53,514: EPOCH 5: training on 412480 raw words (403809 effective words) took 0.9s, 443995 effective words/s
INFO - 2023-11-27 13:11:54,413: EPOCH 6: training on 412480 raw words (403792 effective words) took 0.9s, 450837 effective words/s
INFO - 2023-11-27 13:11:55,281: EPOCH 7: training on 412480 raw words (403615 effective words) took 0.9s, 467417 effective words/s
INFO - 2023-11-27 13:11:56,180: EPOCH 8: training on 412480 raw words (403622 effective words) took 0.9s, 450230 effective words/s
INFO - 2023-11-27 13:11:57,113: EPOCH 9: training on 412480 raw words (403751 effective words) took 0.9s, 436898 effective words/s
INFO - 2023-11-27 13:11:58,015: EPOCH 10: training on 412480 raw words (403832 effective words) took 0.9s, 448745 effective words/s
INFO - 2023-11-27 13:11:58,852: EPOCH 11: training on 412480 raw words (403718 effective words) took 0.8s, 484009 effective words/s
INFO - 2023-11-27 13:11:59,683: EPOCH 12: training on 412480 raw words (403778 effective words) took 0.8s, 486978 effective words/s
INFO - 2023-11-27 13:12:00,509: EPOCH 13: training on 412480 raw words (403814 effective words) took 0.8s, 489708 effective words/s
INFO - 2023-11-27 13:12:01,312: EPOCH 14: training on 412480 raw words (403808 effective words) took 0.8s, 504281 effective words/s
INFO - 2023-11-27 13:12:02,199: EPOCH 15: training on 412480 raw words (403945 effective words) took 0.9s, 456197 effective words/s
INFO - 2023-11-27 13:12:03,011: EPOCH 16: training on 412480 raw words (403936 effective words) took 0.8s, 499238 effective words/s
INFO - 2023-11-27 13:12:03,835: EPOCH 17: training on 412480 raw words (403774 effective words) took 0.8s, 490817 effective words/s
INFO - 2023-11-27 13:12:04,658: EPOCH 18: training on 412480 raw words (403839 effective words) took 0.8s, 492614 effective words/s
INFO - 2023-11-27 13:12:05,488: EPOCH 19: training on 412480 raw words (403889 effective words) took 0.8s, 487756 effective words/s
INFO - 2023-11-27 13:12:05,489: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8076081 effective words) took 17.3s, 466786 effective words/s', 'datetime': '2023-11-27T13:12:05.488995', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:05,489: collecting all words and their counts
INFO - 2023-11-27 13:12:05,489: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:12:05,553: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:12:05,555: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:12:05,555: Updating model with new vocabulary
INFO - 2023-11-27 13:12:05,582: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:12:05.582793', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:05,613: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:12:05,613: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:12:05,613: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403590.75254491507 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:12:05.613839', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:05,665: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:12:05,665: updating layer weights
INFO - 2023-11-27 13:12:05,666: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:12:05.666302', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:12:05,666: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:12:05,666: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:12:05.666477', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:06,578: EPOCH 0: training on 412480 raw words (403575 effective words) took 0.9s, 443908 effective words/s
INFO - 2023-11-27 13:12:07,646: EPOCH 1 - PROGRESS: at 100.00% examples, 378524 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:07,646: EPOCH 1: training on 412480 raw words (403652 effective words) took 1.1s, 378442 effective words/s
INFO - 2023-11-27 13:12:08,664: EPOCH 2 - PROGRESS: at 82.43% examples, 327779 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:12:08,784: EPOCH 2: training on 412480 raw words (403657 effective words) took 1.1s, 355483 effective words/s
INFO - 2023-11-27 13:12:09,793: EPOCH 3 - PROGRESS: at 87.28% examples, 350178 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:12:09,936: EPOCH 3: training on 412480 raw words (403572 effective words) took 1.1s, 351287 effective words/s
INFO - 2023-11-27 13:12:10,966: EPOCH 4 - PROGRESS: at 77.58% examples, 305572 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:12:11,116: EPOCH 4: training on 412480 raw words (403504 effective words) took 1.2s, 343437 effective words/s
INFO - 2023-11-27 13:12:12,132: EPOCH 5 - PROGRESS: at 77.58% examples, 309068 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:12:12,292: EPOCH 5: training on 412480 raw words (403604 effective words) took 1.2s, 343980 effective words/s
INFO - 2023-11-27 13:12:13,326: EPOCH 6 - PROGRESS: at 100.00% examples, 391329 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:13,326: EPOCH 6: training on 412480 raw words (403684 effective words) took 1.0s, 391254 effective words/s
INFO - 2023-11-27 13:12:14,221: EPOCH 7: training on 412480 raw words (403530 effective words) took 0.9s, 451657 effective words/s
INFO - 2023-11-27 13:12:15,156: EPOCH 8: training on 412480 raw words (403616 effective words) took 0.9s, 432611 effective words/s
INFO - 2023-11-27 13:12:16,123: EPOCH 9: training on 412480 raw words (403574 effective words) took 1.0s, 418673 effective words/s
INFO - 2023-11-27 13:12:17,133: EPOCH 10 - PROGRESS: at 100.00% examples, 400316 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:17,134: EPOCH 10: training on 412480 raw words (403566 effective words) took 1.0s, 400232 effective words/s
INFO - 2023-11-27 13:12:18,101: EPOCH 11: training on 412480 raw words (403676 effective words) took 1.0s, 418188 effective words/s
INFO - 2023-11-27 13:12:18,923: EPOCH 12: training on 412480 raw words (403606 effective words) took 0.8s, 492542 effective words/s
INFO - 2023-11-27 13:12:19,782: EPOCH 13: training on 412480 raw words (403545 effective words) took 0.9s, 470674 effective words/s
INFO - 2023-11-27 13:12:20,637: EPOCH 14: training on 412480 raw words (403693 effective words) took 0.9s, 473392 effective words/s
INFO - 2023-11-27 13:12:21,517: EPOCH 15: training on 412480 raw words (403590 effective words) took 0.9s, 459962 effective words/s
INFO - 2023-11-27 13:12:22,395: EPOCH 16: training on 412480 raw words (403642 effective words) took 0.9s, 460410 effective words/s
INFO - 2023-11-27 13:12:23,260: EPOCH 17: training on 412480 raw words (403562 effective words) took 0.9s, 467745 effective words/s
INFO - 2023-11-27 13:12:24,125: EPOCH 18: training on 412480 raw words (403698 effective words) took 0.9s, 468056 effective words/s
INFO - 2023-11-27 13:12:25,031: EPOCH 19: training on 412480 raw words (403470 effective words) took 0.9s, 446295 effective words/s
INFO - 2023-11-27 13:12:25,031: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072016 effective words) took 19.4s, 416838 effective words/s', 'datetime': '2023-11-27T13:12:25.031407', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:25,031: collecting all words and their counts
INFO - 2023-11-27 13:12:25,031: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:12:25,093: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:12:25,095: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:12:25,095: Updating model with new vocabulary
INFO - 2023-11-27 13:12:25,126: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:12:25.126933', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:25,167: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:12:25,168: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:12:25,168: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403709.2917016412 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:12:25.168296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:25,226: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:12:25,226: updating layer weights
INFO - 2023-11-27 13:12:25,227: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:12:25.227374', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:12:25,227: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:12:25,227: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:12:25.227549', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:26,190: EPOCH 0: training on 412480 raw words (403750 effective words) took 1.0s, 420157 effective words/s
INFO - 2023-11-27 13:12:27,121: EPOCH 1: training on 412480 raw words (403689 effective words) took 0.9s, 434678 effective words/s
INFO - 2023-11-27 13:12:28,023: EPOCH 2: training on 412480 raw words (403600 effective words) took 0.9s, 448225 effective words/s
INFO - 2023-11-27 13:12:29,017: EPOCH 3: training on 412480 raw words (403714 effective words) took 1.0s, 407460 effective words/s
INFO - 2023-11-27 13:12:30,113: EPOCH 4 - PROGRESS: at 100.00% examples, 369084 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:30,113: EPOCH 4: training on 412480 raw words (403886 effective words) took 1.1s, 369010 effective words/s
INFO - 2023-11-27 13:12:31,192: EPOCH 5 - PROGRESS: at 100.00% examples, 375205 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:31,192: EPOCH 5: training on 412480 raw words (403695 effective words) took 1.1s, 375105 effective words/s
INFO - 2023-11-27 13:12:32,205: EPOCH 6 - PROGRESS: at 75.16% examples, 300170 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:32,441: EPOCH 6: training on 412480 raw words (403626 effective words) took 1.2s, 323922 effective words/s
INFO - 2023-11-27 13:12:33,464: EPOCH 7 - PROGRESS: at 75.16% examples, 297459 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:33,687: EPOCH 7: training on 412480 raw words (403771 effective words) took 1.2s, 324795 effective words/s
INFO - 2023-11-27 13:12:34,755: EPOCH 8 - PROGRESS: at 77.58% examples, 293803 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:12:34,914: EPOCH 8: training on 412480 raw words (403688 effective words) took 1.2s, 329700 effective words/s
INFO - 2023-11-27 13:12:35,933: EPOCH 9 - PROGRESS: at 75.16% examples, 298656 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:36,131: EPOCH 9: training on 412480 raw words (403680 effective words) took 1.2s, 332667 effective words/s
INFO - 2023-11-27 13:12:37,137: EPOCH 10 - PROGRESS: at 75.16% examples, 302184 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:37,278: EPOCH 10: training on 412480 raw words (403730 effective words) took 1.1s, 352899 effective words/s
INFO - 2023-11-27 13:12:38,263: EPOCH 11: training on 412480 raw words (403776 effective words) took 1.0s, 410405 effective words/s
INFO - 2023-11-27 13:12:39,096: EPOCH 12: training on 412480 raw words (403661 effective words) took 0.8s, 485708 effective words/s
INFO - 2023-11-27 13:12:39,987: EPOCH 13: training on 412480 raw words (403516 effective words) took 0.9s, 453907 effective words/s
INFO - 2023-11-27 13:12:40,990: EPOCH 14: training on 412480 raw words (403706 effective words) took 1.0s, 403779 effective words/s
INFO - 2023-11-27 13:12:41,932: EPOCH 15: training on 412480 raw words (403660 effective words) took 0.9s, 429441 effective words/s
INFO - 2023-11-27 13:12:42,874: EPOCH 16: training on 412480 raw words (403763 effective words) took 0.9s, 429971 effective words/s
INFO - 2023-11-27 13:12:43,787: EPOCH 17: training on 412480 raw words (403752 effective words) took 0.9s, 443129 effective words/s
INFO - 2023-11-27 13:12:44,732: EPOCH 18: training on 412480 raw words (403644 effective words) took 0.9s, 428048 effective words/s
INFO - 2023-11-27 13:12:45,670: EPOCH 19: training on 412480 raw words (403723 effective words) took 0.9s, 432047 effective words/s
INFO - 2023-11-27 13:12:45,670: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074030 effective words) took 20.4s, 394959 effective words/s', 'datetime': '2023-11-27T13:12:45.670355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:45,670: collecting all words and their counts
INFO - 2023-11-27 13:12:45,670: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:12:45,741: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:12:45,743: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:12:45,743: Updating model with new vocabulary
INFO - 2023-11-27 13:12:45,775: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:12:45.775613', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:45,813: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:12:45,813: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:12:45,813: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403513.5790341897 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:12:45.813971', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:12:45,876: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:12:45,877: updating layer weights
INFO - 2023-11-27 13:12:45,877: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:12:45.877718', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:12:45,877: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:12:45,877: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:12:45.877912', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:12:46,879: EPOCH 0: training on 412480 raw words (403560 effective words) took 1.0s, 403756 effective words/s
INFO - 2023-11-27 13:12:47,812: EPOCH 1: training on 412480 raw words (403545 effective words) took 0.9s, 433392 effective words/s
INFO - 2023-11-27 13:12:48,778: EPOCH 2: training on 412480 raw words (403566 effective words) took 1.0s, 418744 effective words/s
INFO - 2023-11-27 13:12:49,773: EPOCH 3: training on 412480 raw words (403515 effective words) took 1.0s, 406574 effective words/s
INFO - 2023-11-27 13:12:50,706: EPOCH 4: training on 412480 raw words (403574 effective words) took 0.9s, 433343 effective words/s
INFO - 2023-11-27 13:12:51,655: EPOCH 5: training on 412480 raw words (403496 effective words) took 0.9s, 426229 effective words/s
INFO - 2023-11-27 13:12:52,711: EPOCH 6 - PROGRESS: at 100.00% examples, 382896 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:12:52,711: EPOCH 6: training on 412480 raw words (403330 effective words) took 1.1s, 382811 effective words/s
INFO - 2023-11-27 13:12:53,748: EPOCH 7 - PROGRESS: at 77.58% examples, 302679 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:12:53,913: EPOCH 7: training on 412480 raw words (403422 effective words) took 1.2s, 336349 effective words/s
INFO - 2023-11-27 13:12:54,951: EPOCH 8 - PROGRESS: at 77.58% examples, 302415 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:12:55,118: EPOCH 8: training on 412480 raw words (403589 effective words) took 1.2s, 335620 effective words/s
INFO - 2023-11-27 13:12:56,181: EPOCH 9 - PROGRESS: at 75.16% examples, 286121 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:56,383: EPOCH 9: training on 412480 raw words (403439 effective words) took 1.3s, 319788 effective words/s
INFO - 2023-11-27 13:12:57,442: EPOCH 10 - PROGRESS: at 75.16% examples, 287054 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:12:57,656: EPOCH 10: training on 412480 raw words (403523 effective words) took 1.3s, 317674 effective words/s
INFO - 2023-11-27 13:12:58,682: EPOCH 11 - PROGRESS: at 97.58% examples, 384851 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:12:58,754: EPOCH 11: training on 412480 raw words (403562 effective words) took 1.1s, 368557 effective words/s
INFO - 2023-11-27 13:12:59,784: EPOCH 12 - PROGRESS: at 75.16% examples, 295607 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:00,015: EPOCH 12: training on 412480 raw words (403645 effective words) took 1.3s, 320929 effective words/s
INFO - 2023-11-27 13:13:01,024: EPOCH 13 - PROGRESS: at 75.16% examples, 301669 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:01,255: EPOCH 13: training on 412480 raw words (403543 effective words) took 1.2s, 326243 effective words/s
INFO - 2023-11-27 13:13:02,262: EPOCH 14 - PROGRESS: at 95.15% examples, 382385 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:13:02,335: EPOCH 14: training on 412480 raw words (403639 effective words) took 1.1s, 374705 effective words/s
INFO - 2023-11-27 13:13:03,256: EPOCH 15: training on 412480 raw words (403569 effective words) took 0.9s, 439345 effective words/s
INFO - 2023-11-27 13:13:04,158: EPOCH 16: training on 412480 raw words (403496 effective words) took 0.9s, 448674 effective words/s
INFO - 2023-11-27 13:13:05,090: EPOCH 17: training on 412480 raw words (403722 effective words) took 0.9s, 434278 effective words/s
INFO - 2023-11-27 13:13:06,021: EPOCH 18: training on 412480 raw words (403472 effective words) took 0.9s, 434362 effective words/s
INFO - 2023-11-27 13:13:06,937: EPOCH 19: training on 412480 raw words (403530 effective words) took 0.9s, 441276 effective words/s
INFO - 2023-11-27 13:13:06,938: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070737 effective words) took 21.1s, 383224 effective words/s', 'datetime': '2023-11-27T13:13:06.938121', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:06,938: collecting all words and their counts
INFO - 2023-11-27 13:13:06,938: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:13:06,999: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:13:07,001: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:13:07,001: Updating model with new vocabulary
INFO - 2023-11-27 13:13:07,035: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:13:07.035161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:07,089: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:13:07,089: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:13:07,090: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403447.85678416694 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:13:07.089966', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:07,163: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:13:07,163: updating layer weights
INFO - 2023-11-27 13:13:07,164: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:13:07.164502', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:13:07,164: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:13:07,164: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:13:07.164710', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:08,086: EPOCH 0: training on 412480 raw words (403506 effective words) took 0.9s, 450260 effective words/s
INFO - 2023-11-27 13:13:09,035: EPOCH 1: training on 412480 raw words (403484 effective words) took 0.9s, 426498 effective words/s
INFO - 2023-11-27 13:13:09,872: EPOCH 2: training on 412480 raw words (403564 effective words) took 0.8s, 482921 effective words/s
INFO - 2023-11-27 13:13:10,711: EPOCH 3: training on 412480 raw words (403392 effective words) took 0.8s, 482088 effective words/s
INFO - 2023-11-27 13:13:11,546: EPOCH 4: training on 412480 raw words (403405 effective words) took 0.8s, 484599 effective words/s
INFO - 2023-11-27 13:13:12,376: EPOCH 5: training on 412480 raw words (403380 effective words) took 0.8s, 486858 effective words/s
INFO - 2023-11-27 13:13:13,238: EPOCH 6: training on 412480 raw words (403458 effective words) took 0.9s, 469409 effective words/s
INFO - 2023-11-27 13:13:14,156: EPOCH 7: training on 412480 raw words (403478 effective words) took 0.9s, 440497 effective words/s
INFO - 2023-11-27 13:13:15,098: EPOCH 8: training on 412480 raw words (403540 effective words) took 0.9s, 429420 effective words/s
INFO - 2023-11-27 13:13:16,009: EPOCH 9: training on 412480 raw words (403373 effective words) took 0.9s, 443921 effective words/s
INFO - 2023-11-27 13:13:17,051: EPOCH 10 - PROGRESS: at 100.00% examples, 388069 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:13:17,051: EPOCH 10: training on 412480 raw words (403363 effective words) took 1.0s, 387972 effective words/s
INFO - 2023-11-27 13:13:18,070: EPOCH 11 - PROGRESS: at 80.00% examples, 317702 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:13:18,199: EPOCH 11: training on 412480 raw words (403466 effective words) took 1.1s, 352305 effective words/s
INFO - 2023-11-27 13:13:19,258: EPOCH 12 - PROGRESS: at 75.16% examples, 287356 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:19,452: EPOCH 12: training on 412480 raw words (403413 effective words) took 1.3s, 322701 effective words/s
INFO - 2023-11-27 13:13:20,563: EPOCH 13 - PROGRESS: at 75.16% examples, 273804 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:20,765: EPOCH 13: training on 412480 raw words (403368 effective words) took 1.3s, 308038 effective words/s
INFO - 2023-11-27 13:13:21,792: EPOCH 14 - PROGRESS: at 77.58% examples, 305533 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:13:21,950: EPOCH 14: training on 412480 raw words (403494 effective words) took 1.2s, 341219 effective words/s
INFO - 2023-11-27 13:13:22,976: EPOCH 15 - PROGRESS: at 75.16% examples, 296565 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:23,183: EPOCH 15: training on 412480 raw words (403517 effective words) took 1.2s, 328051 effective words/s
INFO - 2023-11-27 13:13:24,193: EPOCH 16 - PROGRESS: at 75.16% examples, 301292 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:24,392: EPOCH 16: training on 412480 raw words (403372 effective words) took 1.2s, 334606 effective words/s
INFO - 2023-11-27 13:13:25,403: EPOCH 17 - PROGRESS: at 75.16% examples, 300813 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:25,547: EPOCH 17: training on 412480 raw words (403491 effective words) took 1.2s, 350301 effective words/s
INFO - 2023-11-27 13:13:26,424: EPOCH 18: training on 412480 raw words (403488 effective words) took 0.9s, 460650 effective words/s
INFO - 2023-11-27 13:13:27,294: EPOCH 19: training on 412480 raw words (403482 effective words) took 0.9s, 465330 effective words/s
INFO - 2023-11-27 13:13:27,294: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8069034 effective words) took 20.1s, 400849 effective words/s', 'datetime': '2023-11-27T13:13:27.294661', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:27,294: collecting all words and their counts
INFO - 2023-11-27 13:13:27,294: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:13:27,370: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:13:27,373: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:13:27,373: Updating model with new vocabulary
INFO - 2023-11-27 13:13:27,411: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:13:27.411727', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:27,453: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:13:27,453: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:13:27,453: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403652.1630995333 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:13:27.453786', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:27,518: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:13:27,519: updating layer weights
INFO - 2023-11-27 13:13:27,519: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:13:27.519653', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:13:27,519: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:13:27,519: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:13:27.519828', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:28,443: EPOCH 0: training on 412480 raw words (403509 effective words) took 0.9s, 437918 effective words/s
INFO - 2023-11-27 13:13:29,355: EPOCH 1: training on 412480 raw words (403520 effective words) took 0.9s, 443312 effective words/s
INFO - 2023-11-27 13:13:30,246: EPOCH 2: training on 412480 raw words (403616 effective words) took 0.9s, 454118 effective words/s
INFO - 2023-11-27 13:13:31,203: EPOCH 3: training on 412480 raw words (403737 effective words) took 1.0s, 422657 effective words/s
INFO - 2023-11-27 13:13:32,158: EPOCH 4: training on 412480 raw words (403764 effective words) took 1.0s, 423919 effective words/s
INFO - 2023-11-27 13:13:33,112: EPOCH 5: training on 412480 raw words (403604 effective words) took 1.0s, 424081 effective words/s
INFO - 2023-11-27 13:13:34,047: EPOCH 6: training on 412480 raw words (403621 effective words) took 0.9s, 432471 effective words/s
INFO - 2023-11-27 13:13:34,955: EPOCH 7: training on 412480 raw words (403694 effective words) took 0.9s, 445586 effective words/s
INFO - 2023-11-27 13:13:35,875: EPOCH 8: training on 412480 raw words (403598 effective words) took 0.9s, 439924 effective words/s
INFO - 2023-11-27 13:13:36,881: EPOCH 9 - PROGRESS: at 100.00% examples, 401876 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:13:36,881: EPOCH 9: training on 412480 raw words (403631 effective words) took 1.0s, 401802 effective words/s
INFO - 2023-11-27 13:13:37,814: EPOCH 10: training on 412480 raw words (403676 effective words) took 0.9s, 433802 effective words/s
INFO - 2023-11-27 13:13:38,735: EPOCH 11: training on 412480 raw words (403656 effective words) took 0.9s, 439231 effective words/s
INFO - 2023-11-27 13:13:39,691: EPOCH 12: training on 412480 raw words (403542 effective words) took 1.0s, 423275 effective words/s
INFO - 2023-11-27 13:13:40,565: EPOCH 13: training on 412480 raw words (403545 effective words) took 0.9s, 463031 effective words/s
INFO - 2023-11-27 13:13:41,571: EPOCH 14 - PROGRESS: at 80.00% examples, 321749 words/s, in_qsize 8, out_qsize 3
INFO - 2023-11-27 13:13:41,719: EPOCH 14: training on 412480 raw words (403628 effective words) took 1.2s, 350583 effective words/s
INFO - 2023-11-27 13:13:42,800: EPOCH 15 - PROGRESS: at 75.16% examples, 281319 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:13:42,985: EPOCH 15: training on 412480 raw words (403684 effective words) took 1.3s, 319436 effective words/s
INFO - 2023-11-27 13:13:44,021: EPOCH 16 - PROGRESS: at 77.58% examples, 310704 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:13:44,225: EPOCH 16: training on 412480 raw words (403731 effective words) took 1.2s, 333025 effective words/s
INFO - 2023-11-27 13:13:45,230: EPOCH 17 - PROGRESS: at 80.00% examples, 322138 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:13:45,379: EPOCH 17: training on 412480 raw words (403656 effective words) took 1.2s, 350484 effective words/s
INFO - 2023-11-27 13:13:46,385: EPOCH 18 - PROGRESS: at 82.43% examples, 331776 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:13:46,499: EPOCH 18: training on 412480 raw words (403666 effective words) took 1.1s, 361218 effective words/s
INFO - 2023-11-27 13:13:47,513: EPOCH 19 - PROGRESS: at 80.00% examples, 319416 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:13:47,645: EPOCH 19: training on 412480 raw words (403681 effective words) took 1.1s, 352917 effective words/s
INFO - 2023-11-27 13:13:47,646: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072759 effective words) took 20.1s, 401105 effective words/s', 'datetime': '2023-11-27T13:13:47.646229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:47,646: collecting all words and their counts
INFO - 2023-11-27 13:13:47,646: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:13:47,738: PROGRESS: at sentence #10000, processed 400000 words, keeping 10307 word types
INFO - 2023-11-27 13:13:47,740: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:13:47,740: Updating model with new vocabulary
INFO - 2023-11-27 13:13:47,773: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:13:47.773314', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:47,821: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:13:47,821: sample=0.001 downsamples 26 most-common words
INFO - 2023-11-27 13:13:47,821: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403584.81173286354 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:13:47.821776', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:13:47,895: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:13:47,895: updating layer weights
INFO - 2023-11-27 13:13:47,896: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:13:47.896124', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:13:47,896: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:13:47,896: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:13:47.896315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:13:48,995: EPOCH 0 - PROGRESS: at 100.00% examples, 367904 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:13:48,996: EPOCH 0: training on 412480 raw words (403707 effective words) took 1.1s, 367825 effective words/s
INFO - 2023-11-27 13:13:50,037: EPOCH 1 - PROGRESS: at 100.00% examples, 388613 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:13:50,037: EPOCH 1: training on 412480 raw words (403582 effective words) took 1.0s, 388536 effective words/s
INFO - 2023-11-27 13:13:50,872: EPOCH 2: training on 412480 raw words (403568 effective words) took 0.8s, 484196 effective words/s
INFO - 2023-11-27 13:13:51,854: EPOCH 3: training on 412480 raw words (403706 effective words) took 1.0s, 412057 effective words/s
INFO - 2023-11-27 13:13:52,794: EPOCH 4: training on 412480 raw words (403673 effective words) took 0.9s, 430985 effective words/s
INFO - 2023-11-27 13:13:53,737: EPOCH 5: training on 412480 raw words (403690 effective words) took 0.9s, 428995 effective words/s
INFO - 2023-11-27 13:13:54,647: EPOCH 6: training on 412480 raw words (403597 effective words) took 0.9s, 444780 effective words/s
INFO - 2023-11-27 13:13:55,568: EPOCH 7: training on 412480 raw words (403478 effective words) took 0.9s, 439314 effective words/s
INFO - 2023-11-27 13:13:56,440: EPOCH 8: training on 412480 raw words (403571 effective words) took 0.9s, 463836 effective words/s
INFO - 2023-11-27 13:13:57,344: EPOCH 9: training on 412480 raw words (403494 effective words) took 0.9s, 447290 effective words/s
INFO - 2023-11-27 13:13:58,219: EPOCH 10: training on 412480 raw words (403485 effective words) took 0.9s, 462890 effective words/s
INFO - 2023-11-27 13:13:59,040: EPOCH 11: training on 412480 raw words (403470 effective words) took 0.8s, 492879 effective words/s
INFO - 2023-11-27 13:14:00,013: EPOCH 12: training on 412480 raw words (403587 effective words) took 1.0s, 415625 effective words/s
INFO - 2023-11-27 13:14:01,024: EPOCH 13 - PROGRESS: at 100.00% examples, 400180 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:01,024: EPOCH 13: training on 412480 raw words (403656 effective words) took 1.0s, 400060 effective words/s
INFO - 2023-11-27 13:14:01,963: EPOCH 14: training on 412480 raw words (403606 effective words) took 0.9s, 430865 effective words/s
INFO - 2023-11-27 13:14:02,906: EPOCH 15: training on 412480 raw words (403721 effective words) took 0.9s, 429094 effective words/s
INFO - 2023-11-27 13:14:03,813: EPOCH 16: training on 412480 raw words (403616 effective words) took 0.9s, 445631 effective words/s
INFO - 2023-11-27 13:14:04,711: EPOCH 17: training on 412480 raw words (403597 effective words) took 0.9s, 450592 effective words/s
INFO - 2023-11-27 13:14:05,714: EPOCH 18 - PROGRESS: at 97.58% examples, 393447 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:14:05,818: EPOCH 18: training on 412480 raw words (403441 effective words) took 1.1s, 365028 effective words/s
INFO - 2023-11-27 13:14:06,824: EPOCH 19 - PROGRESS: at 72.73% examples, 292596 words/s, in_qsize 11, out_qsize 1
INFO - 2023-11-27 13:14:07,183: EPOCH 19: training on 412480 raw words (403592 effective words) took 1.4s, 296226 effective words/s
INFO - 2023-11-27 13:14:07,183: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071837 effective words) took 19.3s, 418503 effective words/s', 'datetime': '2023-11-27T13:14:07.183811', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:07,184: collecting all words and their counts
INFO - 2023-11-27 13:14:07,184: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:14:07,311: PROGRESS: at sentence #10000, processed 400000 words, keeping 10293 word types
INFO - 2023-11-27 13:14:07,317: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:14:07,318: Updating model with new vocabulary
INFO - 2023-11-27 13:14:07,371: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:14:07.371264', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:07,432: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:14:07,432: sample=0.001 downsamples 26 most-common words
INFO - 2023-11-27 13:14:07,432: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403775.44868992583 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:14:07.432935', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:07,503: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:14:07,503: updating layer weights
INFO - 2023-11-27 13:14:07,504: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:14:07.504123', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:14:07,504: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:14:07,504: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:14:07.504345', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:08,526: EPOCH 0 - PROGRESS: at 77.58% examples, 308389 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:14:08,672: EPOCH 0: training on 412480 raw words (403804 effective words) took 1.2s, 347581 effective words/s
INFO - 2023-11-27 13:14:09,675: EPOCH 1 - PROGRESS: at 89.70% examples, 362046 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:14:09,810: EPOCH 1: training on 412480 raw words (403803 effective words) took 1.1s, 355514 effective words/s
INFO - 2023-11-27 13:14:10,818: EPOCH 2 - PROGRESS: at 87.28% examples, 350463 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:14:10,972: EPOCH 2: training on 412480 raw words (403822 effective words) took 1.2s, 348357 effective words/s
INFO - 2023-11-27 13:14:11,984: EPOCH 3 - PROGRESS: at 75.16% examples, 300575 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:14:12,174: EPOCH 3: training on 412480 raw words (403767 effective words) took 1.2s, 336657 effective words/s
INFO - 2023-11-27 13:14:13,190: EPOCH 4 - PROGRESS: at 77.58% examples, 309126 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:14:13,345: EPOCH 4: training on 412480 raw words (403796 effective words) took 1.2s, 345497 effective words/s
INFO - 2023-11-27 13:14:14,310: EPOCH 5: training on 412480 raw words (403786 effective words) took 1.0s, 419549 effective words/s
INFO - 2023-11-27 13:14:15,150: EPOCH 6: training on 412480 raw words (403853 effective words) took 0.8s, 481828 effective words/s
INFO - 2023-11-27 13:14:16,063: EPOCH 7: training on 412480 raw words (403747 effective words) took 0.9s, 443483 effective words/s
INFO - 2023-11-27 13:14:16,925: EPOCH 8: training on 412480 raw words (403938 effective words) took 0.9s, 469775 effective words/s
INFO - 2023-11-27 13:14:17,763: EPOCH 9: training on 412480 raw words (403812 effective words) took 0.8s, 482964 effective words/s
INFO - 2023-11-27 13:14:18,646: EPOCH 10: training on 412480 raw words (403659 effective words) took 0.9s, 458680 effective words/s
INFO - 2023-11-27 13:14:19,463: EPOCH 11: training on 412480 raw words (403901 effective words) took 0.8s, 495125 effective words/s
INFO - 2023-11-27 13:14:20,343: EPOCH 12: training on 412480 raw words (403875 effective words) took 0.9s, 459875 effective words/s
INFO - 2023-11-27 13:14:21,203: EPOCH 13: training on 412480 raw words (403765 effective words) took 0.9s, 471016 effective words/s
INFO - 2023-11-27 13:14:22,052: EPOCH 14: training on 412480 raw words (403864 effective words) took 0.8s, 476932 effective words/s
INFO - 2023-11-27 13:14:22,926: EPOCH 15: training on 412480 raw words (403846 effective words) took 0.9s, 463239 effective words/s
INFO - 2023-11-27 13:14:23,760: EPOCH 16: training on 412480 raw words (403757 effective words) took 0.8s, 485036 effective words/s
INFO - 2023-11-27 13:14:24,653: EPOCH 17: training on 412480 raw words (403740 effective words) took 0.9s, 453331 effective words/s
INFO - 2023-11-27 13:14:25,519: EPOCH 18: training on 412480 raw words (403784 effective words) took 0.9s, 467412 effective words/s
INFO - 2023-11-27 13:14:26,363: EPOCH 19: training on 412480 raw words (403810 effective words) took 0.8s, 479496 effective words/s
INFO - 2023-11-27 13:14:26,363: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8076129 effective words) took 18.9s, 428237 effective words/s', 'datetime': '2023-11-27T13:14:26.363469', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:26,363: collecting all words and their counts
INFO - 2023-11-27 13:14:26,363: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:14:26,425: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:14:26,427: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:14:26,427: Updating model with new vocabulary
INFO - 2023-11-27 13:14:26,453: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:14:26.453116', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:26,483: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:14:26,483: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:14:26,484: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403632.90760095464 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:14:26.484064', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:26,538: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:14:26,538: updating layer weights
INFO - 2023-11-27 13:14:26,539: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:14:26.539100', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:14:26,539: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:14:26,539: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:14:26.539256', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:27,351: EPOCH 0: training on 412480 raw words (403690 effective words) took 0.8s, 498015 effective words/s
INFO - 2023-11-27 13:14:28,136: EPOCH 1: training on 412480 raw words (403705 effective words) took 0.8s, 515359 effective words/s
INFO - 2023-11-27 13:14:28,930: EPOCH 2: training on 412480 raw words (403672 effective words) took 0.8s, 509689 effective words/s
INFO - 2023-11-27 13:14:29,967: EPOCH 3 - PROGRESS: at 100.00% examples, 390281 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:29,968: EPOCH 3: training on 412480 raw words (403760 effective words) took 1.0s, 390193 effective words/s
INFO - 2023-11-27 13:14:30,991: EPOCH 4 - PROGRESS: at 100.00% examples, 395095 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:30,991: EPOCH 4: training on 412480 raw words (403459 effective words) took 1.0s, 395004 effective words/s
INFO - 2023-11-27 13:14:31,995: EPOCH 5 - PROGRESS: at 97.58% examples, 393310 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:14:32,113: EPOCH 5: training on 412480 raw words (403649 effective words) took 1.1s, 360600 effective words/s
INFO - 2023-11-27 13:14:33,124: EPOCH 6 - PROGRESS: at 97.58% examples, 390865 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:14:33,186: EPOCH 6: training on 412480 raw words (403697 effective words) took 1.1s, 377145 effective words/s
INFO - 2023-11-27 13:14:34,250: EPOCH 7 - PROGRESS: at 100.00% examples, 380551 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:34,250: EPOCH 7: training on 412480 raw words (403747 effective words) took 1.1s, 380469 effective words/s
INFO - 2023-11-27 13:14:35,253: EPOCH 8 - PROGRESS: at 97.58% examples, 393811 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:14:35,374: EPOCH 8: training on 412480 raw words (403726 effective words) took 1.1s, 359961 effective words/s
INFO - 2023-11-27 13:14:36,385: EPOCH 9 - PROGRESS: at 80.61% examples, 322517 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:14:36,515: EPOCH 9: training on 412480 raw words (403671 effective words) took 1.1s, 354636 effective words/s
INFO - 2023-11-27 13:14:37,602: EPOCH 10 - PROGRESS: at 75.16% examples, 279934 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:14:37,792: EPOCH 10: training on 412480 raw words (403827 effective words) took 1.3s, 316976 effective words/s
INFO - 2023-11-27 13:14:38,771: EPOCH 11: training on 412480 raw words (403576 effective words) took 1.0s, 413333 effective words/s
INFO - 2023-11-27 13:14:39,762: EPOCH 12: training on 412480 raw words (403587 effective words) took 1.0s, 408384 effective words/s
INFO - 2023-11-27 13:14:40,767: EPOCH 13 - PROGRESS: at 100.00% examples, 402547 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:40,768: EPOCH 13: training on 412480 raw words (403713 effective words) took 1.0s, 402452 effective words/s
INFO - 2023-11-27 13:14:41,847: EPOCH 14 - PROGRESS: at 100.00% examples, 374577 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:41,848: EPOCH 14: training on 412480 raw words (403618 effective words) took 1.1s, 374484 effective words/s
INFO - 2023-11-27 13:14:42,845: EPOCH 15: training on 412480 raw words (403704 effective words) took 1.0s, 405929 effective words/s
INFO - 2023-11-27 13:14:43,905: EPOCH 16 - PROGRESS: at 100.00% examples, 381324 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:43,906: EPOCH 16: training on 412480 raw words (403486 effective words) took 1.1s, 381236 effective words/s
INFO - 2023-11-27 13:14:44,891: EPOCH 17: training on 412480 raw words (403651 effective words) took 1.0s, 410856 effective words/s
INFO - 2023-11-27 13:14:45,949: EPOCH 18 - PROGRESS: at 100.00% examples, 382687 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:45,949: EPOCH 18: training on 412480 raw words (403708 effective words) took 1.1s, 382601 effective words/s
INFO - 2023-11-27 13:14:46,948: EPOCH 19: training on 412480 raw words (403515 effective words) took 1.0s, 404767 effective words/s
INFO - 2023-11-27 13:14:46,949: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073161 effective words) took 20.4s, 395556 effective words/s', 'datetime': '2023-11-27T13:14:46.948980', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:46,949: collecting all words and their counts
INFO - 2023-11-27 13:14:46,949: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:14:47,046: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:14:47,049: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:14:47,049: Updating model with new vocabulary
INFO - 2023-11-27 13:14:47,084: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:14:47.084614', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:47,135: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:14:47,136: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:14:47,136: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403409.80201806274 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:14:47.136481', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:14:47,221: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:14:47,222: updating layer weights
INFO - 2023-11-27 13:14:47,222: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:14:47.222835', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:14:47,222: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:14:47,223: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:14:47.223066', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:14:48,298: EPOCH 0 - PROGRESS: at 100.00% examples, 375757 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:48,298: EPOCH 0: training on 412480 raw words (403312 effective words) took 1.1s, 375679 effective words/s
INFO - 2023-11-27 13:14:49,305: EPOCH 1 - PROGRESS: at 100.00% examples, 401777 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:49,305: EPOCH 1: training on 412480 raw words (403397 effective words) took 1.0s, 401706 effective words/s
INFO - 2023-11-27 13:14:50,273: EPOCH 2: training on 412480 raw words (403439 effective words) took 1.0s, 417674 effective words/s
INFO - 2023-11-27 13:14:51,214: EPOCH 3: training on 412480 raw words (403357 effective words) took 0.9s, 429827 effective words/s
INFO - 2023-11-27 13:14:52,228: EPOCH 4 - PROGRESS: at 100.00% examples, 398659 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:14:52,228: EPOCH 4: training on 412480 raw words (403329 effective words) took 1.0s, 398555 effective words/s
INFO - 2023-11-27 13:14:53,235: EPOCH 5 - PROGRESS: at 90.30% examples, 362525 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:14:53,310: EPOCH 5: training on 412480 raw words (403274 effective words) took 1.1s, 373501 effective words/s
INFO - 2023-11-27 13:14:54,321: EPOCH 6 - PROGRESS: at 82.43% examples, 329554 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:14:54,375: EPOCH 6: training on 412480 raw words (403257 effective words) took 1.1s, 379665 effective words/s
INFO - 2023-11-27 13:14:55,348: EPOCH 7: training on 412480 raw words (403538 effective words) took 1.0s, 415506 effective words/s
INFO - 2023-11-27 13:14:56,322: EPOCH 8: training on 412480 raw words (403426 effective words) took 1.0s, 415146 effective words/s
INFO - 2023-11-27 13:14:57,272: EPOCH 9: training on 412480 raw words (403529 effective words) took 0.9s, 425826 effective words/s
INFO - 2023-11-27 13:14:58,175: EPOCH 10: training on 412480 raw words (403386 effective words) took 0.9s, 447829 effective words/s
INFO - 2023-11-27 13:14:59,037: EPOCH 11: training on 412480 raw words (403335 effective words) took 0.9s, 469139 effective words/s
INFO - 2023-11-27 13:14:59,948: EPOCH 12: training on 412480 raw words (403216 effective words) took 0.9s, 443530 effective words/s
INFO - 2023-11-27 13:15:00,837: EPOCH 13: training on 412480 raw words (403408 effective words) took 0.9s, 454822 effective words/s
INFO - 2023-11-27 13:15:01,918: EPOCH 14 - PROGRESS: at 100.00% examples, 374116 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:15:01,918: EPOCH 14: training on 412480 raw words (403402 effective words) took 1.1s, 374027 effective words/s
INFO - 2023-11-27 13:15:02,949: EPOCH 15 - PROGRESS: at 75.16% examples, 294902 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:03,166: EPOCH 15: training on 412480 raw words (403505 effective words) took 1.2s, 323931 effective words/s
INFO - 2023-11-27 13:15:04,185: EPOCH 16 - PROGRESS: at 82.43% examples, 332472 words/s, in_qsize 7, out_qsize 3
INFO - 2023-11-27 13:15:04,309: EPOCH 16: training on 412480 raw words (403493 effective words) took 1.1s, 358922 effective words/s
INFO - 2023-11-27 13:15:05,315: EPOCH 17 - PROGRESS: at 67.88% examples, 273157 words/s, in_qsize 14, out_qsize 0
INFO - 2023-11-27 13:15:05,670: EPOCH 17: training on 412480 raw words (403275 effective words) took 1.4s, 296907 effective words/s
INFO - 2023-11-27 13:15:06,732: EPOCH 18 - PROGRESS: at 70.31% examples, 268044 words/s, in_qsize 13, out_qsize 0
INFO - 2023-11-27 13:15:06,997: EPOCH 18: training on 412480 raw words (403424 effective words) took 1.3s, 304834 effective words/s
INFO - 2023-11-27 13:15:08,100: EPOCH 19 - PROGRESS: at 75.16% examples, 275611 words/s, in_qsize 10, out_qsize 1
INFO - 2023-11-27 13:15:08,319: EPOCH 19: training on 412480 raw words (403367 effective words) took 1.3s, 305868 effective words/s
INFO - 2023-11-27 13:15:08,319: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8067669 effective words) took 21.1s, 382420 effective words/s', 'datetime': '2023-11-27T13:15:08.319534', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:08,319: collecting all words and their counts
INFO - 2023-11-27 13:15:08,319: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:15:08,414: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:15:08,416: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:15:08,416: Updating model with new vocabulary
INFO - 2023-11-27 13:15:08,452: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:15:08.452485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:08,503: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:15:08,504: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:15:08,504: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403535.51827376813 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:15:08.504361', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:08,611: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:15:08,611: updating layer weights
INFO - 2023-11-27 13:15:08,613: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:15:08.613028', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:15:08,614: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:15:08,614: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:15:08.614347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:09,635: EPOCH 0 - PROGRESS: at 48.49% examples, 192966 words/s, in_qsize 20, out_qsize 0
INFO - 2023-11-27 13:15:10,193: EPOCH 0: training on 412480 raw words (403590 effective words) took 1.6s, 256578 effective words/s
INFO - 2023-11-27 13:15:11,164: EPOCH 1: training on 412480 raw words (403599 effective words) took 1.0s, 416751 effective words/s
INFO - 2023-11-27 13:15:12,123: EPOCH 2: training on 412480 raw words (403573 effective words) took 1.0s, 422041 effective words/s
INFO - 2023-11-27 13:15:12,957: EPOCH 3: training on 412480 raw words (403611 effective words) took 0.8s, 485146 effective words/s
INFO - 2023-11-27 13:15:13,802: EPOCH 4: training on 412480 raw words (403342 effective words) took 0.8s, 478480 effective words/s
INFO - 2023-11-27 13:15:14,666: EPOCH 5: training on 412480 raw words (403459 effective words) took 0.9s, 467965 effective words/s
INFO - 2023-11-27 13:15:15,578: EPOCH 6: training on 412480 raw words (403485 effective words) took 0.9s, 443405 effective words/s
INFO - 2023-11-27 13:15:16,542: EPOCH 7: training on 412480 raw words (403578 effective words) took 1.0s, 419744 effective words/s
INFO - 2023-11-27 13:15:17,428: EPOCH 8: training on 412480 raw words (403481 effective words) took 0.9s, 456269 effective words/s
INFO - 2023-11-27 13:15:18,274: EPOCH 9: training on 412480 raw words (403502 effective words) took 0.8s, 478258 effective words/s
INFO - 2023-11-27 13:15:19,179: EPOCH 10: training on 412480 raw words (403286 effective words) took 0.9s, 446504 effective words/s
INFO - 2023-11-27 13:15:19,991: EPOCH 11: training on 412480 raw words (403456 effective words) took 0.8s, 498031 effective words/s
INFO - 2023-11-27 13:15:20,836: EPOCH 12: training on 412480 raw words (403512 effective words) took 0.8s, 479163 effective words/s
INFO - 2023-11-27 13:15:21,808: EPOCH 13: training on 412480 raw words (403570 effective words) took 1.0s, 415920 effective words/s
INFO - 2023-11-27 13:15:22,688: EPOCH 14: training on 412480 raw words (403534 effective words) took 0.9s, 460147 effective words/s
INFO - 2023-11-27 13:15:23,541: EPOCH 15: training on 412480 raw words (403564 effective words) took 0.9s, 473912 effective words/s
INFO - 2023-11-27 13:15:24,411: EPOCH 16: training on 412480 raw words (403570 effective words) took 0.9s, 465216 effective words/s
INFO - 2023-11-27 13:15:25,245: EPOCH 17: training on 412480 raw words (403463 effective words) took 0.8s, 484726 effective words/s
INFO - 2023-11-27 13:15:26,332: EPOCH 18 - PROGRESS: at 100.00% examples, 372047 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:15:26,332: EPOCH 18: training on 412480 raw words (403539 effective words) took 1.1s, 371966 effective words/s
INFO - 2023-11-27 13:15:27,382: EPOCH 19 - PROGRESS: at 100.00% examples, 385372 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:15:27,382: EPOCH 19: training on 412480 raw words (403528 effective words) took 1.0s, 385288 effective words/s
INFO - 2023-11-27 13:15:27,382: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070242 effective words) took 18.8s, 429994 effective words/s', 'datetime': '2023-11-27T13:15:27.382767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:27,382: collecting all words and their counts
INFO - 2023-11-27 13:15:27,383: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:15:27,465: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:15:27,467: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:15:27,468: Updating model with new vocabulary
INFO - 2023-11-27 13:15:27,502: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:15:27.502518', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:27,547: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:15:27,547: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:15:27,547: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403552.74101897574 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:15:27.547577', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:27,615: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:15:27,615: updating layer weights
INFO - 2023-11-27 13:15:27,616: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:15:27.616242', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:15:27,616: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:15:27,616: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:15:27.616462', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:28,635: EPOCH 0 - PROGRESS: at 80.00% examples, 317754 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:15:28,797: EPOCH 0: training on 412480 raw words (403574 effective words) took 1.2s, 342362 effective words/s
INFO - 2023-11-27 13:15:29,813: EPOCH 1 - PROGRESS: at 80.00% examples, 318544 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:15:29,972: EPOCH 1: training on 412480 raw words (403494 effective words) took 1.2s, 344085 effective words/s
INFO - 2023-11-27 13:15:31,038: EPOCH 2 - PROGRESS: at 75.16% examples, 285275 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:31,255: EPOCH 2: training on 412480 raw words (403607 effective words) took 1.3s, 315350 effective words/s
INFO - 2023-11-27 13:15:32,286: EPOCH 3 - PROGRESS: at 65.46% examples, 256838 words/s, in_qsize 15, out_qsize 0
INFO - 2023-11-27 13:15:32,688: EPOCH 3: training on 412480 raw words (403626 effective words) took 1.4s, 282200 effective words/s
INFO - 2023-11-27 13:15:33,808: EPOCH 4 - PROGRESS: at 75.16% examples, 271972 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:34,021: EPOCH 4: training on 412480 raw words (403659 effective words) took 1.3s, 303851 effective words/s
INFO - 2023-11-27 13:15:35,008: EPOCH 5: training on 412480 raw words (403528 effective words) took 1.0s, 418455 effective words/s
INFO - 2023-11-27 13:15:35,886: EPOCH 6: training on 412480 raw words (403578 effective words) took 0.9s, 460841 effective words/s
INFO - 2023-11-27 13:15:36,776: EPOCH 7: training on 412480 raw words (403641 effective words) took 0.9s, 454718 effective words/s
INFO - 2023-11-27 13:15:37,720: EPOCH 8: training on 412480 raw words (403562 effective words) took 0.9s, 428467 effective words/s
INFO - 2023-11-27 13:15:38,661: EPOCH 9: training on 412480 raw words (403637 effective words) took 0.9s, 429617 effective words/s
INFO - 2023-11-27 13:15:39,741: EPOCH 10 - PROGRESS: at 100.00% examples, 374459 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:15:39,741: EPOCH 10: training on 412480 raw words (403514 effective words) took 1.1s, 374394 effective words/s
INFO - 2023-11-27 13:15:40,855: EPOCH 11 - PROGRESS: at 90.30% examples, 327811 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:15:40,903: EPOCH 11: training on 412480 raw words (403432 effective words) took 1.2s, 347946 effective words/s
INFO - 2023-11-27 13:15:41,990: EPOCH 12 - PROGRESS: at 90.30% examples, 341094 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:15:42,014: EPOCH 12: training on 412480 raw words (403506 effective words) took 1.1s, 369552 effective words/s
INFO - 2023-11-27 13:15:42,969: EPOCH 13: training on 412480 raw words (403570 effective words) took 1.0s, 423672 effective words/s
INFO - 2023-11-27 13:15:43,972: EPOCH 14 - PROGRESS: at 87.88% examples, 354523 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:15:44,004: EPOCH 14: training on 412480 raw words (403608 effective words) took 1.0s, 390723 effective words/s
INFO - 2023-11-27 13:15:44,995: EPOCH 15: training on 412480 raw words (403569 effective words) took 1.0s, 408224 effective words/s
INFO - 2023-11-27 13:15:45,930: EPOCH 16: training on 412480 raw words (403531 effective words) took 0.9s, 432457 effective words/s
INFO - 2023-11-27 13:15:46,844: EPOCH 17: training on 412480 raw words (403630 effective words) took 0.9s, 443174 effective words/s
INFO - 2023-11-27 13:15:47,803: EPOCH 18: training on 412480 raw words (403401 effective words) took 1.0s, 421254 effective words/s
INFO - 2023-11-27 13:15:48,801: EPOCH 19: training on 412480 raw words (403670 effective words) took 1.0s, 405554 effective words/s
INFO - 2023-11-27 13:15:48,801: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071337 effective words) took 21.2s, 380988 effective words/s', 'datetime': '2023-11-27T13:15:48.801913', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:48,802: collecting all words and their counts
INFO - 2023-11-27 13:15:48,802: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:15:48,916: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:15:48,919: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:15:48,919: Updating model with new vocabulary
INFO - 2023-11-27 13:15:48,959: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:15:48.959508', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:48,995: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:15:48,995: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:15:48,995: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403648.13638613315 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:15:48.995638', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:15:49,058: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:15:49,059: updating layer weights
INFO - 2023-11-27 13:15:49,059: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:15:49.059812', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:15:49,059: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:15:49,060: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:15:49.060011', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:15:50,164: EPOCH 0 - PROGRESS: at 100.00% examples, 366209 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:15:50,164: EPOCH 0: training on 412480 raw words (403677 effective words) took 1.1s, 366140 effective words/s
INFO - 2023-11-27 13:15:51,192: EPOCH 1 - PROGRESS: at 75.16% examples, 296008 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:51,417: EPOCH 1: training on 412480 raw words (403619 effective words) took 1.3s, 322895 effective words/s
INFO - 2023-11-27 13:15:52,465: EPOCH 2 - PROGRESS: at 75.16% examples, 290256 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:52,661: EPOCH 2: training on 412480 raw words (403649 effective words) took 1.2s, 325223 effective words/s
INFO - 2023-11-27 13:15:53,693: EPOCH 3 - PROGRESS: at 75.16% examples, 294948 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:53,910: EPOCH 3: training on 412480 raw words (403781 effective words) took 1.2s, 324027 effective words/s
INFO - 2023-11-27 13:15:54,923: EPOCH 4 - PROGRESS: at 75.16% examples, 300642 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:55,155: EPOCH 4: training on 412480 raw words (403711 effective words) took 1.2s, 325357 effective words/s
INFO - 2023-11-27 13:15:56,287: EPOCH 5 - PROGRESS: at 75.16% examples, 268725 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:56,512: EPOCH 5: training on 412480 raw words (403589 effective words) took 1.4s, 297945 effective words/s
INFO - 2023-11-27 13:15:57,664: EPOCH 6 - PROGRESS: at 75.16% examples, 265572 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:57,891: EPOCH 6: training on 412480 raw words (403672 effective words) took 1.4s, 294979 effective words/s
INFO - 2023-11-27 13:15:58,925: EPOCH 7 - PROGRESS: at 75.16% examples, 294236 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:15:59,101: EPOCH 7: training on 412480 raw words (403536 effective words) took 1.2s, 334298 effective words/s
INFO - 2023-11-27 13:16:00,135: EPOCH 8 - PROGRESS: at 92.73% examples, 364500 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:16:00,192: EPOCH 8: training on 412480 raw words (403606 effective words) took 1.1s, 372589 effective words/s
INFO - 2023-11-27 13:16:01,222: EPOCH 9 - PROGRESS: at 100.00% examples, 392894 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:16:01,222: EPOCH 9: training on 412480 raw words (403641 effective words) took 1.0s, 392816 effective words/s
INFO - 2023-11-27 13:16:02,190: EPOCH 10: training on 412480 raw words (403666 effective words) took 1.0s, 417941 effective words/s
INFO - 2023-11-27 13:16:03,227: EPOCH 11 - PROGRESS: at 100.00% examples, 389958 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:16:03,227: EPOCH 11: training on 412480 raw words (403478 effective words) took 1.0s, 389847 effective words/s
INFO - 2023-11-27 13:16:04,105: EPOCH 12: training on 412480 raw words (403596 effective words) took 0.9s, 460764 effective words/s
INFO - 2023-11-27 13:16:04,997: EPOCH 13: training on 412480 raw words (403549 effective words) took 0.9s, 453655 effective words/s
INFO - 2023-11-27 13:16:05,996: EPOCH 14: training on 412480 raw words (403599 effective words) took 1.0s, 405381 effective words/s
INFO - 2023-11-27 13:16:06,913: EPOCH 15: training on 412480 raw words (403698 effective words) took 0.9s, 441313 effective words/s
INFO - 2023-11-27 13:16:07,806: EPOCH 16: training on 412480 raw words (403697 effective words) took 0.9s, 452775 effective words/s
INFO - 2023-11-27 13:16:08,754: EPOCH 17: training on 412480 raw words (403697 effective words) took 0.9s, 426958 effective words/s
INFO - 2023-11-27 13:16:09,675: EPOCH 18: training on 412480 raw words (403656 effective words) took 0.9s, 439312 effective words/s
INFO - 2023-11-27 13:16:10,611: EPOCH 19: training on 412480 raw words (403707 effective words) took 0.9s, 432237 effective words/s
INFO - 2023-11-27 13:16:10,611: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072824 effective words) took 21.6s, 374581 effective words/s', 'datetime': '2023-11-27T13:16:10.611715', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:10,611: collecting all words and their counts
INFO - 2023-11-27 13:16:10,612: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:16:10,690: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:16:10,693: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:16:10,694: Updating model with new vocabulary
INFO - 2023-11-27 13:16:10,721: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:16:10.721847', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:10,768: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:16:10,768: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:16:10,769: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403554.17214772175 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:16:10.769054', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:10,854: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:16:10,854: updating layer weights
INFO - 2023-11-27 13:16:10,855: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:16:10.855307', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:16:10,855: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:16:10,855: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:16:10.855478', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:11,786: EPOCH 0: training on 412480 raw words (403469 effective words) took 0.9s, 434306 effective words/s
INFO - 2023-11-27 13:16:12,707: EPOCH 1: training on 412480 raw words (403624 effective words) took 0.9s, 439212 effective words/s
INFO - 2023-11-27 13:16:13,631: EPOCH 2: training on 412480 raw words (403641 effective words) took 0.9s, 437924 effective words/s
INFO - 2023-11-27 13:16:14,682: EPOCH 3 - PROGRESS: at 77.58% examples, 298805 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:16:14,759: EPOCH 3: training on 412480 raw words (403588 effective words) took 1.1s, 358835 effective words/s
INFO - 2023-11-27 13:16:15,794: EPOCH 4 - PROGRESS: at 75.16% examples, 293898 words/s, in_qsize 10, out_qsize 1
INFO - 2023-11-27 13:16:15,982: EPOCH 4: training on 412480 raw words (403462 effective words) took 1.2s, 330799 effective words/s
INFO - 2023-11-27 13:16:17,070: EPOCH 5 - PROGRESS: at 75.16% examples, 279514 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:16:17,271: EPOCH 5: training on 412480 raw words (403514 effective words) took 1.3s, 313775 effective words/s
INFO - 2023-11-27 13:16:18,313: EPOCH 6 - PROGRESS: at 75.16% examples, 291793 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:16:18,539: EPOCH 6: training on 412480 raw words (403467 effective words) took 1.3s, 318954 effective words/s
INFO - 2023-11-27 13:16:19,572: EPOCH 7 - PROGRESS: at 75.16% examples, 294371 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:16:19,792: EPOCH 7: training on 412480 raw words (403579 effective words) took 1.3s, 322609 effective words/s
INFO - 2023-11-27 13:16:20,821: EPOCH 8 - PROGRESS: at 75.16% examples, 295841 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:16:21,040: EPOCH 8: training on 412480 raw words (403557 effective words) took 1.2s, 324324 effective words/s
INFO - 2023-11-27 13:16:22,086: EPOCH 9 - PROGRESS: at 75.16% examples, 290861 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:16:22,320: EPOCH 9: training on 412480 raw words (403515 effective words) took 1.3s, 315897 effective words/s
INFO - 2023-11-27 13:16:23,337: EPOCH 10 - PROGRESS: at 77.58% examples, 308916 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:16:23,451: EPOCH 10: training on 412480 raw words (403625 effective words) took 1.1s, 357886 effective words/s
INFO - 2023-11-27 13:16:24,410: EPOCH 11: training on 412480 raw words (403512 effective words) took 1.0s, 421910 effective words/s
INFO - 2023-11-27 13:16:25,303: EPOCH 12: training on 412480 raw words (403620 effective words) took 0.9s, 453307 effective words/s
INFO - 2023-11-27 13:16:26,283: EPOCH 13: training on 412480 raw words (403522 effective words) took 1.0s, 412853 effective words/s
INFO - 2023-11-27 13:16:27,222: EPOCH 14: training on 412480 raw words (403509 effective words) took 0.9s, 430988 effective words/s
INFO - 2023-11-27 13:16:28,149: EPOCH 15: training on 412480 raw words (403424 effective words) took 0.9s, 446228 effective words/s
INFO - 2023-11-27 13:16:29,047: EPOCH 16: training on 412480 raw words (403537 effective words) took 0.9s, 450600 effective words/s
INFO - 2023-11-27 13:16:29,922: EPOCH 17: training on 412480 raw words (403584 effective words) took 0.9s, 462286 effective words/s
INFO - 2023-11-27 13:16:30,817: EPOCH 18: training on 412480 raw words (403586 effective words) took 0.9s, 452022 effective words/s
INFO - 2023-11-27 13:16:31,800: EPOCH 19: training on 412480 raw words (403498 effective words) took 1.0s, 411428 effective words/s
INFO - 2023-11-27 13:16:31,800: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070833 effective words) took 20.9s, 385340 effective words/s', 'datetime': '2023-11-27T13:16:31.800216', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:31,800: collecting all words and their counts
INFO - 2023-11-27 13:16:31,800: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:16:31,873: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:16:31,875: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:16:31,875: Updating model with new vocabulary
INFO - 2023-11-27 13:16:31,901: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:16:31.901383', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:31,946: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:16:31,947: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:16:31,947: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403671.2867845076 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:16:31.947219', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:32,017: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:16:32,017: updating layer weights
INFO - 2023-11-27 13:16:32,018: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:16:32.018114', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:16:32,018: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:16:32,018: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:16:32.018308', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:32,864: EPOCH 0: training on 412480 raw words (403615 effective words) took 0.8s, 478075 effective words/s
INFO - 2023-11-27 13:16:33,746: EPOCH 1: training on 412480 raw words (403799 effective words) took 0.9s, 459062 effective words/s
INFO - 2023-11-27 13:16:34,595: EPOCH 2: training on 412480 raw words (403736 effective words) took 0.8s, 476438 effective words/s
INFO - 2023-11-27 13:16:35,448: EPOCH 3: training on 412480 raw words (403659 effective words) took 0.8s, 484806 effective words/s
INFO - 2023-11-27 13:16:36,296: EPOCH 4: training on 412480 raw words (403700 effective words) took 0.8s, 477780 effective words/s
INFO - 2023-11-27 13:16:37,150: EPOCH 5: training on 412480 raw words (403734 effective words) took 0.9s, 473979 effective words/s
INFO - 2023-11-27 13:16:38,048: EPOCH 6: training on 412480 raw words (403657 effective words) took 0.9s, 450574 effective words/s
INFO - 2023-11-27 13:16:39,069: EPOCH 7 - PROGRESS: at 80.00% examples, 316874 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:16:39,226: EPOCH 7: training on 412480 raw words (403649 effective words) took 1.2s, 343250 effective words/s
INFO - 2023-11-27 13:16:40,230: EPOCH 8 - PROGRESS: at 82.43% examples, 332376 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:16:40,364: EPOCH 8: training on 412480 raw words (403675 effective words) took 1.1s, 355417 effective words/s
INFO - 2023-11-27 13:16:41,367: EPOCH 9 - PROGRESS: at 80.00% examples, 322877 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:16:41,507: EPOCH 9: training on 412480 raw words (403703 effective words) took 1.1s, 354035 effective words/s
INFO - 2023-11-27 13:16:42,603: EPOCH 10 - PROGRESS: at 77.58% examples, 286351 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:16:42,726: EPOCH 10: training on 412480 raw words (403603 effective words) took 1.2s, 331897 effective words/s
INFO - 2023-11-27 13:16:43,673: EPOCH 11: training on 412480 raw words (403622 effective words) took 0.9s, 426963 effective words/s
INFO - 2023-11-27 13:16:44,627: EPOCH 12: training on 412480 raw words (403834 effective words) took 1.0s, 424649 effective words/s
INFO - 2023-11-27 13:16:45,676: EPOCH 13 - PROGRESS: at 95.15% examples, 366842 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:16:45,756: EPOCH 13: training on 412480 raw words (403815 effective words) took 1.1s, 358160 effective words/s
INFO - 2023-11-27 13:16:46,811: EPOCH 14 - PROGRESS: at 77.58% examples, 297636 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:16:46,932: EPOCH 14: training on 412480 raw words (403661 effective words) took 1.2s, 344155 effective words/s
INFO - 2023-11-27 13:16:47,957: EPOCH 15 - PROGRESS: at 100.00% examples, 394604 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:16:47,957: EPOCH 15: training on 412480 raw words (403591 effective words) took 1.0s, 394526 effective words/s
INFO - 2023-11-27 13:16:48,818: EPOCH 16: training on 412480 raw words (403635 effective words) took 0.9s, 469951 effective words/s
INFO - 2023-11-27 13:16:49,656: EPOCH 17: training on 412480 raw words (403809 effective words) took 0.8s, 482916 effective words/s
INFO - 2023-11-27 13:16:50,538: EPOCH 18: training on 412480 raw words (403490 effective words) took 0.9s, 458851 effective words/s
INFO - 2023-11-27 13:16:51,436: EPOCH 19: training on 412480 raw words (403760 effective words) took 0.9s, 450584 effective words/s
INFO - 2023-11-27 13:16:51,437: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073747 effective words) took 19.4s, 415769 effective words/s', 'datetime': '2023-11-27T13:16:51.437213', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:51,437: collecting all words and their counts
INFO - 2023-11-27 13:16:51,437: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:16:51,512: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:16:51,515: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:16:51,515: Updating model with new vocabulary
INFO - 2023-11-27 13:16:51,548: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:16:51.548336', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:51,596: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:16:51,596: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:16:51,596: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403558.5255435749 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:16:51.596815', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:16:51,655: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:16:51,655: updating layer weights
INFO - 2023-11-27 13:16:51,656: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:16:51.656084', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:16:51,656: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:16:51,656: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:16:51.656259', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:16:52,595: EPOCH 0: training on 412480 raw words (403681 effective words) took 0.9s, 430617 effective words/s
INFO - 2023-11-27 13:16:53,513: EPOCH 1: training on 412480 raw words (403564 effective words) took 0.9s, 441369 effective words/s
INFO - 2023-11-27 13:16:54,427: EPOCH 2: training on 412480 raw words (403676 effective words) took 0.9s, 442289 effective words/s
INFO - 2023-11-27 13:16:55,361: EPOCH 3: training on 412480 raw words (403499 effective words) took 0.9s, 435329 effective words/s
INFO - 2023-11-27 13:16:56,285: EPOCH 4: training on 412480 raw words (403481 effective words) took 0.9s, 437628 effective words/s
INFO - 2023-11-27 13:16:57,300: EPOCH 5 - PROGRESS: at 100.00% examples, 398839 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:16:57,300: EPOCH 5: training on 412480 raw words (403550 effective words) took 1.0s, 398690 effective words/s
INFO - 2023-11-27 13:16:58,296: EPOCH 6: training on 412480 raw words (403621 effective words) took 1.0s, 405950 effective words/s
INFO - 2023-11-27 13:16:59,195: EPOCH 7: training on 412480 raw words (403573 effective words) took 0.9s, 450182 effective words/s
INFO - 2023-11-27 13:17:00,082: EPOCH 8: training on 412480 raw words (403481 effective words) took 0.9s, 456066 effective words/s
INFO - 2023-11-27 13:17:00,982: EPOCH 9: training on 412480 raw words (403602 effective words) took 0.9s, 449519 effective words/s
INFO - 2023-11-27 13:17:01,891: EPOCH 10: training on 412480 raw words (403384 effective words) took 0.9s, 444812 effective words/s
INFO - 2023-11-27 13:17:02,912: EPOCH 11 - PROGRESS: at 100.00% examples, 396346 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:17:02,912: EPOCH 11: training on 412480 raw words (403543 effective words) took 1.0s, 396256 effective words/s
INFO - 2023-11-27 13:17:03,914: EPOCH 12 - PROGRESS: at 87.28% examples, 352239 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:17:04,072: EPOCH 12: training on 412480 raw words (403539 effective words) took 1.2s, 348579 effective words/s
INFO - 2023-11-27 13:17:05,099: EPOCH 13 - PROGRESS: at 77.58% examples, 305419 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:17:05,202: EPOCH 13: training on 412480 raw words (403484 effective words) took 1.1s, 357834 effective words/s
INFO - 2023-11-27 13:17:06,208: EPOCH 14 - PROGRESS: at 89.70% examples, 360729 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:17:06,299: EPOCH 14: training on 412480 raw words (403443 effective words) took 1.1s, 368671 effective words/s
INFO - 2023-11-27 13:17:07,195: EPOCH 15: training on 412480 raw words (403456 effective words) took 0.9s, 451422 effective words/s
INFO - 2023-11-27 13:17:08,201: EPOCH 16 - PROGRESS: at 82.43% examples, 331296 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:17:08,331: EPOCH 16: training on 412480 raw words (403423 effective words) took 1.1s, 355845 effective words/s
INFO - 2023-11-27 13:17:09,440: EPOCH 17 - PROGRESS: at 75.16% examples, 273985 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:17:09,654: EPOCH 17: training on 412480 raw words (403577 effective words) took 1.3s, 305552 effective words/s
INFO - 2023-11-27 13:17:10,804: EPOCH 18 - PROGRESS: at 75.16% examples, 264339 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:17:11,004: EPOCH 18: training on 412480 raw words (403562 effective words) took 1.3s, 299561 effective words/s
INFO - 2023-11-27 13:17:12,032: EPOCH 19: training on 412480 raw words (403466 effective words) took 1.0s, 403487 effective words/s
INFO - 2023-11-27 13:17:12,032: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070605 effective words) took 20.4s, 396080 effective words/s', 'datetime': '2023-11-27T13:17:12.032530', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:12,032: collecting all words and their counts
INFO - 2023-11-27 13:17:12,032: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:17:12,093: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:17:12,095: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:17:12,095: Updating model with new vocabulary
INFO - 2023-11-27 13:17:12,127: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:17:12.127092', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:12,174: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:17:12,175: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:17:12,175: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403530.09064076573 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:17:12.175397', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:12,243: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:17:12,243: updating layer weights
INFO - 2023-11-27 13:17:12,244: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:17:12.244231', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:17:12,244: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:17:12,244: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:17:12.244485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:13,108: EPOCH 0: training on 412480 raw words (403517 effective words) took 0.9s, 468198 effective words/s
INFO - 2023-11-27 13:17:13,983: EPOCH 1: training on 412480 raw words (403547 effective words) took 0.9s, 462402 effective words/s
INFO - 2023-11-27 13:17:14,833: EPOCH 2: training on 412480 raw words (403499 effective words) took 0.8s, 475856 effective words/s
INFO - 2023-11-27 13:17:15,682: EPOCH 3: training on 412480 raw words (403378 effective words) took 0.8s, 476731 effective words/s
INFO - 2023-11-27 13:17:16,510: EPOCH 4: training on 412480 raw words (403491 effective words) took 0.8s, 487925 effective words/s
INFO - 2023-11-27 13:17:17,326: EPOCH 5: training on 412480 raw words (403609 effective words) took 0.8s, 496234 effective words/s
INFO - 2023-11-27 13:17:18,168: EPOCH 6: training on 412480 raw words (403579 effective words) took 0.8s, 480249 effective words/s
INFO - 2023-11-27 13:17:18,956: EPOCH 7: training on 412480 raw words (403444 effective words) took 0.8s, 513712 effective words/s
INFO - 2023-11-27 13:17:19,852: EPOCH 8: training on 412480 raw words (403617 effective words) took 0.9s, 451390 effective words/s
INFO - 2023-11-27 13:17:20,699: EPOCH 9: training on 412480 raw words (403659 effective words) took 0.8s, 477361 effective words/s
INFO - 2023-11-27 13:17:21,565: EPOCH 10: training on 412480 raw words (403524 effective words) took 0.9s, 467170 effective words/s
INFO - 2023-11-27 13:17:22,406: EPOCH 11: training on 412480 raw words (403531 effective words) took 0.8s, 481384 effective words/s
INFO - 2023-11-27 13:17:23,263: EPOCH 12: training on 412480 raw words (403372 effective words) took 0.9s, 471569 effective words/s
INFO - 2023-11-27 13:17:24,105: EPOCH 13: training on 412480 raw words (403617 effective words) took 0.8s, 480800 effective words/s
INFO - 2023-11-27 13:17:24,980: EPOCH 14: training on 412480 raw words (403540 effective words) took 0.9s, 462896 effective words/s
INFO - 2023-11-27 13:17:25,872: EPOCH 15: training on 412480 raw words (403691 effective words) took 0.9s, 453323 effective words/s
INFO - 2023-11-27 13:17:26,811: EPOCH 16: training on 412480 raw words (403590 effective words) took 0.9s, 431064 effective words/s
INFO - 2023-11-27 13:17:27,934: EPOCH 17 - PROGRESS: at 85.45% examples, 339965 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:17:28,033: EPOCH 17: training on 412480 raw words (403453 effective words) took 1.1s, 362385 effective words/s
INFO - 2023-11-27 13:17:29,040: EPOCH 18 - PROGRESS: at 95.15% examples, 382917 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:17:29,161: EPOCH 18: training on 412480 raw words (403654 effective words) took 1.1s, 359074 effective words/s
INFO - 2023-11-27 13:17:30,179: EPOCH 19 - PROGRESS: at 80.00% examples, 317879 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:17:30,333: EPOCH 19: training on 412480 raw words (403506 effective words) took 1.2s, 345015 effective words/s
INFO - 2023-11-27 13:17:30,333: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070818 effective words) took 18.1s, 446174 effective words/s', 'datetime': '2023-11-27T13:17:30.333531', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:30,333: collecting all words and their counts
INFO - 2023-11-27 13:17:30,333: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:17:30,428: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:17:30,431: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:17:30,431: Updating model with new vocabulary
INFO - 2023-11-27 13:17:30,469: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:17:30.469398', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:30,522: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:17:30,523: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:17:30,523: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403586.4438350152 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:17:30.523173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:30,621: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:17:30,621: updating layer weights
INFO - 2023-11-27 13:17:30,622: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:17:30.622396', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:17:30,622: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:17:30,622: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:17:30.622586', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:31,664: EPOCH 0 - PROGRESS: at 75.16% examples, 292128 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:17:31,889: EPOCH 0: training on 412480 raw words (403643 effective words) took 1.3s, 319520 effective words/s
INFO - 2023-11-27 13:17:32,936: EPOCH 1 - PROGRESS: at 75.16% examples, 290350 words/s, in_qsize 10, out_qsize 1
INFO - 2023-11-27 13:17:33,139: EPOCH 1: training on 412480 raw words (403611 effective words) took 1.2s, 323663 effective words/s
INFO - 2023-11-27 13:17:34,047: EPOCH 2: training on 412480 raw words (403603 effective words) took 0.9s, 445959 effective words/s
INFO - 2023-11-27 13:17:34,942: EPOCH 3: training on 412480 raw words (403550 effective words) took 0.9s, 462413 effective words/s
INFO - 2023-11-27 13:17:35,867: EPOCH 4: training on 412480 raw words (403358 effective words) took 0.9s, 437274 effective words/s
INFO - 2023-11-27 13:17:36,760: EPOCH 5: training on 412480 raw words (403630 effective words) took 0.9s, 453100 effective words/s
INFO - 2023-11-27 13:17:37,598: EPOCH 6: training on 412480 raw words (403611 effective words) took 0.8s, 482901 effective words/s
INFO - 2023-11-27 13:17:38,465: EPOCH 7: training on 412480 raw words (403592 effective words) took 0.9s, 466388 effective words/s
INFO - 2023-11-27 13:17:39,352: EPOCH 8: training on 412480 raw words (403573 effective words) took 0.9s, 456056 effective words/s
INFO - 2023-11-27 13:17:40,206: EPOCH 9: training on 412480 raw words (403568 effective words) took 0.9s, 474156 effective words/s
INFO - 2023-11-27 13:17:41,028: EPOCH 10: training on 412480 raw words (403420 effective words) took 0.8s, 492010 effective words/s
INFO - 2023-11-27 13:17:41,912: EPOCH 11: training on 412480 raw words (403552 effective words) took 0.9s, 457669 effective words/s
INFO - 2023-11-27 13:17:42,765: EPOCH 12: training on 412480 raw words (403390 effective words) took 0.9s, 474092 effective words/s
INFO - 2023-11-27 13:17:43,640: EPOCH 13: training on 412480 raw words (403564 effective words) took 0.9s, 462130 effective words/s
INFO - 2023-11-27 13:17:44,495: EPOCH 14: training on 412480 raw words (403569 effective words) took 0.9s, 473429 effective words/s
INFO - 2023-11-27 13:17:45,368: EPOCH 15: training on 412480 raw words (403472 effective words) took 0.9s, 463346 effective words/s
INFO - 2023-11-27 13:17:46,236: EPOCH 16: training on 412480 raw words (403629 effective words) took 0.9s, 466022 effective words/s
INFO - 2023-11-27 13:17:47,124: EPOCH 17: training on 412480 raw words (403697 effective words) took 0.9s, 455936 effective words/s
INFO - 2023-11-27 13:17:47,989: EPOCH 18: training on 412480 raw words (403541 effective words) took 0.9s, 467299 effective words/s
INFO - 2023-11-27 13:17:48,867: EPOCH 19: training on 412480 raw words (403530 effective words) took 0.9s, 460581 effective words/s
INFO - 2023-11-27 13:17:48,868: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071103 effective words) took 18.2s, 442361 effective words/s', 'datetime': '2023-11-27T13:17:48.868149', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:48,868: collecting all words and their counts
INFO - 2023-11-27 13:17:48,868: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:17:48,926: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:17:48,928: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:17:48,928: Updating model with new vocabulary
INFO - 2023-11-27 13:17:48,952: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:17:48.952708', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:48,982: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:17:48,982: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:17:48,982: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403666.7440557854 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:17:48.982537', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:17:49,030: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:17:49,030: updating layer weights
INFO - 2023-11-27 13:17:49,030: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:17:49.030779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:17:49,030: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:17:49,030: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:17:49.030929', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:17:49,882: EPOCH 0: training on 412480 raw words (403652 effective words) took 0.8s, 474961 effective words/s
INFO - 2023-11-27 13:17:50,724: EPOCH 1: training on 412480 raw words (403595 effective words) took 0.8s, 480417 effective words/s
INFO - 2023-11-27 13:17:51,540: EPOCH 2: training on 412480 raw words (403706 effective words) took 0.8s, 495815 effective words/s
INFO - 2023-11-27 13:17:52,504: EPOCH 3: training on 412480 raw words (403658 effective words) took 1.0s, 419876 effective words/s
INFO - 2023-11-27 13:17:53,583: EPOCH 4 - PROGRESS: at 100.00% examples, 375279 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:17:53,583: EPOCH 4: training on 412480 raw words (403703 effective words) took 1.1s, 375194 effective words/s
INFO - 2023-11-27 13:17:54,588: EPOCH 5 - PROGRESS: at 97.58% examples, 393091 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:17:54,646: EPOCH 5: training on 412480 raw words (403723 effective words) took 1.1s, 380791 effective words/s
INFO - 2023-11-27 13:17:55,719: EPOCH 6 - PROGRESS: at 100.00% examples, 376893 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:17:55,719: EPOCH 6: training on 412480 raw words (403671 effective words) took 1.1s, 376811 effective words/s
INFO - 2023-11-27 13:17:56,772: EPOCH 7 - PROGRESS: at 100.00% examples, 384385 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:17:56,772: EPOCH 7: training on 412480 raw words (403625 effective words) took 1.1s, 384299 effective words/s
INFO - 2023-11-27 13:17:57,784: EPOCH 8 - PROGRESS: at 85.45% examples, 341888 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:17:57,898: EPOCH 8: training on 412480 raw words (403751 effective words) took 1.1s, 359511 effective words/s
INFO - 2023-11-27 13:17:58,908: EPOCH 9 - PROGRESS: at 77.58% examples, 310999 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:17:59,048: EPOCH 9: training on 412480 raw words (403811 effective words) took 1.1s, 351891 effective words/s
INFO - 2023-11-27 13:18:00,052: EPOCH 10 - PROGRESS: at 89.70% examples, 361760 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:18:00,175: EPOCH 10: training on 412480 raw words (403691 effective words) took 1.1s, 359124 effective words/s
INFO - 2023-11-27 13:18:01,139: EPOCH 11: training on 412480 raw words (403536 effective words) took 1.0s, 419761 effective words/s
INFO - 2023-11-27 13:18:01,933: EPOCH 12: training on 412480 raw words (403594 effective words) took 0.8s, 509872 effective words/s
INFO - 2023-11-27 13:18:02,746: EPOCH 13: training on 412480 raw words (403706 effective words) took 0.8s, 497749 effective words/s
INFO - 2023-11-27 13:18:03,553: EPOCH 14: training on 412480 raw words (403835 effective words) took 0.8s, 501274 effective words/s
INFO - 2023-11-27 13:18:04,378: EPOCH 15: training on 412480 raw words (403552 effective words) took 0.8s, 490797 effective words/s
INFO - 2023-11-27 13:18:05,218: EPOCH 16: training on 412480 raw words (403744 effective words) took 0.8s, 482065 effective words/s
INFO - 2023-11-27 13:18:06,028: EPOCH 17: training on 412480 raw words (403695 effective words) took 0.8s, 499125 effective words/s
INFO - 2023-11-27 13:18:06,847: EPOCH 18: training on 412480 raw words (403667 effective words) took 0.8s, 494130 effective words/s
INFO - 2023-11-27 13:18:07,680: EPOCH 19: training on 412480 raw words (403698 effective words) took 0.8s, 486140 effective words/s
INFO - 2023-11-27 13:18:07,680: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073613 effective words) took 18.6s, 432914 effective words/s', 'datetime': '2023-11-27T13:18:07.680440', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:07,680: collecting all words and their counts
INFO - 2023-11-27 13:18:07,680: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:18:07,740: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:18:07,742: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:18:07,742: Updating model with new vocabulary
INFO - 2023-11-27 13:18:07,770: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:18:07.770720', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:07,805: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:18:07,805: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:18:07,805: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403630.49157296086 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:18:07.805279', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:07,852: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:18:07,853: updating layer weights
INFO - 2023-11-27 13:18:07,853: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:18:07.853578', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:18:07,853: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:18:07,853: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:18:07.853744', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:08,729: EPOCH 0: training on 412480 raw words (403675 effective words) took 0.9s, 461895 effective words/s
INFO - 2023-11-27 13:18:09,628: EPOCH 1: training on 412480 raw words (403653 effective words) took 0.9s, 449717 effective words/s
INFO - 2023-11-27 13:18:10,504: EPOCH 2: training on 412480 raw words (403667 effective words) took 0.9s, 462469 effective words/s
INFO - 2023-11-27 13:18:11,375: EPOCH 3: training on 412480 raw words (403613 effective words) took 0.9s, 464515 effective words/s
INFO - 2023-11-27 13:18:12,258: EPOCH 4: training on 412480 raw words (403676 effective words) took 0.9s, 458332 effective words/s
INFO - 2023-11-27 13:18:13,194: EPOCH 5: training on 412480 raw words (403741 effective words) took 0.9s, 431892 effective words/s
INFO - 2023-11-27 13:18:14,065: EPOCH 6: training on 412480 raw words (403574 effective words) took 0.9s, 464983 effective words/s
INFO - 2023-11-27 13:18:14,934: EPOCH 7: training on 412480 raw words (403583 effective words) took 0.9s, 465735 effective words/s
INFO - 2023-11-27 13:18:15,936: EPOCH 8 - PROGRESS: at 92.13% examples, 371831 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:18:16,067: EPOCH 8: training on 412480 raw words (403738 effective words) took 1.1s, 356881 effective words/s
INFO - 2023-11-27 13:18:17,164: EPOCH 9 - PROGRESS: at 100.00% examples, 368991 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:18:17,165: EPOCH 9: training on 412480 raw words (403676 effective words) took 1.1s, 368914 effective words/s
INFO - 2023-11-27 13:18:18,168: EPOCH 10 - PROGRESS: at 95.15% examples, 383478 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:18:18,280: EPOCH 10: training on 412480 raw words (403553 effective words) took 1.1s, 362403 effective words/s
INFO - 2023-11-27 13:18:19,287: EPOCH 11 - PROGRESS: at 89.70% examples, 360413 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:18:19,418: EPOCH 11: training on 412480 raw words (403532 effective words) took 1.1s, 355327 effective words/s
INFO - 2023-11-27 13:18:20,430: EPOCH 12 - PROGRESS: at 77.58% examples, 310300 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:18:20,539: EPOCH 12: training on 412480 raw words (403569 effective words) took 1.1s, 360824 effective words/s
INFO - 2023-11-27 13:18:21,543: EPOCH 13 - PROGRESS: at 80.00% examples, 322456 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:18:21,711: EPOCH 13: training on 412480 raw words (403578 effective words) took 1.2s, 345217 effective words/s
INFO - 2023-11-27 13:18:22,743: EPOCH 14 - PROGRESS: at 77.58% examples, 304093 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:18:22,896: EPOCH 14: training on 412480 raw words (403592 effective words) took 1.2s, 341190 effective words/s
INFO - 2023-11-27 13:18:23,919: EPOCH 15 - PROGRESS: at 77.58% examples, 306807 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:18:24,036: EPOCH 15: training on 412480 raw words (403685 effective words) took 1.1s, 354845 effective words/s
INFO - 2023-11-27 13:18:24,847: EPOCH 16: training on 412480 raw words (403630 effective words) took 0.8s, 499092 effective words/s
INFO - 2023-11-27 13:18:25,783: EPOCH 17: training on 412480 raw words (403661 effective words) took 0.9s, 432334 effective words/s
INFO - 2023-11-27 13:18:26,660: EPOCH 18: training on 412480 raw words (403693 effective words) took 0.9s, 461229 effective words/s
INFO - 2023-11-27 13:18:27,535: EPOCH 19: training on 412480 raw words (403380 effective words) took 0.9s, 462080 effective words/s
INFO - 2023-11-27 13:18:27,535: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072469 effective words) took 19.7s, 410147 effective words/s', 'datetime': '2023-11-27T13:18:27.535744', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:27,535: collecting all words and their counts
INFO - 2023-11-27 13:18:27,536: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:18:27,603: PROGRESS: at sentence #10000, processed 400000 words, keeping 10297 word types
INFO - 2023-11-27 13:18:27,606: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:18:27,606: Updating model with new vocabulary
INFO - 2023-11-27 13:18:27,638: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:18:27.637994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:27,668: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:18:27,668: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:18:27,668: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403608.0735024718 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:18:27.668865', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:27,719: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:18:27,719: updating layer weights
INFO - 2023-11-27 13:18:27,720: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:18:27.720492', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:18:27,720: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:18:27,720: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:18:27.720650', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:28,543: EPOCH 0: training on 412480 raw words (403572 effective words) took 0.8s, 491412 effective words/s
INFO - 2023-11-27 13:18:29,356: EPOCH 1: training on 412480 raw words (403532 effective words) took 0.8s, 497819 effective words/s
INFO - 2023-11-27 13:18:30,183: EPOCH 2: training on 412480 raw words (403449 effective words) took 0.8s, 489298 effective words/s
INFO - 2023-11-27 13:18:31,013: EPOCH 3: training on 412480 raw words (403661 effective words) took 0.8s, 487687 effective words/s
INFO - 2023-11-27 13:18:31,837: EPOCH 4: training on 412480 raw words (403672 effective words) took 0.8s, 491072 effective words/s
INFO - 2023-11-27 13:18:32,634: EPOCH 5: training on 412480 raw words (403721 effective words) took 0.8s, 507407 effective words/s
INFO - 2023-11-27 13:18:33,502: EPOCH 6: training on 412480 raw words (403574 effective words) took 0.9s, 466090 effective words/s
INFO - 2023-11-27 13:18:34,284: EPOCH 7: training on 412480 raw words (403551 effective words) took 0.8s, 517189 effective words/s
INFO - 2023-11-27 13:18:35,087: EPOCH 8: training on 412480 raw words (403646 effective words) took 0.8s, 504257 effective words/s
INFO - 2023-11-27 13:18:35,950: EPOCH 9: training on 412480 raw words (403555 effective words) took 0.9s, 468933 effective words/s
INFO - 2023-11-27 13:18:36,812: EPOCH 10: training on 412480 raw words (403501 effective words) took 0.9s, 470115 effective words/s
INFO - 2023-11-27 13:18:37,608: EPOCH 11: training on 412480 raw words (403673 effective words) took 0.8s, 508367 effective words/s
INFO - 2023-11-27 13:18:38,453: EPOCH 12: training on 412480 raw words (403612 effective words) took 0.8s, 478301 effective words/s
INFO - 2023-11-27 13:18:39,328: EPOCH 13: training on 412480 raw words (403668 effective words) took 0.9s, 462533 effective words/s
INFO - 2023-11-27 13:18:40,398: EPOCH 14 - PROGRESS: at 100.00% examples, 378182 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:18:40,398: EPOCH 14: training on 412480 raw words (403588 effective words) took 1.1s, 378105 effective words/s
INFO - 2023-11-27 13:18:41,406: EPOCH 15 - PROGRESS: at 97.58% examples, 391635 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:18:41,518: EPOCH 15: training on 412480 raw words (403750 effective words) took 1.1s, 361254 effective words/s
INFO - 2023-11-27 13:18:42,602: EPOCH 16 - PROGRESS: at 100.00% examples, 373051 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:18:42,603: EPOCH 16: training on 412480 raw words (403674 effective words) took 1.1s, 372976 effective words/s
INFO - 2023-11-27 13:18:43,695: EPOCH 17 - PROGRESS: at 100.00% examples, 370234 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:18:43,697: EPOCH 17: training on 412480 raw words (403601 effective words) took 1.1s, 369599 effective words/s
INFO - 2023-11-27 13:18:44,702: EPOCH 18 - PROGRESS: at 95.15% examples, 383306 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:18:44,814: EPOCH 18: training on 412480 raw words (403748 effective words) took 1.1s, 362456 effective words/s
INFO - 2023-11-27 13:18:45,818: EPOCH 19 - PROGRESS: at 82.43% examples, 332153 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:18:45,962: EPOCH 19: training on 412480 raw words (403681 effective words) took 1.1s, 352207 effective words/s
INFO - 2023-11-27 13:18:45,963: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072429 effective words) took 18.2s, 442507 effective words/s', 'datetime': '2023-11-27T13:18:45.963179', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:45,963: collecting all words and their counts
INFO - 2023-11-27 13:18:45,963: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:18:46,066: PROGRESS: at sentence #10000, processed 400000 words, keeping 10297 word types
INFO - 2023-11-27 13:18:46,069: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:18:46,069: Updating model with new vocabulary
INFO - 2023-11-27 13:18:46,118: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:18:46.118890', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:46,174: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:18:46,174: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:18:46,174: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403574.79342469724 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:18:46.174953', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:18:46,276: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:18:46,276: updating layer weights
INFO - 2023-11-27 13:18:46,277: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:18:46.276973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:18:46,277: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:18:46,277: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:18:46.277240', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:18:47,430: EPOCH 0 - PROGRESS: at 77.58% examples, 272099 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:18:47,517: EPOCH 0: training on 412480 raw words (403530 effective words) took 1.2s, 326080 effective words/s
INFO - 2023-11-27 13:18:48,521: EPOCH 1 - PROGRESS: at 87.88% examples, 354466 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:18:48,607: EPOCH 1: training on 412480 raw words (403530 effective words) took 1.1s, 371239 effective words/s
INFO - 2023-11-27 13:18:49,502: EPOCH 2: training on 412480 raw words (403646 effective words) took 0.9s, 452069 effective words/s
INFO - 2023-11-27 13:18:50,380: EPOCH 3: training on 412480 raw words (403623 effective words) took 0.9s, 460999 effective words/s
INFO - 2023-11-27 13:18:51,339: EPOCH 4: training on 412480 raw words (403566 effective words) took 1.0s, 421982 effective words/s
INFO - 2023-11-27 13:18:52,247: EPOCH 5: training on 412480 raw words (403551 effective words) took 0.9s, 445473 effective words/s
INFO - 2023-11-27 13:18:53,173: EPOCH 6: training on 412480 raw words (403513 effective words) took 0.9s, 436968 effective words/s
INFO - 2023-11-27 13:18:54,071: EPOCH 7: training on 412480 raw words (403512 effective words) took 0.9s, 449990 effective words/s
INFO - 2023-11-27 13:18:55,025: EPOCH 8: training on 412480 raw words (403446 effective words) took 1.0s, 423865 effective words/s
INFO - 2023-11-27 13:18:55,953: EPOCH 9: training on 412480 raw words (403654 effective words) took 0.9s, 435881 effective words/s
INFO - 2023-11-27 13:18:56,891: EPOCH 10: training on 412480 raw words (403648 effective words) took 0.9s, 431697 effective words/s
INFO - 2023-11-27 13:18:57,870: EPOCH 11: training on 412480 raw words (403585 effective words) took 1.0s, 413215 effective words/s
INFO - 2023-11-27 13:18:58,787: EPOCH 12: training on 412480 raw words (403647 effective words) took 0.9s, 440818 effective words/s
INFO - 2023-11-27 13:18:59,763: EPOCH 13: training on 412480 raw words (403531 effective words) took 1.0s, 414722 effective words/s
INFO - 2023-11-27 13:19:00,740: EPOCH 14: training on 412480 raw words (403359 effective words) took 1.0s, 413952 effective words/s
INFO - 2023-11-27 13:19:01,785: EPOCH 15 - PROGRESS: at 100.00% examples, 387003 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:19:01,785: EPOCH 15: training on 412480 raw words (403714 effective words) took 1.0s, 386923 effective words/s
INFO - 2023-11-27 13:19:02,795: EPOCH 16 - PROGRESS: at 100.00% examples, 400295 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:19:02,796: EPOCH 16: training on 412480 raw words (403483 effective words) took 1.0s, 400217 effective words/s
INFO - 2023-11-27 13:19:03,805: EPOCH 17 - PROGRESS: at 80.61% examples, 323099 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:19:03,920: EPOCH 17: training on 412480 raw words (403629 effective words) took 1.1s, 359702 effective words/s
INFO - 2023-11-27 13:19:04,963: EPOCH 18 - PROGRESS: at 77.58% examples, 300993 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:05,093: EPOCH 18: training on 412480 raw words (403513 effective words) took 1.2s, 344722 effective words/s
INFO - 2023-11-27 13:19:06,122: EPOCH 19 - PROGRESS: at 80.00% examples, 314522 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:19:06,286: EPOCH 19: training on 412480 raw words (403630 effective words) took 1.2s, 339204 effective words/s
INFO - 2023-11-27 13:19:06,286: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071310 effective words) took 20.0s, 403382 effective words/s', 'datetime': '2023-11-27T13:19:06.286487', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:06,286: collecting all words and their counts
INFO - 2023-11-27 13:19:06,286: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:19:06,381: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:19:06,386: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:19:06,386: Updating model with new vocabulary
INFO - 2023-11-27 13:19:06,429: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:19:06.429383', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:06,491: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:19:06,491: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:19:06,491: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403538.02480496827 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:19:06.491555', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:06,579: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:19:06,579: updating layer weights
INFO - 2023-11-27 13:19:06,579: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:19:06.579864', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:19:06,580: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:19:06,580: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:19:06.580069', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:07,634: EPOCH 0 - PROGRESS: at 77.58% examples, 297643 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:07,774: EPOCH 0: training on 412480 raw words (403547 effective words) took 1.2s, 338541 effective words/s
INFO - 2023-11-27 13:19:08,794: EPOCH 1 - PROGRESS: at 77.58% examples, 311689 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:08,962: EPOCH 1: training on 412480 raw words (403550 effective words) took 1.2s, 343946 effective words/s
INFO - 2023-11-27 13:19:10,016: EPOCH 2 - PROGRESS: at 75.16% examples, 288652 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:19:10,210: EPOCH 2: training on 412480 raw words (403601 effective words) took 1.2s, 324245 effective words/s
INFO - 2023-11-27 13:19:11,232: EPOCH 3 - PROGRESS: at 77.58% examples, 307366 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:11,381: EPOCH 3: training on 412480 raw words (403607 effective words) took 1.2s, 345563 effective words/s
INFO - 2023-11-27 13:19:12,396: EPOCH 4 - PROGRESS: at 84.85% examples, 342111 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:19:12,494: EPOCH 4: training on 412480 raw words (403444 effective words) took 1.1s, 367092 effective words/s
INFO - 2023-11-27 13:19:13,405: EPOCH 5: training on 412480 raw words (403422 effective words) took 0.9s, 444125 effective words/s
INFO - 2023-11-27 13:19:14,258: EPOCH 6: training on 412480 raw words (403715 effective words) took 0.8s, 480742 effective words/s
INFO - 2023-11-27 13:19:15,140: EPOCH 7: training on 412480 raw words (403606 effective words) took 0.9s, 458675 effective words/s
INFO - 2023-11-27 13:19:16,014: EPOCH 8: training on 412480 raw words (403534 effective words) took 0.9s, 462922 effective words/s
INFO - 2023-11-27 13:19:16,875: EPOCH 9: training on 412480 raw words (403479 effective words) took 0.9s, 470142 effective words/s
INFO - 2023-11-27 13:19:17,776: EPOCH 10: training on 412480 raw words (403444 effective words) took 0.9s, 448879 effective words/s
INFO - 2023-11-27 13:19:18,651: EPOCH 11: training on 412480 raw words (403563 effective words) took 0.9s, 462372 effective words/s
INFO - 2023-11-27 13:19:19,526: EPOCH 12: training on 412480 raw words (403589 effective words) took 0.9s, 462370 effective words/s
INFO - 2023-11-27 13:19:20,386: EPOCH 13: training on 412480 raw words (403506 effective words) took 0.9s, 470426 effective words/s
INFO - 2023-11-27 13:19:21,260: EPOCH 14: training on 412480 raw words (403547 effective words) took 0.9s, 462852 effective words/s
INFO - 2023-11-27 13:19:22,127: EPOCH 15: training on 412480 raw words (403483 effective words) took 0.9s, 466397 effective words/s
INFO - 2023-11-27 13:19:22,992: EPOCH 16: training on 412480 raw words (403472 effective words) took 0.9s, 468032 effective words/s
INFO - 2023-11-27 13:19:23,891: EPOCH 17: training on 412480 raw words (403492 effective words) took 0.9s, 449868 effective words/s
INFO - 2023-11-27 13:19:24,754: EPOCH 18: training on 412480 raw words (403420 effective words) took 0.9s, 468679 effective words/s
INFO - 2023-11-27 13:19:25,600: EPOCH 19: training on 412480 raw words (403455 effective words) took 0.8s, 478047 effective words/s
INFO - 2023-11-27 13:19:25,600: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070476 effective words) took 19.0s, 424299 effective words/s', 'datetime': '2023-11-27T13:19:25.600871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:25,601: collecting all words and their counts
INFO - 2023-11-27 13:19:25,601: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:19:25,663: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:19:25,665: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:19:25,665: Updating model with new vocabulary
INFO - 2023-11-27 13:19:25,704: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:19:25.704684', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:25,738: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:19:25,738: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:19:25,738: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403612.165487553 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:19:25.738570', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:25,796: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:19:25,796: updating layer weights
INFO - 2023-11-27 13:19:25,796: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:19:25.796842', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:19:25,796: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:19:25,797: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:19:25.797051', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:26,692: EPOCH 0: training on 412480 raw words (403652 effective words) took 0.9s, 453049 effective words/s
INFO - 2023-11-27 13:19:27,637: EPOCH 1: training on 412480 raw words (403713 effective words) took 0.9s, 428381 effective words/s
INFO - 2023-11-27 13:19:28,646: EPOCH 2 - PROGRESS: at 82.43% examples, 330490 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:19:28,804: EPOCH 2: training on 412480 raw words (403584 effective words) took 1.2s, 346669 effective words/s
INFO - 2023-11-27 13:19:29,815: EPOCH 3 - PROGRESS: at 82.43% examples, 329740 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:19:29,968: EPOCH 3: training on 412480 raw words (403424 effective words) took 1.2s, 347346 effective words/s
INFO - 2023-11-27 13:19:30,990: EPOCH 4 - PROGRESS: at 77.58% examples, 307396 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:31,153: EPOCH 4: training on 412480 raw words (403604 effective words) took 1.2s, 341326 effective words/s
INFO - 2023-11-27 13:19:32,162: EPOCH 5 - PROGRESS: at 77.58% examples, 311222 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:32,298: EPOCH 5: training on 412480 raw words (403541 effective words) took 1.1s, 353652 effective words/s
INFO - 2023-11-27 13:19:33,307: EPOCH 6 - PROGRESS: at 75.16% examples, 301558 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:19:33,496: EPOCH 6: training on 412480 raw words (403655 effective words) took 1.2s, 337717 effective words/s
INFO - 2023-11-27 13:19:34,516: EPOCH 7 - PROGRESS: at 77.58% examples, 307834 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:34,658: EPOCH 7: training on 412480 raw words (403593 effective words) took 1.2s, 348058 effective words/s
INFO - 2023-11-27 13:19:35,662: EPOCH 8 - PROGRESS: at 75.16% examples, 303292 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:19:35,849: EPOCH 8: training on 412480 raw words (403574 effective words) took 1.2s, 339983 effective words/s
INFO - 2023-11-27 13:19:36,858: EPOCH 9 - PROGRESS: at 77.58% examples, 311285 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:19:36,923: EPOCH 9: training on 412480 raw words (403550 effective words) took 1.1s, 376814 effective words/s
INFO - 2023-11-27 13:19:37,776: EPOCH 10: training on 412480 raw words (403652 effective words) took 0.9s, 474476 effective words/s
INFO - 2023-11-27 13:19:38,676: EPOCH 11: training on 412480 raw words (403717 effective words) took 0.9s, 449399 effective words/s
INFO - 2023-11-27 13:19:39,612: EPOCH 12: training on 412480 raw words (403716 effective words) took 0.9s, 432450 effective words/s
INFO - 2023-11-27 13:19:40,499: EPOCH 13: training on 412480 raw words (403647 effective words) took 0.9s, 456440 effective words/s
INFO - 2023-11-27 13:19:41,371: EPOCH 14: training on 412480 raw words (403599 effective words) took 0.9s, 463928 effective words/s
INFO - 2023-11-27 13:19:42,281: EPOCH 15: training on 412480 raw words (403612 effective words) took 0.9s, 444531 effective words/s
INFO - 2023-11-27 13:19:43,191: EPOCH 16: training on 412480 raw words (403613 effective words) took 0.9s, 444990 effective words/s
INFO - 2023-11-27 13:19:44,082: EPOCH 17: training on 412480 raw words (403699 effective words) took 0.9s, 454039 effective words/s
INFO - 2023-11-27 13:19:44,966: EPOCH 18: training on 412480 raw words (403830 effective words) took 0.9s, 458029 effective words/s
INFO - 2023-11-27 13:19:45,844: EPOCH 19: training on 412480 raw words (403612 effective words) took 0.9s, 460571 effective words/s
INFO - 2023-11-27 13:19:45,844: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072587 effective words) took 20.0s, 402667 effective words/s', 'datetime': '2023-11-27T13:19:45.844945', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:45,845: collecting all words and their counts
INFO - 2023-11-27 13:19:45,845: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:19:45,928: PROGRESS: at sentence #10000, processed 400000 words, keeping 10303 word types
INFO - 2023-11-27 13:19:45,931: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:19:45,931: Updating model with new vocabulary
INFO - 2023-11-27 13:19:45,964: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:19:45.964916', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:45,997: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:19:45,997: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:19:45,997: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403517.09051040834 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:19:45.997370', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:19:46,047: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:19:46,047: updating layer weights
INFO - 2023-11-27 13:19:46,048: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:19:46.047971', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:19:46,048: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:19:46,048: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:19:46.048137', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:19:46,928: EPOCH 0: training on 412480 raw words (403442 effective words) took 0.9s, 459161 effective words/s
INFO - 2023-11-27 13:19:47,803: EPOCH 1: training on 412480 raw words (403551 effective words) took 0.9s, 462371 effective words/s
INFO - 2023-11-27 13:19:48,664: EPOCH 2: training on 412480 raw words (403649 effective words) took 0.8s, 476333 effective words/s
INFO - 2023-11-27 13:19:49,523: EPOCH 3: training on 412480 raw words (403409 effective words) took 0.9s, 470759 effective words/s
INFO - 2023-11-27 13:19:50,394: EPOCH 4: training on 412480 raw words (403375 effective words) took 0.9s, 464456 effective words/s
INFO - 2023-11-27 13:19:51,264: EPOCH 5: training on 412480 raw words (403560 effective words) took 0.9s, 465149 effective words/s
INFO - 2023-11-27 13:19:52,300: EPOCH 6 - PROGRESS: at 100.00% examples, 390607 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:19:52,300: EPOCH 6: training on 412480 raw words (403645 effective words) took 1.0s, 390530 effective words/s
INFO - 2023-11-27 13:19:53,305: EPOCH 7 - PROGRESS: at 89.70% examples, 361156 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:19:53,394: EPOCH 7: training on 412480 raw words (403414 effective words) took 1.1s, 369602 effective words/s
INFO - 2023-11-27 13:19:54,398: EPOCH 8 - PROGRESS: at 94.55% examples, 381083 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:19:54,485: EPOCH 8: training on 412480 raw words (403468 effective words) took 1.1s, 370740 effective words/s
INFO - 2023-11-27 13:19:55,490: EPOCH 9 - PROGRESS: at 82.43% examples, 332039 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:19:55,604: EPOCH 9: training on 412480 raw words (403364 effective words) took 1.1s, 361438 effective words/s
INFO - 2023-11-27 13:19:56,611: EPOCH 10 - PROGRESS: at 89.70% examples, 360834 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:19:56,753: EPOCH 10: training on 412480 raw words (403639 effective words) took 1.1s, 352408 effective words/s
INFO - 2023-11-27 13:19:57,766: EPOCH 11 - PROGRESS: at 82.43% examples, 332517 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:19:57,888: EPOCH 11: training on 412480 raw words (403529 effective words) took 1.1s, 359672 effective words/s
INFO - 2023-11-27 13:19:58,899: EPOCH 12 - PROGRESS: at 75.16% examples, 301027 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:19:59,081: EPOCH 12: training on 412480 raw words (403629 effective words) took 1.2s, 339312 effective words/s
INFO - 2023-11-27 13:20:00,123: EPOCH 13 - PROGRESS: at 77.58% examples, 306628 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:20:00,273: EPOCH 13: training on 412480 raw words (403616 effective words) took 1.2s, 344740 effective words/s
INFO - 2023-11-27 13:20:01,343: EPOCH 14 - PROGRESS: at 100.00% examples, 378499 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:01,343: EPOCH 14: training on 412480 raw words (403467 effective words) took 1.1s, 378418 effective words/s
INFO - 2023-11-27 13:20:02,407: EPOCH 15 - PROGRESS: at 100.00% examples, 380518 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:02,407: EPOCH 15: training on 412480 raw words (403562 effective words) took 1.1s, 380426 effective words/s
INFO - 2023-11-27 13:20:03,429: EPOCH 16 - PROGRESS: at 92.13% examples, 370336 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:20:03,535: EPOCH 16: training on 412480 raw words (403546 effective words) took 1.1s, 363477 effective words/s
INFO - 2023-11-27 13:20:04,608: EPOCH 17 - PROGRESS: at 100.00% examples, 377161 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:04,608: EPOCH 17: training on 412480 raw words (403608 effective words) took 1.1s, 377049 effective words/s
INFO - 2023-11-27 13:20:05,680: EPOCH 18 - PROGRESS: at 100.00% examples, 377621 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:05,680: EPOCH 18: training on 412480 raw words (403553 effective words) took 1.1s, 377530 effective words/s
INFO - 2023-11-27 13:20:06,778: EPOCH 19 - PROGRESS: at 100.00% examples, 368012 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:06,779: EPOCH 19: training on 412480 raw words (403413 effective words) took 1.1s, 367917 effective words/s
INFO - 2023-11-27 13:20:06,779: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070439 effective words) took 20.7s, 389290 effective words/s', 'datetime': '2023-11-27T13:20:06.779376', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:06,779: collecting all words and their counts
INFO - 2023-11-27 13:20:06,779: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:20:06,917: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:20:06,920: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:20:06,920: Updating model with new vocabulary
INFO - 2023-11-27 13:20:06,957: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:20:06.957500', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:07,000: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:20:07,001: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:20:07,001: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403935.8589561512 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:20:07.001149', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:07,075: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:20:07,075: updating layer weights
INFO - 2023-11-27 13:20:07,076: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:20:07.076463', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:20:07,076: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:20:07,076: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:20:07.076697', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:08,081: EPOCH 0 - PROGRESS: at 92.13% examples, 371565 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:20:08,176: EPOCH 0: training on 412480 raw words (403946 effective words) took 1.1s, 368319 effective words/s
INFO - 2023-11-27 13:20:09,186: EPOCH 1 - PROGRESS: at 97.58% examples, 391539 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:20:09,281: EPOCH 1: training on 412480 raw words (403946 effective words) took 1.1s, 366379 effective words/s
INFO - 2023-11-27 13:20:10,426: EPOCH 2 - PROGRESS: at 100.00% examples, 359025 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:10,427: EPOCH 2: training on 412480 raw words (404064 effective words) took 1.1s, 358948 effective words/s
INFO - 2023-11-27 13:20:11,511: EPOCH 3 - PROGRESS: at 100.00% examples, 373589 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:11,511: EPOCH 3: training on 412480 raw words (403897 effective words) took 1.1s, 373499 effective words/s
INFO - 2023-11-27 13:20:12,630: EPOCH 4 - PROGRESS: at 100.00% examples, 361987 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:12,630: EPOCH 4: training on 412480 raw words (403904 effective words) took 1.1s, 361902 effective words/s
INFO - 2023-11-27 13:20:13,728: EPOCH 5 - PROGRESS: at 100.00% examples, 369239 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:13,728: EPOCH 5: training on 412480 raw words (404093 effective words) took 1.1s, 369168 effective words/s
INFO - 2023-11-27 13:20:14,834: EPOCH 6 - PROGRESS: at 100.00% examples, 366444 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:14,834: EPOCH 6: training on 412480 raw words (403953 effective words) took 1.1s, 366371 effective words/s
INFO - 2023-11-27 13:20:15,930: EPOCH 7 - PROGRESS: at 100.00% examples, 369485 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:15,930: EPOCH 7: training on 412480 raw words (404012 effective words) took 1.1s, 369404 effective words/s
INFO - 2023-11-27 13:20:16,944: EPOCH 8 - PROGRESS: at 77.58% examples, 309984 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:20:17,086: EPOCH 8: training on 412480 raw words (403911 effective words) took 1.2s, 350445 effective words/s
INFO - 2023-11-27 13:20:18,206: EPOCH 9 - PROGRESS: at 100.00% examples, 361769 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:18,206: EPOCH 9: training on 412480 raw words (404026 effective words) took 1.1s, 361693 effective words/s
INFO - 2023-11-27 13:20:19,210: EPOCH 10 - PROGRESS: at 96.97% examples, 391369 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:20:19,345: EPOCH 10: training on 412480 raw words (403892 effective words) took 1.1s, 355568 effective words/s
INFO - 2023-11-27 13:20:20,479: EPOCH 11 - PROGRESS: at 100.00% examples, 364669 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:20,479: EPOCH 11: training on 412480 raw words (403980 effective words) took 1.1s, 364591 effective words/s
INFO - 2023-11-27 13:20:21,592: EPOCH 12 - PROGRESS: at 100.00% examples, 363623 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:21,592: EPOCH 12: training on 412480 raw words (403878 effective words) took 1.1s, 363546 effective words/s
INFO - 2023-11-27 13:20:22,601: EPOCH 13 - PROGRESS: at 96.97% examples, 390861 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:20:22,702: EPOCH 13: training on 412480 raw words (403986 effective words) took 1.1s, 366161 effective words/s
INFO - 2023-11-27 13:20:23,708: EPOCH 14 - PROGRESS: at 97.58% examples, 393075 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:20:23,819: EPOCH 14: training on 412480 raw words (404040 effective words) took 1.1s, 362481 effective words/s
INFO - 2023-11-27 13:20:24,831: EPOCH 15 - PROGRESS: at 92.13% examples, 369058 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:20:24,921: EPOCH 15: training on 412480 raw words (403967 effective words) took 1.1s, 367582 effective words/s
INFO - 2023-11-27 13:20:25,986: EPOCH 16 - PROGRESS: at 100.00% examples, 380467 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:20:25,986: EPOCH 16: training on 412480 raw words (403952 effective words) took 1.1s, 380388 effective words/s
INFO - 2023-11-27 13:20:26,960: EPOCH 17: training on 412480 raw words (403898 effective words) took 1.0s, 416213 effective words/s
INFO - 2023-11-27 13:20:27,884: EPOCH 18: training on 412480 raw words (403955 effective words) took 0.9s, 437827 effective words/s
INFO - 2023-11-27 13:20:28,783: EPOCH 19: training on 412480 raw words (404009 effective words) took 0.9s, 450906 effective words/s
INFO - 2023-11-27 13:20:28,783: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8079309 effective words) took 21.7s, 372207 effective words/s', 'datetime': '2023-11-27T13:20:28.783268', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:28,783: collecting all words and their counts
INFO - 2023-11-27 13:20:28,783: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:20:28,853: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:20:28,855: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:20:28,855: Updating model with new vocabulary
INFO - 2023-11-27 13:20:28,891: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:20:28.891871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:28,945: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:20:28,945: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:20:28,945: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403793.2505440052 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:20:28.945737', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:29,008: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:20:29,008: updating layer weights
INFO - 2023-11-27 13:20:29,009: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:20:29.009119', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:20:29,009: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:20:29,009: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:20:29.009337', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:30,004: EPOCH 0: training on 412480 raw words (403776 effective words) took 1.0s, 412909 effective words/s
INFO - 2023-11-27 13:20:30,872: EPOCH 1: training on 412480 raw words (403660 effective words) took 0.9s, 465966 effective words/s
INFO - 2023-11-27 13:20:31,738: EPOCH 2: training on 412480 raw words (403734 effective words) took 0.9s, 467528 effective words/s
INFO - 2023-11-27 13:20:32,621: EPOCH 3: training on 412480 raw words (403704 effective words) took 0.9s, 457912 effective words/s
INFO - 2023-11-27 13:20:33,497: EPOCH 4: training on 412480 raw words (403791 effective words) took 0.9s, 468747 effective words/s
INFO - 2023-11-27 13:20:34,421: EPOCH 5: training on 412480 raw words (403777 effective words) took 0.9s, 437971 effective words/s
INFO - 2023-11-27 13:20:35,400: EPOCH 6: training on 412480 raw words (403818 effective words) took 1.0s, 413365 effective words/s
INFO - 2023-11-27 13:20:36,327: EPOCH 7: training on 412480 raw words (403738 effective words) took 0.9s, 436553 effective words/s
INFO - 2023-11-27 13:20:37,238: EPOCH 8: training on 412480 raw words (403677 effective words) took 0.9s, 444141 effective words/s
INFO - 2023-11-27 13:20:38,237: EPOCH 9: training on 412480 raw words (403926 effective words) took 1.0s, 405184 effective words/s
INFO - 2023-11-27 13:20:39,187: EPOCH 10: training on 412480 raw words (403823 effective words) took 0.9s, 425989 effective words/s
INFO - 2023-11-27 13:20:40,167: EPOCH 11: training on 412480 raw words (403850 effective words) took 1.0s, 413007 effective words/s
INFO - 2023-11-27 13:20:41,175: EPOCH 12 - PROGRESS: at 82.43% examples, 330942 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:20:41,314: EPOCH 12: training on 412480 raw words (403614 effective words) took 1.1s, 352599 effective words/s
INFO - 2023-11-27 13:20:42,321: EPOCH 13 - PROGRESS: at 75.16% examples, 302383 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:20:42,511: EPOCH 13: training on 412480 raw words (403810 effective words) took 1.2s, 338240 effective words/s
INFO - 2023-11-27 13:20:43,515: EPOCH 14 - PROGRESS: at 87.88% examples, 354244 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:20:43,617: EPOCH 14: training on 412480 raw words (403736 effective words) took 1.1s, 365528 effective words/s
INFO - 2023-11-27 13:20:44,688: EPOCH 15 - PROGRESS: at 77.58% examples, 293589 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:20:44,827: EPOCH 15: training on 412480 raw words (403808 effective words) took 1.2s, 334758 effective words/s
INFO - 2023-11-27 13:20:45,893: EPOCH 16 - PROGRESS: at 77.58% examples, 299001 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:20:46,052: EPOCH 16: training on 412480 raw words (403802 effective words) took 1.2s, 334601 effective words/s
INFO - 2023-11-27 13:20:47,160: EPOCH 17 - PROGRESS: at 75.16% examples, 274593 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:20:47,385: EPOCH 17: training on 412480 raw words (403922 effective words) took 1.3s, 303680 effective words/s
INFO - 2023-11-27 13:20:48,432: EPOCH 18 - PROGRESS: at 75.16% examples, 290885 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:20:48,629: EPOCH 18: training on 412480 raw words (403718 effective words) took 1.2s, 325339 effective words/s
INFO - 2023-11-27 13:20:49,571: EPOCH 19: training on 412480 raw words (403900 effective words) took 0.9s, 444311 effective words/s
INFO - 2023-11-27 13:20:49,571: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8075584 effective words) took 20.6s, 392747 effective words/s', 'datetime': '2023-11-27T13:20:49.571249', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:49,571: collecting all words and their counts
INFO - 2023-11-27 13:20:49,571: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:20:49,645: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:20:49,648: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:20:49,648: Updating model with new vocabulary
INFO - 2023-11-27 13:20:49,690: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:20:49.690259', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:49,748: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:20:49,749: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:20:49,749: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403674.7895187894 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:20:49.749236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:20:49,803: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:20:49,803: updating layer weights
INFO - 2023-11-27 13:20:49,804: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:20:49.804513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:20:49,804: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:20:49,804: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:20:49.804722', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:20:50,691: EPOCH 0: training on 412480 raw words (403822 effective words) took 0.9s, 456734 effective words/s
INFO - 2023-11-27 13:20:51,565: EPOCH 1: training on 412480 raw words (403816 effective words) took 0.9s, 463147 effective words/s
INFO - 2023-11-27 13:20:52,428: EPOCH 2: training on 412480 raw words (403693 effective words) took 0.9s, 468714 effective words/s
INFO - 2023-11-27 13:20:53,415: EPOCH 3: training on 412480 raw words (403633 effective words) took 1.0s, 409812 effective words/s
INFO - 2023-11-27 13:20:54,348: EPOCH 4: training on 412480 raw words (403700 effective words) took 0.9s, 433602 effective words/s
INFO - 2023-11-27 13:20:55,271: EPOCH 5: training on 412480 raw words (403717 effective words) took 0.9s, 438577 effective words/s
INFO - 2023-11-27 13:20:56,187: EPOCH 6: training on 412480 raw words (403620 effective words) took 0.9s, 443837 effective words/s
INFO - 2023-11-27 13:20:57,144: EPOCH 7: training on 412480 raw words (403667 effective words) took 1.0s, 422954 effective words/s
INFO - 2023-11-27 13:20:58,169: EPOCH 8 - PROGRESS: at 95.15% examples, 375524 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:20:58,176: EPOCH 8: training on 412480 raw words (403514 effective words) took 1.0s, 391967 effective words/s
INFO - 2023-11-27 13:20:59,129: EPOCH 9: training on 412480 raw words (403693 effective words) took 1.0s, 424587 effective words/s
INFO - 2023-11-27 13:21:00,070: EPOCH 10: training on 412480 raw words (403661 effective words) took 0.9s, 429856 effective words/s
INFO - 2023-11-27 13:21:00,961: EPOCH 11: training on 412480 raw words (403715 effective words) took 0.9s, 454206 effective words/s
INFO - 2023-11-27 13:21:01,864: EPOCH 12: training on 412480 raw words (403800 effective words) took 0.9s, 448050 effective words/s
INFO - 2023-11-27 13:21:02,776: EPOCH 13: training on 412480 raw words (403840 effective words) took 0.9s, 444586 effective words/s
INFO - 2023-11-27 13:21:03,729: EPOCH 14: training on 412480 raw words (403654 effective words) took 1.0s, 424648 effective words/s
INFO - 2023-11-27 13:21:04,733: EPOCH 15 - PROGRESS: at 85.45% examples, 344339 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:21:04,764: EPOCH 15: training on 412480 raw words (403706 effective words) took 1.0s, 390727 effective words/s
INFO - 2023-11-27 13:21:05,782: EPOCH 16 - PROGRESS: at 82.43% examples, 327686 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:21:05,910: EPOCH 16: training on 412480 raw words (403825 effective words) took 1.1s, 353295 effective words/s
INFO - 2023-11-27 13:21:06,982: EPOCH 17 - PROGRESS: at 75.16% examples, 283547 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:21:07,192: EPOCH 17: training on 412480 raw words (403730 effective words) took 1.3s, 315448 effective words/s
INFO - 2023-11-27 13:21:08,207: EPOCH 18 - PROGRESS: at 77.58% examples, 309309 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:21:08,355: EPOCH 18: training on 412480 raw words (403766 effective words) took 1.2s, 347816 effective words/s
INFO - 2023-11-27 13:21:09,368: EPOCH 19 - PROGRESS: at 75.16% examples, 300164 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:21:09,574: EPOCH 19: training on 412480 raw words (403438 effective words) took 1.2s, 331909 effective words/s
INFO - 2023-11-27 13:21:09,574: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074010 effective words) took 19.8s, 408401 effective words/s', 'datetime': '2023-11-27T13:21:09.574624', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:09,574: collecting all words and their counts
INFO - 2023-11-27 13:21:09,574: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:21:09,683: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:21:09,687: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:21:09,687: Updating model with new vocabulary
INFO - 2023-11-27 13:21:09,728: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:21:09.728931', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:09,779: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:21:09,779: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:21:09,779: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403359.5497290119 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:21:09.779465', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:09,871: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:21:09,871: updating layer weights
INFO - 2023-11-27 13:21:09,872: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:21:09.872430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:21:09,872: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:21:09,872: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:21:09.872637', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:10,915: EPOCH 0 - PROGRESS: at 75.16% examples, 291279 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:21:11,138: EPOCH 0: training on 412480 raw words (403290 effective words) took 1.3s, 319311 effective words/s
INFO - 2023-11-27 13:21:12,179: EPOCH 1 - PROGRESS: at 77.58% examples, 301448 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:21:12,340: EPOCH 1: training on 412480 raw words (403457 effective words) took 1.2s, 336492 effective words/s
INFO - 2023-11-27 13:21:13,343: EPOCH 2 - PROGRESS: at 77.58% examples, 312674 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:21:13,467: EPOCH 2: training on 412480 raw words (403322 effective words) took 1.1s, 358723 effective words/s
INFO - 2023-11-27 13:21:14,304: EPOCH 3: training on 412480 raw words (403338 effective words) took 0.8s, 483096 effective words/s
INFO - 2023-11-27 13:21:15,146: EPOCH 4: training on 412480 raw words (403345 effective words) took 0.8s, 479859 effective words/s
INFO - 2023-11-27 13:21:15,951: EPOCH 5: training on 412480 raw words (403421 effective words) took 0.8s, 502839 effective words/s
INFO - 2023-11-27 13:21:16,877: EPOCH 6: training on 412480 raw words (403337 effective words) took 0.9s, 436741 effective words/s
INFO - 2023-11-27 13:21:17,658: EPOCH 7: training on 412480 raw words (403369 effective words) took 0.8s, 517708 effective words/s
INFO - 2023-11-27 13:21:18,490: EPOCH 8: training on 412480 raw words (403352 effective words) took 0.8s, 485896 effective words/s
INFO - 2023-11-27 13:21:19,289: EPOCH 9: training on 412480 raw words (403307 effective words) took 0.8s, 506261 effective words/s
INFO - 2023-11-27 13:21:20,135: EPOCH 10: training on 412480 raw words (403301 effective words) took 0.8s, 477699 effective words/s
INFO - 2023-11-27 13:21:20,974: EPOCH 11: training on 412480 raw words (403351 effective words) took 0.8s, 481667 effective words/s
INFO - 2023-11-27 13:21:21,794: EPOCH 12: training on 412480 raw words (403346 effective words) took 0.8s, 493791 effective words/s
INFO - 2023-11-27 13:21:22,612: EPOCH 13: training on 412480 raw words (403415 effective words) took 0.8s, 494421 effective words/s
INFO - 2023-11-27 13:21:23,503: EPOCH 14: training on 412480 raw words (403291 effective words) took 0.9s, 453487 effective words/s
INFO - 2023-11-27 13:21:24,360: EPOCH 15: training on 412480 raw words (403356 effective words) took 0.9s, 471585 effective words/s
INFO - 2023-11-27 13:21:25,208: EPOCH 16: training on 412480 raw words (403399 effective words) took 0.8s, 476818 effective words/s
INFO - 2023-11-27 13:21:26,092: EPOCH 17: training on 412480 raw words (403388 effective words) took 0.9s, 457214 effective words/s
INFO - 2023-11-27 13:21:26,984: EPOCH 18: training on 412480 raw words (403346 effective words) took 0.9s, 453241 effective words/s
INFO - 2023-11-27 13:21:27,805: EPOCH 19: training on 412480 raw words (403399 effective words) took 0.8s, 492339 effective words/s
INFO - 2023-11-27 13:21:27,806: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8067130 effective words) took 17.9s, 449836 effective words/s', 'datetime': '2023-11-27T13:21:27.806202', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:27,806: collecting all words and their counts
INFO - 2023-11-27 13:21:27,806: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:21:27,865: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:21:27,868: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:21:27,868: Updating model with new vocabulary
INFO - 2023-11-27 13:21:27,893: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:21:27.893609', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:27,928: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:21:27,928: sample=0.001 downsamples 26 most-common words
INFO - 2023-11-27 13:21:27,928: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403634.8022633203 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:21:27.928418', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:27,978: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:21:27,978: updating layer weights
INFO - 2023-11-27 13:21:27,978: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:21:27.978709', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:21:27,978: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:21:27,978: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:21:27.978871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:28,985: EPOCH 0 - PROGRESS: at 100.00% examples, 401707 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:21:28,985: EPOCH 0: training on 412480 raw words (403727 effective words) took 1.0s, 401617 effective words/s
INFO - 2023-11-27 13:21:29,990: EPOCH 1 - PROGRESS: at 94.55% examples, 380801 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:21:30,118: EPOCH 1: training on 412480 raw words (403551 effective words) took 1.1s, 356948 effective words/s
INFO - 2023-11-27 13:21:31,219: EPOCH 2 - PROGRESS: at 100.00% examples, 367611 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:21:31,219: EPOCH 2: training on 412480 raw words (403663 effective words) took 1.1s, 367541 effective words/s
INFO - 2023-11-27 13:21:32,224: EPOCH 3 - PROGRESS: at 82.43% examples, 331889 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:21:32,342: EPOCH 3: training on 412480 raw words (403620 effective words) took 1.1s, 360137 effective words/s
INFO - 2023-11-27 13:21:33,357: EPOCH 4 - PROGRESS: at 92.73% examples, 369576 words/s, in_qsize 2, out_qsize 3
INFO - 2023-11-27 13:21:33,434: EPOCH 4: training on 412480 raw words (403548 effective words) took 1.1s, 370464 effective words/s
INFO - 2023-11-27 13:21:34,440: EPOCH 5 - PROGRESS: at 89.70% examples, 360932 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:21:34,590: EPOCH 5: training on 412480 raw words (403574 effective words) took 1.2s, 349943 effective words/s
INFO - 2023-11-27 13:21:35,594: EPOCH 6 - PROGRESS: at 75.16% examples, 302939 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:21:35,777: EPOCH 6: training on 412480 raw words (403606 effective words) took 1.2s, 340708 effective words/s
INFO - 2023-11-27 13:21:36,791: EPOCH 7 - PROGRESS: at 80.00% examples, 319301 words/s, in_qsize 8, out_qsize 3
INFO - 2023-11-27 13:21:36,947: EPOCH 7: training on 412480 raw words (403503 effective words) took 1.2s, 345844 effective words/s
INFO - 2023-11-27 13:21:37,888: EPOCH 8: training on 412480 raw words (403655 effective words) took 0.9s, 429965 effective words/s
INFO - 2023-11-27 13:21:38,728: EPOCH 9: training on 412480 raw words (403709 effective words) took 0.8s, 481943 effective words/s
INFO - 2023-11-27 13:21:39,611: EPOCH 10: training on 412480 raw words (403568 effective words) took 0.9s, 457759 effective words/s
INFO - 2023-11-27 13:21:40,460: EPOCH 11: training on 412480 raw words (403792 effective words) took 0.8s, 477187 effective words/s
INFO - 2023-11-27 13:21:41,351: EPOCH 12: training on 412480 raw words (403624 effective words) took 0.9s, 453985 effective words/s
INFO - 2023-11-27 13:21:42,206: EPOCH 13: training on 412480 raw words (403674 effective words) took 0.9s, 473454 effective words/s
INFO - 2023-11-27 13:21:43,066: EPOCH 14: training on 412480 raw words (403756 effective words) took 0.9s, 470624 effective words/s
INFO - 2023-11-27 13:21:43,947: EPOCH 15: training on 412480 raw words (403756 effective words) took 0.9s, 459406 effective words/s
INFO - 2023-11-27 13:21:44,837: EPOCH 16: training on 412480 raw words (403563 effective words) took 0.9s, 454691 effective words/s
INFO - 2023-11-27 13:21:45,704: EPOCH 17: training on 412480 raw words (403667 effective words) took 0.9s, 466626 effective words/s
INFO - 2023-11-27 13:21:46,598: EPOCH 18: training on 412480 raw words (403628 effective words) took 0.9s, 452590 effective words/s
INFO - 2023-11-27 13:21:47,444: EPOCH 19: training on 412480 raw words (403691 effective words) took 0.8s, 477939 effective words/s
INFO - 2023-11-27 13:21:47,445: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072875 effective words) took 19.5s, 414713 effective words/s', 'datetime': '2023-11-27T13:21:47.445128', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:47,445: collecting all words and their counts
INFO - 2023-11-27 13:21:47,445: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:21:47,505: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:21:47,507: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:21:47,507: Updating model with new vocabulary
INFO - 2023-11-27 13:21:47,552: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:21:47.552733', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:47,595: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:21:47,595: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:21:47,595: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403758.3511029426 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:21:47.595633', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:21:47,646: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:21:47,646: updating layer weights
INFO - 2023-11-27 13:21:47,647: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:21:47.647484', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:21:47,647: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:21:47,647: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:21:47.647712', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:21:48,496: EPOCH 0: training on 412480 raw words (403657 effective words) took 0.8s, 476781 effective words/s
INFO - 2023-11-27 13:21:49,353: EPOCH 1: training on 412480 raw words (403808 effective words) took 0.9s, 472433 effective words/s
INFO - 2023-11-27 13:21:50,191: EPOCH 2: training on 412480 raw words (403687 effective words) took 0.8s, 483333 effective words/s
INFO - 2023-11-27 13:21:51,043: EPOCH 3: training on 412480 raw words (403764 effective words) took 0.8s, 475094 effective words/s
INFO - 2023-11-27 13:21:51,896: EPOCH 4: training on 412480 raw words (403637 effective words) took 0.9s, 473949 effective words/s
INFO - 2023-11-27 13:21:52,859: EPOCH 5: training on 412480 raw words (403779 effective words) took 1.0s, 420361 effective words/s
INFO - 2023-11-27 13:21:53,964: EPOCH 6 - PROGRESS: at 100.00% examples, 366259 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:21:53,964: EPOCH 6: training on 412480 raw words (403843 effective words) took 1.1s, 366174 effective words/s
INFO - 2023-11-27 13:21:54,967: EPOCH 7 - PROGRESS: at 97.58% examples, 393877 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:21:55,084: EPOCH 7: training on 412480 raw words (403820 effective words) took 1.1s, 361366 effective words/s
INFO - 2023-11-27 13:21:56,168: EPOCH 8 - PROGRESS: at 100.00% examples, 373622 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:21:56,168: EPOCH 8: training on 412480 raw words (403833 effective words) took 1.1s, 373540 effective words/s
INFO - 2023-11-27 13:21:57,185: EPOCH 9 - PROGRESS: at 77.58% examples, 308836 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:21:57,310: EPOCH 9: training on 412480 raw words (403673 effective words) took 1.1s, 354445 effective words/s
INFO - 2023-11-27 13:21:58,354: EPOCH 10 - PROGRESS: at 80.61% examples, 312228 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:21:58,463: EPOCH 10: training on 412480 raw words (403793 effective words) took 1.2s, 350975 effective words/s
INFO - 2023-11-27 13:21:59,473: EPOCH 11 - PROGRESS: at 87.28% examples, 349781 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:21:59,572: EPOCH 11: training on 412480 raw words (403662 effective words) took 1.1s, 364794 effective words/s
INFO - 2023-11-27 13:22:00,586: EPOCH 12 - PROGRESS: at 84.85% examples, 338652 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:22:00,700: EPOCH 12: training on 412480 raw words (403887 effective words) took 1.1s, 358922 effective words/s
INFO - 2023-11-27 13:22:01,739: EPOCH 13 - PROGRESS: at 100.00% examples, 389589 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:22:01,739: EPOCH 13: training on 412480 raw words (403781 effective words) took 1.0s, 389514 effective words/s
INFO - 2023-11-27 13:22:02,544: EPOCH 14: training on 412480 raw words (403646 effective words) took 0.8s, 502248 effective words/s
INFO - 2023-11-27 13:22:03,369: EPOCH 15: training on 412480 raw words (403683 effective words) took 0.8s, 490368 effective words/s
INFO - 2023-11-27 13:22:04,223: EPOCH 16: training on 412480 raw words (403937 effective words) took 0.9s, 474239 effective words/s
INFO - 2023-11-27 13:22:05,057: EPOCH 17: training on 412480 raw words (403812 effective words) took 0.8s, 485524 effective words/s
INFO - 2023-11-27 13:22:05,895: EPOCH 18: training on 412480 raw words (403716 effective words) took 0.8s, 482870 effective words/s
INFO - 2023-11-27 13:22:06,723: EPOCH 19: training on 412480 raw words (403766 effective words) took 0.8s, 492002 effective words/s
INFO - 2023-11-27 13:22:06,723: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8075184 effective words) took 19.1s, 423319 effective words/s', 'datetime': '2023-11-27T13:22:06.723681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:06,723: collecting all words and their counts
INFO - 2023-11-27 13:22:06,724: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:22:06,795: PROGRESS: at sentence #10000, processed 400000 words, keeping 10304 word types
INFO - 2023-11-27 13:22:06,797: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:22:06,797: Updating model with new vocabulary
INFO - 2023-11-27 13:22:06,830: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:22:06.830588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:06,867: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:22:06,868: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:22:06,868: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403598.1136683866 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:22:06.868244', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:06,927: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:22:06,927: updating layer weights
INFO - 2023-11-27 13:22:06,927: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:22:06.927946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:22:06,928: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:22:06,928: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:22:06.928142', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:07,789: EPOCH 0: training on 412480 raw words (403616 effective words) took 0.9s, 469753 effective words/s
INFO - 2023-11-27 13:22:08,705: EPOCH 1: training on 412480 raw words (403550 effective words) took 0.9s, 441421 effective words/s
INFO - 2023-11-27 13:22:09,611: EPOCH 2: training on 412480 raw words (403654 effective words) took 0.9s, 446512 effective words/s
INFO - 2023-11-27 13:22:10,485: EPOCH 3: training on 412480 raw words (403634 effective words) took 0.9s, 462754 effective words/s
INFO - 2023-11-27 13:22:11,420: EPOCH 4: training on 412480 raw words (403683 effective words) took 0.9s, 433097 effective words/s
INFO - 2023-11-27 13:22:12,284: EPOCH 5: training on 412480 raw words (403606 effective words) took 0.9s, 470240 effective words/s
INFO - 2023-11-27 13:22:13,134: EPOCH 6: training on 412480 raw words (403716 effective words) took 0.8s, 476011 effective words/s
INFO - 2023-11-27 13:22:13,988: EPOCH 7: training on 412480 raw words (403771 effective words) took 0.9s, 473678 effective words/s
INFO - 2023-11-27 13:22:14,896: EPOCH 8: training on 412480 raw words (403586 effective words) took 0.9s, 445590 effective words/s
INFO - 2023-11-27 13:22:15,787: EPOCH 9: training on 412480 raw words (403657 effective words) took 0.9s, 454126 effective words/s
INFO - 2023-11-27 13:22:16,681: EPOCH 10: training on 412480 raw words (403550 effective words) took 0.9s, 452491 effective words/s
INFO - 2023-11-27 13:22:17,682: EPOCH 11: training on 412480 raw words (403660 effective words) took 1.0s, 404309 effective words/s
INFO - 2023-11-27 13:22:18,635: EPOCH 12: training on 412480 raw words (403628 effective words) took 1.0s, 424375 effective words/s
INFO - 2023-11-27 13:22:19,568: EPOCH 13: training on 412480 raw words (403546 effective words) took 0.9s, 433620 effective words/s
INFO - 2023-11-27 13:22:20,571: EPOCH 14 - PROGRESS: at 75.16% examples, 302959 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:22:20,779: EPOCH 14: training on 412480 raw words (403471 effective words) took 1.2s, 333776 effective words/s
INFO - 2023-11-27 13:22:21,793: EPOCH 15 - PROGRESS: at 77.58% examples, 309457 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:21,958: EPOCH 15: training on 412480 raw words (403509 effective words) took 1.2s, 342930 effective words/s
INFO - 2023-11-27 13:22:23,007: EPOCH 16 - PROGRESS: at 77.58% examples, 299127 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:23,141: EPOCH 16: training on 412480 raw words (403555 effective words) took 1.2s, 341991 effective words/s
INFO - 2023-11-27 13:22:24,171: EPOCH 17 - PROGRESS: at 77.58% examples, 304828 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:24,312: EPOCH 17: training on 412480 raw words (403568 effective words) took 1.2s, 345474 effective words/s
INFO - 2023-11-27 13:22:25,321: EPOCH 18 - PROGRESS: at 75.16% examples, 301535 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:22:25,517: EPOCH 18: training on 412480 raw words (403508 effective words) took 1.2s, 335753 effective words/s
INFO - 2023-11-27 13:22:26,472: EPOCH 19: training on 412480 raw words (403712 effective words) took 1.0s, 423730 effective words/s
INFO - 2023-11-27 13:22:26,472: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072180 effective words) took 19.5s, 413019 effective words/s', 'datetime': '2023-11-27T13:22:26.472559', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:26,472: collecting all words and their counts
INFO - 2023-11-27 13:22:26,472: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:22:26,531: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:22:26,533: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:22:26,533: Updating model with new vocabulary
INFO - 2023-11-27 13:22:26,559: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:22:26.559346', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:26,599: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:22:26,600: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:22:26,600: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403545.028654206 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:22:26.600083', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:26,656: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:22:26,656: updating layer weights
INFO - 2023-11-27 13:22:26,657: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:22:26.657238', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:22:26,657: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:22:26,657: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:22:26.657402', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:27,477: EPOCH 0: training on 412480 raw words (403520 effective words) took 0.8s, 492934 effective words/s
INFO - 2023-11-27 13:22:28,318: EPOCH 1: training on 412480 raw words (403507 effective words) took 0.8s, 481269 effective words/s
INFO - 2023-11-27 13:22:29,142: EPOCH 2: training on 412480 raw words (403622 effective words) took 0.8s, 490703 effective words/s
INFO - 2023-11-27 13:22:30,061: EPOCH 3: training on 412480 raw words (403599 effective words) took 0.9s, 440327 effective words/s
INFO - 2023-11-27 13:22:30,889: EPOCH 4: training on 412480 raw words (403628 effective words) took 0.8s, 489037 effective words/s
INFO - 2023-11-27 13:22:31,725: EPOCH 5: training on 412480 raw words (403555 effective words) took 0.8s, 483750 effective words/s
INFO - 2023-11-27 13:22:32,559: EPOCH 6: training on 412480 raw words (403626 effective words) took 0.8s, 485110 effective words/s
INFO - 2023-11-27 13:22:33,426: EPOCH 7: training on 412480 raw words (403505 effective words) took 0.9s, 466604 effective words/s
INFO - 2023-11-27 13:22:34,273: EPOCH 8: training on 412480 raw words (403497 effective words) took 0.8s, 477644 effective words/s
INFO - 2023-11-27 13:22:35,083: EPOCH 9: training on 412480 raw words (403484 effective words) took 0.8s, 499407 effective words/s
INFO - 2023-11-27 13:22:35,934: EPOCH 10: training on 412480 raw words (403573 effective words) took 0.8s, 475012 effective words/s
INFO - 2023-11-27 13:22:36,758: EPOCH 11: training on 412480 raw words (403654 effective words) took 0.8s, 491120 effective words/s
INFO - 2023-11-27 13:22:37,628: EPOCH 12: training on 412480 raw words (403548 effective words) took 0.9s, 465105 effective words/s
INFO - 2023-11-27 13:22:38,463: EPOCH 13: training on 412480 raw words (403544 effective words) took 0.8s, 484514 effective words/s
INFO - 2023-11-27 13:22:39,318: EPOCH 14: training on 412480 raw words (403460 effective words) took 0.9s, 474038 effective words/s
INFO - 2023-11-27 13:22:40,203: EPOCH 15: training on 412480 raw words (403498 effective words) took 0.9s, 457156 effective words/s
INFO - 2023-11-27 13:22:41,082: EPOCH 16: training on 412480 raw words (403636 effective words) took 0.9s, 460310 effective words/s
INFO - 2023-11-27 13:22:42,126: EPOCH 17 - PROGRESS: at 100.00% examples, 387346 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:22:42,126: EPOCH 17: training on 412480 raw words (403601 effective words) took 1.0s, 387247 effective words/s
INFO - 2023-11-27 13:22:43,193: EPOCH 18 - PROGRESS: at 100.00% examples, 379338 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:22:43,194: EPOCH 18: training on 412480 raw words (403594 effective words) took 1.1s, 379255 effective words/s
INFO - 2023-11-27 13:22:44,212: EPOCH 19 - PROGRESS: at 100.00% examples, 397176 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:22:44,212: EPOCH 19: training on 412480 raw words (403574 effective words) took 1.0s, 397075 effective words/s
INFO - 2023-11-27 13:22:44,213: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071225 effective words) took 17.6s, 459755 effective words/s', 'datetime': '2023-11-27T13:22:44.212984', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:44,213: collecting all words and their counts
INFO - 2023-11-27 13:22:44,213: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:22:44,300: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:22:44,303: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:22:44,303: Updating model with new vocabulary
INFO - 2023-11-27 13:22:44,335: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:22:44.335861', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:44,382: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:22:44,383: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:22:44,383: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403555.63218909566 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:22:44.383214', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:22:44,448: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:22:44,448: updating layer weights
INFO - 2023-11-27 13:22:44,449: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:22:44.449403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:22:44,449: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:22:44,449: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:22:44.449588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:22:45,463: EPOCH 0 - PROGRESS: at 84.85% examples, 338428 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:22:45,592: EPOCH 0: training on 412480 raw words (403603 effective words) took 1.1s, 353890 effective words/s
INFO - 2023-11-27 13:22:46,607: EPOCH 1 - PROGRESS: at 77.58% examples, 309778 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:46,772: EPOCH 1: training on 412480 raw words (403633 effective words) took 1.2s, 343083 effective words/s
INFO - 2023-11-27 13:22:47,836: EPOCH 2 - PROGRESS: at 77.58% examples, 294919 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:47,968: EPOCH 2: training on 412480 raw words (403493 effective words) took 1.2s, 338160 effective words/s
INFO - 2023-11-27 13:22:48,999: EPOCH 3 - PROGRESS: at 77.58% examples, 304561 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:49,114: EPOCH 3: training on 412480 raw words (403554 effective words) took 1.1s, 352896 effective words/s
INFO - 2023-11-27 13:22:50,123: EPOCH 4 - PROGRESS: at 77.58% examples, 311285 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:22:50,229: EPOCH 4: training on 412480 raw words (403580 effective words) took 1.1s, 362663 effective words/s
INFO - 2023-11-27 13:22:51,085: EPOCH 5: training on 412480 raw words (403683 effective words) took 0.9s, 472839 effective words/s
INFO - 2023-11-27 13:22:51,971: EPOCH 6: training on 412480 raw words (403586 effective words) took 0.9s, 456701 effective words/s
INFO - 2023-11-27 13:22:52,951: EPOCH 7: training on 412480 raw words (403587 effective words) took 1.0s, 412743 effective words/s
INFO - 2023-11-27 13:22:53,813: EPOCH 8: training on 412480 raw words (403475 effective words) took 0.9s, 469008 effective words/s
INFO - 2023-11-27 13:22:54,732: EPOCH 9: training on 412480 raw words (403547 effective words) took 0.9s, 440193 effective words/s
INFO - 2023-11-27 13:22:55,633: EPOCH 10: training on 412480 raw words (403373 effective words) took 0.9s, 448527 effective words/s
INFO - 2023-11-27 13:22:56,526: EPOCH 11: training on 412480 raw words (403425 effective words) took 0.9s, 452825 effective words/s
INFO - 2023-11-27 13:22:57,451: EPOCH 12: training on 412480 raw words (403521 effective words) took 0.9s, 437454 effective words/s
INFO - 2023-11-27 13:22:58,349: EPOCH 13: training on 412480 raw words (403530 effective words) took 0.9s, 450111 effective words/s
INFO - 2023-11-27 13:22:59,235: EPOCH 14: training on 412480 raw words (403460 effective words) took 0.9s, 456529 effective words/s
INFO - 2023-11-27 13:23:00,114: EPOCH 15: training on 412480 raw words (403661 effective words) took 0.9s, 460355 effective words/s
INFO - 2023-11-27 13:23:01,086: EPOCH 16: training on 412480 raw words (403434 effective words) took 1.0s, 415842 effective words/s
INFO - 2023-11-27 13:23:01,986: EPOCH 17: training on 412480 raw words (403673 effective words) took 0.9s, 449424 effective words/s
INFO - 2023-11-27 13:23:02,898: EPOCH 18: training on 412480 raw words (403592 effective words) took 0.9s, 443589 effective words/s
INFO - 2023-11-27 13:23:03,810: EPOCH 19: training on 412480 raw words (403577 effective words) took 0.9s, 443405 effective words/s
INFO - 2023-11-27 13:23:03,811: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070987 effective words) took 19.4s, 416858 effective words/s', 'datetime': '2023-11-27T13:23:03.811124', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:03,811: collecting all words and their counts
INFO - 2023-11-27 13:23:03,811: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:23:03,877: PROGRESS: at sentence #10000, processed 400000 words, keeping 10297 word types
INFO - 2023-11-27 13:23:03,880: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:23:03,880: Updating model with new vocabulary
INFO - 2023-11-27 13:23:03,912: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:23:03.912360', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:03,946: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:23:03,946: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:23:03,946: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403620.1175295843 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:23:03.946535', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:04,012: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:23:04,012: updating layer weights
INFO - 2023-11-27 13:23:04,013: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:23:04.013413', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:23:04,013: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:23:04,013: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:23:04.013589', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:04,863: EPOCH 0: training on 412480 raw words (403700 effective words) took 0.8s, 476054 effective words/s
INFO - 2023-11-27 13:23:05,734: EPOCH 1: training on 412480 raw words (403705 effective words) took 0.9s, 464705 effective words/s
INFO - 2023-11-27 13:23:06,609: EPOCH 2: training on 412480 raw words (403692 effective words) took 0.9s, 462279 effective words/s
INFO - 2023-11-27 13:23:07,442: EPOCH 3: training on 412480 raw words (403582 effective words) took 0.8s, 485712 effective words/s
INFO - 2023-11-27 13:23:08,396: EPOCH 4: training on 412480 raw words (403623 effective words) took 1.0s, 423852 effective words/s
INFO - 2023-11-27 13:23:09,416: EPOCH 5 - PROGRESS: at 84.85% examples, 336552 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:23:09,560: EPOCH 5: training on 412480 raw words (403499 effective words) took 1.2s, 347417 effective words/s
INFO - 2023-11-27 13:23:10,581: EPOCH 6 - PROGRESS: at 75.16% examples, 297929 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:23:10,758: EPOCH 6: training on 412480 raw words (403593 effective words) took 1.2s, 337859 effective words/s
INFO - 2023-11-27 13:23:11,791: EPOCH 7 - PROGRESS: at 77.58% examples, 303809 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:23:11,926: EPOCH 7: training on 412480 raw words (403617 effective words) took 1.2s, 346229 effective words/s
INFO - 2023-11-27 13:23:12,938: EPOCH 8 - PROGRESS: at 82.43% examples, 329579 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:23:13,053: EPOCH 8: training on 412480 raw words (403653 effective words) took 1.1s, 358824 effective words/s
INFO - 2023-11-27 13:23:14,066: EPOCH 9 - PROGRESS: at 80.00% examples, 319863 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:23:14,200: EPOCH 9: training on 412480 raw words (403602 effective words) took 1.1s, 352909 effective words/s
INFO - 2023-11-27 13:23:15,296: EPOCH 10 - PROGRESS: at 100.00% examples, 369148 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:15,297: EPOCH 10: training on 412480 raw words (403608 effective words) took 1.1s, 369045 effective words/s
INFO - 2023-11-27 13:23:16,389: EPOCH 11 - PROGRESS: at 100.00% examples, 370428 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:16,389: EPOCH 11: training on 412480 raw words (403565 effective words) took 1.1s, 370340 effective words/s
INFO - 2023-11-27 13:23:17,404: EPOCH 12 - PROGRESS: at 92.73% examples, 369714 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:23:17,513: EPOCH 12: training on 412480 raw words (403660 effective words) took 1.1s, 359946 effective words/s
INFO - 2023-11-27 13:23:18,540: EPOCH 13 - PROGRESS: at 100.00% examples, 394223 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:18,540: EPOCH 13: training on 412480 raw words (403672 effective words) took 1.0s, 394127 effective words/s
INFO - 2023-11-27 13:23:19,664: EPOCH 14 - PROGRESS: at 100.00% examples, 360030 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:19,664: EPOCH 14: training on 412480 raw words (403562 effective words) took 1.1s, 359939 effective words/s
INFO - 2023-11-27 13:23:20,713: EPOCH 15 - PROGRESS: at 100.00% examples, 385643 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:20,713: EPOCH 15: training on 412480 raw words (403564 effective words) took 1.0s, 385518 effective words/s
INFO - 2023-11-27 13:23:21,764: EPOCH 16 - PROGRESS: at 100.00% examples, 385314 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:21,764: EPOCH 16: training on 412480 raw words (403740 effective words) took 1.0s, 385195 effective words/s
INFO - 2023-11-27 13:23:22,849: EPOCH 17 - PROGRESS: at 100.00% examples, 372884 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:22,849: EPOCH 17: training on 412480 raw words (403486 effective words) took 1.1s, 372796 effective words/s
INFO - 2023-11-27 13:23:23,878: EPOCH 18 - PROGRESS: at 100.00% examples, 393798 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:23,878: EPOCH 18: training on 412480 raw words (403695 effective words) took 1.0s, 393694 effective words/s
INFO - 2023-11-27 13:23:24,951: EPOCH 19 - PROGRESS: at 100.00% examples, 377376 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:24,951: EPOCH 19: training on 412480 raw words (403571 effective words) took 1.1s, 377292 effective words/s
INFO - 2023-11-27 13:23:24,951: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072389 effective words) took 20.9s, 385543 effective words/s', 'datetime': '2023-11-27T13:23:24.951407', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:24,951: collecting all words and their counts
INFO - 2023-11-27 13:23:24,951: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:23:25,053: PROGRESS: at sentence #10000, processed 400000 words, keeping 10299 word types
INFO - 2023-11-27 13:23:25,056: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:23:25,056: Updating model with new vocabulary
INFO - 2023-11-27 13:23:25,094: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:23:25.094804', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:25,146: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:23:25,146: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:23:25,147: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403338.3318310748 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:23:25.147067', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:25,221: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:23:25,221: updating layer weights
INFO - 2023-11-27 13:23:25,222: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:23:25.222207', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:23:25,222: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:23:25,222: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:23:25.222443', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:26,242: EPOCH 0 - PROGRESS: at 80.00% examples, 317603 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:23:26,378: EPOCH 0: training on 412480 raw words (403386 effective words) took 1.2s, 349814 effective words/s
INFO - 2023-11-27 13:23:27,397: EPOCH 1 - PROGRESS: at 77.58% examples, 307938 words/s, in_qsize 9, out_qsize 2
INFO - 2023-11-27 13:23:27,508: EPOCH 1: training on 412480 raw words (403278 effective words) took 1.1s, 357932 effective words/s
INFO - 2023-11-27 13:23:28,566: EPOCH 2 - PROGRESS: at 100.00% examples, 382393 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:28,566: EPOCH 2: training on 412480 raw words (403325 effective words) took 1.1s, 382311 effective words/s
INFO - 2023-11-27 13:23:29,660: EPOCH 3 - PROGRESS: at 100.00% examples, 369317 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:29,661: EPOCH 3: training on 412480 raw words (403272 effective words) took 1.1s, 369236 effective words/s
INFO - 2023-11-27 13:23:30,663: EPOCH 4 - PROGRESS: at 97.58% examples, 393327 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:23:30,782: EPOCH 4: training on 412480 raw words (403354 effective words) took 1.1s, 360348 effective words/s
INFO - 2023-11-27 13:23:31,785: EPOCH 5 - PROGRESS: at 95.15% examples, 383643 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:23:31,877: EPOCH 5: training on 412480 raw words (403287 effective words) took 1.1s, 369167 effective words/s
INFO - 2023-11-27 13:23:32,999: EPOCH 6 - PROGRESS: at 100.00% examples, 360661 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:32,999: EPOCH 6: training on 412480 raw words (403318 effective words) took 1.1s, 360581 effective words/s
INFO - 2023-11-27 13:23:34,085: EPOCH 7 - PROGRESS: at 100.00% examples, 372287 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:34,086: EPOCH 7: training on 412480 raw words (403322 effective words) took 1.1s, 372117 effective words/s
INFO - 2023-11-27 13:23:35,108: EPOCH 8 - PROGRESS: at 82.43% examples, 326257 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:23:35,246: EPOCH 8: training on 412480 raw words (403329 effective words) took 1.2s, 348562 effective words/s
INFO - 2023-11-27 13:23:36,305: EPOCH 9 - PROGRESS: at 100.00% examples, 381730 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:36,305: EPOCH 9: training on 412480 raw words (403295 effective words) took 1.1s, 381642 effective words/s
INFO - 2023-11-27 13:23:37,308: EPOCH 10 - PROGRESS: at 95.15% examples, 383612 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:23:37,391: EPOCH 10: training on 412480 raw words (403265 effective words) took 1.1s, 372158 effective words/s
INFO - 2023-11-27 13:23:38,398: EPOCH 11 - PROGRESS: at 92.73% examples, 372541 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:23:38,518: EPOCH 11: training on 412480 raw words (403374 effective words) took 1.1s, 358878 effective words/s
INFO - 2023-11-27 13:23:39,609: EPOCH 12 - PROGRESS: at 100.00% examples, 370676 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:39,609: EPOCH 12: training on 412480 raw words (403233 effective words) took 1.1s, 370593 effective words/s
INFO - 2023-11-27 13:23:40,685: EPOCH 13 - PROGRESS: at 100.00% examples, 375523 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:40,685: EPOCH 13: training on 412480 raw words (403406 effective words) took 1.1s, 375441 effective words/s
INFO - 2023-11-27 13:23:41,697: EPOCH 14 - PROGRESS: at 80.00% examples, 319829 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:23:41,845: EPOCH 14: training on 412480 raw words (403386 effective words) took 1.2s, 348814 effective words/s
INFO - 2023-11-27 13:23:42,862: EPOCH 15 - PROGRESS: at 84.85% examples, 337245 words/s, in_qsize 6, out_qsize 3
INFO - 2023-11-27 13:23:42,957: EPOCH 15: training on 412480 raw words (403362 effective words) took 1.1s, 363647 effective words/s
INFO - 2023-11-27 13:23:43,961: EPOCH 16 - PROGRESS: at 82.43% examples, 332062 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:23:44,117: EPOCH 16: training on 412480 raw words (403458 effective words) took 1.2s, 348691 effective words/s
INFO - 2023-11-27 13:23:45,120: EPOCH 17 - PROGRESS: at 87.28% examples, 351752 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:23:45,174: EPOCH 17: training on 412480 raw words (403342 effective words) took 1.1s, 382478 effective words/s
INFO - 2023-11-27 13:23:46,235: EPOCH 18 - PROGRESS: at 100.00% examples, 386137 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:46,235: EPOCH 18: training on 412480 raw words (403275 effective words) took 1.0s, 386050 effective words/s
INFO - 2023-11-27 13:23:47,336: EPOCH 19 - PROGRESS: at 100.00% examples, 367206 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:47,336: EPOCH 19: training on 412480 raw words (403331 effective words) took 1.1s, 367125 effective words/s
INFO - 2023-11-27 13:23:47,336: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8066598 effective words) took 22.1s, 364768 effective words/s', 'datetime': '2023-11-27T13:23:47.336833', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:47,336: collecting all words and their counts
INFO - 2023-11-27 13:23:47,337: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:23:47,433: PROGRESS: at sentence #10000, processed 400000 words, keeping 10297 word types
INFO - 2023-11-27 13:23:47,436: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:23:47,436: Updating model with new vocabulary
INFO - 2023-11-27 13:23:47,477: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:23:47.477355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:47,528: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:23:47,528: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:23:47,529: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403734.3352654248 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:23:47.529022', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:23:47,601: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:23:47,601: updating layer weights
INFO - 2023-11-27 13:23:47,602: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:23:47.602062', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:23:47,602: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:23:47,602: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:23:47.602341', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:23:48,672: EPOCH 0 - PROGRESS: at 100.00% examples, 378589 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:48,672: EPOCH 0: training on 412480 raw words (403828 effective words) took 1.1s, 378504 effective words/s
INFO - 2023-11-27 13:23:49,682: EPOCH 1 - PROGRESS: at 80.00% examples, 320688 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:23:49,840: EPOCH 1: training on 412480 raw words (403871 effective words) took 1.2s, 346691 effective words/s
INFO - 2023-11-27 13:23:50,898: EPOCH 2 - PROGRESS: at 100.00% examples, 382622 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:50,898: EPOCH 2: training on 412480 raw words (403757 effective words) took 1.1s, 382536 effective words/s
INFO - 2023-11-27 13:23:51,969: EPOCH 3 - PROGRESS: at 100.00% examples, 377702 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:51,969: EPOCH 3: training on 412480 raw words (403584 effective words) took 1.1s, 377609 effective words/s
INFO - 2023-11-27 13:23:53,013: EPOCH 4 - PROGRESS: at 100.00% examples, 388170 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:53,013: EPOCH 4: training on 412480 raw words (403708 effective words) took 1.0s, 388074 effective words/s
INFO - 2023-11-27 13:23:54,105: EPOCH 5 - PROGRESS: at 100.00% examples, 370661 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:54,105: EPOCH 5: training on 412480 raw words (403681 effective words) took 1.1s, 370559 effective words/s
INFO - 2023-11-27 13:23:55,175: EPOCH 6 - PROGRESS: at 100.00% examples, 378154 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:55,175: EPOCH 6: training on 412480 raw words (403662 effective words) took 1.1s, 378075 effective words/s
INFO - 2023-11-27 13:23:56,221: EPOCH 7 - PROGRESS: at 100.00% examples, 387081 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:56,222: EPOCH 7: training on 412480 raw words (403929 effective words) took 1.0s, 387000 effective words/s
INFO - 2023-11-27 13:23:57,287: EPOCH 8 - PROGRESS: at 77.58% examples, 294593 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:23:57,389: EPOCH 8: training on 412480 raw words (403691 effective words) took 1.2s, 346577 effective words/s
INFO - 2023-11-27 13:23:58,450: EPOCH 9 - PROGRESS: at 100.00% examples, 381402 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:58,451: EPOCH 9: training on 412480 raw words (403659 effective words) took 1.1s, 381297 effective words/s
INFO - 2023-11-27 13:23:59,499: EPOCH 10 - PROGRESS: at 100.00% examples, 386009 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:23:59,500: EPOCH 10: training on 412480 raw words (403731 effective words) took 1.0s, 385911 effective words/s
INFO - 2023-11-27 13:24:00,583: EPOCH 11 - PROGRESS: at 100.00% examples, 378850 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:00,583: EPOCH 11: training on 412480 raw words (403804 effective words) took 1.1s, 378765 effective words/s
INFO - 2023-11-27 13:24:01,618: EPOCH 12 - PROGRESS: at 100.00% examples, 391110 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:01,618: EPOCH 12: training on 412480 raw words (403651 effective words) took 1.0s, 390999 effective words/s
INFO - 2023-11-27 13:24:02,663: EPOCH 13 - PROGRESS: at 100.00% examples, 387575 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:02,663: EPOCH 13: training on 412480 raw words (403835 effective words) took 1.0s, 387485 effective words/s
INFO - 2023-11-27 13:24:03,707: EPOCH 14 - PROGRESS: at 100.00% examples, 387695 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:03,707: EPOCH 14: training on 412480 raw words (403701 effective words) took 1.0s, 387604 effective words/s
INFO - 2023-11-27 13:24:04,787: EPOCH 15 - PROGRESS: at 100.00% examples, 374278 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:04,788: EPOCH 15: training on 412480 raw words (403582 effective words) took 1.1s, 374193 effective words/s
INFO - 2023-11-27 13:24:05,849: EPOCH 16 - PROGRESS: at 100.00% examples, 381120 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:05,850: EPOCH 16: training on 412480 raw words (403729 effective words) took 1.1s, 381029 effective words/s
INFO - 2023-11-27 13:24:06,926: EPOCH 17 - PROGRESS: at 100.00% examples, 376032 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:06,926: EPOCH 17: training on 412480 raw words (403738 effective words) took 1.1s, 375944 effective words/s
INFO - 2023-11-27 13:24:07,929: EPOCH 18 - PROGRESS: at 95.15% examples, 383988 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:24:08,019: EPOCH 18: training on 412480 raw words (403733 effective words) took 1.1s, 370143 effective words/s
INFO - 2023-11-27 13:24:09,104: EPOCH 19 - PROGRESS: at 100.00% examples, 373251 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:09,105: EPOCH 19: training on 412480 raw words (403814 effective words) took 1.1s, 373166 effective words/s
INFO - 2023-11-27 13:24:09,105: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074688 effective words) took 21.5s, 375517 effective words/s', 'datetime': '2023-11-27T13:24:09.105332', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:09,105: collecting all words and their counts
INFO - 2023-11-27 13:24:09,105: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:24:09,197: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:24:09,200: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:24:09,200: Updating model with new vocabulary
INFO - 2023-11-27 13:24:09,233: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:24:09.233761', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:09,281: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:24:09,281: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:24:09,281: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403662.42938638874 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:24:09.281640', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:09,354: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:24:09,355: updating layer weights
INFO - 2023-11-27 13:24:09,355: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:24:09.355728', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:24:09,355: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:24:09,356: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:24:09.356021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:10,382: EPOCH 0 - PROGRESS: at 100.00% examples, 394453 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:10,382: EPOCH 0: training on 412480 raw words (403757 effective words) took 1.0s, 394324 effective words/s
INFO - 2023-11-27 13:24:11,312: EPOCH 1: training on 412480 raw words (403659 effective words) took 0.9s, 435337 effective words/s
INFO - 2023-11-27 13:24:12,192: EPOCH 2: training on 412480 raw words (403690 effective words) took 0.9s, 459855 effective words/s
INFO - 2023-11-27 13:24:13,086: EPOCH 3: training on 412480 raw words (403578 effective words) took 0.9s, 452106 effective words/s
INFO - 2023-11-27 13:24:13,989: EPOCH 4: training on 412480 raw words (403695 effective words) took 0.9s, 448369 effective words/s
INFO - 2023-11-27 13:24:14,906: EPOCH 5: training on 412480 raw words (403581 effective words) took 0.9s, 440884 effective words/s
INFO - 2023-11-27 13:24:15,870: EPOCH 6: training on 412480 raw words (403618 effective words) took 1.0s, 419793 effective words/s
INFO - 2023-11-27 13:24:16,770: EPOCH 7: training on 412480 raw words (403598 effective words) took 0.9s, 449739 effective words/s
INFO - 2023-11-27 13:24:17,643: EPOCH 8: training on 412480 raw words (403853 effective words) took 0.9s, 463265 effective words/s
INFO - 2023-11-27 13:24:18,489: EPOCH 9: training on 412480 raw words (403741 effective words) took 0.8s, 478456 effective words/s
INFO - 2023-11-27 13:24:19,412: EPOCH 10: training on 412480 raw words (403714 effective words) took 0.9s, 443447 effective words/s
INFO - 2023-11-27 13:24:20,317: EPOCH 11: training on 412480 raw words (403708 effective words) took 0.9s, 447648 effective words/s
INFO - 2023-11-27 13:24:21,168: EPOCH 12: training on 412480 raw words (403459 effective words) took 0.8s, 475101 effective words/s
INFO - 2023-11-27 13:24:22,030: EPOCH 13: training on 412480 raw words (403759 effective words) took 0.9s, 469679 effective words/s
INFO - 2023-11-27 13:24:22,904: EPOCH 14: training on 412480 raw words (403644 effective words) took 0.9s, 462555 effective words/s
INFO - 2023-11-27 13:24:23,803: EPOCH 15: training on 412480 raw words (403761 effective words) took 0.9s, 450409 effective words/s
INFO - 2023-11-27 13:24:24,673: EPOCH 16: training on 412480 raw words (403657 effective words) took 0.9s, 465204 effective words/s
INFO - 2023-11-27 13:24:25,539: EPOCH 17: training on 412480 raw words (403757 effective words) took 0.9s, 467354 effective words/s
INFO - 2023-11-27 13:24:26,548: EPOCH 18 - PROGRESS: at 100.00% examples, 401340 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:26,548: EPOCH 18: training on 412480 raw words (403739 effective words) took 1.0s, 401252 effective words/s
INFO - 2023-11-27 13:24:27,570: EPOCH 19 - PROGRESS: at 80.00% examples, 316841 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:24:27,717: EPOCH 19: training on 412480 raw words (403725 effective words) took 1.2s, 345897 effective words/s
INFO - 2023-11-27 13:24:27,718: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073693 effective words) took 18.4s, 439695 effective words/s', 'datetime': '2023-11-27T13:24:27.718181', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:27,718: collecting all words and their counts
INFO - 2023-11-27 13:24:27,718: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:24:27,806: PROGRESS: at sentence #10000, processed 400000 words, keeping 10305 word types
INFO - 2023-11-27 13:24:27,810: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:24:27,810: Updating model with new vocabulary
INFO - 2023-11-27 13:24:27,850: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:24:27.850784', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:27,913: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:24:27,913: sample=0.001 downsamples 26 most-common words
INFO - 2023-11-27 13:24:27,913: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403582.0771455726 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:24:27.913446', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:27,993: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:24:27,993: updating layer weights
INFO - 2023-11-27 13:24:27,994: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:24:27.994550', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:24:27,994: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:24:27,994: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:24:27.994750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:29,004: EPOCH 0 - PROGRESS: at 87.28% examples, 349575 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:24:29,131: EPOCH 0: training on 412480 raw words (403497 effective words) took 1.1s, 355646 effective words/s
INFO - 2023-11-27 13:24:30,173: EPOCH 1 - PROGRESS: at 75.16% examples, 291722 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:24:30,377: EPOCH 1: training on 412480 raw words (403646 effective words) took 1.2s, 324545 effective words/s
INFO - 2023-11-27 13:24:31,424: EPOCH 2 - PROGRESS: at 77.58% examples, 308694 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:24:31,576: EPOCH 2: training on 412480 raw words (403625 effective words) took 1.2s, 345995 effective words/s
INFO - 2023-11-27 13:24:32,635: EPOCH 3 - PROGRESS: at 75.16% examples, 287038 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:24:32,832: EPOCH 3: training on 412480 raw words (403732 effective words) took 1.3s, 322008 effective words/s
INFO - 2023-11-27 13:24:33,932: EPOCH 4 - PROGRESS: at 75.16% examples, 276854 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:24:34,132: EPOCH 4: training on 412480 raw words (403685 effective words) took 1.3s, 311607 effective words/s
INFO - 2023-11-27 13:24:35,194: EPOCH 5 - PROGRESS: at 75.16% examples, 286459 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:24:35,389: EPOCH 5: training on 412480 raw words (403597 effective words) took 1.3s, 322014 effective words/s
INFO - 2023-11-27 13:24:36,414: EPOCH 6 - PROGRESS: at 77.58% examples, 306021 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:24:36,550: EPOCH 6: training on 412480 raw words (403440 effective words) took 1.2s, 348160 effective words/s
INFO - 2023-11-27 13:24:37,564: EPOCH 7 - PROGRESS: at 72.73% examples, 290344 words/s, in_qsize 12, out_qsize 0
INFO - 2023-11-27 13:24:37,825: EPOCH 7: training on 412480 raw words (403642 effective words) took 1.3s, 317265 effective words/s
INFO - 2023-11-27 13:24:38,744: EPOCH 8: training on 412480 raw words (403581 effective words) took 0.9s, 440605 effective words/s
INFO - 2023-11-27 13:24:39,620: EPOCH 9: training on 412480 raw words (403539 effective words) took 0.9s, 461656 effective words/s
INFO - 2023-11-27 13:24:40,522: EPOCH 10: training on 412480 raw words (403560 effective words) took 0.9s, 448818 effective words/s
INFO - 2023-11-27 13:24:41,426: EPOCH 11: training on 412480 raw words (403703 effective words) took 0.9s, 447467 effective words/s
INFO - 2023-11-27 13:24:42,339: EPOCH 12: training on 412480 raw words (403666 effective words) took 0.9s, 452582 effective words/s
INFO - 2023-11-27 13:24:43,273: EPOCH 13: training on 412480 raw words (403636 effective words) took 0.9s, 433223 effective words/s
INFO - 2023-11-27 13:24:44,118: EPOCH 14: training on 412480 raw words (403615 effective words) took 0.8s, 479096 effective words/s
INFO - 2023-11-27 13:24:44,922: EPOCH 15: training on 412480 raw words (403546 effective words) took 0.8s, 502815 effective words/s
INFO - 2023-11-27 13:24:45,773: EPOCH 16: training on 412480 raw words (403727 effective words) took 0.8s, 475555 effective words/s
INFO - 2023-11-27 13:24:46,605: EPOCH 17: training on 412480 raw words (403566 effective words) took 0.8s, 495447 effective words/s
INFO - 2023-11-27 13:24:47,487: EPOCH 18: training on 412480 raw words (403483 effective words) took 0.9s, 458621 effective words/s
INFO - 2023-11-27 13:24:48,295: EPOCH 19: training on 412480 raw words (403640 effective words) took 0.8s, 501037 effective words/s
INFO - 2023-11-27 13:24:48,295: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072126 effective words) took 20.3s, 397633 effective words/s', 'datetime': '2023-11-27T13:24:48.295285', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:48,295: collecting all words and their counts
INFO - 2023-11-27 13:24:48,295: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:24:48,353: PROGRESS: at sentence #10000, processed 400000 words, keeping 10305 word types
INFO - 2023-11-27 13:24:48,355: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:24:48,355: Updating model with new vocabulary
INFO - 2023-11-27 13:24:48,380: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:24:48.380817', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:48,413: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:24:48,413: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:24:48,413: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403501.4882329973 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:24:48.413956', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:24:48,466: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:24:48,467: updating layer weights
INFO - 2023-11-27 13:24:48,467: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:24:48.467569', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:24:48,467: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:24:48,467: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:24:48.467725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:24:49,378: EPOCH 0: training on 412480 raw words (403465 effective words) took 0.9s, 444013 effective words/s
INFO - 2023-11-27 13:24:50,274: EPOCH 1: training on 412480 raw words (403537 effective words) took 0.9s, 450871 effective words/s
INFO - 2023-11-27 13:24:51,154: EPOCH 2: training on 412480 raw words (403478 effective words) took 0.9s, 459812 effective words/s
INFO - 2023-11-27 13:24:52,052: EPOCH 3: training on 412480 raw words (403509 effective words) took 0.9s, 450885 effective words/s
INFO - 2023-11-27 13:24:52,947: EPOCH 4: training on 412480 raw words (403481 effective words) took 0.9s, 451733 effective words/s
INFO - 2023-11-27 13:24:54,022: EPOCH 5 - PROGRESS: at 100.00% examples, 375970 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:24:54,022: EPOCH 5: training on 412480 raw words (403447 effective words) took 1.1s, 375882 effective words/s
INFO - 2023-11-27 13:24:55,053: EPOCH 6 - PROGRESS: at 80.00% examples, 319111 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:24:55,185: EPOCH 6: training on 412480 raw words (403499 effective words) took 1.1s, 352944 effective words/s
INFO - 2023-11-27 13:24:56,189: EPOCH 7 - PROGRESS: at 87.28% examples, 351442 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:24:56,312: EPOCH 7: training on 412480 raw words (403294 effective words) took 1.1s, 358588 effective words/s
INFO - 2023-11-27 13:24:57,332: EPOCH 8 - PROGRESS: at 77.58% examples, 307560 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:24:57,486: EPOCH 8: training on 412480 raw words (403576 effective words) took 1.2s, 344493 effective words/s
INFO - 2023-11-27 13:24:58,493: EPOCH 9 - PROGRESS: at 75.16% examples, 301909 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:24:58,685: EPOCH 9: training on 412480 raw words (403515 effective words) took 1.2s, 337089 effective words/s
INFO - 2023-11-27 13:24:59,691: EPOCH 10 - PROGRESS: at 97.58% examples, 392711 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:24:59,758: EPOCH 10: training on 412480 raw words (403493 effective words) took 1.1s, 377218 effective words/s
INFO - 2023-11-27 13:25:00,627: EPOCH 11: training on 412480 raw words (403478 effective words) took 0.9s, 464819 effective words/s
INFO - 2023-11-27 13:25:01,519: EPOCH 12: training on 412480 raw words (403536 effective words) took 0.9s, 453874 effective words/s
INFO - 2023-11-27 13:25:02,354: EPOCH 13: training on 412480 raw words (403426 effective words) took 0.8s, 484218 effective words/s
INFO - 2023-11-27 13:25:03,249: EPOCH 14: training on 412480 raw words (403484 effective words) took 0.9s, 451559 effective words/s
INFO - 2023-11-27 13:25:04,138: EPOCH 15: training on 412480 raw words (403506 effective words) took 0.9s, 455459 effective words/s
INFO - 2023-11-27 13:25:05,029: EPOCH 16: training on 412480 raw words (403490 effective words) took 0.9s, 453634 effective words/s
INFO - 2023-11-27 13:25:05,930: EPOCH 17: training on 412480 raw words (403485 effective words) took 0.9s, 448607 effective words/s
INFO - 2023-11-27 13:25:06,794: EPOCH 18: training on 412480 raw words (403318 effective words) took 0.9s, 468160 effective words/s
INFO - 2023-11-27 13:25:07,725: EPOCH 19: training on 412480 raw words (403541 effective words) took 0.9s, 434525 effective words/s
INFO - 2023-11-27 13:25:07,726: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8069558 effective words) took 19.3s, 419017 effective words/s', 'datetime': '2023-11-27T13:25:07.726133', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:07,726: collecting all words and their counts
INFO - 2023-11-27 13:25:07,726: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:25:07,786: PROGRESS: at sentence #10000, processed 400000 words, keeping 10294 word types
INFO - 2023-11-27 13:25:07,788: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:25:07,788: Updating model with new vocabulary
INFO - 2023-11-27 13:25:07,820: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:25:07.819952', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:07,851: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:25:07,851: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:25:07,851: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403552.82831022114 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:25:07.851360', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:07,906: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:25:07,907: updating layer weights
INFO - 2023-11-27 13:25:07,907: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:25:07.907631', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:25:07,907: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:25:07,907: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:25:07.907786', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:08,735: EPOCH 0: training on 412480 raw words (403644 effective words) took 0.8s, 489035 effective words/s
INFO - 2023-11-27 13:25:09,574: EPOCH 1: training on 412480 raw words (403633 effective words) took 0.8s, 481959 effective words/s
INFO - 2023-11-27 13:25:10,447: EPOCH 2: training on 412480 raw words (403490 effective words) took 0.9s, 463082 effective words/s
INFO - 2023-11-27 13:25:11,339: EPOCH 3: training on 412480 raw words (403649 effective words) took 0.9s, 453615 effective words/s
INFO - 2023-11-27 13:25:12,209: EPOCH 4: training on 412480 raw words (403421 effective words) took 0.9s, 464583 effective words/s
INFO - 2023-11-27 13:25:13,058: EPOCH 5: training on 412480 raw words (403680 effective words) took 0.8s, 476907 effective words/s
INFO - 2023-11-27 13:25:13,922: EPOCH 6: training on 412480 raw words (403588 effective words) took 0.9s, 468215 effective words/s
INFO - 2023-11-27 13:25:14,747: EPOCH 7: training on 412480 raw words (403436 effective words) took 0.8s, 490096 effective words/s
INFO - 2023-11-27 13:25:15,813: EPOCH 8 - PROGRESS: at 100.00% examples, 379097 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:15,814: EPOCH 8: training on 412480 raw words (403342 effective words) took 1.1s, 379012 effective words/s
INFO - 2023-11-27 13:25:16,901: EPOCH 9 - PROGRESS: at 100.00% examples, 372130 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:16,901: EPOCH 9: training on 412480 raw words (403573 effective words) took 1.1s, 372050 effective words/s
INFO - 2023-11-27 13:25:17,944: EPOCH 10 - PROGRESS: at 100.00% examples, 387622 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:17,944: EPOCH 10: training on 412480 raw words (403423 effective words) took 1.0s, 387533 effective words/s
INFO - 2023-11-27 13:25:18,949: EPOCH 11 - PROGRESS: at 89.70% examples, 361093 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:25:19,096: EPOCH 11: training on 412480 raw words (403481 effective words) took 1.1s, 351035 effective words/s
INFO - 2023-11-27 13:25:20,170: EPOCH 12 - PROGRESS: at 100.00% examples, 376823 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:20,170: EPOCH 12: training on 412480 raw words (403597 effective words) took 1.1s, 376737 effective words/s
INFO - 2023-11-27 13:25:21,173: EPOCH 13 - PROGRESS: at 92.13% examples, 371624 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:25:21,308: EPOCH 13: training on 412480 raw words (403638 effective words) took 1.1s, 355663 effective words/s
INFO - 2023-11-27 13:25:22,345: EPOCH 14 - PROGRESS: at 80.00% examples, 311982 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:25:22,480: EPOCH 14: training on 412480 raw words (403526 effective words) took 1.2s, 344898 effective words/s
INFO - 2023-11-27 13:25:23,485: EPOCH 15 - PROGRESS: at 82.43% examples, 332027 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:25:23,637: EPOCH 15: training on 412480 raw words (403547 effective words) took 1.2s, 349866 effective words/s
INFO - 2023-11-27 13:25:24,637: EPOCH 16: training on 412480 raw words (403477 effective words) took 1.0s, 404164 effective words/s
INFO - 2023-11-27 13:25:25,645: EPOCH 17 - PROGRESS: at 100.00% examples, 401917 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:25,645: EPOCH 17: training on 412480 raw words (403622 effective words) took 1.0s, 401819 effective words/s
INFO - 2023-11-27 13:25:26,595: EPOCH 18: training on 412480 raw words (403538 effective words) took 0.9s, 425709 effective words/s
INFO - 2023-11-27 13:25:27,576: EPOCH 19: training on 412480 raw words (403655 effective words) took 1.0s, 412733 effective words/s
INFO - 2023-11-27 13:25:27,576: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070960 effective words) took 19.7s, 410346 effective words/s', 'datetime': '2023-11-27T13:25:27.576558', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:27,576: collecting all words and their counts
INFO - 2023-11-27 13:25:27,576: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:25:27,672: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:25:27,675: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:25:27,675: Updating model with new vocabulary
INFO - 2023-11-27 13:25:27,715: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:25:27.715933', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:27,761: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:25:27,761: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:25:27,761: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403688.98440472595 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:25:27.761529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:27,831: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:25:27,831: updating layer weights
INFO - 2023-11-27 13:25:27,831: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:25:27.831870', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:25:27,832: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:25:27,832: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:25:27.832129', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:28,872: EPOCH 0 - PROGRESS: at 100.00% examples, 389032 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:28,872: EPOCH 0: training on 412480 raw words (403856 effective words) took 1.0s, 388934 effective words/s
INFO - 2023-11-27 13:25:29,880: EPOCH 1 - PROGRESS: at 97.58% examples, 391933 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:25:29,944: EPOCH 1: training on 412480 raw words (403636 effective words) took 1.1s, 377843 effective words/s
INFO - 2023-11-27 13:25:30,984: EPOCH 2 - PROGRESS: at 100.00% examples, 389145 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:30,984: EPOCH 2: training on 412480 raw words (403607 effective words) took 1.0s, 389056 effective words/s
INFO - 2023-11-27 13:25:32,006: EPOCH 3 - PROGRESS: at 82.43% examples, 326576 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:25:32,167: EPOCH 3: training on 412480 raw words (403742 effective words) took 1.2s, 342084 effective words/s
INFO - 2023-11-27 13:25:33,165: EPOCH 4: training on 412480 raw words (403526 effective words) took 1.0s, 405432 effective words/s
INFO - 2023-11-27 13:25:34,016: EPOCH 5: training on 412480 raw words (403548 effective words) took 0.8s, 475083 effective words/s
INFO - 2023-11-27 13:25:34,851: EPOCH 6: training on 412480 raw words (403749 effective words) took 0.8s, 484662 effective words/s
INFO - 2023-11-27 13:25:35,681: EPOCH 7: training on 412480 raw words (403786 effective words) took 0.8s, 487644 effective words/s
INFO - 2023-11-27 13:25:36,523: EPOCH 8: training on 412480 raw words (403497 effective words) took 0.8s, 480479 effective words/s
INFO - 2023-11-27 13:25:37,400: EPOCH 9: training on 412480 raw words (403654 effective words) took 0.9s, 461786 effective words/s
INFO - 2023-11-27 13:25:38,254: EPOCH 10: training on 412480 raw words (403805 effective words) took 0.9s, 473817 effective words/s
INFO - 2023-11-27 13:25:39,129: EPOCH 11: training on 412480 raw words (403628 effective words) took 0.9s, 462598 effective words/s
INFO - 2023-11-27 13:25:40,023: EPOCH 12: training on 412480 raw words (403723 effective words) took 0.9s, 452166 effective words/s
INFO - 2023-11-27 13:25:40,909: EPOCH 13: training on 412480 raw words (403738 effective words) took 0.9s, 457086 effective words/s
INFO - 2023-11-27 13:25:41,826: EPOCH 14: training on 412480 raw words (403654 effective words) took 0.9s, 440925 effective words/s
INFO - 2023-11-27 13:25:42,703: EPOCH 15: training on 412480 raw words (403661 effective words) took 0.9s, 461211 effective words/s
INFO - 2023-11-27 13:25:43,600: EPOCH 16: training on 412480 raw words (403744 effective words) took 0.9s, 451532 effective words/s
INFO - 2023-11-27 13:25:44,526: EPOCH 17: training on 412480 raw words (403644 effective words) took 0.9s, 447421 effective words/s
INFO - 2023-11-27 13:25:45,422: EPOCH 18: training on 412480 raw words (403674 effective words) took 0.9s, 451582 effective words/s
INFO - 2023-11-27 13:25:46,294: EPOCH 19: training on 412480 raw words (403719 effective words) took 0.9s, 463936 effective words/s
INFO - 2023-11-27 13:25:46,295: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073591 effective words) took 18.5s, 437290 effective words/s', 'datetime': '2023-11-27T13:25:46.294978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:46,295: collecting all words and their counts
INFO - 2023-11-27 13:25:46,295: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:25:46,352: PROGRESS: at sentence #10000, processed 400000 words, keeping 10298 word types
INFO - 2023-11-27 13:25:46,354: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:25:46,354: Updating model with new vocabulary
INFO - 2023-11-27 13:25:46,381: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:25:46.381557', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:46,413: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:25:46,413: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:25:46,413: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403654.59792083903 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:25:46.413659', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:25:46,464: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:25:46,464: updating layer weights
INFO - 2023-11-27 13:25:46,465: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:25:46.465409', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:25:46,465: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:25:46,465: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:25:46.465559', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:25:47,412: EPOCH 0: training on 412480 raw words (403773 effective words) took 0.9s, 427319 effective words/s
INFO - 2023-11-27 13:25:48,480: EPOCH 1 - PROGRESS: at 100.00% examples, 379258 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:25:48,480: EPOCH 1: training on 412480 raw words (403523 effective words) took 1.1s, 379178 effective words/s
INFO - 2023-11-27 13:25:49,485: EPOCH 2 - PROGRESS: at 95.15% examples, 383311 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:25:49,579: EPOCH 2: training on 412480 raw words (403640 effective words) took 1.1s, 368140 effective words/s
INFO - 2023-11-27 13:25:50,586: EPOCH 3 - PROGRESS: at 89.70% examples, 360369 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:25:50,723: EPOCH 3: training on 412480 raw words (403668 effective words) took 1.1s, 353487 effective words/s
INFO - 2023-11-27 13:25:51,728: EPOCH 4 - PROGRESS: at 92.73% examples, 373691 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:25:51,841: EPOCH 4: training on 412480 raw words (403744 effective words) took 1.1s, 362034 effective words/s
INFO - 2023-11-27 13:25:52,849: EPOCH 5 - PROGRESS: at 95.15% examples, 382251 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:25:52,906: EPOCH 5: training on 412480 raw words (403727 effective words) took 1.1s, 380246 effective words/s
INFO - 2023-11-27 13:25:53,913: EPOCH 6 - PROGRESS: at 75.16% examples, 301831 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:25:54,122: EPOCH 6: training on 412480 raw words (403653 effective words) took 1.2s, 332396 effective words/s
INFO - 2023-11-27 13:25:55,148: EPOCH 7 - PROGRESS: at 87.28% examples, 351291 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:25:55,267: EPOCH 7: training on 412480 raw words (403698 effective words) took 1.1s, 359774 effective words/s
INFO - 2023-11-27 13:25:56,273: EPOCH 8 - PROGRESS: at 87.28% examples, 351497 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:25:56,375: EPOCH 8: training on 412480 raw words (403604 effective words) took 1.1s, 365329 effective words/s
INFO - 2023-11-27 13:25:57,281: EPOCH 9: training on 412480 raw words (403627 effective words) took 0.9s, 446820 effective words/s
INFO - 2023-11-27 13:25:58,121: EPOCH 10: training on 412480 raw words (403691 effective words) took 0.8s, 481715 effective words/s
INFO - 2023-11-27 13:25:59,045: EPOCH 11: training on 412480 raw words (403581 effective words) took 0.9s, 437557 effective words/s
INFO - 2023-11-27 13:25:59,929: EPOCH 12: training on 412480 raw words (403699 effective words) took 0.9s, 458099 effective words/s
INFO - 2023-11-27 13:26:00,766: EPOCH 13: training on 412480 raw words (403741 effective words) took 0.8s, 483544 effective words/s
INFO - 2023-11-27 13:26:01,694: EPOCH 14: training on 412480 raw words (403626 effective words) took 0.9s, 435597 effective words/s
INFO - 2023-11-27 13:26:02,611: EPOCH 15: training on 412480 raw words (403761 effective words) took 0.9s, 441718 effective words/s
INFO - 2023-11-27 13:26:03,514: EPOCH 16: training on 412480 raw words (403634 effective words) took 0.9s, 447995 effective words/s
INFO - 2023-11-27 13:26:04,350: EPOCH 17: training on 412480 raw words (403638 effective words) took 0.8s, 484155 effective words/s
INFO - 2023-11-27 13:26:05,221: EPOCH 18: training on 412480 raw words (403603 effective words) took 0.9s, 464507 effective words/s
INFO - 2023-11-27 13:26:06,076: EPOCH 19: training on 412480 raw words (403758 effective words) took 0.9s, 473298 effective words/s
INFO - 2023-11-27 13:26:06,076: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8073389 effective words) took 19.6s, 411674 effective words/s', 'datetime': '2023-11-27T13:26:06.076754', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:06,076: collecting all words and their counts
INFO - 2023-11-27 13:26:06,077: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:26:06,136: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:26:06,138: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:26:06,138: Updating model with new vocabulary
INFO - 2023-11-27 13:26:06,163: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:26:06.163462', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:06,202: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:26:06,203: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:26:06,203: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403516.016527221 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:26:06.203295', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:06,252: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:26:06,253: updating layer weights
INFO - 2023-11-27 13:26:06,253: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:26:06.253628', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:26:06,253: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:26:06,253: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:26:06.253911', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:07,099: EPOCH 0: training on 412480 raw words (403556 effective words) took 0.8s, 478334 effective words/s
INFO - 2023-11-27 13:26:07,991: EPOCH 1: training on 412480 raw words (403490 effective words) took 0.9s, 453512 effective words/s
INFO - 2023-11-27 13:26:08,912: EPOCH 2: training on 412480 raw words (403550 effective words) took 0.9s, 438927 effective words/s
INFO - 2023-11-27 13:26:09,793: EPOCH 3: training on 412480 raw words (403625 effective words) took 0.9s, 469840 effective words/s
INFO - 2023-11-27 13:26:10,701: EPOCH 4: training on 412480 raw words (403461 effective words) took 0.9s, 444974 effective words/s
INFO - 2023-11-27 13:26:11,666: EPOCH 5: training on 412480 raw words (403567 effective words) took 1.0s, 419234 effective words/s
INFO - 2023-11-27 13:26:12,760: EPOCH 6 - PROGRESS: at 100.00% examples, 369899 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:26:12,760: EPOCH 6: training on 412480 raw words (403475 effective words) took 1.1s, 369829 effective words/s
INFO - 2023-11-27 13:26:13,763: EPOCH 7 - PROGRESS: at 89.70% examples, 361636 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:26:13,904: EPOCH 7: training on 412480 raw words (403529 effective words) took 1.1s, 353523 effective words/s
INFO - 2023-11-27 13:26:14,912: EPOCH 8 - PROGRESS: at 82.43% examples, 330695 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:26:15,036: EPOCH 8: training on 412480 raw words (403447 effective words) took 1.1s, 357074 effective words/s
INFO - 2023-11-27 13:26:16,040: EPOCH 9 - PROGRESS: at 84.85% examples, 342050 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:26:16,191: EPOCH 9: training on 412480 raw words (403589 effective words) took 1.2s, 350138 effective words/s
INFO - 2023-11-27 13:26:17,195: EPOCH 10 - PROGRESS: at 77.58% examples, 312685 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:26:17,350: EPOCH 10: training on 412480 raw words (403628 effective words) took 1.2s, 349079 effective words/s
INFO - 2023-11-27 13:26:18,492: EPOCH 11 - PROGRESS: at 75.16% examples, 266215 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:26:18,680: EPOCH 11: training on 412480 raw words (403628 effective words) took 1.3s, 303979 effective words/s
INFO - 2023-11-27 13:26:19,749: EPOCH 12 - PROGRESS: at 77.58% examples, 293719 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:26:19,862: EPOCH 12: training on 412480 raw words (403503 effective words) took 1.2s, 342187 effective words/s
INFO - 2023-11-27 13:26:20,782: EPOCH 13: training on 412480 raw words (403380 effective words) took 0.9s, 439740 effective words/s
INFO - 2023-11-27 13:26:21,711: EPOCH 14: training on 412480 raw words (403515 effective words) took 0.9s, 435209 effective words/s
INFO - 2023-11-27 13:26:22,573: EPOCH 15: training on 412480 raw words (403698 effective words) took 0.9s, 469432 effective words/s
INFO - 2023-11-27 13:26:23,468: EPOCH 16: training on 412480 raw words (403576 effective words) took 0.9s, 452173 effective words/s
INFO - 2023-11-27 13:26:24,501: EPOCH 17 - PROGRESS: at 100.00% examples, 391009 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:26:24,502: EPOCH 17: training on 412480 raw words (403483 effective words) took 1.0s, 390936 effective words/s
INFO - 2023-11-27 13:26:25,364: EPOCH 18: training on 412480 raw words (403458 effective words) took 0.9s, 468831 effective words/s
INFO - 2023-11-27 13:26:26,246: EPOCH 19: training on 412480 raw words (403363 effective words) took 0.9s, 458589 effective words/s
INFO - 2023-11-27 13:26:26,246: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070521 effective words) took 20.0s, 403681 effective words/s', 'datetime': '2023-11-27T13:26:26.246349', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:26,246: collecting all words and their counts
INFO - 2023-11-27 13:26:26,246: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:26:26,304: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:26:26,306: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:26:26,306: Updating model with new vocabulary
INFO - 2023-11-27 13:26:26,340: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:26:26.340064', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:26,370: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:26:26,370: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:26:26,370: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403770.9760553919 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:26:26.370644', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:26,424: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:26:26,425: updating layer weights
INFO - 2023-11-27 13:26:26,425: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:26:26.425589', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:26:26,425: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:26:26,425: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:26:26.425744', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:27,304: EPOCH 0: training on 412480 raw words (403902 effective words) took 0.9s, 460444 effective words/s
INFO - 2023-11-27 13:26:28,249: EPOCH 1: training on 412480 raw words (403882 effective words) took 0.9s, 428639 effective words/s
INFO - 2023-11-27 13:26:29,219: EPOCH 2: training on 412480 raw words (403807 effective words) took 1.0s, 417018 effective words/s
INFO - 2023-11-27 13:26:30,132: EPOCH 3: training on 412480 raw words (403884 effective words) took 0.9s, 444578 effective words/s
INFO - 2023-11-27 13:26:31,079: EPOCH 4: training on 412480 raw words (403636 effective words) took 0.9s, 426822 effective words/s
INFO - 2023-11-27 13:26:31,981: EPOCH 5: training on 412480 raw words (403834 effective words) took 0.9s, 448626 effective words/s
INFO - 2023-11-27 13:26:32,928: EPOCH 6: training on 412480 raw words (403834 effective words) took 0.9s, 427643 effective words/s
INFO - 2023-11-27 13:26:33,815: EPOCH 7: training on 412480 raw words (403900 effective words) took 0.9s, 456235 effective words/s
INFO - 2023-11-27 13:26:34,745: EPOCH 8: training on 412480 raw words (403802 effective words) took 0.9s, 435076 effective words/s
INFO - 2023-11-27 13:26:35,688: EPOCH 9: training on 412480 raw words (403919 effective words) took 0.9s, 429367 effective words/s
INFO - 2023-11-27 13:26:36,713: EPOCH 10 - PROGRESS: at 80.00% examples, 316091 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:26:36,836: EPOCH 10: training on 412480 raw words (403718 effective words) took 1.1s, 352656 effective words/s
INFO - 2023-11-27 13:26:37,848: EPOCH 11 - PROGRESS: at 77.58% examples, 310460 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:26:38,013: EPOCH 11: training on 412480 raw words (403812 effective words) took 1.2s, 344010 effective words/s
INFO - 2023-11-27 13:26:39,020: EPOCH 12 - PROGRESS: at 80.00% examples, 321853 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:26:39,189: EPOCH 12: training on 412480 raw words (403905 effective words) took 1.2s, 344370 effective words/s
INFO - 2023-11-27 13:26:40,237: EPOCH 13 - PROGRESS: at 75.16% examples, 290435 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:26:40,440: EPOCH 13: training on 412480 raw words (403940 effective words) took 1.2s, 323473 effective words/s
INFO - 2023-11-27 13:26:41,459: EPOCH 14 - PROGRESS: at 75.16% examples, 298759 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:26:41,667: EPOCH 14: training on 412480 raw words (403751 effective words) took 1.2s, 330031 effective words/s
INFO - 2023-11-27 13:26:42,738: EPOCH 15 - PROGRESS: at 75.16% examples, 284028 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:26:42,935: EPOCH 15: training on 412480 raw words (403767 effective words) took 1.3s, 319006 effective words/s
INFO - 2023-11-27 13:26:44,040: EPOCH 16 - PROGRESS: at 75.16% examples, 275315 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:26:44,271: EPOCH 16: training on 412480 raw words (403863 effective words) took 1.3s, 302886 effective words/s
INFO - 2023-11-27 13:26:45,333: EPOCH 17 - PROGRESS: at 100.00% examples, 381295 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:26:45,333: EPOCH 17: training on 412480 raw words (403741 effective words) took 1.1s, 381206 effective words/s
INFO - 2023-11-27 13:26:46,332: EPOCH 18: training on 412480 raw words (403748 effective words) took 1.0s, 405138 effective words/s
INFO - 2023-11-27 13:26:47,186: EPOCH 19: training on 412480 raw words (403759 effective words) took 0.9s, 474812 effective words/s
INFO - 2023-11-27 13:26:47,186: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8076404 effective words) took 20.8s, 389027 effective words/s', 'datetime': '2023-11-27T13:26:47.186298', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:47,186: collecting all words and their counts
INFO - 2023-11-27 13:26:47,186: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:26:47,246: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:26:47,248: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:26:47,248: Updating model with new vocabulary
INFO - 2023-11-27 13:26:47,279: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:26:47.279893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:47,320: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:26:47,320: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:26:47,320: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403817.71317331167 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:26:47.320887', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:26:47,369: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:26:47,369: updating layer weights
INFO - 2023-11-27 13:26:47,369: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:26:47.369752', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:26:47,369: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:26:47,369: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:26:47.369919', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:26:48,249: EPOCH 0: training on 412480 raw words (403824 effective words) took 0.9s, 460035 effective words/s
INFO - 2023-11-27 13:26:49,096: EPOCH 1: training on 412480 raw words (403747 effective words) took 0.8s, 477709 effective words/s
INFO - 2023-11-27 13:26:49,956: EPOCH 2: training on 412480 raw words (403925 effective words) took 0.9s, 471050 effective words/s
INFO - 2023-11-27 13:26:50,840: EPOCH 3: training on 412480 raw words (403971 effective words) took 0.9s, 457855 effective words/s
INFO - 2023-11-27 13:26:51,736: EPOCH 4: training on 412480 raw words (403853 effective words) took 0.9s, 451787 effective words/s
INFO - 2023-11-27 13:26:52,607: EPOCH 5: training on 412480 raw words (403868 effective words) took 0.9s, 464486 effective words/s
INFO - 2023-11-27 13:26:53,567: EPOCH 6: training on 412480 raw words (403820 effective words) took 1.0s, 421679 effective words/s
INFO - 2023-11-27 13:26:54,477: EPOCH 7: training on 412480 raw words (403870 effective words) took 0.9s, 444785 effective words/s
INFO - 2023-11-27 13:26:55,321: EPOCH 8: training on 412480 raw words (403803 effective words) took 0.8s, 479324 effective words/s
INFO - 2023-11-27 13:26:56,217: EPOCH 9: training on 412480 raw words (403758 effective words) took 0.9s, 452060 effective words/s
INFO - 2023-11-27 13:26:57,075: EPOCH 10: training on 412480 raw words (403898 effective words) took 0.9s, 471425 effective words/s
INFO - 2023-11-27 13:26:57,939: EPOCH 11: training on 412480 raw words (403742 effective words) took 0.9s, 468370 effective words/s
INFO - 2023-11-27 13:26:58,825: EPOCH 12: training on 412480 raw words (403770 effective words) took 0.9s, 456858 effective words/s
INFO - 2023-11-27 13:26:59,699: EPOCH 13: training on 412480 raw words (403849 effective words) took 0.9s, 462922 effective words/s
INFO - 2023-11-27 13:27:00,707: EPOCH 14 - PROGRESS: at 87.28% examples, 350588 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:27:00,806: EPOCH 14: training on 412480 raw words (403760 effective words) took 1.1s, 365447 effective words/s
INFO - 2023-11-27 13:27:01,812: EPOCH 15 - PROGRESS: at 97.58% examples, 392997 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:27:01,882: EPOCH 15: training on 412480 raw words (403729 effective words) took 1.1s, 376360 effective words/s
INFO - 2023-11-27 13:27:02,885: EPOCH 16 - PROGRESS: at 97.58% examples, 393758 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:27:02,992: EPOCH 16: training on 412480 raw words (403778 effective words) took 1.1s, 364551 effective words/s
INFO - 2023-11-27 13:27:04,000: EPOCH 17 - PROGRESS: at 82.43% examples, 331908 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:27:04,121: EPOCH 17: training on 412480 raw words (403826 effective words) took 1.1s, 359494 effective words/s
INFO - 2023-11-27 13:27:05,144: EPOCH 18 - PROGRESS: at 75.16% examples, 297250 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:27:05,320: EPOCH 18: training on 412480 raw words (403845 effective words) took 1.2s, 337304 effective words/s
INFO - 2023-11-27 13:27:06,349: EPOCH 19 - PROGRESS: at 77.58% examples, 305498 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:27:06,490: EPOCH 19: training on 412480 raw words (403798 effective words) took 1.2s, 345991 effective words/s
INFO - 2023-11-27 13:27:06,491: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8076434 effective words) took 19.1s, 422382 effective words/s', 'datetime': '2023-11-27T13:27:06.491137', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:06,491: collecting all words and their counts
INFO - 2023-11-27 13:27:06,491: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:27:06,574: PROGRESS: at sentence #10000, processed 400000 words, keeping 10294 word types
INFO - 2023-11-27 13:27:06,577: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:27:06,577: Updating model with new vocabulary
INFO - 2023-11-27 13:27:06,611: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:27:06.611061', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:06,662: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:27:06,663: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:27:06,663: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403469.5103667573 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:27:06.663179', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:06,742: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:27:06,742: updating layer weights
INFO - 2023-11-27 13:27:06,742: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:27:06.742939', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:27:06,743: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:27:06,743: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:27:06.743256', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:07,779: EPOCH 0 - PROGRESS: at 77.58% examples, 302868 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:27:07,854: EPOCH 0: training on 412480 raw words (403519 effective words) took 1.1s, 363996 effective words/s
INFO - 2023-11-27 13:27:08,878: EPOCH 1 - PROGRESS: at 77.58% examples, 306590 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:27:09,016: EPOCH 1: training on 412480 raw words (403568 effective words) took 1.2s, 348222 effective words/s
INFO - 2023-11-27 13:27:09,890: EPOCH 2: training on 412480 raw words (403586 effective words) took 0.9s, 462911 effective words/s
INFO - 2023-11-27 13:27:10,811: EPOCH 3: training on 412480 raw words (403558 effective words) took 0.9s, 439089 effective words/s
INFO - 2023-11-27 13:27:11,765: EPOCH 4: training on 412480 raw words (403465 effective words) took 1.0s, 423992 effective words/s
INFO - 2023-11-27 13:27:12,684: EPOCH 5: training on 412480 raw words (403491 effective words) took 0.9s, 440074 effective words/s
INFO - 2023-11-27 13:27:13,608: EPOCH 6: training on 412480 raw words (403433 effective words) took 0.9s, 437459 effective words/s
INFO - 2023-11-27 13:27:14,456: EPOCH 7: training on 412480 raw words (403640 effective words) took 0.8s, 477542 effective words/s
INFO - 2023-11-27 13:27:15,316: EPOCH 8: training on 412480 raw words (403315 effective words) took 0.9s, 469683 effective words/s
INFO - 2023-11-27 13:27:16,121: EPOCH 9: training on 412480 raw words (403462 effective words) took 0.8s, 502744 effective words/s
INFO - 2023-11-27 13:27:16,915: EPOCH 10: training on 412480 raw words (403424 effective words) took 0.8s, 509344 effective words/s
INFO - 2023-11-27 13:27:17,808: EPOCH 11: training on 412480 raw words (403567 effective words) took 0.9s, 452762 effective words/s
INFO - 2023-11-27 13:27:18,715: EPOCH 12: training on 412480 raw words (403340 effective words) took 0.9s, 446006 effective words/s
INFO - 2023-11-27 13:27:19,596: EPOCH 13: training on 412480 raw words (403583 effective words) took 0.9s, 459644 effective words/s
INFO - 2023-11-27 13:27:20,439: EPOCH 14: training on 412480 raw words (403492 effective words) took 0.8s, 479890 effective words/s
INFO - 2023-11-27 13:27:21,362: EPOCH 15: training on 412480 raw words (403447 effective words) took 0.9s, 437806 effective words/s
INFO - 2023-11-27 13:27:22,289: EPOCH 16: training on 412480 raw words (403524 effective words) took 0.9s, 436007 effective words/s
INFO - 2023-11-27 13:27:23,290: EPOCH 17: training on 412480 raw words (403403 effective words) took 1.0s, 403890 effective words/s
INFO - 2023-11-27 13:27:24,312: EPOCH 18 - PROGRESS: at 100.00% examples, 395941 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:27:24,312: EPOCH 18: training on 412480 raw words (403530 effective words) took 1.0s, 395853 effective words/s
INFO - 2023-11-27 13:27:25,319: EPOCH 19 - PROGRESS: at 87.88% examples, 353000 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:27:25,407: EPOCH 19: training on 412480 raw words (403404 effective words) took 1.1s, 369327 effective words/s
INFO - 2023-11-27 13:27:25,407: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8069751 effective words) took 18.7s, 432367 effective words/s', 'datetime': '2023-11-27T13:27:25.407468', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:25,407: collecting all words and their counts
INFO - 2023-11-27 13:27:25,407: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:27:25,490: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:27:25,494: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:27:25,495: Updating model with new vocabulary
INFO - 2023-11-27 13:27:25,539: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:27:25.539261', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:25,603: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:27:25,603: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:27:25,603: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403522.1457717272 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:27:25.603589', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:25,693: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:27:25,694: updating layer weights
INFO - 2023-11-27 13:27:25,698: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:27:25.698065', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:27:25,698: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:27:25,698: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:27:25.698660', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:26,784: EPOCH 0 - PROGRESS: at 75.16% examples, 280444 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:27:27,121: EPOCH 0: training on 412480 raw words (403508 effective words) took 1.4s, 284438 effective words/s
INFO - 2023-11-27 13:27:28,136: EPOCH 1 - PROGRESS: at 58.18% examples, 232194 words/s, in_qsize 16, out_qsize 2
INFO - 2023-11-27 13:27:28,714: EPOCH 1: training on 412480 raw words (403518 effective words) took 1.6s, 253850 effective words/s
INFO - 2023-11-27 13:27:29,724: EPOCH 2 - PROGRESS: at 43.64% examples, 175137 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:27:30,449: EPOCH 2: training on 412480 raw words (403502 effective words) took 1.7s, 233160 effective words/s
INFO - 2023-11-27 13:27:31,466: EPOCH 3 - PROGRESS: at 53.34% examples, 212101 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:27:32,030: EPOCH 3: training on 412480 raw words (403486 effective words) took 1.6s, 255650 effective words/s
INFO - 2023-11-27 13:27:33,057: EPOCH 4 - PROGRESS: at 75.16% examples, 296217 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:27:33,241: EPOCH 4: training on 412480 raw words (403487 effective words) took 1.2s, 333863 effective words/s
INFO - 2023-11-27 13:27:34,160: EPOCH 5: training on 412480 raw words (403478 effective words) took 0.9s, 440016 effective words/s
INFO - 2023-11-27 13:27:35,068: EPOCH 6: training on 412480 raw words (403424 effective words) took 0.9s, 445464 effective words/s
INFO - 2023-11-27 13:27:36,052: EPOCH 7: training on 412480 raw words (403482 effective words) took 1.0s, 411062 effective words/s
INFO - 2023-11-27 13:27:36,999: EPOCH 8: training on 412480 raw words (403502 effective words) took 0.9s, 427559 effective words/s
INFO - 2023-11-27 13:27:37,907: EPOCH 9: training on 412480 raw words (403565 effective words) took 0.9s, 445863 effective words/s
INFO - 2023-11-27 13:27:38,844: EPOCH 10: training on 412480 raw words (403657 effective words) took 0.9s, 431413 effective words/s
INFO - 2023-11-27 13:27:39,839: EPOCH 11: training on 412480 raw words (403444 effective words) took 1.0s, 406439 effective words/s
INFO - 2023-11-27 13:27:40,760: EPOCH 12: training on 412480 raw words (403483 effective words) took 0.9s, 439110 effective words/s
INFO - 2023-11-27 13:27:41,640: EPOCH 13: training on 412480 raw words (403544 effective words) took 0.9s, 459768 effective words/s
INFO - 2023-11-27 13:27:42,546: EPOCH 14: training on 412480 raw words (403390 effective words) took 0.9s, 446247 effective words/s
INFO - 2023-11-27 13:27:43,407: EPOCH 15: training on 412480 raw words (403473 effective words) took 0.9s, 469689 effective words/s
INFO - 2023-11-27 13:27:44,295: EPOCH 16: training on 412480 raw words (403559 effective words) took 0.9s, 455568 effective words/s
INFO - 2023-11-27 13:27:45,161: EPOCH 17: training on 412480 raw words (403632 effective words) took 0.9s, 467174 effective words/s
INFO - 2023-11-27 13:27:46,014: EPOCH 18: training on 412480 raw words (403499 effective words) took 0.9s, 474122 effective words/s
INFO - 2023-11-27 13:27:46,891: EPOCH 19: training on 412480 raw words (403584 effective words) took 0.9s, 461494 effective words/s
INFO - 2023-11-27 13:27:46,891: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8070217 effective words) took 21.2s, 380806 effective words/s', 'datetime': '2023-11-27T13:27:46.891326', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:46,891: collecting all words and their counts
INFO - 2023-11-27 13:27:46,891: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:27:46,955: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:27:46,958: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:27:46,958: Updating model with new vocabulary
INFO - 2023-11-27 13:27:46,992: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:27:46.992728', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:47,035: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:27:47,035: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:27:47,035: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403563.0852578399 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:27:47.035357', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:27:47,085: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:27:47,085: updating layer weights
INFO - 2023-11-27 13:27:47,086: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:27:47.086289', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:27:47,086: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:27:47,086: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:27:47.086528', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:27:47,934: EPOCH 0: training on 412480 raw words (403495 effective words) took 0.8s, 476890 effective words/s
INFO - 2023-11-27 13:27:48,815: EPOCH 1: training on 412480 raw words (403492 effective words) took 0.9s, 458989 effective words/s
INFO - 2023-11-27 13:27:49,693: EPOCH 2: training on 412480 raw words (403556 effective words) took 0.9s, 460426 effective words/s
INFO - 2023-11-27 13:27:50,548: EPOCH 3: training on 412480 raw words (403623 effective words) took 0.9s, 473616 effective words/s
INFO - 2023-11-27 13:27:51,543: EPOCH 4: training on 412480 raw words (403539 effective words) took 1.0s, 406262 effective words/s
INFO - 2023-11-27 13:27:52,547: EPOCH 5 - PROGRESS: at 87.88% examples, 354386 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:27:52,681: EPOCH 5: training on 412480 raw words (403540 effective words) took 1.1s, 355521 effective words/s
INFO - 2023-11-27 13:27:53,687: EPOCH 6 - PROGRESS: at 92.73% examples, 373040 words/s, in_qsize 3, out_qsize 1
INFO - 2023-11-27 13:27:53,784: EPOCH 6: training on 412480 raw words (403647 effective words) took 1.1s, 366804 effective words/s
INFO - 2023-11-27 13:27:54,790: EPOCH 7 - PROGRESS: at 77.58% examples, 311937 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:27:54,952: EPOCH 7: training on 412480 raw words (403513 effective words) took 1.2s, 346310 effective words/s
INFO - 2023-11-27 13:27:55,963: EPOCH 8 - PROGRESS: at 84.85% examples, 339676 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:27:56,093: EPOCH 8: training on 412480 raw words (403613 effective words) took 1.1s, 354727 effective words/s
INFO - 2023-11-27 13:27:57,103: EPOCH 9 - PROGRESS: at 97.58% examples, 390859 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:27:57,183: EPOCH 9: training on 412480 raw words (403520 effective words) took 1.1s, 371139 effective words/s
INFO - 2023-11-27 13:27:58,031: EPOCH 10: training on 412480 raw words (403658 effective words) took 0.8s, 477122 effective words/s
INFO - 2023-11-27 13:27:58,913: EPOCH 11: training on 412480 raw words (403505 effective words) took 0.9s, 458611 effective words/s
INFO - 2023-11-27 13:27:59,773: EPOCH 12: training on 412480 raw words (403635 effective words) took 0.9s, 470227 effective words/s
INFO - 2023-11-27 13:28:00,596: EPOCH 13: training on 412480 raw words (403686 effective words) took 0.8s, 492275 effective words/s
INFO - 2023-11-27 13:28:01,422: EPOCH 14: training on 412480 raw words (403404 effective words) took 0.8s, 489245 effective words/s
INFO - 2023-11-27 13:28:02,298: EPOCH 15: training on 412480 raw words (403567 effective words) took 0.9s, 461739 effective words/s
INFO - 2023-11-27 13:28:03,165: EPOCH 16: training on 412480 raw words (403463 effective words) took 0.9s, 466816 effective words/s
INFO - 2023-11-27 13:28:04,048: EPOCH 17: training on 412480 raw words (403483 effective words) took 0.9s, 458178 effective words/s
INFO - 2023-11-27 13:28:04,876: EPOCH 18: training on 412480 raw words (403424 effective words) took 0.8s, 488140 effective words/s
INFO - 2023-11-27 13:28:05,796: EPOCH 19: training on 412480 raw words (403672 effective words) took 0.9s, 439742 effective words/s
INFO - 2023-11-27 13:28:05,796: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071035 effective words) took 18.7s, 431369 effective words/s', 'datetime': '2023-11-27T13:28:05.796885', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:05,797: collecting all words and their counts
INFO - 2023-11-27 13:28:05,797: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:28:05,863: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:28:05,866: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:28:05,866: Updating model with new vocabulary
INFO - 2023-11-27 13:28:05,899: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:28:05.899100', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:05,937: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:28:05,938: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:28:05,938: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403500.28598006605 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:28:05.938364', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:05,988: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:28:05,988: updating layer weights
INFO - 2023-11-27 13:28:05,989: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:28:05.989542', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:28:05,989: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:28:05,989: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:28:05.989721', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:06,906: EPOCH 0: training on 412480 raw words (403640 effective words) took 0.9s, 441311 effective words/s
INFO - 2023-11-27 13:28:07,842: EPOCH 1: training on 412480 raw words (403512 effective words) took 0.9s, 431939 effective words/s
INFO - 2023-11-27 13:28:08,794: EPOCH 2: training on 412480 raw words (403571 effective words) took 0.9s, 425056 effective words/s
INFO - 2023-11-27 13:28:09,675: EPOCH 3: training on 412480 raw words (403530 effective words) took 0.9s, 459016 effective words/s
INFO - 2023-11-27 13:28:10,620: EPOCH 4: training on 412480 raw words (403483 effective words) took 0.9s, 428140 effective words/s
INFO - 2023-11-27 13:28:11,580: EPOCH 5: training on 412480 raw words (403321 effective words) took 1.0s, 421087 effective words/s
INFO - 2023-11-27 13:28:12,593: EPOCH 6 - PROGRESS: at 77.58% examples, 309348 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:12,766: EPOCH 6: training on 412480 raw words (403403 effective words) took 1.2s, 340568 effective words/s
INFO - 2023-11-27 13:28:13,814: EPOCH 7 - PROGRESS: at 77.58% examples, 299470 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:13,971: EPOCH 7: training on 412480 raw words (403470 effective words) took 1.2s, 335562 effective words/s
INFO - 2023-11-27 13:28:14,975: EPOCH 8 - PROGRESS: at 87.88% examples, 354538 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:28:15,061: EPOCH 8: training on 412480 raw words (403697 effective words) took 1.1s, 371370 effective words/s
INFO - 2023-11-27 13:28:16,098: EPOCH 9 - PROGRESS: at 77.58% examples, 302823 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:16,229: EPOCH 9: training on 412480 raw words (403541 effective words) took 1.2s, 346317 effective words/s
INFO - 2023-11-27 13:28:17,234: EPOCH 10 - PROGRESS: at 82.43% examples, 331744 words/s, in_qsize 8, out_qsize 1
INFO - 2023-11-27 13:28:17,369: EPOCH 10: training on 412480 raw words (403493 effective words) took 1.1s, 354717 effective words/s
INFO - 2023-11-27 13:28:18,374: EPOCH 11 - PROGRESS: at 84.85% examples, 341710 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:28:18,459: EPOCH 11: training on 412480 raw words (403521 effective words) took 1.1s, 371232 effective words/s
INFO - 2023-11-27 13:28:19,482: EPOCH 12 - PROGRESS: at 77.58% examples, 306644 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:19,615: EPOCH 12: training on 412480 raw words (403403 effective words) took 1.2s, 349822 effective words/s
INFO - 2023-11-27 13:28:20,637: EPOCH 13 - PROGRESS: at 77.58% examples, 306721 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:20,789: EPOCH 13: training on 412480 raw words (403345 effective words) took 1.2s, 344357 effective words/s
INFO - 2023-11-27 13:28:21,721: EPOCH 14: training on 412480 raw words (403543 effective words) took 0.9s, 433766 effective words/s
INFO - 2023-11-27 13:28:22,586: EPOCH 15: training on 412480 raw words (403541 effective words) took 0.9s, 467712 effective words/s
INFO - 2023-11-27 13:28:23,446: EPOCH 16: training on 412480 raw words (403379 effective words) took 0.9s, 469985 effective words/s
INFO - 2023-11-27 13:28:24,287: EPOCH 17: training on 412480 raw words (403481 effective words) took 0.8s, 481186 effective words/s
INFO - 2023-11-27 13:28:25,176: EPOCH 18: training on 412480 raw words (403439 effective words) took 0.9s, 454368 effective words/s
INFO - 2023-11-27 13:28:26,083: EPOCH 19: training on 412480 raw words (403505 effective words) took 0.9s, 446284 effective words/s
INFO - 2023-11-27 13:28:26,083: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8069818 effective words) took 20.1s, 401611 effective words/s', 'datetime': '2023-11-27T13:28:26.083376', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:26,083: collecting all words and their counts
INFO - 2023-11-27 13:28:26,083: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:28:26,141: PROGRESS: at sentence #10000, processed 400000 words, keeping 10300 word types
INFO - 2023-11-27 13:28:26,143: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:28:26,143: Updating model with new vocabulary
INFO - 2023-11-27 13:28:26,173: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:28:26.173822', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:26,212: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:28:26,212: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:28:26,212: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403628.0086957644 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:28:26.212540', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:26,260: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:28:26,260: updating layer weights
INFO - 2023-11-27 13:28:26,261: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:28:26.261242', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:28:26,261: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:28:26,261: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:28:26.261386', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:27,077: EPOCH 0: training on 412480 raw words (403566 effective words) took 0.8s, 495299 effective words/s
INFO - 2023-11-27 13:28:27,924: EPOCH 1: training on 412480 raw words (403778 effective words) took 0.8s, 477832 effective words/s
INFO - 2023-11-27 13:28:28,738: EPOCH 2: training on 412480 raw words (403575 effective words) took 0.8s, 497135 effective words/s
INFO - 2023-11-27 13:28:29,606: EPOCH 3: training on 412480 raw words (403634 effective words) took 0.9s, 466273 effective words/s
INFO - 2023-11-27 13:28:30,443: EPOCH 4: training on 412480 raw words (403749 effective words) took 0.8s, 483739 effective words/s
INFO - 2023-11-27 13:28:31,284: EPOCH 5: training on 412480 raw words (403583 effective words) took 0.8s, 480494 effective words/s
INFO - 2023-11-27 13:28:32,130: EPOCH 6: training on 412480 raw words (403537 effective words) took 0.8s, 478424 effective words/s
INFO - 2023-11-27 13:28:32,991: EPOCH 7: training on 412480 raw words (403480 effective words) took 0.9s, 469626 effective words/s
INFO - 2023-11-27 13:28:33,852: EPOCH 8: training on 412480 raw words (403618 effective words) took 0.9s, 470100 effective words/s
INFO - 2023-11-27 13:28:34,784: EPOCH 9: training on 412480 raw words (403597 effective words) took 0.9s, 434032 effective words/s
INFO - 2023-11-27 13:28:35,799: EPOCH 10 - PROGRESS: at 100.00% examples, 399012 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:28:35,799: EPOCH 10: training on 412480 raw words (403575 effective words) took 1.0s, 398920 effective words/s
INFO - 2023-11-27 13:28:36,895: EPOCH 11 - PROGRESS: at 100.00% examples, 368803 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:28:36,895: EPOCH 11: training on 412480 raw words (403482 effective words) took 1.1s, 368712 effective words/s
INFO - 2023-11-27 13:28:37,909: EPOCH 12 - PROGRESS: at 75.16% examples, 300019 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:28:38,101: EPOCH 12: training on 412480 raw words (403629 effective words) took 1.2s, 335466 effective words/s
INFO - 2023-11-27 13:28:39,117: EPOCH 13 - PROGRESS: at 80.00% examples, 318662 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:28:39,263: EPOCH 13: training on 412480 raw words (403620 effective words) took 1.2s, 348072 effective words/s
INFO - 2023-11-27 13:28:40,271: EPOCH 14 - PROGRESS: at 84.85% examples, 340702 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:28:40,421: EPOCH 14: training on 412480 raw words (403676 effective words) took 1.2s, 349531 effective words/s
INFO - 2023-11-27 13:28:41,438: EPOCH 15 - PROGRESS: at 84.85% examples, 337855 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:28:41,573: EPOCH 15: training on 412480 raw words (403606 effective words) took 1.1s, 351186 effective words/s
INFO - 2023-11-27 13:28:42,582: EPOCH 16 - PROGRESS: at 77.58% examples, 311572 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:28:42,746: EPOCH 16: training on 412480 raw words (403608 effective words) took 1.2s, 345141 effective words/s
INFO - 2023-11-27 13:28:43,787: EPOCH 17 - PROGRESS: at 75.16% examples, 292177 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:28:44,033: EPOCH 17: training on 412480 raw words (403614 effective words) took 1.3s, 314255 effective words/s
INFO - 2023-11-27 13:28:45,104: EPOCH 18 - PROGRESS: at 75.16% examples, 284268 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:28:45,291: EPOCH 18: training on 412480 raw words (403641 effective words) took 1.3s, 321663 effective words/s
INFO - 2023-11-27 13:28:46,381: EPOCH 19 - PROGRESS: at 100.00% examples, 375405 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:28:46,381: EPOCH 19: training on 412480 raw words (403496 effective words) took 1.1s, 375322 effective words/s
INFO - 2023-11-27 13:28:46,381: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8072064 effective words) took 20.1s, 401192 effective words/s', 'datetime': '2023-11-27T13:28:46.381679', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:46,381: collecting all words and their counts
INFO - 2023-11-27 13:28:46,382: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:28:46,478: PROGRESS: at sentence #10000, processed 400000 words, keeping 10295 word types
INFO - 2023-11-27 13:28:46,481: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:28:46,481: Updating model with new vocabulary
INFO - 2023-11-27 13:28:46,522: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:28:46.522486', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:46,567: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:28:46,567: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:28:46,567: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403596.98405439506 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:28:46.567814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:28:46,645: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:28:46,645: updating layer weights
INFO - 2023-11-27 13:28:46,646: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:28:46.646343', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:28:46,646: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:28:46,646: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:28:46.646541', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:28:47,651: EPOCH 0 - PROGRESS: at 96.97% examples, 390480 words/s, in_qsize 2, out_qsize 1
INFO - 2023-11-27 13:28:47,749: EPOCH 0: training on 412480 raw words (403541 effective words) took 1.1s, 366657 effective words/s
INFO - 2023-11-27 13:28:48,651: EPOCH 1: training on 412480 raw words (403544 effective words) took 0.9s, 448390 effective words/s
INFO - 2023-11-27 13:28:49,526: EPOCH 2: training on 412480 raw words (403739 effective words) took 0.9s, 462769 effective words/s
INFO - 2023-11-27 13:28:50,376: EPOCH 3: training on 412480 raw words (403674 effective words) took 0.8s, 476227 effective words/s
INFO - 2023-11-27 13:28:51,264: EPOCH 4: training on 412480 raw words (403582 effective words) took 0.9s, 455221 effective words/s
INFO - 2023-11-27 13:28:52,148: EPOCH 5: training on 412480 raw words (403908 effective words) took 0.9s, 458250 effective words/s
INFO - 2023-11-27 13:28:53,074: EPOCH 6: training on 412480 raw words (403582 effective words) took 0.9s, 436738 effective words/s
INFO - 2023-11-27 13:28:53,920: EPOCH 7: training on 412480 raw words (403523 effective words) took 0.8s, 478239 effective words/s
INFO - 2023-11-27 13:28:54,769: EPOCH 8: training on 412480 raw words (403565 effective words) took 0.8s, 476049 effective words/s
INFO - 2023-11-27 13:28:55,645: EPOCH 9: training on 412480 raw words (403624 effective words) took 0.9s, 461850 effective words/s
INFO - 2023-11-27 13:28:56,553: EPOCH 10: training on 412480 raw words (403595 effective words) took 0.9s, 445549 effective words/s
INFO - 2023-11-27 13:28:57,452: EPOCH 11: training on 412480 raw words (403440 effective words) took 0.9s, 450017 effective words/s
INFO - 2023-11-27 13:28:58,313: EPOCH 12: training on 412480 raw words (403658 effective words) took 0.9s, 469832 effective words/s
INFO - 2023-11-27 13:28:59,165: EPOCH 13: training on 412480 raw words (403567 effective words) took 0.9s, 474765 effective words/s
INFO - 2023-11-27 13:29:00,052: EPOCH 14: training on 412480 raw words (403775 effective words) took 0.9s, 456304 effective words/s
INFO - 2023-11-27 13:29:01,053: EPOCH 15: training on 412480 raw words (403511 effective words) took 1.0s, 403838 effective words/s
INFO - 2023-11-27 13:29:02,061: EPOCH 16 - PROGRESS: at 75.16% examples, 301453 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:02,240: EPOCH 16: training on 412480 raw words (403595 effective words) took 1.2s, 340675 effective words/s
INFO - 2023-11-27 13:29:03,260: EPOCH 17 - PROGRESS: at 78.18% examples, 309838 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:29:03,394: EPOCH 17: training on 412480 raw words (403403 effective words) took 1.2s, 350219 effective words/s
INFO - 2023-11-27 13:29:04,402: EPOCH 18 - PROGRESS: at 75.16% examples, 301907 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:04,616: EPOCH 18: training on 412480 raw words (403593 effective words) took 1.2s, 331244 effective words/s
INFO - 2023-11-27 13:29:05,681: EPOCH 19 - PROGRESS: at 75.16% examples, 285439 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:05,887: EPOCH 19: training on 412480 raw words (403566 effective words) took 1.3s, 318086 effective words/s
INFO - 2023-11-27 13:29:05,887: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071985 effective words) took 19.2s, 419515 effective words/s', 'datetime': '2023-11-27T13:29:05.887854', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:05,888: collecting all words and their counts
INFO - 2023-11-27 13:29:05,888: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:29:05,988: PROGRESS: at sentence #10000, processed 400000 words, keeping 10295 word types
INFO - 2023-11-27 13:29:05,993: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:29:05,993: Updating model with new vocabulary
INFO - 2023-11-27 13:29:06,039: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:29:06.039388', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:06,084: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:29:06,085: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:29:06,085: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403896.0398732359 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:29:06.085254', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:06,151: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:29:06,151: updating layer weights
INFO - 2023-11-27 13:29:06,152: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:29:06.152481', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:29:06,152: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:29:06,152: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:29:06.152689', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:07,209: EPOCH 0 - PROGRESS: at 75.16% examples, 287874 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:07,408: EPOCH 0: training on 412480 raw words (404022 effective words) took 1.3s, 322282 effective words/s
INFO - 2023-11-27 13:29:08,447: EPOCH 1 - PROGRESS: at 77.58% examples, 302289 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:29:08,576: EPOCH 1: training on 412480 raw words (403965 effective words) took 1.2s, 346590 effective words/s
INFO - 2023-11-27 13:29:09,593: EPOCH 2 - PROGRESS: at 80.00% examples, 318852 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:29:09,723: EPOCH 2: training on 412480 raw words (403851 effective words) took 1.1s, 352966 effective words/s
INFO - 2023-11-27 13:29:10,616: EPOCH 3: training on 412480 raw words (403899 effective words) took 0.9s, 453401 effective words/s
INFO - 2023-11-27 13:29:11,472: EPOCH 4: training on 412480 raw words (404004 effective words) took 0.8s, 477831 effective words/s
INFO - 2023-11-27 13:29:12,334: EPOCH 5: training on 412480 raw words (403819 effective words) took 0.9s, 469333 effective words/s
INFO - 2023-11-27 13:29:13,221: EPOCH 6: training on 412480 raw words (403938 effective words) took 0.9s, 456604 effective words/s
INFO - 2023-11-27 13:29:14,079: EPOCH 7: training on 412480 raw words (403966 effective words) took 0.9s, 471940 effective words/s
INFO - 2023-11-27 13:29:14,905: EPOCH 8: training on 412480 raw words (403893 effective words) took 0.8s, 490108 effective words/s
INFO - 2023-11-27 13:29:15,761: EPOCH 9: training on 412480 raw words (403965 effective words) took 0.9s, 472881 effective words/s
INFO - 2023-11-27 13:29:16,645: EPOCH 10: training on 412480 raw words (403986 effective words) took 0.9s, 458001 effective words/s
INFO - 2023-11-27 13:29:17,488: EPOCH 11: training on 412480 raw words (403937 effective words) took 0.8s, 480576 effective words/s
INFO - 2023-11-27 13:29:18,528: EPOCH 12 - PROGRESS: at 100.00% examples, 389172 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:29:18,528: EPOCH 12: training on 412480 raw words (403821 effective words) took 1.0s, 389072 effective words/s
INFO - 2023-11-27 13:29:19,549: EPOCH 13 - PROGRESS: at 63.03% examples, 249973 words/s, in_qsize 15, out_qsize 1
INFO - 2023-11-27 13:29:19,786: EPOCH 13: training on 412480 raw words (403932 effective words) took 1.3s, 321659 effective words/s
INFO - 2023-11-27 13:29:20,663: EPOCH 14: training on 412480 raw words (403823 effective words) took 0.9s, 461462 effective words/s
INFO - 2023-11-27 13:29:21,626: EPOCH 15: training on 412480 raw words (404050 effective words) took 1.0s, 420780 effective words/s
INFO - 2023-11-27 13:29:22,527: EPOCH 16: training on 412480 raw words (403913 effective words) took 0.9s, 449185 effective words/s
INFO - 2023-11-27 13:29:23,452: EPOCH 17: training on 412480 raw words (403697 effective words) took 0.9s, 437429 effective words/s
INFO - 2023-11-27 13:29:24,373: EPOCH 18: training on 412480 raw words (403757 effective words) took 0.9s, 439437 effective words/s
INFO - 2023-11-27 13:29:25,481: EPOCH 19 - PROGRESS: at 100.00% examples, 365452 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:29:25,481: EPOCH 19: training on 412480 raw words (403833 effective words) took 1.1s, 365371 effective words/s
INFO - 2023-11-27 13:29:25,481: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8078071 effective words) took 19.3s, 417933 effective words/s', 'datetime': '2023-11-27T13:29:25.481423', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:25,481: collecting all words and their counts
INFO - 2023-11-27 13:29:25,481: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:29:25,587: PROGRESS: at sentence #10000, processed 400000 words, keeping 10304 word types
INFO - 2023-11-27 13:29:25,589: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:29:25,590: Updating model with new vocabulary
INFO - 2023-11-27 13:29:25,623: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:29:25.623560', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:25,668: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:29:25,668: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:29:25,668: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403266.6201083631 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:29:25.668721', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:25,744: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:29:25,744: updating layer weights
INFO - 2023-11-27 13:29:25,745: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:29:25.745442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:29:25,745: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:29:25,745: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:29:25.745654', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:26,753: EPOCH 0 - PROGRESS: at 90.30% examples, 362284 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:29:26,808: EPOCH 0: training on 412480 raw words (403262 effective words) took 1.1s, 380293 effective words/s
INFO - 2023-11-27 13:29:27,853: EPOCH 1 - PROGRESS: at 100.00% examples, 386728 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:29:27,853: EPOCH 1: training on 412480 raw words (403269 effective words) took 1.0s, 386641 effective words/s
INFO - 2023-11-27 13:29:28,914: EPOCH 2 - PROGRESS: at 75.16% examples, 286433 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:29,105: EPOCH 2: training on 412480 raw words (403320 effective words) took 1.2s, 322812 effective words/s
INFO - 2023-11-27 13:29:30,200: EPOCH 3 - PROGRESS: at 75.16% examples, 277558 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:30,399: EPOCH 3: training on 412480 raw words (403267 effective words) took 1.3s, 312226 effective words/s
INFO - 2023-11-27 13:29:31,457: EPOCH 4 - PROGRESS: at 75.16% examples, 287233 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:31,656: EPOCH 4: training on 412480 raw words (403308 effective words) took 1.3s, 321519 effective words/s
INFO - 2023-11-27 13:29:32,583: EPOCH 5: training on 412480 raw words (403301 effective words) took 0.9s, 436735 effective words/s
INFO - 2023-11-27 13:29:33,574: EPOCH 6: training on 412480 raw words (403337 effective words) took 1.0s, 407708 effective words/s
INFO - 2023-11-27 13:29:34,483: EPOCH 7: training on 412480 raw words (403264 effective words) took 0.9s, 444566 effective words/s
INFO - 2023-11-27 13:29:35,383: EPOCH 8: training on 412480 raw words (403321 effective words) took 0.9s, 449417 effective words/s
INFO - 2023-11-27 13:29:36,278: EPOCH 9: training on 412480 raw words (403202 effective words) took 0.9s, 451566 effective words/s
INFO - 2023-11-27 13:29:37,155: EPOCH 10: training on 412480 raw words (403245 effective words) took 0.9s, 461070 effective words/s
INFO - 2023-11-27 13:29:38,171: EPOCH 11 - PROGRESS: at 77.58% examples, 308400 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:29:38,272: EPOCH 11: training on 412480 raw words (403353 effective words) took 1.1s, 361667 effective words/s
INFO - 2023-11-27 13:29:39,142: EPOCH 12: training on 412480 raw words (403251 effective words) took 0.9s, 464376 effective words/s
INFO - 2023-11-27 13:29:39,996: EPOCH 13: training on 412480 raw words (403314 effective words) took 0.9s, 473101 effective words/s
INFO - 2023-11-27 13:29:40,879: EPOCH 14: training on 412480 raw words (403264 effective words) took 0.9s, 458056 effective words/s
INFO - 2023-11-27 13:29:41,748: EPOCH 15: training on 412480 raw words (403359 effective words) took 0.9s, 465108 effective words/s
INFO - 2023-11-27 13:29:42,686: EPOCH 16: training on 412480 raw words (403187 effective words) took 0.9s, 430948 effective words/s
INFO - 2023-11-27 13:29:43,550: EPOCH 17: training on 412480 raw words (403308 effective words) took 0.9s, 467314 effective words/s
INFO - 2023-11-27 13:29:44,437: EPOCH 18: training on 412480 raw words (403407 effective words) took 0.9s, 456202 effective words/s
INFO - 2023-11-27 13:29:45,348: EPOCH 19: training on 412480 raw words (403306 effective words) took 0.9s, 443819 effective words/s
INFO - 2023-11-27 13:29:45,348: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8065845 effective words) took 19.6s, 411464 effective words/s', 'datetime': '2023-11-27T13:29:45.348537', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:45,348: collecting all words and their counts
INFO - 2023-11-27 13:29:45,348: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:29:45,426: PROGRESS: at sentence #10000, processed 400000 words, keeping 10302 word types
INFO - 2023-11-27 13:29:45,429: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:29:45,429: Updating model with new vocabulary
INFO - 2023-11-27 13:29:45,469: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:29:45.468949', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:45,518: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:29:45,518: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:29:45,518: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403603.0858857684 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:29:45.518637', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:29:45,582: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:29:45,582: updating layer weights
INFO - 2023-11-27 13:29:45,583: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:29:45.583349', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:29:45,583: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:29:45,583: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:29:45.583585', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:29:46,587: EPOCH 0 - PROGRESS: at 87.28% examples, 351578 words/s, in_qsize 6, out_qsize 1
INFO - 2023-11-27 13:29:46,658: EPOCH 0: training on 412480 raw words (403564 effective words) took 1.1s, 376092 effective words/s
INFO - 2023-11-27 13:29:47,476: EPOCH 1: training on 412480 raw words (403544 effective words) took 0.8s, 494542 effective words/s
INFO - 2023-11-27 13:29:48,321: EPOCH 2: training on 412480 raw words (403642 effective words) took 0.8s, 478949 effective words/s
INFO - 2023-11-27 13:29:49,155: EPOCH 3: training on 412480 raw words (403580 effective words) took 0.8s, 485217 effective words/s
INFO - 2023-11-27 13:29:50,078: EPOCH 4: training on 412480 raw words (403632 effective words) took 0.9s, 438141 effective words/s
INFO - 2023-11-27 13:29:51,115: EPOCH 5 - PROGRESS: at 90.30% examples, 361910 words/s, in_qsize 4, out_qsize 1
INFO - 2023-11-27 13:29:51,194: EPOCH 5: training on 412480 raw words (403596 effective words) took 1.1s, 371793 effective words/s
INFO - 2023-11-27 13:29:52,281: EPOCH 6 - PROGRESS: at 100.00% examples, 372149 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:29:52,281: EPOCH 6: training on 412480 raw words (403587 effective words) took 1.1s, 372071 effective words/s
INFO - 2023-11-27 13:29:53,367: EPOCH 7 - PROGRESS: at 75.16% examples, 279833 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:53,577: EPOCH 7: training on 412480 raw words (403615 effective words) took 1.3s, 311942 effective words/s
INFO - 2023-11-27 13:29:54,706: EPOCH 8 - PROGRESS: at 75.16% examples, 276462 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:29:54,894: EPOCH 8: training on 412480 raw words (403521 effective words) took 1.3s, 314156 effective words/s
INFO - 2023-11-27 13:29:55,912: EPOCH 9 - PROGRESS: at 78.18% examples, 310826 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:29:56,069: EPOCH 9: training on 412480 raw words (403646 effective words) took 1.2s, 344352 effective words/s
INFO - 2023-11-27 13:29:57,074: EPOCH 10 - PROGRESS: at 80.00% examples, 322351 words/s, in_qsize 9, out_qsize 1
INFO - 2023-11-27 13:29:57,196: EPOCH 10: training on 412480 raw words (403574 effective words) took 1.1s, 359001 effective words/s
INFO - 2023-11-27 13:29:58,205: EPOCH 11 - PROGRESS: at 89.70% examples, 360110 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:29:58,351: EPOCH 11: training on 412480 raw words (403609 effective words) took 1.2s, 350498 effective words/s
INFO - 2023-11-27 13:29:59,262: EPOCH 12: training on 412480 raw words (403535 effective words) took 0.9s, 443995 effective words/s
INFO - 2023-11-27 13:30:00,081: EPOCH 13: training on 412480 raw words (403540 effective words) took 0.8s, 493792 effective words/s
INFO - 2023-11-27 13:30:00,928: EPOCH 14: training on 412480 raw words (403549 effective words) took 0.8s, 477930 effective words/s
INFO - 2023-11-27 13:30:01,761: EPOCH 15: training on 412480 raw words (403620 effective words) took 0.8s, 485516 effective words/s
INFO - 2023-11-27 13:30:02,609: EPOCH 16: training on 412480 raw words (403545 effective words) took 0.8s, 477240 effective words/s
INFO - 2023-11-27 13:30:03,443: EPOCH 17: training on 412480 raw words (403543 effective words) took 0.8s, 484928 effective words/s
INFO - 2023-11-27 13:30:04,237: EPOCH 18: training on 412480 raw words (403564 effective words) took 0.8s, 509539 effective words/s
INFO - 2023-11-27 13:30:05,081: EPOCH 19: training on 412480 raw words (403565 effective words) took 0.8s, 479711 effective words/s
INFO - 2023-11-27 13:30:05,081: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8071571 effective words) took 19.5s, 413977 effective words/s', 'datetime': '2023-11-27T13:30:05.081276', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:05,081: collecting all words and their counts
INFO - 2023-11-27 13:30:05,081: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:30:05,139: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:30:05,141: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:30:05,141: Updating model with new vocabulary
INFO - 2023-11-27 13:30:05,172: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:30:05.172113', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:05,205: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:30:05,205: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:30:05,205: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403727.72405461874 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:30:05.205896', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:05,255: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:30:05,255: updating layer weights
INFO - 2023-11-27 13:30:05,255: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:30:05.255703', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:30:05,255: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:30:05,255: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:30:05.255853', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:06,131: EPOCH 0: training on 412480 raw words (403777 effective words) took 0.9s, 461859 effective words/s
INFO - 2023-11-27 13:30:07,043: EPOCH 1: training on 412480 raw words (403761 effective words) took 0.9s, 444016 effective words/s
INFO - 2023-11-27 13:30:07,916: EPOCH 2: training on 412480 raw words (403780 effective words) took 0.9s, 463494 effective words/s
INFO - 2023-11-27 13:30:08,813: EPOCH 3: training on 412480 raw words (403705 effective words) took 0.9s, 450758 effective words/s
INFO - 2023-11-27 13:30:09,673: EPOCH 4: training on 412480 raw words (403651 effective words) took 0.9s, 470405 effective words/s
INFO - 2023-11-27 13:30:10,532: EPOCH 5: training on 412480 raw words (403630 effective words) took 0.9s, 471138 effective words/s
INFO - 2023-11-27 13:30:11,402: EPOCH 6: training on 412480 raw words (403691 effective words) took 0.9s, 464897 effective words/s
INFO - 2023-11-27 13:30:12,245: EPOCH 7: training on 412480 raw words (403660 effective words) took 0.8s, 480043 effective words/s
INFO - 2023-11-27 13:30:13,146: EPOCH 8: training on 412480 raw words (403819 effective words) took 0.9s, 449100 effective words/s
INFO - 2023-11-27 13:30:14,251: EPOCH 9 - PROGRESS: at 100.00% examples, 366073 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:30:14,251: EPOCH 9: training on 412480 raw words (403608 effective words) took 1.1s, 365995 effective words/s
INFO - 2023-11-27 13:30:15,360: EPOCH 10 - PROGRESS: at 100.00% examples, 373818 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:30:15,361: EPOCH 10: training on 412480 raw words (403759 effective words) took 1.1s, 373737 effective words/s
INFO - 2023-11-27 13:30:16,384: EPOCH 11 - PROGRESS: at 87.88% examples, 349812 words/s, in_qsize 5, out_qsize 1
INFO - 2023-11-27 13:30:16,471: EPOCH 11: training on 412480 raw words (403542 effective words) took 1.1s, 366295 effective words/s
INFO - 2023-11-27 13:30:17,499: EPOCH 12 - PROGRESS: at 75.16% examples, 296132 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:17,683: EPOCH 12: training on 412480 raw words (403715 effective words) took 1.2s, 333873 effective words/s
INFO - 2023-11-27 13:30:18,692: EPOCH 13 - PROGRESS: at 75.16% examples, 301414 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:18,895: EPOCH 13: training on 412480 raw words (403762 effective words) took 1.2s, 333907 effective words/s
INFO - 2023-11-27 13:30:19,918: EPOCH 14 - PROGRESS: at 75.16% examples, 297458 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:20,152: EPOCH 14: training on 412480 raw words (403740 effective words) took 1.3s, 321802 effective words/s
INFO - 2023-11-27 13:30:21,182: EPOCH 15 - PROGRESS: at 75.16% examples, 295496 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:21,377: EPOCH 15: training on 412480 raw words (403682 effective words) took 1.2s, 330229 effective words/s
INFO - 2023-11-27 13:30:22,385: EPOCH 16 - PROGRESS: at 97.58% examples, 391969 words/s, in_qsize 1, out_qsize 1
INFO - 2023-11-27 13:30:22,470: EPOCH 16: training on 412480 raw words (403800 effective words) took 1.1s, 370672 effective words/s
INFO - 2023-11-27 13:30:23,336: EPOCH 17: training on 412480 raw words (403599 effective words) took 0.9s, 466943 effective words/s
INFO - 2023-11-27 13:30:24,219: EPOCH 18: training on 412480 raw words (403659 effective words) took 0.9s, 457996 effective words/s
INFO - 2023-11-27 13:30:25,097: EPOCH 19: training on 412480 raw words (403848 effective words) took 0.9s, 461209 effective words/s
INFO - 2023-11-27 13:30:25,097: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074188 effective words) took 19.8s, 406928 effective words/s', 'datetime': '2023-11-27T13:30:25.097713', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:25,097: collecting all words and their counts
INFO - 2023-11-27 13:30:25,097: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:30:25,159: PROGRESS: at sentence #10000, processed 400000 words, keeping 10305 word types
INFO - 2023-11-27 13:30:25,161: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:30:25,161: Updating model with new vocabulary
INFO - 2023-11-27 13:30:25,188: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:30:25.188879', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:25,220: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:30:25,220: sample=0.001 downsamples 27 most-common words
INFO - 2023-11-27 13:30:25,220: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403349.4709668823 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:30:25.220597', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:25,269: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:30:25,269: updating layer weights
INFO - 2023-11-27 13:30:25,269: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:30:25.269838', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:30:25,269: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:30:25,269: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:30:25.269990', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:26,113: EPOCH 0: training on 412480 raw words (403414 effective words) took 0.8s, 479033 effective words/s
INFO - 2023-11-27 13:30:26,930: EPOCH 1: training on 412480 raw words (403365 effective words) took 0.8s, 495289 effective words/s
INFO - 2023-11-27 13:30:27,767: EPOCH 2: training on 412480 raw words (403294 effective words) took 0.8s, 483061 effective words/s
INFO - 2023-11-27 13:30:28,599: EPOCH 3: training on 412480 raw words (403420 effective words) took 0.8s, 486106 effective words/s
INFO - 2023-11-27 13:30:29,468: EPOCH 4: training on 412480 raw words (403258 effective words) took 0.9s, 464782 effective words/s
INFO - 2023-11-27 13:30:30,315: EPOCH 5: training on 412480 raw words (403228 effective words) took 0.8s, 477259 effective words/s
INFO - 2023-11-27 13:30:31,223: EPOCH 6: training on 412480 raw words (403417 effective words) took 0.9s, 445663 effective words/s
INFO - 2023-11-27 13:30:32,053: EPOCH 7: training on 412480 raw words (403348 effective words) took 0.8s, 486593 effective words/s
INFO - 2023-11-27 13:30:32,876: EPOCH 8: training on 412480 raw words (403310 effective words) took 0.8s, 491474 effective words/s
INFO - 2023-11-27 13:30:33,707: EPOCH 9: training on 412480 raw words (403301 effective words) took 0.8s, 486547 effective words/s
INFO - 2023-11-27 13:30:34,582: EPOCH 10: training on 412480 raw words (403493 effective words) took 0.9s, 462679 effective words/s
INFO - 2023-11-27 13:30:35,420: EPOCH 11: training on 412480 raw words (403347 effective words) took 0.8s, 482250 effective words/s
INFO - 2023-11-27 13:30:36,232: EPOCH 12: training on 412480 raw words (403361 effective words) took 0.8s, 498051 effective words/s
INFO - 2023-11-27 13:30:37,080: EPOCH 13: training on 412480 raw words (403248 effective words) took 0.8s, 476997 effective words/s
INFO - 2023-11-27 13:30:38,161: EPOCH 14 - PROGRESS: at 100.00% examples, 373834 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:30:38,161: EPOCH 14: training on 412480 raw words (403343 effective words) took 1.1s, 373762 effective words/s
INFO - 2023-11-27 13:30:39,231: EPOCH 15 - PROGRESS: at 100.00% examples, 377691 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:30:39,231: EPOCH 15: training on 412480 raw words (403341 effective words) took 1.1s, 377612 effective words/s
INFO - 2023-11-27 13:30:40,300: EPOCH 16 - PROGRESS: at 100.00% examples, 378453 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:30:40,300: EPOCH 16: training on 412480 raw words (403430 effective words) took 1.1s, 378366 effective words/s
INFO - 2023-11-27 13:30:41,305: EPOCH 17 - PROGRESS: at 77.58% examples, 312198 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:30:41,427: EPOCH 17: training on 412480 raw words (403507 effective words) took 1.1s, 359015 effective words/s
INFO - 2023-11-27 13:30:42,433: EPOCH 18 - PROGRESS: at 77.58% examples, 311862 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:30:42,583: EPOCH 18: training on 412480 raw words (403323 effective words) took 1.2s, 349567 effective words/s
INFO - 2023-11-27 13:30:43,634: EPOCH 19 - PROGRESS: at 75.16% examples, 289224 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:43,835: EPOCH 19: training on 412480 raw words (403392 effective words) took 1.2s, 322940 effective words/s
INFO - 2023-11-27 13:30:43,836: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8067140 effective words) took 18.6s, 434513 effective words/s', 'datetime': '2023-11-27T13:30:43.835994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:43,836: collecting all words and their counts
INFO - 2023-11-27 13:30:43,836: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:30:43,943: PROGRESS: at sentence #10000, processed 400000 words, keeping 10296 word types
INFO - 2023-11-27 13:30:43,947: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:30:43,947: Updating model with new vocabulary
INFO - 2023-11-27 13:30:44,004: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:30:44.004085', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:44,061: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:30:44,061: sample=0.001 downsamples 29 most-common words
INFO - 2023-11-27 13:30:44,061: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403793.90105501376 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:30:44.061580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:30:44,138: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:30:44,138: updating layer weights
INFO - 2023-11-27 13:30:44,139: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:30:44.139347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:30:44,139: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:30:44,139: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:30:44.139591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:30:45,145: EPOCH 0 - PROGRESS: at 72.73% examples, 292900 words/s, in_qsize 12, out_qsize 0
INFO - 2023-11-27 13:30:45,570: EPOCH 0: training on 412480 raw words (403914 effective words) took 1.4s, 282956 effective words/s
INFO - 2023-11-27 13:30:46,621: EPOCH 1 - PROGRESS: at 75.16% examples, 289551 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:30:46,790: EPOCH 1: training on 412480 raw words (403810 effective words) took 1.2s, 331796 effective words/s
INFO - 2023-11-27 13:30:47,707: EPOCH 2: training on 412480 raw words (403750 effective words) took 0.9s, 441674 effective words/s
INFO - 2023-11-27 13:30:48,687: EPOCH 3: training on 412480 raw words (403781 effective words) took 1.0s, 413264 effective words/s
INFO - 2023-11-27 13:30:49,633: EPOCH 4: training on 412480 raw words (403764 effective words) took 0.9s, 427754 effective words/s
INFO - 2023-11-27 13:30:50,599: EPOCH 5: training on 412480 raw words (403886 effective words) took 1.0s, 418923 effective words/s
INFO - 2023-11-27 13:30:51,550: EPOCH 6: training on 412480 raw words (403733 effective words) took 0.9s, 425354 effective words/s
INFO - 2023-11-27 13:30:52,475: EPOCH 7: training on 412480 raw words (403812 effective words) took 0.9s, 438016 effective words/s
INFO - 2023-11-27 13:30:53,434: EPOCH 8: training on 412480 raw words (403778 effective words) took 1.0s, 422134 effective words/s
INFO - 2023-11-27 13:30:54,386: EPOCH 9: training on 412480 raw words (403827 effective words) took 0.9s, 425239 effective words/s
INFO - 2023-11-27 13:30:55,319: EPOCH 10: training on 412480 raw words (403704 effective words) took 0.9s, 433662 effective words/s
INFO - 2023-11-27 13:30:56,303: EPOCH 11: training on 412480 raw words (403749 effective words) took 1.0s, 410992 effective words/s
INFO - 2023-11-27 13:30:57,230: EPOCH 12: training on 412480 raw words (403840 effective words) took 0.9s, 436900 effective words/s
INFO - 2023-11-27 13:30:58,188: EPOCH 13: training on 412480 raw words (403869 effective words) took 1.0s, 422256 effective words/s
INFO - 2023-11-27 13:30:59,168: EPOCH 14: training on 412480 raw words (403855 effective words) took 1.0s, 413108 effective words/s
INFO - 2023-11-27 13:31:00,117: EPOCH 15: training on 412480 raw words (403775 effective words) took 0.9s, 426589 effective words/s
INFO - 2023-11-27 13:31:01,074: EPOCH 16: training on 412480 raw words (403736 effective words) took 1.0s, 422922 effective words/s
INFO - 2023-11-27 13:31:02,097: EPOCH 17 - PROGRESS: at 84.85% examples, 335595 words/s, in_qsize 7, out_qsize 1
INFO - 2023-11-27 13:31:02,253: EPOCH 17: training on 412480 raw words (403917 effective words) took 1.2s, 343207 effective words/s
INFO - 2023-11-27 13:31:03,260: EPOCH 18 - PROGRESS: at 65.46% examples, 263259 words/s, in_qsize 15, out_qsize 0
INFO - 2023-11-27 13:31:03,590: EPOCH 18: training on 412480 raw words (403624 effective words) took 1.3s, 302641 effective words/s
INFO - 2023-11-27 13:31:04,657: EPOCH 19 - PROGRESS: at 75.16% examples, 285097 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:31:04,900: EPOCH 19: training on 412480 raw words (403903 effective words) took 1.3s, 308899 effective words/s
INFO - 2023-11-27 13:31:04,901: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8076027 effective words) took 20.8s, 388993 effective words/s', 'datetime': '2023-11-27T13:31:04.901045', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:31:04,901: collecting all words and their counts
INFO - 2023-11-27 13:31:04,901: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:31:05,002: PROGRESS: at sentence #10000, processed 400000 words, keeping 10301 word types
INFO - 2023-11-27 13:31:05,006: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:31:05,006: Updating model with new vocabulary
INFO - 2023-11-27 13:31:05,046: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:31:05.046284', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:31:05,098: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:31:05,099: sample=0.001 downsamples 30 most-common words
INFO - 2023-11-27 13:31:05,099: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403478.4231201465 word corpus (97.8%% of prior 412480)', 'datetime': '2023-11-27T13:31:05.099187', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:31:05,197: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:31:05,198: updating layer weights
INFO - 2023-11-27 13:31:05,198: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:31:05.198848', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:31:05,199: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:31:05,199: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:31:05.199104', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:31:06,259: EPOCH 0 - PROGRESS: at 50.91% examples, 194268 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:31:06,820: EPOCH 0: training on 412480 raw words (403495 effective words) took 1.6s, 249422 effective words/s
INFO - 2023-11-27 13:31:07,828: EPOCH 1 - PROGRESS: at 67.88% examples, 272734 words/s, in_qsize 14, out_qsize 0
INFO - 2023-11-27 13:31:08,225: EPOCH 1: training on 412480 raw words (403480 effective words) took 1.4s, 287974 effective words/s
INFO - 2023-11-27 13:31:09,354: EPOCH 2 - PROGRESS: at 75.16% examples, 269324 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:31:09,591: EPOCH 2: training on 412480 raw words (403485 effective words) took 1.4s, 295933 effective words/s
INFO - 2023-11-27 13:31:10,608: EPOCH 3 - PROGRESS: at 70.31% examples, 279886 words/s, in_qsize 13, out_qsize 0
INFO - 2023-11-27 13:31:10,819: EPOCH 3: training on 412480 raw words (403463 effective words) took 1.2s, 329480 effective words/s
INFO - 2023-11-27 13:31:11,720: EPOCH 4: training on 412480 raw words (403331 effective words) took 0.9s, 448458 effective words/s
INFO - 2023-11-27 13:31:12,598: EPOCH 5: training on 412480 raw words (403467 effective words) took 0.9s, 461086 effective words/s
INFO - 2023-11-27 13:31:13,564: EPOCH 6: training on 412480 raw words (403546 effective words) took 1.0s, 418674 effective words/s
INFO - 2023-11-27 13:31:14,513: EPOCH 7: training on 412480 raw words (403462 effective words) took 0.9s, 425970 effective words/s
INFO - 2023-11-27 13:31:15,408: EPOCH 8: training on 412480 raw words (403337 effective words) took 0.9s, 451891 effective words/s
INFO - 2023-11-27 13:31:16,294: EPOCH 9: training on 412480 raw words (403511 effective words) took 0.9s, 457142 effective words/s
INFO - 2023-11-27 13:31:17,185: EPOCH 10: training on 412480 raw words (403428 effective words) took 0.9s, 454095 effective words/s
INFO - 2023-11-27 13:31:18,175: EPOCH 11: training on 412480 raw words (403594 effective words) took 1.0s, 408661 effective words/s
INFO - 2023-11-27 13:31:19,081: EPOCH 12: training on 412480 raw words (403511 effective words) took 0.9s, 446614 effective words/s
INFO - 2023-11-27 13:31:19,958: EPOCH 13: training on 412480 raw words (403542 effective words) took 0.9s, 461412 effective words/s
INFO - 2023-11-27 13:31:20,844: EPOCH 14: training on 412480 raw words (403551 effective words) took 0.9s, 456536 effective words/s
INFO - 2023-11-27 13:31:21,773: EPOCH 15: training on 412480 raw words (403393 effective words) took 0.9s, 435054 effective words/s
INFO - 2023-11-27 13:31:22,625: EPOCH 16: training on 412480 raw words (403330 effective words) took 0.8s, 474755 effective words/s
INFO - 2023-11-27 13:31:23,547: EPOCH 17: training on 412480 raw words (403402 effective words) took 0.9s, 438609 effective words/s
INFO - 2023-11-27 13:31:24,496: EPOCH 18: training on 412480 raw words (403418 effective words) took 0.9s, 425829 effective words/s
INFO - 2023-11-27 13:31:25,409: EPOCH 19: training on 412480 raw words (403555 effective words) took 0.9s, 443233 effective words/s
INFO - 2023-11-27 13:31:25,409: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8069301 effective words) took 20.2s, 399265 effective words/s', 'datetime': '2023-11-27T13:31:25.409593', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:31:25,409: collecting all words and their counts
INFO - 2023-11-27 13:31:25,409: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 13:31:25,484: PROGRESS: at sentence #10000, processed 400000 words, keeping 10304 word types
INFO - 2023-11-27 13:31:25,488: collected 10312 word types from a corpus of 412480 raw words and 10312 sentences
INFO - 2023-11-27 13:31:25,488: Updating model with new vocabulary
INFO - 2023-11-27 13:31:25,527: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 10312) and increased the count of 10312 pre-existing words (100.00% of original 10312)', 'datetime': '2023-11-27T13:31:25.527566', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:31:25,564: deleting the raw counts dictionary of 10312 items
INFO - 2023-11-27 13:31:25,565: sample=0.001 downsamples 28 most-common words
INFO - 2023-11-27 13:31:25,565: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 403750.534823983 word corpus (97.9%% of prior 412480)', 'datetime': '2023-11-27T13:31:25.565172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 13:31:25,642: estimated required memory for 10312 words and 128 dimensions: 15715488 bytes
INFO - 2023-11-27 13:31:25,642: updating layer weights
INFO - 2023-11-27 13:31:25,643: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T13:31:25.643506', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 13:31:25,643: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 13:31:25,643: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 10312 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T13:31:25.643697', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:31:26,667: EPOCH 0 - PROGRESS: at 100.00% examples, 395158 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:31:26,667: EPOCH 0: training on 412480 raw words (403550 effective words) took 1.0s, 395081 effective words/s
INFO - 2023-11-27 13:31:27,687: EPOCH 1 - PROGRESS: at 100.00% examples, 396276 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:31:27,688: EPOCH 1: training on 412480 raw words (403723 effective words) took 1.0s, 396186 effective words/s
INFO - 2023-11-27 13:31:28,627: EPOCH 2: training on 412480 raw words (403657 effective words) took 0.9s, 440827 effective words/s
INFO - 2023-11-27 13:31:29,537: EPOCH 3: training on 412480 raw words (403793 effective words) took 0.9s, 444787 effective words/s
INFO - 2023-11-27 13:31:30,446: EPOCH 4: training on 412480 raw words (403769 effective words) took 0.9s, 445066 effective words/s
INFO - 2023-11-27 13:31:31,381: EPOCH 5: training on 412480 raw words (403724 effective words) took 0.9s, 432801 effective words/s
INFO - 2023-11-27 13:31:32,505: EPOCH 6 - PROGRESS: at 77.58% examples, 282114 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:31:32,684: EPOCH 6: training on 412480 raw words (403728 effective words) took 1.3s, 313093 effective words/s
INFO - 2023-11-27 13:31:33,716: EPOCH 7 - PROGRESS: at 58.18% examples, 228366 words/s, in_qsize 18, out_qsize 0
INFO - 2023-11-27 13:31:34,140: EPOCH 7: training on 412480 raw words (403859 effective words) took 1.5s, 277875 effective words/s
INFO - 2023-11-27 13:31:35,148: EPOCH 8 - PROGRESS: at 58.18% examples, 233882 words/s, in_qsize 18, out_qsize 0
INFO - 2023-11-27 13:31:35,560: EPOCH 8: training on 412480 raw words (403654 effective words) took 1.4s, 285031 effective words/s
INFO - 2023-11-27 13:31:36,743: EPOCH 9 - PROGRESS: at 75.16% examples, 257200 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:31:36,981: EPOCH 9: training on 412480 raw words (403666 effective words) took 1.4s, 284718 effective words/s
INFO - 2023-11-27 13:31:38,002: EPOCH 10 - PROGRESS: at 60.61% examples, 240580 words/s, in_qsize 17, out_qsize 0
INFO - 2023-11-27 13:31:38,459: EPOCH 10: training on 412480 raw words (403769 effective words) took 1.5s, 274010 effective words/s
INFO - 2023-11-27 13:31:39,486: EPOCH 11 - PROGRESS: at 50.91% examples, 200780 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:31:40,055: EPOCH 11: training on 412480 raw words (403720 effective words) took 1.6s, 253367 effective words/s
INFO - 2023-11-27 13:31:41,101: EPOCH 12 - PROGRESS: at 50.91% examples, 197248 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:31:41,751: EPOCH 12: training on 412480 raw words (403725 effective words) took 1.7s, 238581 effective words/s
INFO - 2023-11-27 13:31:42,903: EPOCH 13 - PROGRESS: at 55.76% examples, 197043 words/s, in_qsize 19, out_qsize 0
INFO - 2023-11-27 13:31:43,423: EPOCH 13: training on 412480 raw words (403770 effective words) took 1.7s, 242872 effective words/s
INFO - 2023-11-27 13:31:44,544: EPOCH 14 - PROGRESS: at 75.16% examples, 271765 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:31:44,745: EPOCH 14: training on 412480 raw words (403810 effective words) took 1.3s, 306382 effective words/s
INFO - 2023-11-27 13:31:45,786: EPOCH 15 - PROGRESS: at 77.58% examples, 301831 words/s, in_qsize 10, out_qsize 0
INFO - 2023-11-27 13:31:45,956: EPOCH 15: training on 412480 raw words (403722 effective words) took 1.2s, 334340 effective words/s
INFO - 2023-11-27 13:31:47,002: EPOCH 16 - PROGRESS: at 75.16% examples, 290856 words/s, in_qsize 11, out_qsize 0
INFO - 2023-11-27 13:31:47,188: EPOCH 16: training on 412480 raw words (403760 effective words) took 1.2s, 328293 effective words/s
INFO - 2023-11-27 13:31:48,113: EPOCH 17: training on 412480 raw words (403763 effective words) took 0.9s, 437405 effective words/s
INFO - 2023-11-27 13:31:49,144: EPOCH 18 - PROGRESS: at 100.00% examples, 392663 words/s, in_qsize 0, out_qsize 1
INFO - 2023-11-27 13:31:49,144: EPOCH 18: training on 412480 raw words (403721 effective words) took 1.0s, 392588 effective words/s
INFO - 2023-11-27 13:31:50,095: EPOCH 19: training on 412480 raw words (403789 effective words) took 0.9s, 425671 effective words/s
INFO - 2023-11-27 13:31:50,095: Word2Vec lifecycle event {'msg': 'training on 8249600 raw words (8074672 effective words) took 24.5s, 330232 effective words/s', 'datetime': '2023-11-27T13:31:50.095269', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 13:31:50,101: storing 10312x128 projection weights into blogcatalog.txt
