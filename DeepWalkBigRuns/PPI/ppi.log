INFO - 2023-11-27 12:04:37,457: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-27T12:04:37.448056', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-27 12:04:37,458: collecting all words and their counts
INFO - 2023-11-27 12:04:37,458: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:04:37,488: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:04:37,488: Creating a fresh vocabulary
INFO - 2023-11-27 12:04:37,497: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 3890 unique words (100.00% of original 3890, drops 0)', 'datetime': '2023-11-27T12:04:37.497920', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:37,498: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 155600 word corpus (100.00% of original 155600, drops 0)', 'datetime': '2023-11-27T12:04:37.498122', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:37,513: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:04:37,514: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:04:37,514: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152013.75665961055 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:04:37.514203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:37,535: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:04:37,535: resetting layer weights
INFO - 2023-11-27 12:04:37,537: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-27T12:04:37.537933', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-27 12:04:37,538: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:04:37.538161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:04:37,897: EPOCH 0: training on 155600 raw words (151980 effective words) took 0.4s, 426189 effective words/s
INFO - 2023-11-27 12:04:38,312: EPOCH 1: training on 155600 raw words (151935 effective words) took 0.4s, 367874 effective words/s
INFO - 2023-11-27 12:04:38,673: EPOCH 2: training on 155600 raw words (152028 effective words) took 0.4s, 424376 effective words/s
INFO - 2023-11-27 12:04:39,052: EPOCH 3: training on 155600 raw words (152066 effective words) took 0.4s, 403245 effective words/s
INFO - 2023-11-27 12:04:39,416: EPOCH 4: training on 155600 raw words (152011 effective words) took 0.4s, 420600 effective words/s
INFO - 2023-11-27 12:04:39,788: EPOCH 5: training on 155600 raw words (151932 effective words) took 0.4s, 411542 effective words/s
INFO - 2023-11-27 12:04:40,144: EPOCH 6: training on 155600 raw words (152022 effective words) took 0.4s, 430074 effective words/s
INFO - 2023-11-27 12:04:40,508: EPOCH 7: training on 155600 raw words (152096 effective words) took 0.4s, 420201 effective words/s
INFO - 2023-11-27 12:04:40,891: EPOCH 8: training on 155600 raw words (152014 effective words) took 0.4s, 404032 effective words/s
INFO - 2023-11-27 12:04:41,268: EPOCH 9: training on 155600 raw words (151948 effective words) took 0.4s, 405555 effective words/s
INFO - 2023-11-27 12:04:41,637: EPOCH 10: training on 155600 raw words (151911 effective words) took 0.4s, 414194 effective words/s
INFO - 2023-11-27 12:04:42,002: EPOCH 11: training on 155600 raw words (151909 effective words) took 0.4s, 419793 effective words/s
INFO - 2023-11-27 12:04:42,365: EPOCH 12: training on 155600 raw words (151992 effective words) took 0.4s, 421776 effective words/s
INFO - 2023-11-27 12:04:42,716: EPOCH 13: training on 155600 raw words (151992 effective words) took 0.3s, 435080 effective words/s
INFO - 2023-11-27 12:04:43,077: EPOCH 14: training on 155600 raw words (152086 effective words) took 0.4s, 424475 effective words/s
INFO - 2023-11-27 12:04:43,428: EPOCH 15: training on 155600 raw words (152097 effective words) took 0.3s, 436558 effective words/s
INFO - 2023-11-27 12:04:43,806: EPOCH 16: training on 155600 raw words (152010 effective words) took 0.4s, 423283 effective words/s
INFO - 2023-11-27 12:04:44,160: EPOCH 17: training on 155600 raw words (151964 effective words) took 0.4s, 431846 effective words/s
INFO - 2023-11-27 12:04:44,538: EPOCH 18: training on 155600 raw words (152008 effective words) took 0.4s, 404368 effective words/s
INFO - 2023-11-27 12:04:44,931: EPOCH 19: training on 155600 raw words (151926 effective words) took 0.4s, 388430 effective words/s
INFO - 2023-11-27 12:04:44,932: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039927 effective words) took 7.4s, 411140 effective words/s', 'datetime': '2023-11-27T12:04:44.932201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:04:44,932: collecting all words and their counts
INFO - 2023-11-27 12:04:44,932: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:04:44,954: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:04:44,954: Updating model with new vocabulary
INFO - 2023-11-27 12:04:44,964: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:04:44.964805', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:44,978: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:04:44,978: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:04:44,978: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151930.98526490218 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:04:44.978807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:45,004: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:04:45,004: updating layer weights
INFO - 2023-11-27 12:04:45,006: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:04:45.006037', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:04:45,006: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:04:45,006: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:04:45.006335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:04:45,356: EPOCH 0: training on 155600 raw words (151963 effective words) took 0.3s, 452063 effective words/s
INFO - 2023-11-27 12:04:45,688: EPOCH 1: training on 155600 raw words (151948 effective words) took 0.3s, 462126 effective words/s
INFO - 2023-11-27 12:04:46,031: EPOCH 2: training on 155600 raw words (151974 effective words) took 0.3s, 445846 effective words/s
INFO - 2023-11-27 12:04:46,365: EPOCH 3: training on 155600 raw words (151950 effective words) took 0.3s, 458730 effective words/s
INFO - 2023-11-27 12:04:46,751: EPOCH 4: training on 155600 raw words (152006 effective words) took 0.4s, 396582 effective words/s
INFO - 2023-11-27 12:04:47,078: EPOCH 5: training on 155600 raw words (151981 effective words) took 0.3s, 467508 effective words/s
INFO - 2023-11-27 12:04:47,452: EPOCH 6: training on 155600 raw words (151953 effective words) took 0.4s, 408998 effective words/s
INFO - 2023-11-27 12:04:47,789: EPOCH 7: training on 155600 raw words (151924 effective words) took 0.3s, 453663 effective words/s
INFO - 2023-11-27 12:04:48,134: EPOCH 8: training on 155600 raw words (151907 effective words) took 0.3s, 443168 effective words/s
INFO - 2023-11-27 12:04:48,464: EPOCH 9: training on 155600 raw words (151898 effective words) took 0.3s, 464979 effective words/s
INFO - 2023-11-27 12:04:48,851: EPOCH 10: training on 155600 raw words (151904 effective words) took 0.4s, 394324 effective words/s
INFO - 2023-11-27 12:04:49,249: EPOCH 11: training on 155600 raw words (151953 effective words) took 0.4s, 384779 effective words/s
INFO - 2023-11-27 12:04:49,605: EPOCH 12: training on 155600 raw words (151915 effective words) took 0.4s, 431642 effective words/s
INFO - 2023-11-27 12:04:49,957: EPOCH 13: training on 155600 raw words (152020 effective words) took 0.3s, 434751 effective words/s
INFO - 2023-11-27 12:04:50,326: EPOCH 14: training on 155600 raw words (151912 effective words) took 0.4s, 414034 effective words/s
INFO - 2023-11-27 12:04:50,660: EPOCH 15: training on 155600 raw words (151934 effective words) took 0.3s, 458142 effective words/s
INFO - 2023-11-27 12:04:51,017: EPOCH 16: training on 155600 raw words (152017 effective words) took 0.4s, 428868 effective words/s
INFO - 2023-11-27 12:04:51,429: EPOCH 17: training on 155600 raw words (151917 effective words) took 0.4s, 370754 effective words/s
INFO - 2023-11-27 12:04:51,878: EPOCH 18: training on 155600 raw words (151881 effective words) took 0.4s, 339917 effective words/s
INFO - 2023-11-27 12:04:52,309: EPOCH 19: training on 155600 raw words (151995 effective words) took 0.4s, 355360 effective words/s
INFO - 2023-11-27 12:04:52,310: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038952 effective words) took 7.3s, 416092 effective words/s', 'datetime': '2023-11-27T12:04:52.310032', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:04:52,310: collecting all words and their counts
INFO - 2023-11-27 12:04:52,310: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:04:52,343: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:04:52,343: Updating model with new vocabulary
INFO - 2023-11-27 12:04:52,358: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:04:52.358125', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:52,377: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:04:52,377: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:04:52,377: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151967.3419728366 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:04:52.377599', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:04:52,404: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:04:52,404: updating layer weights
INFO - 2023-11-27 12:04:52,405: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:04:52.405779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:04:52,405: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:04:52,406: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:04:52.406169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:04:52,933: EPOCH 0: training on 155600 raw words (151886 effective words) took 0.5s, 289601 effective words/s
INFO - 2023-11-27 12:04:53,415: EPOCH 1: training on 155600 raw words (151866 effective words) took 0.5s, 317470 effective words/s
INFO - 2023-11-27 12:04:53,925: EPOCH 2: training on 155600 raw words (151981 effective words) took 0.5s, 300122 effective words/s
INFO - 2023-11-27 12:04:54,423: EPOCH 3: training on 155600 raw words (152031 effective words) took 0.5s, 307063 effective words/s
INFO - 2023-11-27 12:04:54,925: EPOCH 4: training on 155600 raw words (151951 effective words) took 0.5s, 304171 effective words/s
INFO - 2023-11-27 12:04:55,425: EPOCH 5: training on 155600 raw words (151993 effective words) took 0.5s, 312174 effective words/s
INFO - 2023-11-27 12:04:55,927: EPOCH 6: training on 155600 raw words (152040 effective words) took 0.5s, 305201 effective words/s
INFO - 2023-11-27 12:04:56,372: EPOCH 7: training on 155600 raw words (151943 effective words) took 0.4s, 343688 effective words/s
INFO - 2023-11-27 12:04:56,796: EPOCH 8: training on 155600 raw words (151878 effective words) took 0.4s, 372647 effective words/s
INFO - 2023-11-27 12:04:57,165: EPOCH 9: training on 155600 raw words (151957 effective words) took 0.4s, 415004 effective words/s
INFO - 2023-11-27 12:04:57,555: EPOCH 10: training on 155600 raw words (151917 effective words) took 0.4s, 392675 effective words/s
INFO - 2023-11-27 12:04:57,942: EPOCH 11: training on 155600 raw words (151927 effective words) took 0.4s, 395385 effective words/s
INFO - 2023-11-27 12:04:58,324: EPOCH 12: training on 155600 raw words (152000 effective words) took 0.4s, 400930 effective words/s
INFO - 2023-11-27 12:04:58,704: EPOCH 13: training on 155600 raw words (151995 effective words) took 0.4s, 402054 effective words/s
INFO - 2023-11-27 12:04:59,087: EPOCH 14: training on 155600 raw words (151920 effective words) took 0.4s, 399244 effective words/s
INFO - 2023-11-27 12:04:59,475: EPOCH 15: training on 155600 raw words (151888 effective words) took 0.4s, 399836 effective words/s
INFO - 2023-11-27 12:04:59,874: EPOCH 16: training on 155600 raw words (151910 effective words) took 0.4s, 382758 effective words/s
INFO - 2023-11-27 12:05:00,238: EPOCH 17: training on 155600 raw words (151978 effective words) took 0.4s, 420695 effective words/s
INFO - 2023-11-27 12:05:00,620: EPOCH 18: training on 155600 raw words (152082 effective words) took 0.4s, 400411 effective words/s
INFO - 2023-11-27 12:05:00,978: EPOCH 19: training on 155600 raw words (152020 effective words) took 0.4s, 428495 effective words/s
INFO - 2023-11-27 12:05:00,978: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039163 effective words) took 8.6s, 354536 effective words/s', 'datetime': '2023-11-27T12:05:00.978565', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:00,978: collecting all words and their counts
INFO - 2023-11-27 12:05:00,979: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:01,002: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:01,002: Updating model with new vocabulary
INFO - 2023-11-27 12:05:01,013: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:01.013453', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:01,025: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:01,025: sample=0.001 downsamples 25 most-common words
INFO - 2023-11-27 12:05:01,025: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151950.2072630272 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:05:01.025931', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:01,044: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:01,044: updating layer weights
INFO - 2023-11-27 12:05:01,045: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:01.045079', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:01,045: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:01,045: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:01.045263', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:01,375: EPOCH 0: training on 155600 raw words (151917 effective words) took 0.3s, 486634 effective words/s
INFO - 2023-11-27 12:05:01,717: EPOCH 1: training on 155600 raw words (151909 effective words) took 0.3s, 447847 effective words/s
INFO - 2023-11-27 12:05:02,071: EPOCH 2: training on 155600 raw words (151967 effective words) took 0.4s, 432674 effective words/s
INFO - 2023-11-27 12:05:02,397: EPOCH 3: training on 155600 raw words (151988 effective words) took 0.3s, 469827 effective words/s
INFO - 2023-11-27 12:05:02,755: EPOCH 4: training on 155600 raw words (151944 effective words) took 0.4s, 428679 effective words/s
INFO - 2023-11-27 12:05:03,114: EPOCH 5: training on 155600 raw words (151981 effective words) took 0.4s, 425984 effective words/s
INFO - 2023-11-27 12:05:03,465: EPOCH 6: training on 155600 raw words (151930 effective words) took 0.3s, 435421 effective words/s
INFO - 2023-11-27 12:05:03,850: EPOCH 7: training on 155600 raw words (151921 effective words) took 0.4s, 398286 effective words/s
INFO - 2023-11-27 12:05:04,199: EPOCH 8: training on 155600 raw words (152004 effective words) took 0.3s, 438988 effective words/s
INFO - 2023-11-27 12:05:04,557: EPOCH 9: training on 155600 raw words (152004 effective words) took 0.4s, 426880 effective words/s
INFO - 2023-11-27 12:05:04,933: EPOCH 10: training on 155600 raw words (151908 effective words) took 0.4s, 406778 effective words/s
INFO - 2023-11-27 12:05:05,304: EPOCH 11: training on 155600 raw words (151975 effective words) took 0.4s, 411504 effective words/s
INFO - 2023-11-27 12:05:05,652: EPOCH 12: training on 155600 raw words (151997 effective words) took 0.3s, 439748 effective words/s
INFO - 2023-11-27 12:05:05,997: EPOCH 13: training on 155600 raw words (152076 effective words) took 0.3s, 444425 effective words/s
INFO - 2023-11-27 12:05:06,369: EPOCH 14: training on 155600 raw words (151993 effective words) took 0.4s, 412887 effective words/s
INFO - 2023-11-27 12:05:06,746: EPOCH 15: training on 155600 raw words (151838 effective words) took 0.4s, 404883 effective words/s
INFO - 2023-11-27 12:05:07,131: EPOCH 16: training on 155600 raw words (152010 effective words) took 0.4s, 399242 effective words/s
INFO - 2023-11-27 12:05:07,508: EPOCH 17: training on 155600 raw words (151974 effective words) took 0.4s, 405292 effective words/s
INFO - 2023-11-27 12:05:07,855: EPOCH 18: training on 155600 raw words (151940 effective words) took 0.3s, 441888 effective words/s
INFO - 2023-11-27 12:05:08,230: EPOCH 19: training on 155600 raw words (152016 effective words) took 0.4s, 407534 effective words/s
INFO - 2023-11-27 12:05:08,231: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039292 effective words) took 7.2s, 422957 effective words/s', 'datetime': '2023-11-27T12:05:08.231186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:08,231: collecting all words and their counts
INFO - 2023-11-27 12:05:08,231: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:08,258: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:08,258: Updating model with new vocabulary
INFO - 2023-11-27 12:05:08,269: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:08.269867', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:08,282: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:08,282: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:05:08,283: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151777.06436821446 word corpus (97.5%% of prior 155600)', 'datetime': '2023-11-27T12:05:08.283089', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:08,302: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:08,302: updating layer weights
INFO - 2023-11-27 12:05:08,302: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:08.302873', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:08,303: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:08,303: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:08.303151', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:08,655: EPOCH 0: training on 155600 raw words (151746 effective words) took 0.3s, 433640 effective words/s
INFO - 2023-11-27 12:05:09,043: EPOCH 1: training on 155600 raw words (151928 effective words) took 0.4s, 393821 effective words/s
INFO - 2023-11-27 12:05:09,421: EPOCH 2: training on 155600 raw words (151745 effective words) took 0.4s, 404340 effective words/s
INFO - 2023-11-27 12:05:09,828: EPOCH 3: training on 155600 raw words (151781 effective words) took 0.4s, 376986 effective words/s
INFO - 2023-11-27 12:05:10,203: EPOCH 4: training on 155600 raw words (151740 effective words) took 0.4s, 407770 effective words/s
INFO - 2023-11-27 12:05:10,595: EPOCH 5: training on 155600 raw words (151738 effective words) took 0.4s, 388388 effective words/s
INFO - 2023-11-27 12:05:10,964: EPOCH 6: training on 155600 raw words (151749 effective words) took 0.4s, 413844 effective words/s
INFO - 2023-11-27 12:05:11,315: EPOCH 7: training on 155600 raw words (151752 effective words) took 0.3s, 435858 effective words/s
INFO - 2023-11-27 12:05:11,699: EPOCH 8: training on 155600 raw words (151805 effective words) took 0.4s, 397869 effective words/s
INFO - 2023-11-27 12:05:12,079: EPOCH 9: training on 155600 raw words (151840 effective words) took 0.4s, 401619 effective words/s
INFO - 2023-11-27 12:05:12,490: EPOCH 10: training on 155600 raw words (151868 effective words) took 0.4s, 371741 effective words/s
INFO - 2023-11-27 12:05:12,973: EPOCH 11: training on 155600 raw words (151777 effective words) took 0.5s, 316627 effective words/s
INFO - 2023-11-27 12:05:13,500: EPOCH 12: training on 155600 raw words (151752 effective words) took 0.5s, 300948 effective words/s
INFO - 2023-11-27 12:05:13,996: EPOCH 13: training on 155600 raw words (151777 effective words) took 0.5s, 307967 effective words/s
INFO - 2023-11-27 12:05:14,769: EPOCH 14: training on 155600 raw words (151797 effective words) took 0.8s, 197151 effective words/s
INFO - 2023-11-27 12:05:15,354: EPOCH 15: training on 155600 raw words (151752 effective words) took 0.6s, 262385 effective words/s
INFO - 2023-11-27 12:05:15,883: EPOCH 16: training on 155600 raw words (151772 effective words) took 0.5s, 289050 effective words/s
INFO - 2023-11-27 12:05:16,408: EPOCH 17: training on 155600 raw words (151748 effective words) took 0.5s, 290376 effective words/s
INFO - 2023-11-27 12:05:16,961: EPOCH 18: training on 155600 raw words (151888 effective words) took 0.5s, 277411 effective words/s
INFO - 2023-11-27 12:05:17,518: EPOCH 19: training on 155600 raw words (151720 effective words) took 0.6s, 274554 effective words/s
INFO - 2023-11-27 12:05:17,518: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3035675 effective words) took 9.2s, 329426 effective words/s', 'datetime': '2023-11-27T12:05:17.518353', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:17,518: collecting all words and their counts
INFO - 2023-11-27 12:05:17,518: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:17,556: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:17,556: Updating model with new vocabulary
INFO - 2023-11-27 12:05:17,573: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:17.573915', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:17,598: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:17,599: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:05:17,599: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151944.22497465418 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:05:17.599315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:17,631: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:17,631: updating layer weights
INFO - 2023-11-27 12:05:17,632: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:17.632119', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:17,632: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:17,632: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:17.632415', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:18,152: EPOCH 0: training on 155600 raw words (152024 effective words) took 0.5s, 295189 effective words/s
INFO - 2023-11-27 12:05:18,668: EPOCH 1: training on 155600 raw words (151967 effective words) took 0.5s, 296330 effective words/s
INFO - 2023-11-27 12:05:19,196: EPOCH 2: training on 155600 raw words (151953 effective words) took 0.5s, 290091 effective words/s
INFO - 2023-11-27 12:05:19,725: EPOCH 3: training on 155600 raw words (151831 effective words) took 0.5s, 288791 effective words/s
INFO - 2023-11-27 12:05:20,262: EPOCH 4: training on 155600 raw words (151850 effective words) took 0.5s, 284438 effective words/s
INFO - 2023-11-27 12:05:20,779: EPOCH 5: training on 155600 raw words (151916 effective words) took 0.5s, 295708 effective words/s
INFO - 2023-11-27 12:05:21,331: EPOCH 6: training on 155600 raw words (151951 effective words) took 0.5s, 276896 effective words/s
INFO - 2023-11-27 12:05:21,814: EPOCH 7: training on 155600 raw words (151949 effective words) took 0.5s, 316710 effective words/s
INFO - 2023-11-27 12:05:22,309: EPOCH 8: training on 155600 raw words (151957 effective words) took 0.5s, 309011 effective words/s
INFO - 2023-11-27 12:05:22,827: EPOCH 9: training on 155600 raw words (151876 effective words) took 0.5s, 296070 effective words/s
INFO - 2023-11-27 12:05:23,326: EPOCH 10: training on 155600 raw words (151966 effective words) took 0.5s, 306100 effective words/s
INFO - 2023-11-27 12:05:23,779: EPOCH 11: training on 155600 raw words (151984 effective words) took 0.4s, 338005 effective words/s
INFO - 2023-11-27 12:05:24,213: EPOCH 12: training on 155600 raw words (151944 effective words) took 0.4s, 352830 effective words/s
INFO - 2023-11-27 12:05:24,619: EPOCH 13: training on 155600 raw words (152013 effective words) took 0.4s, 377332 effective words/s
INFO - 2023-11-27 12:05:25,031: EPOCH 14: training on 155600 raw words (151958 effective words) took 0.4s, 371203 effective words/s
INFO - 2023-11-27 12:05:25,388: EPOCH 15: training on 155600 raw words (151922 effective words) took 0.4s, 430416 effective words/s
INFO - 2023-11-27 12:05:25,741: EPOCH 16: training on 155600 raw words (151929 effective words) took 0.4s, 432418 effective words/s
INFO - 2023-11-27 12:05:26,161: EPOCH 17: training on 155600 raw words (151935 effective words) took 0.4s, 364226 effective words/s
INFO - 2023-11-27 12:05:26,476: EPOCH 18: training on 155600 raw words (151924 effective words) took 0.3s, 514086 effective words/s
INFO - 2023-11-27 12:05:26,793: EPOCH 19: training on 155600 raw words (151916 effective words) took 0.3s, 482670 effective words/s
INFO - 2023-11-27 12:05:26,794: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038765 effective words) took 9.2s, 331691 effective words/s', 'datetime': '2023-11-27T12:05:26.793994', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:26,794: collecting all words and their counts
INFO - 2023-11-27 12:05:26,794: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:26,816: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:26,816: Updating model with new vocabulary
INFO - 2023-11-27 12:05:26,826: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:26.826588', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:26,839: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:26,839: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:05:26,839: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151928.36333901962 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:05:26.839386', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:26,857: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:26,857: updating layer weights
INFO - 2023-11-27 12:05:26,857: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:26.857601', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:26,857: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:26,857: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:26.857781', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:27,189: EPOCH 0: training on 155600 raw words (151877 effective words) took 0.3s, 460584 effective words/s
INFO - 2023-11-27 12:05:27,561: EPOCH 1: training on 155600 raw words (151879 effective words) took 0.4s, 410839 effective words/s
INFO - 2023-11-27 12:05:27,923: EPOCH 2: training on 155600 raw words (151943 effective words) took 0.4s, 422272 effective words/s
INFO - 2023-11-27 12:05:28,312: EPOCH 3: training on 155600 raw words (151918 effective words) took 0.4s, 393275 effective words/s
INFO - 2023-11-27 12:05:28,697: EPOCH 4: training on 155600 raw words (151954 effective words) took 0.4s, 397129 effective words/s
INFO - 2023-11-27 12:05:29,054: EPOCH 5: training on 155600 raw words (151805 effective words) took 0.4s, 428453 effective words/s
INFO - 2023-11-27 12:05:29,419: EPOCH 6: training on 155600 raw words (151868 effective words) took 0.4s, 418491 effective words/s
INFO - 2023-11-27 12:05:29,774: EPOCH 7: training on 155600 raw words (152010 effective words) took 0.4s, 431506 effective words/s
INFO - 2023-11-27 12:05:30,150: EPOCH 8: training on 155600 raw words (151980 effective words) took 0.4s, 406285 effective words/s
INFO - 2023-11-27 12:05:30,636: EPOCH 9: training on 155600 raw words (151853 effective words) took 0.5s, 315930 effective words/s
INFO - 2023-11-27 12:05:31,119: EPOCH 10: training on 155600 raw words (151884 effective words) took 0.5s, 316631 effective words/s
INFO - 2023-11-27 12:05:31,495: EPOCH 11: training on 155600 raw words (151929 effective words) took 0.4s, 406476 effective words/s
INFO - 2023-11-27 12:05:31,891: EPOCH 12: training on 155600 raw words (151937 effective words) took 0.4s, 386376 effective words/s
INFO - 2023-11-27 12:05:32,257: EPOCH 13: training on 155600 raw words (151944 effective words) took 0.4s, 420393 effective words/s
INFO - 2023-11-27 12:05:32,638: EPOCH 14: training on 155600 raw words (151977 effective words) took 0.4s, 401999 effective words/s
INFO - 2023-11-27 12:05:33,012: EPOCH 15: training on 155600 raw words (151909 effective words) took 0.3s, 436045 effective words/s
INFO - 2023-11-27 12:05:33,376: EPOCH 16: training on 155600 raw words (151937 effective words) took 0.4s, 420920 effective words/s
INFO - 2023-11-27 12:05:33,743: EPOCH 17: training on 155600 raw words (151902 effective words) took 0.4s, 415627 effective words/s
INFO - 2023-11-27 12:05:34,123: EPOCH 18: training on 155600 raw words (151914 effective words) took 0.4s, 402800 effective words/s
INFO - 2023-11-27 12:05:34,493: EPOCH 19: training on 155600 raw words (151867 effective words) took 0.4s, 413342 effective words/s
INFO - 2023-11-27 12:05:34,493: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038287 effective words) took 7.6s, 397920 effective words/s', 'datetime': '2023-11-27T12:05:34.493310', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:34,493: collecting all words and their counts
INFO - 2023-11-27 12:05:34,493: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:34,516: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:34,516: Updating model with new vocabulary
INFO - 2023-11-27 12:05:34,528: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:34.528268', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:34,541: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:34,541: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:05:34,541: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152066.74782153728 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:05:34.541797', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:34,566: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:34,566: updating layer weights
INFO - 2023-11-27 12:05:34,567: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:34.567333', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:34,567: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:34,567: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:34.567555', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:34,925: EPOCH 0: training on 155600 raw words (152094 effective words) took 0.4s, 434091 effective words/s
INFO - 2023-11-27 12:05:35,292: EPOCH 1: training on 155600 raw words (152115 effective words) took 0.3s, 437312 effective words/s
INFO - 2023-11-27 12:05:35,654: EPOCH 2: training on 155600 raw words (152085 effective words) took 0.4s, 423472 effective words/s
INFO - 2023-11-27 12:05:36,077: EPOCH 3: training on 155600 raw words (152042 effective words) took 0.4s, 360920 effective words/s
INFO - 2023-11-27 12:05:36,424: EPOCH 4: training on 155600 raw words (152121 effective words) took 0.3s, 442628 effective words/s
INFO - 2023-11-27 12:05:36,781: EPOCH 5: training on 155600 raw words (152071 effective words) took 0.4s, 428462 effective words/s
INFO - 2023-11-27 12:05:37,124: EPOCH 6: training on 155600 raw words (151996 effective words) took 0.3s, 454743 effective words/s
INFO - 2023-11-27 12:05:37,468: EPOCH 7: training on 155600 raw words (152169 effective words) took 0.3s, 446412 effective words/s
INFO - 2023-11-27 12:05:37,834: EPOCH 8: training on 155600 raw words (151951 effective words) took 0.4s, 417326 effective words/s
INFO - 2023-11-27 12:05:38,181: EPOCH 9: training on 155600 raw words (152084 effective words) took 0.3s, 441182 effective words/s
INFO - 2023-11-27 12:05:38,538: EPOCH 10: training on 155600 raw words (152103 effective words) took 0.4s, 428921 effective words/s
INFO - 2023-11-27 12:05:38,926: EPOCH 11: training on 155600 raw words (152071 effective words) took 0.4s, 395508 effective words/s
INFO - 2023-11-27 12:05:39,264: EPOCH 12: training on 155600 raw words (152057 effective words) took 0.3s, 457387 effective words/s
INFO - 2023-11-27 12:05:39,613: EPOCH 13: training on 155600 raw words (152101 effective words) took 0.3s, 440605 effective words/s
INFO - 2023-11-27 12:05:39,991: EPOCH 14: training on 155600 raw words (152115 effective words) took 0.4s, 404375 effective words/s
INFO - 2023-11-27 12:05:40,334: EPOCH 15: training on 155600 raw words (151959 effective words) took 0.3s, 446155 effective words/s
INFO - 2023-11-27 12:05:40,689: EPOCH 16: training on 155600 raw words (152026 effective words) took 0.4s, 431822 effective words/s
INFO - 2023-11-27 12:05:41,042: EPOCH 17: training on 155600 raw words (151989 effective words) took 0.4s, 433072 effective words/s
INFO - 2023-11-27 12:05:41,388: EPOCH 18: training on 155600 raw words (152027 effective words) took 0.3s, 443538 effective words/s
INFO - 2023-11-27 12:05:41,732: EPOCH 19: training on 155600 raw words (152086 effective words) took 0.3s, 444494 effective words/s
INFO - 2023-11-27 12:05:41,733: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3041262 effective words) took 7.2s, 424443 effective words/s', 'datetime': '2023-11-27T12:05:41.732973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:41,733: collecting all words and their counts
INFO - 2023-11-27 12:05:41,733: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:41,766: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:41,766: Updating model with new vocabulary
INFO - 2023-11-27 12:05:41,777: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:41.777768', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:41,796: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:41,797: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:05:41,797: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151962.1595032709 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:05:41.797174', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:41,818: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:41,818: updating layer weights
INFO - 2023-11-27 12:05:41,819: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:41.819461', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:41,819: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:41,819: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:41.819839', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:42,194: EPOCH 0: training on 155600 raw words (151989 effective words) took 0.4s, 408143 effective words/s
INFO - 2023-11-27 12:05:42,580: EPOCH 1: training on 155600 raw words (152031 effective words) took 0.4s, 396359 effective words/s
INFO - 2023-11-27 12:05:42,945: EPOCH 2: training on 155600 raw words (152010 effective words) took 0.4s, 419338 effective words/s
INFO - 2023-11-27 12:05:43,309: EPOCH 3: training on 155600 raw words (152019 effective words) took 0.4s, 420586 effective words/s
INFO - 2023-11-27 12:05:43,713: EPOCH 4: training on 155600 raw words (151853 effective words) took 0.4s, 377716 effective words/s
INFO - 2023-11-27 12:05:44,115: EPOCH 5: training on 155600 raw words (151916 effective words) took 0.4s, 380934 effective words/s
INFO - 2023-11-27 12:05:44,497: EPOCH 6: training on 155600 raw words (152052 effective words) took 0.4s, 403312 effective words/s
INFO - 2023-11-27 12:05:44,859: EPOCH 7: training on 155600 raw words (152002 effective words) took 0.4s, 421909 effective words/s
INFO - 2023-11-27 12:05:45,246: EPOCH 8: training on 155600 raw words (151878 effective words) took 0.4s, 395588 effective words/s
INFO - 2023-11-27 12:05:45,693: EPOCH 9: training on 155600 raw words (151956 effective words) took 0.4s, 341723 effective words/s
INFO - 2023-11-27 12:05:46,200: EPOCH 10: training on 155600 raw words (151855 effective words) took 0.5s, 301262 effective words/s
INFO - 2023-11-27 12:05:46,698: EPOCH 11: training on 155600 raw words (151973 effective words) took 0.5s, 307460 effective words/s
INFO - 2023-11-27 12:05:47,188: EPOCH 12: training on 155600 raw words (151900 effective words) took 0.5s, 312691 effective words/s
INFO - 2023-11-27 12:05:47,657: EPOCH 13: training on 155600 raw words (152006 effective words) took 0.5s, 325670 effective words/s
INFO - 2023-11-27 12:05:48,163: EPOCH 14: training on 155600 raw words (151980 effective words) took 0.5s, 310071 effective words/s
INFO - 2023-11-27 12:05:48,689: EPOCH 15: training on 155600 raw words (151934 effective words) took 0.5s, 301877 effective words/s
INFO - 2023-11-27 12:05:49,237: EPOCH 16: training on 155600 raw words (151998 effective words) took 0.5s, 279043 effective words/s
INFO - 2023-11-27 12:05:49,784: EPOCH 17: training on 155600 raw words (152003 effective words) took 0.5s, 283494 effective words/s
INFO - 2023-11-27 12:05:50,331: EPOCH 18: training on 155600 raw words (151872 effective words) took 0.5s, 279267 effective words/s
INFO - 2023-11-27 12:05:50,884: EPOCH 19: training on 155600 raw words (151995 effective words) took 0.5s, 276812 effective words/s
INFO - 2023-11-27 12:05:50,885: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039222 effective words) took 9.1s, 335273 effective words/s', 'datetime': '2023-11-27T12:05:50.884958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:50,885: collecting all words and their counts
INFO - 2023-11-27 12:05:50,885: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:50,927: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:50,927: Updating model with new vocabulary
INFO - 2023-11-27 12:05:50,944: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:50.944758', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:50,965: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:50,965: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:05:50,966: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151915.237709824 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:05:50.965972', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:50,999: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:50,999: updating layer weights
INFO - 2023-11-27 12:05:51,000: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:51.000136', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:51,000: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:51,000: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:51.000525', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:51,528: EPOCH 0: training on 155600 raw words (151929 effective words) took 0.5s, 290024 effective words/s
INFO - 2023-11-27 12:05:52,155: EPOCH 1: training on 155600 raw words (151883 effective words) took 0.6s, 243693 effective words/s
INFO - 2023-11-27 12:05:52,715: EPOCH 2: training on 155600 raw words (151938 effective words) took 0.6s, 273268 effective words/s
INFO - 2023-11-27 12:05:53,261: EPOCH 3: training on 155600 raw words (151872 effective words) took 0.5s, 280005 effective words/s
INFO - 2023-11-27 12:05:53,814: EPOCH 4: training on 155600 raw words (151945 effective words) took 0.5s, 276786 effective words/s
INFO - 2023-11-27 12:05:54,395: EPOCH 5: training on 155600 raw words (151900 effective words) took 0.6s, 262893 effective words/s
INFO - 2023-11-27 12:05:54,787: EPOCH 6: training on 155600 raw words (151901 effective words) took 0.4s, 391771 effective words/s
INFO - 2023-11-27 12:05:55,194: EPOCH 7: training on 155600 raw words (151875 effective words) took 0.4s, 376367 effective words/s
INFO - 2023-11-27 12:05:55,621: EPOCH 8: training on 155600 raw words (151906 effective words) took 0.3s, 460832 effective words/s
INFO - 2023-11-27 12:05:56,085: EPOCH 9: training on 155600 raw words (151850 effective words) took 0.5s, 331774 effective words/s
INFO - 2023-11-27 12:05:56,522: EPOCH 10: training on 155600 raw words (151951 effective words) took 0.4s, 350877 effective words/s
INFO - 2023-11-27 12:05:56,891: EPOCH 11: training on 155600 raw words (151925 effective words) took 0.4s, 416470 effective words/s
INFO - 2023-11-27 12:05:57,223: EPOCH 12: training on 155600 raw words (151881 effective words) took 0.3s, 459898 effective words/s
INFO - 2023-11-27 12:05:57,566: EPOCH 13: training on 155600 raw words (151912 effective words) took 0.3s, 446273 effective words/s
INFO - 2023-11-27 12:05:57,898: EPOCH 14: training on 155600 raw words (151895 effective words) took 0.3s, 461253 effective words/s
INFO - 2023-11-27 12:05:58,250: EPOCH 15: training on 155600 raw words (151919 effective words) took 0.3s, 434503 effective words/s
INFO - 2023-11-27 12:05:58,575: EPOCH 16: training on 155600 raw words (151845 effective words) took 0.3s, 470451 effective words/s
INFO - 2023-11-27 12:05:58,927: EPOCH 17: training on 155600 raw words (151916 effective words) took 0.3s, 434733 effective words/s
INFO - 2023-11-27 12:05:59,287: EPOCH 18: training on 155600 raw words (151962 effective words) took 0.4s, 426088 effective words/s
INFO - 2023-11-27 12:05:59,629: EPOCH 19: training on 155600 raw words (151892 effective words) took 0.3s, 447169 effective words/s
INFO - 2023-11-27 12:05:59,630: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038097 effective words) took 8.6s, 352065 effective words/s', 'datetime': '2023-11-27T12:05:59.630170', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:05:59,630: collecting all words and their counts
INFO - 2023-11-27 12:05:59,630: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:05:59,663: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:05:59,663: Updating model with new vocabulary
INFO - 2023-11-27 12:05:59,673: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:05:59.673895', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:59,686: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:05:59,686: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:05:59,686: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151893.6728804437 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:05:59.686704', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:05:59,709: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:05:59,709: updating layer weights
INFO - 2023-11-27 12:05:59,710: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:05:59.710065', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:05:59,710: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:05:59,710: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:05:59.710319', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:00,067: EPOCH 0: training on 155600 raw words (152041 effective words) took 0.4s, 428446 effective words/s
INFO - 2023-11-27 12:06:00,441: EPOCH 1: training on 155600 raw words (151802 effective words) took 0.4s, 408859 effective words/s
INFO - 2023-11-27 12:06:00,799: EPOCH 2: training on 155600 raw words (151924 effective words) took 0.4s, 427507 effective words/s
INFO - 2023-11-27 12:06:01,158: EPOCH 3: training on 155600 raw words (151843 effective words) took 0.4s, 425713 effective words/s
INFO - 2023-11-27 12:06:01,518: EPOCH 4: training on 155600 raw words (151954 effective words) took 0.4s, 424403 effective words/s
INFO - 2023-11-27 12:06:01,905: EPOCH 5: training on 155600 raw words (151887 effective words) took 0.4s, 394549 effective words/s
INFO - 2023-11-27 12:06:02,269: EPOCH 6: training on 155600 raw words (151921 effective words) took 0.4s, 420677 effective words/s
INFO - 2023-11-27 12:06:02,615: EPOCH 7: training on 155600 raw words (151961 effective words) took 0.3s, 440980 effective words/s
INFO - 2023-11-27 12:06:02,993: EPOCH 8: training on 155600 raw words (151939 effective words) took 0.4s, 405189 effective words/s
INFO - 2023-11-27 12:06:03,363: EPOCH 9: training on 155600 raw words (151918 effective words) took 0.4s, 412891 effective words/s
INFO - 2023-11-27 12:06:03,735: EPOCH 10: training on 155600 raw words (151801 effective words) took 0.4s, 420466 effective words/s
INFO - 2023-11-27 12:06:04,101: EPOCH 11: training on 155600 raw words (151792 effective words) took 0.4s, 417517 effective words/s
INFO - 2023-11-27 12:06:04,499: EPOCH 12: training on 155600 raw words (151951 effective words) took 0.4s, 393008 effective words/s
INFO - 2023-11-27 12:06:04,858: EPOCH 13: training on 155600 raw words (151807 effective words) took 0.4s, 426669 effective words/s
INFO - 2023-11-27 12:06:05,234: EPOCH 14: training on 155600 raw words (151847 effective words) took 0.4s, 405542 effective words/s
INFO - 2023-11-27 12:06:05,590: EPOCH 15: training on 155600 raw words (151831 effective words) took 0.4s, 430385 effective words/s
INFO - 2023-11-27 12:06:05,983: EPOCH 16: training on 155600 raw words (151871 effective words) took 0.4s, 388969 effective words/s
INFO - 2023-11-27 12:06:06,395: EPOCH 17: training on 155600 raw words (151925 effective words) took 0.4s, 370564 effective words/s
INFO - 2023-11-27 12:06:06,762: EPOCH 18: training on 155600 raw words (151855 effective words) took 0.4s, 416387 effective words/s
INFO - 2023-11-27 12:06:07,134: EPOCH 19: training on 155600 raw words (151860 effective words) took 0.4s, 410765 effective words/s
INFO - 2023-11-27 12:06:07,134: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037730 effective words) took 7.4s, 409156 effective words/s', 'datetime': '2023-11-27T12:06:07.134816', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:07,134: collecting all words and their counts
INFO - 2023-11-27 12:06:07,135: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:07,158: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:07,158: Updating model with new vocabulary
INFO - 2023-11-27 12:06:07,170: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:07.170092', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:07,188: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:07,189: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:06:07,189: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151983.9394844832 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:06:07.189252', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:07,225: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:07,225: updating layer weights
INFO - 2023-11-27 12:06:07,226: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:07.226026', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:07,226: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:07,226: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:07.226298', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:07,578: EPOCH 0: training on 155600 raw words (151960 effective words) took 0.3s, 435318 effective words/s
INFO - 2023-11-27 12:06:07,919: EPOCH 1: training on 155600 raw words (151917 effective words) took 0.3s, 447967 effective words/s
INFO - 2023-11-27 12:06:08,309: EPOCH 2: training on 155600 raw words (151964 effective words) took 0.4s, 392190 effective words/s
INFO - 2023-11-27 12:06:08,683: EPOCH 3: training on 155600 raw words (152018 effective words) took 0.4s, 427810 effective words/s
INFO - 2023-11-27 12:06:09,163: EPOCH 4: training on 155600 raw words (152029 effective words) took 0.5s, 318272 effective words/s
INFO - 2023-11-27 12:06:09,544: EPOCH 5: training on 155600 raw words (151927 effective words) took 0.4s, 401803 effective words/s
INFO - 2023-11-27 12:06:10,049: EPOCH 6: training on 155600 raw words (151999 effective words) took 0.5s, 302972 effective words/s
INFO - 2023-11-27 12:06:10,528: EPOCH 7: training on 155600 raw words (151958 effective words) took 0.5s, 318809 effective words/s
INFO - 2023-11-27 12:06:11,066: EPOCH 8: training on 155600 raw words (151873 effective words) took 0.5s, 284081 effective words/s
INFO - 2023-11-27 12:06:11,530: EPOCH 9: training on 155600 raw words (151999 effective words) took 0.4s, 339276 effective words/s
INFO - 2023-11-27 12:06:11,964: EPOCH 10: training on 155600 raw words (152006 effective words) took 0.4s, 352199 effective words/s
INFO - 2023-11-27 12:06:12,452: EPOCH 11: training on 155600 raw words (151940 effective words) took 0.5s, 314109 effective words/s
INFO - 2023-11-27 12:06:12,900: EPOCH 12: training on 155600 raw words (151989 effective words) took 0.4s, 340935 effective words/s
INFO - 2023-11-27 12:06:13,354: EPOCH 13: training on 155600 raw words (152037 effective words) took 0.5s, 337097 effective words/s
INFO - 2023-11-27 12:06:13,841: EPOCH 14: training on 155600 raw words (151950 effective words) took 0.5s, 314153 effective words/s
INFO - 2023-11-27 12:06:14,446: EPOCH 15: training on 155600 raw words (151967 effective words) took 0.6s, 253002 effective words/s
INFO - 2023-11-27 12:06:14,931: EPOCH 16: training on 155600 raw words (152042 effective words) took 0.5s, 319348 effective words/s
INFO - 2023-11-27 12:06:15,463: EPOCH 17: training on 155600 raw words (151970 effective words) took 0.5s, 287687 effective words/s
INFO - 2023-11-27 12:06:15,928: EPOCH 18: training on 155600 raw words (152030 effective words) took 0.5s, 329081 effective words/s
INFO - 2023-11-27 12:06:16,455: EPOCH 19: training on 155600 raw words (152011 effective words) took 0.5s, 290235 effective words/s
INFO - 2023-11-27 12:06:16,455: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039586 effective words) took 9.2s, 329340 effective words/s', 'datetime': '2023-11-27T12:06:16.455765', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:16,456: collecting all words and their counts
INFO - 2023-11-27 12:06:16,456: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:16,517: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:16,518: Updating model with new vocabulary
INFO - 2023-11-27 12:06:16,555: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:16.555036', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:16,611: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:16,611: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:06:16,611: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151990.35827109742 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:06:16.611807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:16,660: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:16,660: updating layer weights
INFO - 2023-11-27 12:06:16,661: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:16.661607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:16,661: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:16,662: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:16.662150', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:17,206: EPOCH 0: training on 155600 raw words (151995 effective words) took 0.5s, 284668 effective words/s
INFO - 2023-11-27 12:06:17,658: EPOCH 1: training on 155600 raw words (152040 effective words) took 0.4s, 339077 effective words/s
INFO - 2023-11-27 12:06:18,037: EPOCH 2: training on 155600 raw words (151940 effective words) took 0.4s, 403751 effective words/s
INFO - 2023-11-27 12:06:18,400: EPOCH 3: training on 155600 raw words (151866 effective words) took 0.4s, 421323 effective words/s
INFO - 2023-11-27 12:06:18,764: EPOCH 4: training on 155600 raw words (152006 effective words) took 0.4s, 420165 effective words/s
INFO - 2023-11-27 12:06:19,131: EPOCH 5: training on 155600 raw words (152001 effective words) took 0.4s, 416736 effective words/s
INFO - 2023-11-27 12:06:19,482: EPOCH 6: training on 155600 raw words (151976 effective words) took 0.3s, 436503 effective words/s
INFO - 2023-11-27 12:06:19,841: EPOCH 7: training on 155600 raw words (152049 effective words) took 0.4s, 425713 effective words/s
INFO - 2023-11-27 12:06:20,196: EPOCH 8: training on 155600 raw words (151936 effective words) took 0.4s, 431136 effective words/s
INFO - 2023-11-27 12:06:20,570: EPOCH 9: training on 155600 raw words (152005 effective words) took 0.4s, 408690 effective words/s
INFO - 2023-11-27 12:06:20,924: EPOCH 10: training on 155600 raw words (152094 effective words) took 0.4s, 433083 effective words/s
INFO - 2023-11-27 12:06:21,285: EPOCH 11: training on 155600 raw words (152047 effective words) took 0.4s, 424108 effective words/s
INFO - 2023-11-27 12:06:21,645: EPOCH 12: training on 155600 raw words (151874 effective words) took 0.4s, 424907 effective words/s
INFO - 2023-11-27 12:06:22,032: EPOCH 13: training on 155600 raw words (151919 effective words) took 0.4s, 395300 effective words/s
INFO - 2023-11-27 12:06:22,387: EPOCH 14: training on 155600 raw words (152107 effective words) took 0.4s, 431431 effective words/s
INFO - 2023-11-27 12:06:22,743: EPOCH 15: training on 155600 raw words (151985 effective words) took 0.4s, 430609 effective words/s
INFO - 2023-11-27 12:06:23,103: EPOCH 16: training on 155600 raw words (151966 effective words) took 0.4s, 425213 effective words/s
INFO - 2023-11-27 12:06:23,455: EPOCH 17: training on 155600 raw words (152003 effective words) took 0.4s, 434286 effective words/s
INFO - 2023-11-27 12:06:23,810: EPOCH 18: training on 155600 raw words (151932 effective words) took 0.4s, 431530 effective words/s
INFO - 2023-11-27 12:06:24,163: EPOCH 19: training on 155600 raw words (151975 effective words) took 0.4s, 433748 effective words/s
INFO - 2023-11-27 12:06:24,163: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039716 effective words) took 7.5s, 405229 effective words/s', 'datetime': '2023-11-27T12:06:24.163567', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:24,163: collecting all words and their counts
INFO - 2023-11-27 12:06:24,163: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:24,188: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:24,188: Updating model with new vocabulary
INFO - 2023-11-27 12:06:24,198: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:24.198286', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:24,210: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:24,210: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:06:24,210: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151870.51768994972 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:06:24.210647', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:24,229: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:24,229: updating layer weights
INFO - 2023-11-27 12:06:24,229: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:24.229903', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:24,230: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:24,230: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:24.230215', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:24,553: EPOCH 0: training on 155600 raw words (151935 effective words) took 0.3s, 473915 effective words/s
INFO - 2023-11-27 12:06:24,888: EPOCH 1: training on 155600 raw words (151892 effective words) took 0.3s, 455819 effective words/s
INFO - 2023-11-27 12:06:25,219: EPOCH 2: training on 155600 raw words (151938 effective words) took 0.3s, 463143 effective words/s
INFO - 2023-11-27 12:06:25,577: EPOCH 3: training on 155600 raw words (151858 effective words) took 0.4s, 426325 effective words/s
INFO - 2023-11-27 12:06:25,902: EPOCH 4: training on 155600 raw words (151802 effective words) took 0.3s, 471675 effective words/s
INFO - 2023-11-27 12:06:26,226: EPOCH 5: training on 155600 raw words (151851 effective words) took 0.3s, 472285 effective words/s
INFO - 2023-11-27 12:06:26,557: EPOCH 6: training on 155600 raw words (151914 effective words) took 0.3s, 462896 effective words/s
INFO - 2023-11-27 12:06:26,885: EPOCH 7: training on 155600 raw words (151755 effective words) took 0.3s, 465783 effective words/s
INFO - 2023-11-27 12:06:27,220: EPOCH 8: training on 155600 raw words (151912 effective words) took 0.3s, 456500 effective words/s
INFO - 2023-11-27 12:06:27,581: EPOCH 9: training on 155600 raw words (151858 effective words) took 0.4s, 423788 effective words/s
INFO - 2023-11-27 12:06:27,932: EPOCH 10: training on 155600 raw words (151867 effective words) took 0.3s, 436925 effective words/s
INFO - 2023-11-27 12:06:28,297: EPOCH 11: training on 155600 raw words (151825 effective words) took 0.4s, 418731 effective words/s
INFO - 2023-11-27 12:06:28,617: EPOCH 12: training on 155600 raw words (151809 effective words) took 0.3s, 476960 effective words/s
INFO - 2023-11-27 12:06:28,988: EPOCH 13: training on 155600 raw words (151856 effective words) took 0.4s, 411372 effective words/s
INFO - 2023-11-27 12:06:29,330: EPOCH 14: training on 155600 raw words (151804 effective words) took 0.3s, 447317 effective words/s
INFO - 2023-11-27 12:06:29,657: EPOCH 15: training on 155600 raw words (151805 effective words) took 0.3s, 467471 effective words/s
INFO - 2023-11-27 12:06:29,992: EPOCH 16: training on 155600 raw words (151825 effective words) took 0.3s, 455614 effective words/s
INFO - 2023-11-27 12:06:30,351: EPOCH 17: training on 155600 raw words (151854 effective words) took 0.4s, 425793 effective words/s
INFO - 2023-11-27 12:06:30,675: EPOCH 18: training on 155600 raw words (151951 effective words) took 0.3s, 473597 effective words/s
INFO - 2023-11-27 12:06:31,032: EPOCH 19: training on 155600 raw words (151803 effective words) took 0.4s, 426850 effective words/s
INFO - 2023-11-27 12:06:31,033: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037114 effective words) took 6.8s, 446462 effective words/s', 'datetime': '2023-11-27T12:06:31.032988', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:31,033: collecting all words and their counts
INFO - 2023-11-27 12:06:31,033: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:31,056: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:31,056: Updating model with new vocabulary
INFO - 2023-11-27 12:06:31,067: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:31.067508', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:31,080: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:31,080: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:06:31,080: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151973.53491687964 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:06:31.080700', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:31,099: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:31,099: updating layer weights
INFO - 2023-11-27 12:06:31,100: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:31.100007', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:31,100: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:31,100: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:31.100201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:31,460: EPOCH 0: training on 155600 raw words (151925 effective words) took 0.4s, 424520 effective words/s
INFO - 2023-11-27 12:06:31,817: EPOCH 1: training on 155600 raw words (151899 effective words) took 0.4s, 428134 effective words/s
INFO - 2023-11-27 12:06:32,261: EPOCH 2: training on 155600 raw words (152010 effective words) took 0.4s, 344362 effective words/s
INFO - 2023-11-27 12:06:32,615: EPOCH 3: training on 155600 raw words (151967 effective words) took 0.4s, 432202 effective words/s
INFO - 2023-11-27 12:06:33,018: EPOCH 4: training on 155600 raw words (151888 effective words) took 0.4s, 378198 effective words/s
INFO - 2023-11-27 12:06:33,382: EPOCH 5: training on 155600 raw words (151972 effective words) took 0.4s, 421953 effective words/s
INFO - 2023-11-27 12:06:33,755: EPOCH 6: training on 155600 raw words (151989 effective words) took 0.4s, 409418 effective words/s
INFO - 2023-11-27 12:06:34,114: EPOCH 7: training on 155600 raw words (151910 effective words) took 0.4s, 427132 effective words/s
INFO - 2023-11-27 12:06:34,615: EPOCH 8: training on 155600 raw words (151950 effective words) took 0.5s, 305107 effective words/s
INFO - 2023-11-27 12:06:35,095: EPOCH 9: training on 155600 raw words (151888 effective words) took 0.5s, 318089 effective words/s
INFO - 2023-11-27 12:06:35,564: EPOCH 10: training on 155600 raw words (151972 effective words) took 0.5s, 326822 effective words/s
INFO - 2023-11-27 12:06:36,047: EPOCH 11: training on 155600 raw words (151968 effective words) took 0.5s, 317333 effective words/s
INFO - 2023-11-27 12:06:36,549: EPOCH 12: training on 155600 raw words (151951 effective words) took 0.5s, 303875 effective words/s
INFO - 2023-11-27 12:06:37,023: EPOCH 13: training on 155600 raw words (152070 effective words) took 0.5s, 323143 effective words/s
INFO - 2023-11-27 12:06:37,529: EPOCH 14: training on 155600 raw words (151959 effective words) took 0.5s, 306127 effective words/s
INFO - 2023-11-27 12:06:37,998: EPOCH 15: training on 155600 raw words (151970 effective words) took 0.5s, 326634 effective words/s
INFO - 2023-11-27 12:06:38,479: EPOCH 16: training on 155600 raw words (151936 effective words) took 0.5s, 317820 effective words/s
INFO - 2023-11-27 12:06:38,965: EPOCH 17: training on 155600 raw words (151974 effective words) took 0.5s, 314683 effective words/s
INFO - 2023-11-27 12:06:39,444: EPOCH 18: training on 155600 raw words (151926 effective words) took 0.5s, 318846 effective words/s
INFO - 2023-11-27 12:06:39,995: EPOCH 19: training on 155600 raw words (151995 effective words) took 0.5s, 277742 effective words/s
INFO - 2023-11-27 12:06:39,995: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039119 effective words) took 8.9s, 341664 effective words/s', 'datetime': '2023-11-27T12:06:39.995420', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:39,995: collecting all words and their counts
INFO - 2023-11-27 12:06:39,995: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:40,027: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:40,027: Updating model with new vocabulary
INFO - 2023-11-27 12:06:40,042: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:40.042180', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:40,060: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:40,061: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:06:40,061: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152052.4465033829 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:06:40.061296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:40,095: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:40,096: updating layer weights
INFO - 2023-11-27 12:06:40,096: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:40.096366', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:40,096: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:40,096: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:40.096668', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:40,598: EPOCH 0: training on 155600 raw words (152033 effective words) took 0.5s, 307778 effective words/s
INFO - 2023-11-27 12:06:41,072: EPOCH 1: training on 155600 raw words (152108 effective words) took 0.5s, 323740 effective words/s
INFO - 2023-11-27 12:06:41,533: EPOCH 2: training on 155600 raw words (152089 effective words) took 0.5s, 332057 effective words/s
INFO - 2023-11-27 12:06:41,994: EPOCH 3: training on 155600 raw words (152030 effective words) took 0.5s, 332652 effective words/s
INFO - 2023-11-27 12:06:42,428: EPOCH 4: training on 155600 raw words (152040 effective words) took 0.4s, 352868 effective words/s
INFO - 2023-11-27 12:06:42,829: EPOCH 5: training on 155600 raw words (152036 effective words) took 0.4s, 381501 effective words/s
INFO - 2023-11-27 12:06:43,261: EPOCH 6: training on 155600 raw words (152074 effective words) took 0.4s, 355038 effective words/s
INFO - 2023-11-27 12:06:43,692: EPOCH 7: training on 155600 raw words (152035 effective words) took 0.4s, 355914 effective words/s
INFO - 2023-11-27 12:06:44,094: EPOCH 8: training on 155600 raw words (151998 effective words) took 0.4s, 381283 effective words/s
INFO - 2023-11-27 12:06:44,514: EPOCH 9: training on 155600 raw words (152088 effective words) took 0.4s, 365377 effective words/s
INFO - 2023-11-27 12:06:44,971: EPOCH 10: training on 155600 raw words (152050 effective words) took 0.5s, 334326 effective words/s
INFO - 2023-11-27 12:06:45,411: EPOCH 11: training on 155600 raw words (152053 effective words) took 0.4s, 349149 effective words/s
INFO - 2023-11-27 12:06:45,842: EPOCH 12: training on 155600 raw words (152000 effective words) took 0.4s, 355631 effective words/s
INFO - 2023-11-27 12:06:46,323: EPOCH 13: training on 155600 raw words (152086 effective words) took 0.5s, 318242 effective words/s
INFO - 2023-11-27 12:06:46,719: EPOCH 14: training on 155600 raw words (152018 effective words) took 0.4s, 386600 effective words/s
INFO - 2023-11-27 12:06:47,154: EPOCH 15: training on 155600 raw words (152021 effective words) took 0.4s, 352348 effective words/s
INFO - 2023-11-27 12:06:47,547: EPOCH 16: training on 155600 raw words (152079 effective words) took 0.4s, 390504 effective words/s
INFO - 2023-11-27 12:06:47,968: EPOCH 17: training on 155600 raw words (152063 effective words) took 0.4s, 364012 effective words/s
INFO - 2023-11-27 12:06:48,396: EPOCH 18: training on 155600 raw words (152033 effective words) took 0.4s, 357530 effective words/s
INFO - 2023-11-27 12:06:48,853: EPOCH 19: training on 155600 raw words (152032 effective words) took 0.5s, 334710 effective words/s
INFO - 2023-11-27 12:06:48,853: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040966 effective words) took 8.8s, 347259 effective words/s', 'datetime': '2023-11-27T12:06:48.853896', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:48,854: collecting all words and their counts
INFO - 2023-11-27 12:06:48,854: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:48,885: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:48,885: Updating model with new vocabulary
INFO - 2023-11-27 12:06:48,898: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:48.898921', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:48,916: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:48,916: sample=0.001 downsamples 25 most-common words
INFO - 2023-11-27 12:06:48,916: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151784.11210169154 word corpus (97.5%% of prior 155600)', 'datetime': '2023-11-27T12:06:48.916700', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:48,944: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:48,944: updating layer weights
INFO - 2023-11-27 12:06:48,945: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:48.945293', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:48,945: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:48,945: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:48.945884', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:49,414: EPOCH 0: training on 155600 raw words (151714 effective words) took 0.5s, 326303 effective words/s
INFO - 2023-11-27 12:06:49,871: EPOCH 1: training on 155600 raw words (151770 effective words) took 0.5s, 334394 effective words/s
INFO - 2023-11-27 12:06:50,309: EPOCH 2: training on 155600 raw words (151726 effective words) took 0.4s, 348396 effective words/s
INFO - 2023-11-27 12:06:50,750: EPOCH 3: training on 155600 raw words (151759 effective words) took 0.4s, 346469 effective words/s
INFO - 2023-11-27 12:06:51,190: EPOCH 4: training on 155600 raw words (151826 effective words) took 0.4s, 347640 effective words/s
INFO - 2023-11-27 12:06:51,646: EPOCH 5: training on 155600 raw words (151771 effective words) took 0.5s, 335589 effective words/s
INFO - 2023-11-27 12:06:52,130: EPOCH 6: training on 155600 raw words (151824 effective words) took 0.5s, 315766 effective words/s
INFO - 2023-11-27 12:06:52,602: EPOCH 7: training on 155600 raw words (151770 effective words) took 0.5s, 323823 effective words/s
INFO - 2023-11-27 12:06:53,049: EPOCH 8: training on 155600 raw words (151813 effective words) took 0.4s, 341423 effective words/s
INFO - 2023-11-27 12:06:53,498: EPOCH 9: training on 155600 raw words (151795 effective words) took 0.4s, 340462 effective words/s
INFO - 2023-11-27 12:06:53,958: EPOCH 10: training on 155600 raw words (151859 effective words) took 0.5s, 332402 effective words/s
INFO - 2023-11-27 12:06:54,501: EPOCH 11: training on 155600 raw words (151767 effective words) took 0.5s, 281332 effective words/s
INFO - 2023-11-27 12:06:54,932: EPOCH 12: training on 155600 raw words (151739 effective words) took 0.4s, 354860 effective words/s
INFO - 2023-11-27 12:06:55,369: EPOCH 13: training on 155600 raw words (151855 effective words) took 0.4s, 349841 effective words/s
INFO - 2023-11-27 12:06:55,839: EPOCH 14: training on 155600 raw words (151871 effective words) took 0.5s, 325744 effective words/s
INFO - 2023-11-27 12:06:56,274: EPOCH 15: training on 155600 raw words (151790 effective words) took 0.4s, 350798 effective words/s
INFO - 2023-11-27 12:06:56,700: EPOCH 16: training on 155600 raw words (151840 effective words) took 0.4s, 359342 effective words/s
INFO - 2023-11-27 12:06:57,116: EPOCH 17: training on 155600 raw words (151728 effective words) took 0.4s, 367494 effective words/s
INFO - 2023-11-27 12:06:57,564: EPOCH 18: training on 155600 raw words (151811 effective words) took 0.4s, 341472 effective words/s
INFO - 2023-11-27 12:06:58,026: EPOCH 19: training on 155600 raw words (151799 effective words) took 0.5s, 330768 effective words/s
INFO - 2023-11-27 12:06:58,026: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3035827 effective words) took 9.1s, 334313 effective words/s', 'datetime': '2023-11-27T12:06:58.026836', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:58,027: collecting all words and their counts
INFO - 2023-11-27 12:06:58,027: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:06:58,058: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:06:58,059: Updating model with new vocabulary
INFO - 2023-11-27 12:06:58,072: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:06:58.072637', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:58,090: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:06:58,090: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:06:58,090: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151818.04236277248 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:06:58.090672', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:06:58,117: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:06:58,118: updating layer weights
INFO - 2023-11-27 12:06:58,118: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:06:58.118365', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:06:58,118: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:06:58,118: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:06:58.118656', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:06:58,545: EPOCH 0: training on 155600 raw words (151830 effective words) took 0.4s, 358665 effective words/s
INFO - 2023-11-27 12:06:58,972: EPOCH 1: training on 155600 raw words (151823 effective words) took 0.4s, 358172 effective words/s
INFO - 2023-11-27 12:06:59,441: EPOCH 2: training on 155600 raw words (151780 effective words) took 0.5s, 325362 effective words/s
INFO - 2023-11-27 12:06:59,911: EPOCH 3: training on 155600 raw words (151853 effective words) took 0.5s, 324885 effective words/s
INFO - 2023-11-27 12:07:00,378: EPOCH 4: training on 155600 raw words (151792 effective words) took 0.5s, 327971 effective words/s
INFO - 2023-11-27 12:07:00,792: EPOCH 5: training on 155600 raw words (151809 effective words) took 0.4s, 368550 effective words/s
INFO - 2023-11-27 12:07:01,198: EPOCH 6: training on 155600 raw words (151856 effective words) took 0.4s, 377393 effective words/s
INFO - 2023-11-27 12:07:01,620: EPOCH 7: training on 155600 raw words (151859 effective words) took 0.4s, 362446 effective words/s
INFO - 2023-11-27 12:07:02,034: EPOCH 8: training on 155600 raw words (151781 effective words) took 0.4s, 369577 effective words/s
INFO - 2023-11-27 12:07:02,468: EPOCH 9: training on 155600 raw words (151874 effective words) took 0.4s, 352569 effective words/s
INFO - 2023-11-27 12:07:02,913: EPOCH 10: training on 155600 raw words (151807 effective words) took 0.4s, 343757 effective words/s
INFO - 2023-11-27 12:07:03,332: EPOCH 11: training on 155600 raw words (151807 effective words) took 0.4s, 364387 effective words/s
INFO - 2023-11-27 12:07:03,744: EPOCH 12: training on 155600 raw words (151823 effective words) took 0.4s, 391241 effective words/s
INFO - 2023-11-27 12:07:04,168: EPOCH 13: training on 155600 raw words (151867 effective words) took 0.4s, 360421 effective words/s
INFO - 2023-11-27 12:07:04,567: EPOCH 14: training on 155600 raw words (151768 effective words) took 0.4s, 382769 effective words/s
INFO - 2023-11-27 12:07:04,964: EPOCH 15: training on 155600 raw words (151833 effective words) took 0.4s, 385849 effective words/s
INFO - 2023-11-27 12:07:05,398: EPOCH 16: training on 155600 raw words (151860 effective words) took 0.4s, 352676 effective words/s
INFO - 2023-11-27 12:07:05,779: EPOCH 17: training on 155600 raw words (151774 effective words) took 0.4s, 400831 effective words/s
INFO - 2023-11-27 12:07:06,212: EPOCH 18: training on 155600 raw words (151821 effective words) took 0.4s, 353375 effective words/s
INFO - 2023-11-27 12:07:06,645: EPOCH 19: training on 155600 raw words (151848 effective words) took 0.4s, 353185 effective words/s
INFO - 2023-11-27 12:07:06,645: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3036465 effective words) took 8.5s, 356111 effective words/s', 'datetime': '2023-11-27T12:07:06.645561', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:06,645: collecting all words and their counts
INFO - 2023-11-27 12:07:06,646: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:06,678: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:06,678: Updating model with new vocabulary
INFO - 2023-11-27 12:07:06,692: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:06.692431', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:06,710: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:06,710: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:07:06,710: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152119.55820248678 word corpus (97.8%% of prior 155600)', 'datetime': '2023-11-27T12:07:06.710405', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:06,738: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:06,738: updating layer weights
INFO - 2023-11-27 12:07:06,738: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:06.738512', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:06,738: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:06,738: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:06.738814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:07,172: EPOCH 0: training on 155600 raw words (152102 effective words) took 0.4s, 353756 effective words/s
INFO - 2023-11-27 12:07:07,623: EPOCH 1: training on 155600 raw words (152102 effective words) took 0.4s, 339653 effective words/s
INFO - 2023-11-27 12:07:08,060: EPOCH 2: training on 155600 raw words (152115 effective words) took 0.4s, 350350 effective words/s
INFO - 2023-11-27 12:07:08,510: EPOCH 3: training on 155600 raw words (152170 effective words) took 0.4s, 340431 effective words/s
INFO - 2023-11-27 12:07:08,975: EPOCH 4: training on 155600 raw words (152152 effective words) took 0.5s, 330038 effective words/s
INFO - 2023-11-27 12:07:09,437: EPOCH 5: training on 155600 raw words (152108 effective words) took 0.5s, 331377 effective words/s
INFO - 2023-11-27 12:07:09,868: EPOCH 6: training on 155600 raw words (152120 effective words) took 0.4s, 363086 effective words/s
INFO - 2023-11-27 12:07:10,338: EPOCH 7: training on 155600 raw words (152192 effective words) took 0.5s, 325723 effective words/s
INFO - 2023-11-27 12:07:10,800: EPOCH 8: training on 155600 raw words (152067 effective words) took 0.5s, 331482 effective words/s
INFO - 2023-11-27 12:07:11,263: EPOCH 9: training on 155600 raw words (152101 effective words) took 0.5s, 331246 effective words/s
INFO - 2023-11-27 12:07:11,687: EPOCH 10: training on 155600 raw words (152051 effective words) took 0.4s, 360963 effective words/s
INFO - 2023-11-27 12:07:12,130: EPOCH 11: training on 155600 raw words (152056 effective words) took 0.4s, 345533 effective words/s
INFO - 2023-11-27 12:07:12,580: EPOCH 12: training on 155600 raw words (152142 effective words) took 0.4s, 340298 effective words/s
INFO - 2023-11-27 12:07:13,010: EPOCH 13: training on 155600 raw words (152138 effective words) took 0.4s, 364070 effective words/s
INFO - 2023-11-27 12:07:13,466: EPOCH 14: training on 155600 raw words (152056 effective words) took 0.5s, 336280 effective words/s
INFO - 2023-11-27 12:07:13,921: EPOCH 15: training on 155600 raw words (152135 effective words) took 0.5s, 336723 effective words/s
INFO - 2023-11-27 12:07:14,411: EPOCH 16: training on 155600 raw words (152076 effective words) took 0.5s, 311800 effective words/s
INFO - 2023-11-27 12:07:14,861: EPOCH 17: training on 155600 raw words (152160 effective words) took 0.4s, 341074 effective words/s
INFO - 2023-11-27 12:07:15,302: EPOCH 18: training on 155600 raw words (152129 effective words) took 0.4s, 347132 effective words/s
INFO - 2023-11-27 12:07:15,771: EPOCH 19: training on 155600 raw words (152136 effective words) took 0.5s, 326524 effective words/s
INFO - 2023-11-27 12:07:15,772: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3042308 effective words) took 9.0s, 336789 effective words/s', 'datetime': '2023-11-27T12:07:15.772220', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:15,772: collecting all words and their counts
INFO - 2023-11-27 12:07:15,772: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:15,805: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:15,805: Updating model with new vocabulary
INFO - 2023-11-27 12:07:15,819: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:15.819496', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:15,836: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:15,836: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:07:15,836: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151924.85212755384 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:07:15.836676', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:15,866: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:15,866: updating layer weights
INFO - 2023-11-27 12:07:15,867: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:15.867165', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:15,867: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:15,867: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:15.867480', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:16,286: EPOCH 0: training on 155600 raw words (151886 effective words) took 0.4s, 381425 effective words/s
INFO - 2023-11-27 12:07:16,696: EPOCH 1: training on 155600 raw words (151874 effective words) took 0.4s, 372950 effective words/s
INFO - 2023-11-27 12:07:17,107: EPOCH 2: training on 155600 raw words (151871 effective words) took 0.4s, 372178 effective words/s
INFO - 2023-11-27 12:07:17,524: EPOCH 3: training on 155600 raw words (151977 effective words) took 0.4s, 367445 effective words/s
INFO - 2023-11-27 12:07:17,946: EPOCH 4: training on 155600 raw words (151960 effective words) took 0.4s, 362416 effective words/s
INFO - 2023-11-27 12:07:18,357: EPOCH 5: training on 155600 raw words (151897 effective words) took 0.4s, 372693 effective words/s
INFO - 2023-11-27 12:07:18,775: EPOCH 6: training on 155600 raw words (151878 effective words) took 0.4s, 366505 effective words/s
INFO - 2023-11-27 12:07:19,206: EPOCH 7: training on 155600 raw words (151868 effective words) took 0.4s, 354583 effective words/s
INFO - 2023-11-27 12:07:19,654: EPOCH 8: training on 155600 raw words (151886 effective words) took 0.4s, 341950 effective words/s
INFO - 2023-11-27 12:07:20,078: EPOCH 9: training on 155600 raw words (151959 effective words) took 0.4s, 360616 effective words/s
INFO - 2023-11-27 12:07:20,493: EPOCH 10: training on 155600 raw words (152032 effective words) took 0.4s, 369235 effective words/s
INFO - 2023-11-27 12:07:20,907: EPOCH 11: training on 155600 raw words (151947 effective words) took 0.4s, 369272 effective words/s
INFO - 2023-11-27 12:07:21,337: EPOCH 12: training on 155600 raw words (151916 effective words) took 0.4s, 356460 effective words/s
INFO - 2023-11-27 12:07:21,804: EPOCH 13: training on 155600 raw words (151859 effective words) took 0.5s, 327383 effective words/s
INFO - 2023-11-27 12:07:22,269: EPOCH 14: training on 155600 raw words (151895 effective words) took 0.5s, 328395 effective words/s
INFO - 2023-11-27 12:07:22,685: EPOCH 15: training on 155600 raw words (151867 effective words) took 0.4s, 368123 effective words/s
INFO - 2023-11-27 12:07:23,073: EPOCH 16: training on 155600 raw words (151969 effective words) took 0.4s, 395008 effective words/s
INFO - 2023-11-27 12:07:23,499: EPOCH 17: training on 155600 raw words (151937 effective words) took 0.4s, 359480 effective words/s
INFO - 2023-11-27 12:07:23,955: EPOCH 18: training on 155600 raw words (151838 effective words) took 0.5s, 335257 effective words/s
INFO - 2023-11-27 12:07:24,393: EPOCH 19: training on 155600 raw words (151870 effective words) took 0.4s, 349363 effective words/s
INFO - 2023-11-27 12:07:24,393: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038186 effective words) took 8.5s, 356352 effective words/s', 'datetime': '2023-11-27T12:07:24.393449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:24,393: collecting all words and their counts
INFO - 2023-11-27 12:07:24,393: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:24,427: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:24,427: Updating model with new vocabulary
INFO - 2023-11-27 12:07:24,441: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:24.441044', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:24,459: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:24,459: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:07:24,459: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151846.87308625784 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:07:24.459600', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:24,488: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:24,488: updating layer weights
INFO - 2023-11-27 12:07:24,488: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:24.488893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:24,489: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:24,489: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:24.489195', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:24,945: EPOCH 0: training on 155600 raw words (151774 effective words) took 0.5s, 335472 effective words/s
INFO - 2023-11-27 12:07:25,391: EPOCH 1: training on 155600 raw words (151822 effective words) took 0.4s, 342248 effective words/s
INFO - 2023-11-27 12:07:25,854: EPOCH 2: training on 155600 raw words (151838 effective words) took 0.5s, 330792 effective words/s
INFO - 2023-11-27 12:07:26,308: EPOCH 3: training on 155600 raw words (151839 effective words) took 0.5s, 336294 effective words/s
INFO - 2023-11-27 12:07:26,771: EPOCH 4: training on 155600 raw words (151787 effective words) took 0.5s, 330506 effective words/s
INFO - 2023-11-27 12:07:27,232: EPOCH 5: training on 155600 raw words (151819 effective words) took 0.5s, 331848 effective words/s
INFO - 2023-11-27 12:07:27,686: EPOCH 6: training on 155600 raw words (151711 effective words) took 0.5s, 336293 effective words/s
INFO - 2023-11-27 12:07:28,135: EPOCH 7: training on 155600 raw words (151852 effective words) took 0.4s, 340694 effective words/s
INFO - 2023-11-27 12:07:28,580: EPOCH 8: training on 155600 raw words (151807 effective words) took 0.4s, 343275 effective words/s
INFO - 2023-11-27 12:07:29,078: EPOCH 9: training on 155600 raw words (151788 effective words) took 0.5s, 306529 effective words/s
INFO - 2023-11-27 12:07:29,541: EPOCH 10: training on 155600 raw words (151927 effective words) took 0.5s, 330839 effective words/s
INFO - 2023-11-27 12:07:29,993: EPOCH 11: training on 155600 raw words (151848 effective words) took 0.4s, 338020 effective words/s
INFO - 2023-11-27 12:07:30,457: EPOCH 12: training on 155600 raw words (151902 effective words) took 0.4s, 337690 effective words/s
INFO - 2023-11-27 12:07:30,909: EPOCH 13: training on 155600 raw words (151874 effective words) took 0.4s, 337973 effective words/s
INFO - 2023-11-27 12:07:31,345: EPOCH 14: training on 155600 raw words (151854 effective words) took 0.4s, 350743 effective words/s
INFO - 2023-11-27 12:07:31,783: EPOCH 15: training on 155600 raw words (151883 effective words) took 0.4s, 350055 effective words/s
INFO - 2023-11-27 12:07:32,201: EPOCH 16: training on 155600 raw words (151991 effective words) took 0.4s, 366407 effective words/s
INFO - 2023-11-27 12:07:32,661: EPOCH 17: training on 155600 raw words (151774 effective words) took 0.5s, 332040 effective words/s
INFO - 2023-11-27 12:07:33,126: EPOCH 18: training on 155600 raw words (151842 effective words) took 0.5s, 328671 effective words/s
INFO - 2023-11-27 12:07:33,585: EPOCH 19: training on 155600 raw words (151920 effective words) took 0.5s, 333641 effective words/s
INFO - 2023-11-27 12:07:33,585: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3036852 effective words) took 9.1s, 333859 effective words/s', 'datetime': '2023-11-27T12:07:33.585564', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:33,585: collecting all words and their counts
INFO - 2023-11-27 12:07:33,586: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:33,621: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:33,621: Updating model with new vocabulary
INFO - 2023-11-27 12:07:33,636: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:33.636059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:33,653: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:33,653: sample=0.001 downsamples 20 most-common words
INFO - 2023-11-27 12:07:33,653: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151859.64685563926 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:07:33.653547', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:33,681: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:33,681: updating layer weights
INFO - 2023-11-27 12:07:33,681: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:33.681872', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:33,682: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:33,682: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:33.682144', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:34,125: EPOCH 0: training on 155600 raw words (151829 effective words) took 0.4s, 344813 effective words/s
INFO - 2023-11-27 12:07:34,595: EPOCH 1: training on 155600 raw words (151920 effective words) took 0.5s, 325828 effective words/s
INFO - 2023-11-27 12:07:35,037: EPOCH 2: training on 155600 raw words (151913 effective words) took 0.4s, 345766 effective words/s
INFO - 2023-11-27 12:07:35,489: EPOCH 3: training on 155600 raw words (151842 effective words) took 0.4s, 338610 effective words/s
INFO - 2023-11-27 12:07:35,877: EPOCH 4: training on 155600 raw words (151825 effective words) took 0.4s, 394211 effective words/s
INFO - 2023-11-27 12:07:36,353: EPOCH 5: training on 155600 raw words (151893 effective words) took 0.5s, 321011 effective words/s
INFO - 2023-11-27 12:07:36,793: EPOCH 6: training on 155600 raw words (151855 effective words) took 0.4s, 348557 effective words/s
INFO - 2023-11-27 12:07:37,254: EPOCH 7: training on 155600 raw words (151887 effective words) took 0.5s, 331138 effective words/s
INFO - 2023-11-27 12:07:37,661: EPOCH 8: training on 155600 raw words (151920 effective words) took 0.4s, 376834 effective words/s
INFO - 2023-11-27 12:07:38,068: EPOCH 9: training on 155600 raw words (151928 effective words) took 0.4s, 375668 effective words/s
INFO - 2023-11-27 12:07:38,465: EPOCH 10: training on 155600 raw words (151845 effective words) took 0.4s, 385391 effective words/s
INFO - 2023-11-27 12:07:38,877: EPOCH 11: training on 155600 raw words (151773 effective words) took 0.4s, 370755 effective words/s
INFO - 2023-11-27 12:07:39,302: EPOCH 12: training on 155600 raw words (151857 effective words) took 0.4s, 360295 effective words/s
INFO - 2023-11-27 12:07:39,765: EPOCH 13: training on 155600 raw words (151864 effective words) took 0.5s, 330579 effective words/s
INFO - 2023-11-27 12:07:40,205: EPOCH 14: training on 155600 raw words (151795 effective words) took 0.4s, 347957 effective words/s
INFO - 2023-11-27 12:07:40,650: EPOCH 15: training on 155600 raw words (151771 effective words) took 0.4s, 343194 effective words/s
INFO - 2023-11-27 12:07:41,067: EPOCH 16: training on 155600 raw words (151881 effective words) took 0.4s, 366450 effective words/s
INFO - 2023-11-27 12:07:41,537: EPOCH 17: training on 155600 raw words (151863 effective words) took 0.5s, 324646 effective words/s
INFO - 2023-11-27 12:07:41,949: EPOCH 18: training on 155600 raw words (151786 effective words) took 0.4s, 371913 effective words/s
INFO - 2023-11-27 12:07:42,377: EPOCH 19: training on 155600 raw words (151884 effective words) took 0.4s, 357084 effective words/s
INFO - 2023-11-27 12:07:42,377: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037131 effective words) took 8.7s, 349278 effective words/s', 'datetime': '2023-11-27T12:07:42.377774', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:42,378: collecting all words and their counts
INFO - 2023-11-27 12:07:42,378: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:42,412: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:42,413: Updating model with new vocabulary
INFO - 2023-11-27 12:07:42,428: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:42.428351', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:42,445: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:42,445: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:07:42,445: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151976.97738810183 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:07:42.445966', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:42,473: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:42,473: updating layer weights
INFO - 2023-11-27 12:07:42,473: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:42.473957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:42,474: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:42,474: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:42.474250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:42,937: EPOCH 0: training on 155600 raw words (151998 effective words) took 0.5s, 331194 effective words/s
INFO - 2023-11-27 12:07:43,407: EPOCH 1: training on 155600 raw words (152034 effective words) took 0.5s, 325572 effective words/s
INFO - 2023-11-27 12:07:43,867: EPOCH 2: training on 155600 raw words (152016 effective words) took 0.5s, 333563 effective words/s
INFO - 2023-11-27 12:07:44,309: EPOCH 3: training on 155600 raw words (152010 effective words) took 0.4s, 346276 effective words/s
INFO - 2023-11-27 12:07:44,756: EPOCH 4: training on 155600 raw words (151982 effective words) took 0.4s, 342363 effective words/s
INFO - 2023-11-27 12:07:45,242: EPOCH 5: training on 155600 raw words (152027 effective words) took 0.5s, 314711 effective words/s
INFO - 2023-11-27 12:07:45,745: EPOCH 6: training on 155600 raw words (151961 effective words) took 0.5s, 304121 effective words/s
INFO - 2023-11-27 12:07:46,195: EPOCH 7: training on 155600 raw words (151991 effective words) took 0.4s, 340710 effective words/s
INFO - 2023-11-27 12:07:46,624: EPOCH 8: training on 155600 raw words (152040 effective words) took 0.4s, 357214 effective words/s
INFO - 2023-11-27 12:07:47,085: EPOCH 9: training on 155600 raw words (151968 effective words) took 0.5s, 331873 effective words/s
INFO - 2023-11-27 12:07:47,560: EPOCH 10: training on 155600 raw words (151931 effective words) took 0.5s, 322156 effective words/s
INFO - 2023-11-27 12:07:47,988: EPOCH 11: training on 155600 raw words (151873 effective words) took 0.4s, 357735 effective words/s
INFO - 2023-11-27 12:07:48,452: EPOCH 12: training on 155600 raw words (151989 effective words) took 0.5s, 329458 effective words/s
INFO - 2023-11-27 12:07:48,911: EPOCH 13: training on 155600 raw words (151944 effective words) took 0.5s, 333673 effective words/s
INFO - 2023-11-27 12:07:49,356: EPOCH 14: training on 155600 raw words (151997 effective words) took 0.4s, 343697 effective words/s
INFO - 2023-11-27 12:07:49,777: EPOCH 15: training on 155600 raw words (151984 effective words) took 0.4s, 363431 effective words/s
INFO - 2023-11-27 12:07:50,205: EPOCH 16: training on 155600 raw words (152016 effective words) took 0.4s, 357459 effective words/s
INFO - 2023-11-27 12:07:50,620: EPOCH 17: training on 155600 raw words (151968 effective words) took 0.4s, 369470 effective words/s
INFO - 2023-11-27 12:07:51,049: EPOCH 18: training on 155600 raw words (152030 effective words) took 0.4s, 357304 effective words/s
INFO - 2023-11-27 12:07:51,466: EPOCH 19: training on 155600 raw words (151990 effective words) took 0.4s, 367217 effective words/s
INFO - 2023-11-27 12:07:51,466: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039749 effective words) took 9.0s, 338040 effective words/s', 'datetime': '2023-11-27T12:07:51.466667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:51,467: collecting all words and their counts
INFO - 2023-11-27 12:07:51,467: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:07:51,501: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:07:51,501: Updating model with new vocabulary
INFO - 2023-11-27 12:07:51,516: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:07:51.516000', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:51,533: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:07:51,533: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:07:51,533: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151938.53539218093 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:07:51.533919', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:07:51,561: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:07:51,561: updating layer weights
INFO - 2023-11-27 12:07:51,561: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:07:51.561854', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:07:51,562: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:07:51,562: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:07:51.562155', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:07:51,988: EPOCH 0: training on 155600 raw words (151968 effective words) took 0.4s, 359247 effective words/s
INFO - 2023-11-27 12:07:52,370: EPOCH 1: training on 155600 raw words (151875 effective words) took 0.4s, 400806 effective words/s
INFO - 2023-11-27 12:07:52,756: EPOCH 2: training on 155600 raw words (151995 effective words) took 0.4s, 396640 effective words/s
INFO - 2023-11-27 12:07:53,168: EPOCH 3: training on 155600 raw words (151883 effective words) took 0.4s, 371240 effective words/s
INFO - 2023-11-27 12:07:53,595: EPOCH 4: training on 155600 raw words (151957 effective words) took 0.4s, 358441 effective words/s
INFO - 2023-11-27 12:07:54,016: EPOCH 5: training on 155600 raw words (151922 effective words) took 0.4s, 363191 effective words/s
INFO - 2023-11-27 12:07:54,425: EPOCH 6: training on 155600 raw words (151917 effective words) took 0.4s, 374456 effective words/s
INFO - 2023-11-27 12:07:54,841: EPOCH 7: training on 155600 raw words (151982 effective words) took 0.4s, 367793 effective words/s
INFO - 2023-11-27 12:07:55,296: EPOCH 8: training on 155600 raw words (151981 effective words) took 0.5s, 336059 effective words/s
INFO - 2023-11-27 12:07:55,709: EPOCH 9: training on 155600 raw words (151934 effective words) took 0.4s, 370735 effective words/s
INFO - 2023-11-27 12:07:56,201: EPOCH 10: training on 155600 raw words (151980 effective words) took 0.5s, 310791 effective words/s
INFO - 2023-11-27 12:07:56,624: EPOCH 11: training on 155600 raw words (151995 effective words) took 0.4s, 366131 effective words/s
INFO - 2023-11-27 12:07:57,061: EPOCH 12: training on 155600 raw words (151909 effective words) took 0.4s, 349615 effective words/s
INFO - 2023-11-27 12:07:57,519: EPOCH 13: training on 155600 raw words (151867 effective words) took 0.5s, 333471 effective words/s
INFO - 2023-11-27 12:07:57,944: EPOCH 14: training on 155600 raw words (151958 effective words) took 0.4s, 360879 effective words/s
INFO - 2023-11-27 12:07:58,374: EPOCH 15: training on 155600 raw words (151964 effective words) took 0.4s, 356095 effective words/s
INFO - 2023-11-27 12:07:58,779: EPOCH 16: training on 155600 raw words (152002 effective words) took 0.4s, 378575 effective words/s
INFO - 2023-11-27 12:07:59,208: EPOCH 17: training on 155600 raw words (151900 effective words) took 0.4s, 356057 effective words/s
INFO - 2023-11-27 12:07:59,631: EPOCH 18: training on 155600 raw words (152063 effective words) took 0.4s, 362566 effective words/s
INFO - 2023-11-27 12:08:00,054: EPOCH 19: training on 155600 raw words (151939 effective words) took 0.4s, 361826 effective words/s
INFO - 2023-11-27 12:08:00,054: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038991 effective words) took 8.5s, 357850 effective words/s', 'datetime': '2023-11-27T12:08:00.054682', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:00,054: collecting all words and their counts
INFO - 2023-11-27 12:08:00,055: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:00,085: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:00,085: Updating model with new vocabulary
INFO - 2023-11-27 12:08:00,098: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:00.098437', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:00,114: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:00,115: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:08:00,115: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151886.2804670025 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:08:00.115145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:00,141: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:00,141: updating layer weights
INFO - 2023-11-27 12:08:00,142: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:00.142188', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:00,142: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:00,142: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:00.142760', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:00,648: EPOCH 0: training on 155600 raw words (151797 effective words) took 0.5s, 303016 effective words/s
INFO - 2023-11-27 12:08:01,124: EPOCH 1: training on 155600 raw words (151945 effective words) took 0.5s, 321568 effective words/s
INFO - 2023-11-27 12:08:01,587: EPOCH 2: training on 155600 raw words (151886 effective words) took 0.5s, 330188 effective words/s
INFO - 2023-11-27 12:08:02,031: EPOCH 3: training on 155600 raw words (151931 effective words) took 0.4s, 344598 effective words/s
INFO - 2023-11-27 12:08:02,473: EPOCH 4: training on 155600 raw words (151903 effective words) took 0.4s, 346496 effective words/s
INFO - 2023-11-27 12:08:02,917: EPOCH 5: training on 155600 raw words (151879 effective words) took 0.4s, 344173 effective words/s
INFO - 2023-11-27 12:08:03,362: EPOCH 6: training on 155600 raw words (151869 effective words) took 0.4s, 343577 effective words/s
INFO - 2023-11-27 12:08:03,773: EPOCH 7: training on 155600 raw words (151902 effective words) took 0.4s, 371954 effective words/s
INFO - 2023-11-27 12:08:04,283: EPOCH 8: training on 155600 raw words (151945 effective words) took 0.5s, 299954 effective words/s
INFO - 2023-11-27 12:08:04,777: EPOCH 9: training on 155600 raw words (151953 effective words) took 0.5s, 309647 effective words/s
INFO - 2023-11-27 12:08:05,223: EPOCH 10: training on 155600 raw words (151857 effective words) took 0.4s, 343067 effective words/s
INFO - 2023-11-27 12:08:05,688: EPOCH 11: training on 155600 raw words (151972 effective words) took 0.5s, 329248 effective words/s
INFO - 2023-11-27 12:08:06,119: EPOCH 12: training on 155600 raw words (151905 effective words) took 0.4s, 372770 effective words/s
INFO - 2023-11-27 12:08:06,549: EPOCH 13: training on 155600 raw words (151864 effective words) took 0.4s, 355552 effective words/s
INFO - 2023-11-27 12:08:06,990: EPOCH 14: training on 155600 raw words (151895 effective words) took 0.4s, 346237 effective words/s
INFO - 2023-11-27 12:08:07,439: EPOCH 15: training on 155600 raw words (151849 effective words) took 0.4s, 340747 effective words/s
INFO - 2023-11-27 12:08:07,876: EPOCH 16: training on 155600 raw words (151864 effective words) took 0.4s, 350316 effective words/s
INFO - 2023-11-27 12:08:08,305: EPOCH 17: training on 155600 raw words (151852 effective words) took 0.4s, 356112 effective words/s
INFO - 2023-11-27 12:08:08,749: EPOCH 18: training on 155600 raw words (151935 effective words) took 0.4s, 344889 effective words/s
INFO - 2023-11-27 12:08:09,183: EPOCH 19: training on 155600 raw words (151901 effective words) took 0.4s, 352207 effective words/s
INFO - 2023-11-27 12:08:09,183: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037904 effective words) took 9.0s, 336026 effective words/s', 'datetime': '2023-11-27T12:08:09.183747', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:09,183: collecting all words and their counts
INFO - 2023-11-27 12:08:09,184: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:09,219: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:09,219: Updating model with new vocabulary
INFO - 2023-11-27 12:08:09,233: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:09.232977', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:09,250: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:09,251: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:08:09,251: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151919.53621395005 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:08:09.251448', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:09,280: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:09,280: updating layer weights
INFO - 2023-11-27 12:08:09,280: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:09.280526', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:09,280: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:09,280: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:09.280813', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:09,706: EPOCH 0: training on 155600 raw words (151911 effective words) took 0.4s, 359805 effective words/s
INFO - 2023-11-27 12:08:10,148: EPOCH 1: training on 155600 raw words (151903 effective words) took 0.4s, 346373 effective words/s
INFO - 2023-11-27 12:08:10,618: EPOCH 2: training on 155600 raw words (151800 effective words) took 0.5s, 324679 effective words/s
INFO - 2023-11-27 12:08:11,067: EPOCH 3: training on 155600 raw words (151860 effective words) took 0.4s, 340169 effective words/s
INFO - 2023-11-27 12:08:11,472: EPOCH 4: training on 155600 raw words (151955 effective words) took 0.4s, 378126 effective words/s
INFO - 2023-11-27 12:08:11,927: EPOCH 5: training on 155600 raw words (151958 effective words) took 0.5s, 336827 effective words/s
INFO - 2023-11-27 12:08:12,422: EPOCH 6: training on 155600 raw words (151906 effective words) took 0.5s, 308821 effective words/s
INFO - 2023-11-27 12:08:12,808: EPOCH 7: training on 155600 raw words (151951 effective words) took 0.4s, 396429 effective words/s
INFO - 2023-11-27 12:08:13,225: EPOCH 8: training on 155600 raw words (151882 effective words) took 0.4s, 367123 effective words/s
INFO - 2023-11-27 12:08:13,656: EPOCH 9: training on 155600 raw words (151891 effective words) took 0.4s, 355370 effective words/s
INFO - 2023-11-27 12:08:14,047: EPOCH 10: training on 155600 raw words (151929 effective words) took 0.4s, 391922 effective words/s
INFO - 2023-11-27 12:08:14,457: EPOCH 11: training on 155600 raw words (151894 effective words) took 0.4s, 373022 effective words/s
INFO - 2023-11-27 12:08:14,883: EPOCH 12: training on 155600 raw words (151962 effective words) took 0.4s, 359289 effective words/s
INFO - 2023-11-27 12:08:15,317: EPOCH 13: training on 155600 raw words (151928 effective words) took 0.4s, 353033 effective words/s
INFO - 2023-11-27 12:08:15,784: EPOCH 14: training on 155600 raw words (151859 effective words) took 0.5s, 327059 effective words/s
INFO - 2023-11-27 12:08:16,250: EPOCH 15: training on 155600 raw words (151914 effective words) took 0.5s, 328168 effective words/s
INFO - 2023-11-27 12:08:16,662: EPOCH 16: training on 155600 raw words (151866 effective words) took 0.4s, 371327 effective words/s
INFO - 2023-11-27 12:08:17,074: EPOCH 17: training on 155600 raw words (151981 effective words) took 0.4s, 372625 effective words/s
INFO - 2023-11-27 12:08:17,510: EPOCH 18: training on 155600 raw words (151945 effective words) took 0.4s, 350976 effective words/s
INFO - 2023-11-27 12:08:17,977: EPOCH 19: training on 155600 raw words (151844 effective words) took 0.5s, 327382 effective words/s
INFO - 2023-11-27 12:08:17,977: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038139 effective words) took 8.7s, 349354 effective words/s', 'datetime': '2023-11-27T12:08:17.977420', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:17,977: collecting all words and their counts
INFO - 2023-11-27 12:08:17,977: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:18,010: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:18,010: Updating model with new vocabulary
INFO - 2023-11-27 12:08:18,024: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:18.024871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:18,043: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:18,043: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:08:18,043: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151744.65330670465 word corpus (97.5%% of prior 155600)', 'datetime': '2023-11-27T12:08:18.043864', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:18,072: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:18,072: updating layer weights
INFO - 2023-11-27 12:08:18,072: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:18.072662', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:18,072: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:18,073: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:18.072971', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:18,541: EPOCH 0: training on 155600 raw words (151665 effective words) took 0.5s, 325695 effective words/s
INFO - 2023-11-27 12:08:18,995: EPOCH 1: training on 155600 raw words (151712 effective words) took 0.5s, 336625 effective words/s
INFO - 2023-11-27 12:08:19,445: EPOCH 2: training on 155600 raw words (151630 effective words) took 0.4s, 338994 effective words/s
INFO - 2023-11-27 12:08:19,897: EPOCH 3: training on 155600 raw words (151850 effective words) took 0.4s, 338797 effective words/s
INFO - 2023-11-27 12:08:20,330: EPOCH 4: training on 155600 raw words (151679 effective words) took 0.4s, 353099 effective words/s
INFO - 2023-11-27 12:08:20,767: EPOCH 5: training on 155600 raw words (151732 effective words) took 0.4s, 349213 effective words/s
INFO - 2023-11-27 12:08:21,194: EPOCH 6: training on 155600 raw words (151629 effective words) took 0.4s, 375524 effective words/s
INFO - 2023-11-27 12:08:21,644: EPOCH 7: training on 155600 raw words (151786 effective words) took 0.4s, 339032 effective words/s
INFO - 2023-11-27 12:08:22,052: EPOCH 8: training on 155600 raw words (151752 effective words) took 0.4s, 375118 effective words/s
INFO - 2023-11-27 12:08:22,469: EPOCH 9: training on 155600 raw words (151702 effective words) took 0.4s, 366859 effective words/s
INFO - 2023-11-27 12:08:22,910: EPOCH 10: training on 155600 raw words (151665 effective words) took 0.4s, 346282 effective words/s
INFO - 2023-11-27 12:08:23,367: EPOCH 11: training on 155600 raw words (151687 effective words) took 0.5s, 334012 effective words/s
INFO - 2023-11-27 12:08:23,824: EPOCH 12: training on 155600 raw words (151757 effective words) took 0.5s, 334913 effective words/s
INFO - 2023-11-27 12:08:24,290: EPOCH 13: training on 155600 raw words (151712 effective words) took 0.5s, 328100 effective words/s
INFO - 2023-11-27 12:08:24,742: EPOCH 14: training on 155600 raw words (151726 effective words) took 0.4s, 338232 effective words/s
INFO - 2023-11-27 12:08:25,212: EPOCH 15: training on 155600 raw words (151725 effective words) took 0.5s, 324823 effective words/s
INFO - 2023-11-27 12:08:25,625: EPOCH 16: training on 155600 raw words (151822 effective words) took 0.4s, 369908 effective words/s
INFO - 2023-11-27 12:08:26,083: EPOCH 17: training on 155600 raw words (151700 effective words) took 0.5s, 334048 effective words/s
INFO - 2023-11-27 12:08:26,523: EPOCH 18: training on 155600 raw words (151761 effective words) took 0.4s, 347146 effective words/s
INFO - 2023-11-27 12:08:26,985: EPOCH 19: training on 155600 raw words (151665 effective words) took 0.5s, 330753 effective words/s
INFO - 2023-11-27 12:08:26,985: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3034357 effective words) took 8.9s, 340453 effective words/s', 'datetime': '2023-11-27T12:08:26.985820', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:26,986: collecting all words and their counts
INFO - 2023-11-27 12:08:26,986: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:27,019: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:27,019: Updating model with new vocabulary
INFO - 2023-11-27 12:08:27,033: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:27.033162', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:27,050: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:27,050: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:08:27,050: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151830.71618604747 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:08:27.050776', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:27,077: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:27,077: updating layer weights
INFO - 2023-11-27 12:08:27,078: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:27.078236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:27,078: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:27,078: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:27.078500', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:27,530: EPOCH 0: training on 155600 raw words (151737 effective words) took 0.4s, 337832 effective words/s
INFO - 2023-11-27 12:08:27,942: EPOCH 1: training on 155600 raw words (151798 effective words) took 0.4s, 371536 effective words/s
INFO - 2023-11-27 12:08:28,348: EPOCH 2: training on 155600 raw words (151901 effective words) took 0.4s, 397450 effective words/s
INFO - 2023-11-27 12:08:28,744: EPOCH 3: training on 155600 raw words (151823 effective words) took 0.4s, 385511 effective words/s
INFO - 2023-11-27 12:08:29,129: EPOCH 4: training on 155600 raw words (151800 effective words) took 0.4s, 397196 effective words/s
INFO - 2023-11-27 12:08:29,470: EPOCH 5: training on 155600 raw words (151807 effective words) took 0.3s, 449545 effective words/s
INFO - 2023-11-27 12:08:29,802: EPOCH 6: training on 155600 raw words (151874 effective words) took 0.3s, 459733 effective words/s
INFO - 2023-11-27 12:08:30,181: EPOCH 7: training on 155600 raw words (151872 effective words) took 0.4s, 403138 effective words/s
INFO - 2023-11-27 12:08:30,524: EPOCH 8: training on 155600 raw words (151831 effective words) took 0.3s, 447057 effective words/s
INFO - 2023-11-27 12:08:30,858: EPOCH 9: training on 155600 raw words (151830 effective words) took 0.3s, 460940 effective words/s
INFO - 2023-11-27 12:08:31,173: EPOCH 10: training on 155600 raw words (151849 effective words) took 0.3s, 484961 effective words/s
INFO - 2023-11-27 12:08:31,490: EPOCH 11: training on 155600 raw words (151797 effective words) took 0.3s, 482756 effective words/s
INFO - 2023-11-27 12:08:31,827: EPOCH 12: training on 155600 raw words (151869 effective words) took 0.3s, 453432 effective words/s
INFO - 2023-11-27 12:08:32,147: EPOCH 13: training on 155600 raw words (151817 effective words) took 0.3s, 477590 effective words/s
INFO - 2023-11-27 12:08:32,464: EPOCH 14: training on 155600 raw words (151783 effective words) took 0.3s, 483121 effective words/s
INFO - 2023-11-27 12:08:32,834: EPOCH 15: training on 155600 raw words (151891 effective words) took 0.4s, 412390 effective words/s
INFO - 2023-11-27 12:08:33,157: EPOCH 16: training on 155600 raw words (151873 effective words) took 0.3s, 473982 effective words/s
INFO - 2023-11-27 12:08:33,471: EPOCH 17: training on 155600 raw words (151866 effective words) took 0.3s, 487592 effective words/s
INFO - 2023-11-27 12:08:33,790: EPOCH 18: training on 155600 raw words (151834 effective words) took 0.3s, 478261 effective words/s
INFO - 2023-11-27 12:08:34,126: EPOCH 19: training on 155600 raw words (151820 effective words) took 0.3s, 454958 effective words/s
INFO - 2023-11-27 12:08:34,126: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3036672 effective words) took 7.0s, 430857 effective words/s', 'datetime': '2023-11-27T12:08:34.126642', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:34,126: collecting all words and their counts
INFO - 2023-11-27 12:08:34,127: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:34,150: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:34,151: Updating model with new vocabulary
INFO - 2023-11-27 12:08:34,161: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:34.161114', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:34,173: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:34,173: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:08:34,173: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151993.34416414233 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:08:34.173439', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:34,192: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:34,192: updating layer weights
INFO - 2023-11-27 12:08:34,192: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:34.192734', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:34,192: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:34,192: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:34.192928', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:34,540: EPOCH 0: training on 155600 raw words (151991 effective words) took 0.3s, 459062 effective words/s
INFO - 2023-11-27 12:08:34,892: EPOCH 1: training on 155600 raw words (152084 effective words) took 0.4s, 434169 effective words/s
INFO - 2023-11-27 12:08:35,259: EPOCH 2: training on 155600 raw words (152051 effective words) took 0.4s, 417574 effective words/s
INFO - 2023-11-27 12:08:35,598: EPOCH 3: training on 155600 raw words (152036 effective words) took 0.3s, 451966 effective words/s
INFO - 2023-11-27 12:08:36,005: EPOCH 4: training on 155600 raw words (151987 effective words) took 0.4s, 375269 effective words/s
INFO - 2023-11-27 12:08:36,347: EPOCH 5: training on 155600 raw words (152001 effective words) took 0.3s, 448291 effective words/s
INFO - 2023-11-27 12:08:36,717: EPOCH 6: training on 155600 raw words (151952 effective words) took 0.4s, 413301 effective words/s
INFO - 2023-11-27 12:08:37,100: EPOCH 7: training on 155600 raw words (151972 effective words) took 0.4s, 399183 effective words/s
INFO - 2023-11-27 12:08:37,439: EPOCH 8: training on 155600 raw words (151990 effective words) took 0.3s, 451639 effective words/s
INFO - 2023-11-27 12:08:37,838: EPOCH 9: training on 155600 raw words (152011 effective words) took 0.4s, 382667 effective words/s
INFO - 2023-11-27 12:08:38,190: EPOCH 10: training on 155600 raw words (151996 effective words) took 0.3s, 434930 effective words/s
INFO - 2023-11-27 12:08:38,555: EPOCH 11: training on 155600 raw words (152000 effective words) took 0.4s, 419425 effective words/s
INFO - 2023-11-27 12:08:38,917: EPOCH 12: training on 155600 raw words (151969 effective words) took 0.4s, 422257 effective words/s
INFO - 2023-11-27 12:08:39,272: EPOCH 13: training on 155600 raw words (151909 effective words) took 0.4s, 430933 effective words/s
INFO - 2023-11-27 12:08:39,623: EPOCH 14: training on 155600 raw words (152043 effective words) took 0.3s, 435074 effective words/s
INFO - 2023-11-27 12:08:39,977: EPOCH 15: training on 155600 raw words (151939 effective words) took 0.4s, 432780 effective words/s
INFO - 2023-11-27 12:08:40,328: EPOCH 16: training on 155600 raw words (151995 effective words) took 0.3s, 435596 effective words/s
INFO - 2023-11-27 12:08:40,691: EPOCH 17: training on 155600 raw words (151969 effective words) took 0.4s, 420786 effective words/s
INFO - 2023-11-27 12:08:41,052: EPOCH 18: training on 155600 raw words (151960 effective words) took 0.4s, 424654 effective words/s
INFO - 2023-11-27 12:08:41,399: EPOCH 19: training on 155600 raw words (151997 effective words) took 0.3s, 439544 effective words/s
INFO - 2023-11-27 12:08:41,400: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039852 effective words) took 7.2s, 421784 effective words/s', 'datetime': '2023-11-27T12:08:41.400157', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:41,400: collecting all words and their counts
INFO - 2023-11-27 12:08:41,400: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:41,423: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:41,423: Updating model with new vocabulary
INFO - 2023-11-27 12:08:41,434: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:41.434534', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:41,450: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:41,451: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:08:41,451: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151853.1411627115 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:08:41.451403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:41,477: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:41,478: updating layer weights
INFO - 2023-11-27 12:08:41,478: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:41.478508', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:41,478: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:41,478: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:41.478801', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:41,862: EPOCH 0: training on 155600 raw words (151911 effective words) took 0.4s, 399193 effective words/s
INFO - 2023-11-27 12:08:42,293: EPOCH 1: training on 155600 raw words (151841 effective words) took 0.4s, 354634 effective words/s
INFO - 2023-11-27 12:08:42,721: EPOCH 2: training on 155600 raw words (151861 effective words) took 0.4s, 357756 effective words/s
INFO - 2023-11-27 12:08:43,161: EPOCH 3: training on 155600 raw words (151851 effective words) took 0.4s, 346711 effective words/s
INFO - 2023-11-27 12:08:43,646: EPOCH 4: training on 155600 raw words (151825 effective words) took 0.5s, 315190 effective words/s
INFO - 2023-11-27 12:08:44,075: EPOCH 5: training on 155600 raw words (151877 effective words) took 0.4s, 356396 effective words/s
INFO - 2023-11-27 12:08:44,532: EPOCH 6: training on 155600 raw words (151881 effective words) took 0.5s, 335524 effective words/s
INFO - 2023-11-27 12:08:44,984: EPOCH 7: training on 155600 raw words (151793 effective words) took 0.4s, 337631 effective words/s
INFO - 2023-11-27 12:08:45,452: EPOCH 8: training on 155600 raw words (151779 effective words) took 0.5s, 326865 effective words/s
INFO - 2023-11-27 12:08:45,934: EPOCH 9: training on 155600 raw words (151875 effective words) took 0.5s, 316538 effective words/s
INFO - 2023-11-27 12:08:46,390: EPOCH 10: training on 155600 raw words (151859 effective words) took 0.5s, 336118 effective words/s
INFO - 2023-11-27 12:08:46,848: EPOCH 11: training on 155600 raw words (151976 effective words) took 0.4s, 349851 effective words/s
INFO - 2023-11-27 12:08:47,308: EPOCH 12: training on 155600 raw words (151818 effective words) took 0.5s, 332058 effective words/s
INFO - 2023-11-27 12:08:47,767: EPOCH 13: training on 155600 raw words (151856 effective words) took 0.5s, 332879 effective words/s
INFO - 2023-11-27 12:08:48,266: EPOCH 14: training on 155600 raw words (151766 effective words) took 0.5s, 305950 effective words/s
INFO - 2023-11-27 12:08:48,755: EPOCH 15: training on 155600 raw words (151892 effective words) took 0.5s, 312607 effective words/s
INFO - 2023-11-27 12:08:49,236: EPOCH 16: training on 155600 raw words (151916 effective words) took 0.5s, 317727 effective words/s
INFO - 2023-11-27 12:08:49,711: EPOCH 17: training on 155600 raw words (151839 effective words) took 0.5s, 325186 effective words/s
INFO - 2023-11-27 12:08:50,178: EPOCH 18: training on 155600 raw words (151841 effective words) took 0.5s, 327958 effective words/s
INFO - 2023-11-27 12:08:50,660: EPOCH 19: training on 155600 raw words (151897 effective words) took 0.5s, 317184 effective words/s
INFO - 2023-11-27 12:08:50,661: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037154 effective words) took 9.2s, 330772 effective words/s', 'datetime': '2023-11-27T12:08:50.660957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:50,661: collecting all words and their counts
INFO - 2023-11-27 12:08:50,661: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:50,691: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:50,691: Updating model with new vocabulary
INFO - 2023-11-27 12:08:50,702: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:50.702204', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:50,714: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:50,714: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:08:50,714: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152028.92136816596 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:08:50.714585', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:50,734: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:50,734: updating layer weights
INFO - 2023-11-27 12:08:50,735: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:50.735024', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:50,735: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:50,735: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:50.735296', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:51,110: EPOCH 0: training on 155600 raw words (151992 effective words) took 0.4s, 407845 effective words/s
INFO - 2023-11-27 12:08:51,472: EPOCH 1: training on 155600 raw words (151983 effective words) took 0.4s, 422752 effective words/s
INFO - 2023-11-27 12:08:51,868: EPOCH 2: training on 155600 raw words (152046 effective words) took 0.4s, 386069 effective words/s
INFO - 2023-11-27 12:08:52,264: EPOCH 3: training on 155600 raw words (151968 effective words) took 0.4s, 385775 effective words/s
INFO - 2023-11-27 12:08:52,630: EPOCH 4: training on 155600 raw words (152010 effective words) took 0.3s, 439928 effective words/s
INFO - 2023-11-27 12:08:52,982: EPOCH 5: training on 155600 raw words (152053 effective words) took 0.3s, 435356 effective words/s
INFO - 2023-11-27 12:08:53,350: EPOCH 6: training on 155600 raw words (151996 effective words) took 0.4s, 415999 effective words/s
INFO - 2023-11-27 12:08:53,700: EPOCH 7: training on 155600 raw words (152074 effective words) took 0.3s, 437230 effective words/s
INFO - 2023-11-27 12:08:54,085: EPOCH 8: training on 155600 raw words (152033 effective words) took 0.4s, 397891 effective words/s
INFO - 2023-11-27 12:08:54,434: EPOCH 9: training on 155600 raw words (152043 effective words) took 0.3s, 438125 effective words/s
INFO - 2023-11-27 12:08:54,803: EPOCH 10: training on 155600 raw words (152014 effective words) took 0.4s, 414948 effective words/s
INFO - 2023-11-27 12:08:55,146: EPOCH 11: training on 155600 raw words (152046 effective words) took 0.3s, 445513 effective words/s
INFO - 2023-11-27 12:08:55,537: EPOCH 12: training on 155600 raw words (151992 effective words) took 0.4s, 391595 effective words/s
INFO - 2023-11-27 12:08:55,926: EPOCH 13: training on 155600 raw words (152015 effective words) took 0.4s, 392833 effective words/s
INFO - 2023-11-27 12:08:56,301: EPOCH 14: training on 155600 raw words (152014 effective words) took 0.4s, 408022 effective words/s
INFO - 2023-11-27 12:08:56,652: EPOCH 15: training on 155600 raw words (152041 effective words) took 0.3s, 436306 effective words/s
INFO - 2023-11-27 12:08:57,003: EPOCH 16: training on 155600 raw words (151975 effective words) took 0.3s, 441992 effective words/s
INFO - 2023-11-27 12:08:57,374: EPOCH 17: training on 155600 raw words (151990 effective words) took 0.4s, 411862 effective words/s
INFO - 2023-11-27 12:08:57,786: EPOCH 18: training on 155600 raw words (151929 effective words) took 0.4s, 371402 effective words/s
INFO - 2023-11-27 12:08:58,209: EPOCH 19: training on 155600 raw words (151994 effective words) took 0.4s, 361626 effective words/s
INFO - 2023-11-27 12:08:58,209: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040208 effective words) took 7.5s, 406774 effective words/s', 'datetime': '2023-11-27T12:08:58.209368', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:58,209: collecting all words and their counts
INFO - 2023-11-27 12:08:58,209: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:08:58,236: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:08:58,236: Updating model with new vocabulary
INFO - 2023-11-27 12:08:58,248: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:08:58.248486', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:58,272: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:08:58,272: sample=0.001 downsamples 20 most-common words
INFO - 2023-11-27 12:08:58,272: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152021.14484344673 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:08:58.272355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:08:58,292: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:08:58,293: updating layer weights
INFO - 2023-11-27 12:08:58,293: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:08:58.293617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:08:58,293: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:08:58,293: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:08:58.293928', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:08:58,636: EPOCH 0: training on 155600 raw words (151983 effective words) took 0.3s, 447154 effective words/s
INFO - 2023-11-27 12:08:58,994: EPOCH 1: training on 155600 raw words (151972 effective words) took 0.4s, 428184 effective words/s
INFO - 2023-11-27 12:08:59,324: EPOCH 2: training on 155600 raw words (152006 effective words) took 0.3s, 463989 effective words/s
INFO - 2023-11-27 12:08:59,668: EPOCH 3: training on 155600 raw words (151970 effective words) took 0.3s, 444886 effective words/s
INFO - 2023-11-27 12:09:00,020: EPOCH 4: training on 155600 raw words (152035 effective words) took 0.3s, 434466 effective words/s
INFO - 2023-11-27 12:09:00,364: EPOCH 5: training on 155600 raw words (151969 effective words) took 0.3s, 444736 effective words/s
INFO - 2023-11-27 12:09:00,706: EPOCH 6: training on 155600 raw words (151978 effective words) took 0.3s, 448000 effective words/s
INFO - 2023-11-27 12:09:01,055: EPOCH 7: training on 155600 raw words (152042 effective words) took 0.3s, 438204 effective words/s
INFO - 2023-11-27 12:09:01,390: EPOCH 8: training on 155600 raw words (151953 effective words) took 0.3s, 457871 effective words/s
INFO - 2023-11-27 12:09:01,720: EPOCH 9: training on 155600 raw words (151996 effective words) took 0.3s, 463786 effective words/s
INFO - 2023-11-27 12:09:02,064: EPOCH 10: training on 155600 raw words (152029 effective words) took 0.3s, 444682 effective words/s
INFO - 2023-11-27 12:09:02,385: EPOCH 11: training on 155600 raw words (151955 effective words) took 0.3s, 476012 effective words/s
INFO - 2023-11-27 12:09:02,786: EPOCH 12: training on 155600 raw words (151975 effective words) took 0.4s, 381265 effective words/s
INFO - 2023-11-27 12:09:03,125: EPOCH 13: training on 155600 raw words (151990 effective words) took 0.3s, 451729 effective words/s
INFO - 2023-11-27 12:09:03,508: EPOCH 14: training on 155600 raw words (152032 effective words) took 0.4s, 399991 effective words/s
INFO - 2023-11-27 12:09:03,867: EPOCH 15: training on 155600 raw words (152047 effective words) took 0.4s, 427620 effective words/s
INFO - 2023-11-27 12:09:04,217: EPOCH 16: training on 155600 raw words (151948 effective words) took 0.3s, 437082 effective words/s
INFO - 2023-11-27 12:09:04,556: EPOCH 17: training on 155600 raw words (152050 effective words) took 0.3s, 451366 effective words/s
INFO - 2023-11-27 12:09:04,900: EPOCH 18: training on 155600 raw words (152083 effective words) took 0.3s, 445207 effective words/s
INFO - 2023-11-27 12:09:05,280: EPOCH 19: training on 155600 raw words (152055 effective words) took 0.4s, 402160 effective words/s
INFO - 2023-11-27 12:09:05,281: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040068 effective words) took 7.0s, 435095 effective words/s', 'datetime': '2023-11-27T12:09:05.281189', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:05,281: collecting all words and their counts
INFO - 2023-11-27 12:09:05,281: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:05,305: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:05,305: Updating model with new vocabulary
INFO - 2023-11-27 12:09:05,315: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:05.315147', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:05,327: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:05,327: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:09:05,327: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151948.59200008799 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:09:05.327442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:05,346: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:05,346: updating layer weights
INFO - 2023-11-27 12:09:05,346: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:05.346768', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:05,346: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:05,347: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:05.347001', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:05,718: EPOCH 0: training on 155600 raw words (151949 effective words) took 0.4s, 411988 effective words/s
INFO - 2023-11-27 12:09:06,191: EPOCH 1: training on 155600 raw words (151975 effective words) took 0.5s, 322990 effective words/s
INFO - 2023-11-27 12:09:06,650: EPOCH 2: training on 155600 raw words (152007 effective words) took 0.5s, 333658 effective words/s
INFO - 2023-11-27 12:09:07,129: EPOCH 3: training on 155600 raw words (152019 effective words) took 0.5s, 319650 effective words/s
INFO - 2023-11-27 12:09:07,627: EPOCH 4: training on 155600 raw words (151952 effective words) took 0.5s, 306912 effective words/s
INFO - 2023-11-27 12:09:08,121: EPOCH 5: training on 155600 raw words (151959 effective words) took 0.5s, 309908 effective words/s
INFO - 2023-11-27 12:09:08,600: EPOCH 6: training on 155600 raw words (151919 effective words) took 0.5s, 318579 effective words/s
INFO - 2023-11-27 12:09:09,000: EPOCH 7: training on 155600 raw words (152012 effective words) took 0.4s, 383239 effective words/s
INFO - 2023-11-27 12:09:09,464: EPOCH 8: training on 155600 raw words (151902 effective words) took 0.4s, 342211 effective words/s
INFO - 2023-11-27 12:09:09,917: EPOCH 9: training on 155600 raw words (152024 effective words) took 0.4s, 337999 effective words/s
INFO - 2023-11-27 12:09:10,386: EPOCH 10: training on 155600 raw words (151950 effective words) took 0.5s, 325696 effective words/s
INFO - 2023-11-27 12:09:10,862: EPOCH 11: training on 155600 raw words (152009 effective words) took 0.5s, 333397 effective words/s
INFO - 2023-11-27 12:09:11,329: EPOCH 12: training on 155600 raw words (151898 effective words) took 0.5s, 327010 effective words/s
INFO - 2023-11-27 12:09:11,809: EPOCH 13: training on 155600 raw words (152004 effective words) took 0.5s, 319207 effective words/s
INFO - 2023-11-27 12:09:12,298: EPOCH 14: training on 155600 raw words (151946 effective words) took 0.5s, 312309 effective words/s
INFO - 2023-11-27 12:09:12,775: EPOCH 15: training on 155600 raw words (151977 effective words) took 0.5s, 320627 effective words/s
INFO - 2023-11-27 12:09:13,280: EPOCH 16: training on 155600 raw words (151941 effective words) took 0.5s, 302487 effective words/s
INFO - 2023-11-27 12:09:13,797: EPOCH 17: training on 155600 raw words (151854 effective words) took 0.5s, 295850 effective words/s
INFO - 2023-11-27 12:09:14,372: EPOCH 18: training on 155600 raw words (151902 effective words) took 0.6s, 265777 effective words/s
INFO - 2023-11-27 12:09:14,850: EPOCH 19: training on 155600 raw words (152039 effective words) took 0.5s, 319949 effective words/s
INFO - 2023-11-27 12:09:14,850: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039238 effective words) took 9.5s, 319804 effective words/s', 'datetime': '2023-11-27T12:09:14.850575', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:14,850: collecting all words and their counts
INFO - 2023-11-27 12:09:14,851: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:14,884: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:14,884: Updating model with new vocabulary
INFO - 2023-11-27 12:09:14,897: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:14.897808', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:14,914: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:14,914: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:09:14,915: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151932.3571707733 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:09:14.915134', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:14,942: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:14,943: updating layer weights
INFO - 2023-11-27 12:09:14,943: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:14.943580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:14,943: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:14,943: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:14.943895', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:15,361: EPOCH 0: training on 155600 raw words (151996 effective words) took 0.4s, 372239 effective words/s
INFO - 2023-11-27 12:09:15,873: EPOCH 1: training on 155600 raw words (152045 effective words) took 0.5s, 298825 effective words/s
INFO - 2023-11-27 12:09:16,420: EPOCH 2: training on 155600 raw words (151945 effective words) took 0.5s, 282140 effective words/s
INFO - 2023-11-27 12:09:16,841: EPOCH 3: training on 155600 raw words (151877 effective words) took 0.4s, 363210 effective words/s
INFO - 2023-11-27 12:09:17,263: EPOCH 4: training on 155600 raw words (151972 effective words) took 0.4s, 370832 effective words/s
INFO - 2023-11-27 12:09:17,612: EPOCH 5: training on 155600 raw words (151899 effective words) took 0.3s, 438072 effective words/s
INFO - 2023-11-27 12:09:17,971: EPOCH 6: training on 155600 raw words (151965 effective words) took 0.4s, 426533 effective words/s
INFO - 2023-11-27 12:09:18,326: EPOCH 7: training on 155600 raw words (152009 effective words) took 0.4s, 432042 effective words/s
INFO - 2023-11-27 12:09:18,667: EPOCH 8: training on 155600 raw words (151847 effective words) took 0.3s, 449077 effective words/s
INFO - 2023-11-27 12:09:19,014: EPOCH 9: training on 155600 raw words (151950 effective words) took 0.3s, 441068 effective words/s
INFO - 2023-11-27 12:09:19,362: EPOCH 10: training on 155600 raw words (151992 effective words) took 0.3s, 438754 effective words/s
INFO - 2023-11-27 12:09:19,697: EPOCH 11: training on 155600 raw words (151963 effective words) took 0.3s, 457457 effective words/s
INFO - 2023-11-27 12:09:20,042: EPOCH 12: training on 155600 raw words (151854 effective words) took 0.3s, 442662 effective words/s
INFO - 2023-11-27 12:09:20,391: EPOCH 13: training on 155600 raw words (151950 effective words) took 0.3s, 439460 effective words/s
INFO - 2023-11-27 12:09:20,728: EPOCH 14: training on 155600 raw words (151974 effective words) took 0.3s, 453547 effective words/s
INFO - 2023-11-27 12:09:21,075: EPOCH 15: training on 155600 raw words (151899 effective words) took 0.3s, 441706 effective words/s
INFO - 2023-11-27 12:09:21,418: EPOCH 16: training on 155600 raw words (151932 effective words) took 0.3s, 445635 effective words/s
INFO - 2023-11-27 12:09:21,768: EPOCH 17: training on 155600 raw words (151914 effective words) took 0.3s, 437737 effective words/s
INFO - 2023-11-27 12:09:22,113: EPOCH 18: training on 155600 raw words (151871 effective words) took 0.3s, 448432 effective words/s
INFO - 2023-11-27 12:09:22,470: EPOCH 19: training on 155600 raw words (151936 effective words) took 0.4s, 428525 effective words/s
INFO - 2023-11-27 12:09:22,471: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038790 effective words) took 7.5s, 403717 effective words/s', 'datetime': '2023-11-27T12:09:22.471036', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:22,471: collecting all words and their counts
INFO - 2023-11-27 12:09:22,471: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:22,504: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:22,504: Updating model with new vocabulary
INFO - 2023-11-27 12:09:22,522: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:22.522044', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:22,540: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:22,541: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:09:22,541: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151922.01887707366 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:09:22.541422', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:22,563: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:22,563: updating layer weights
INFO - 2023-11-27 12:09:22,563: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:22.563952', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:22,564: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:22,564: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:22.564237', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:22,939: EPOCH 0: training on 155600 raw words (151970 effective words) took 0.4s, 407056 effective words/s
INFO - 2023-11-27 12:09:23,315: EPOCH 1: training on 155600 raw words (151931 effective words) took 0.4s, 407582 effective words/s
INFO - 2023-11-27 12:09:23,708: EPOCH 2: training on 155600 raw words (151903 effective words) took 0.4s, 388255 effective words/s
INFO - 2023-11-27 12:09:24,083: EPOCH 3: training on 155600 raw words (151924 effective words) took 0.4s, 408710 effective words/s
INFO - 2023-11-27 12:09:24,474: EPOCH 4: training on 155600 raw words (151878 effective words) took 0.4s, 390073 effective words/s
INFO - 2023-11-27 12:09:24,851: EPOCH 5: training on 155600 raw words (151864 effective words) took 0.4s, 425387 effective words/s
INFO - 2023-11-27 12:09:25,225: EPOCH 6: training on 155600 raw words (151844 effective words) took 0.4s, 408666 effective words/s
INFO - 2023-11-27 12:09:25,619: EPOCH 7: training on 155600 raw words (151916 effective words) took 0.4s, 387723 effective words/s
INFO - 2023-11-27 12:09:25,992: EPOCH 8: training on 155600 raw words (151793 effective words) took 0.4s, 410139 effective words/s
INFO - 2023-11-27 12:09:26,393: EPOCH 9: training on 155600 raw words (151956 effective words) took 0.4s, 380742 effective words/s
INFO - 2023-11-27 12:09:26,770: EPOCH 10: training on 155600 raw words (152000 effective words) took 0.4s, 406909 effective words/s
INFO - 2023-11-27 12:09:27,142: EPOCH 11: training on 155600 raw words (151951 effective words) took 0.4s, 411013 effective words/s
INFO - 2023-11-27 12:09:27,538: EPOCH 12: training on 155600 raw words (151924 effective words) took 0.4s, 386146 effective words/s
INFO - 2023-11-27 12:09:27,920: EPOCH 13: training on 155600 raw words (151999 effective words) took 0.4s, 401214 effective words/s
INFO - 2023-11-27 12:09:28,297: EPOCH 14: training on 155600 raw words (151906 effective words) took 0.4s, 404918 effective words/s
INFO - 2023-11-27 12:09:28,685: EPOCH 15: training on 155600 raw words (151895 effective words) took 0.4s, 394794 effective words/s
INFO - 2023-11-27 12:09:29,070: EPOCH 16: training on 155600 raw words (151922 effective words) took 0.4s, 396872 effective words/s
INFO - 2023-11-27 12:09:29,442: EPOCH 17: training on 155600 raw words (151952 effective words) took 0.4s, 411220 effective words/s
INFO - 2023-11-27 12:09:29,801: EPOCH 18: training on 155600 raw words (151994 effective words) took 0.4s, 426930 effective words/s
INFO - 2023-11-27 12:09:30,210: EPOCH 19: training on 155600 raw words (151987 effective words) took 0.4s, 373957 effective words/s
INFO - 2023-11-27 12:09:30,210: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038509 effective words) took 7.6s, 397401 effective words/s', 'datetime': '2023-11-27T12:09:30.210338', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:30,210: collecting all words and their counts
INFO - 2023-11-27 12:09:30,210: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:30,243: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:30,243: Updating model with new vocabulary
INFO - 2023-11-27 12:09:30,257: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:30.257805', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:30,274: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:30,274: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:09:30,275: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151750.18498691544 word corpus (97.5%% of prior 155600)', 'datetime': '2023-11-27T12:09:30.274938', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:30,300: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:30,300: updating layer weights
INFO - 2023-11-27 12:09:30,300: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:30.300914', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:30,301: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:30,301: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:30.301375', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:30,759: EPOCH 0: training on 155600 raw words (151747 effective words) took 0.5s, 333524 effective words/s
INFO - 2023-11-27 12:09:31,207: EPOCH 1: training on 155600 raw words (151819 effective words) took 0.4s, 341645 effective words/s
INFO - 2023-11-27 12:09:31,658: EPOCH 2: training on 155600 raw words (151730 effective words) took 0.4s, 338610 effective words/s
INFO - 2023-11-27 12:09:32,090: EPOCH 3: training on 155600 raw words (151768 effective words) took 0.4s, 353465 effective words/s
INFO - 2023-11-27 12:09:32,530: EPOCH 4: training on 155600 raw words (151727 effective words) took 0.4s, 347695 effective words/s
INFO - 2023-11-27 12:09:32,962: EPOCH 5: training on 155600 raw words (151697 effective words) took 0.4s, 353262 effective words/s
INFO - 2023-11-27 12:09:33,453: EPOCH 6: training on 155600 raw words (151740 effective words) took 0.5s, 310907 effective words/s
INFO - 2023-11-27 12:09:33,956: EPOCH 7: training on 155600 raw words (151736 effective words) took 0.5s, 303600 effective words/s
INFO - 2023-11-27 12:09:34,404: EPOCH 8: training on 155600 raw words (151741 effective words) took 0.4s, 341424 effective words/s
INFO - 2023-11-27 12:09:34,791: EPOCH 9: training on 155600 raw words (151690 effective words) took 0.4s, 394266 effective words/s
INFO - 2023-11-27 12:09:35,128: EPOCH 10: training on 155600 raw words (151732 effective words) took 0.3s, 454494 effective words/s
INFO - 2023-11-27 12:09:35,537: EPOCH 11: training on 155600 raw words (151720 effective words) took 0.4s, 373049 effective words/s
INFO - 2023-11-27 12:09:36,023: EPOCH 12: training on 155600 raw words (151730 effective words) took 0.5s, 314615 effective words/s
INFO - 2023-11-27 12:09:36,515: EPOCH 13: training on 155600 raw words (151695 effective words) took 0.5s, 310230 effective words/s
INFO - 2023-11-27 12:09:36,989: EPOCH 14: training on 155600 raw words (151716 effective words) took 0.5s, 322403 effective words/s
INFO - 2023-11-27 12:09:37,445: EPOCH 15: training on 155600 raw words (151703 effective words) took 0.5s, 335525 effective words/s
INFO - 2023-11-27 12:09:37,899: EPOCH 16: training on 155600 raw words (151783 effective words) took 0.5s, 336679 effective words/s
INFO - 2023-11-27 12:09:38,355: EPOCH 17: training on 155600 raw words (151843 effective words) took 0.5s, 334976 effective words/s
INFO - 2023-11-27 12:09:38,806: EPOCH 18: training on 155600 raw words (151692 effective words) took 0.4s, 338622 effective words/s
INFO - 2023-11-27 12:09:39,192: EPOCH 19: training on 155600 raw words (151757 effective words) took 0.4s, 396642 effective words/s
INFO - 2023-11-27 12:09:39,192: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3034766 effective words) took 8.9s, 341325 effective words/s', 'datetime': '2023-11-27T12:09:39.192671', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:39,192: collecting all words and their counts
INFO - 2023-11-27 12:09:39,193: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:39,214: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:39,214: Updating model with new vocabulary
INFO - 2023-11-27 12:09:39,224: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:39.224506', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:39,237: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:39,237: sample=0.001 downsamples 25 most-common words
INFO - 2023-11-27 12:09:39,237: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151961.43004964397 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:09:39.237478', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:39,255: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:39,255: updating layer weights
INFO - 2023-11-27 12:09:39,256: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:39.256138', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:39,256: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:39,256: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:39.256335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:39,623: EPOCH 0: training on 155600 raw words (151930 effective words) took 0.4s, 417390 effective words/s
INFO - 2023-11-27 12:09:39,967: EPOCH 1: training on 155600 raw words (152021 effective words) took 0.3s, 443939 effective words/s
INFO - 2023-11-27 12:09:40,309: EPOCH 2: training on 155600 raw words (151927 effective words) took 0.3s, 448457 effective words/s
INFO - 2023-11-27 12:09:40,664: EPOCH 3: training on 155600 raw words (151988 effective words) took 0.4s, 430726 effective words/s
INFO - 2023-11-27 12:09:41,013: EPOCH 4: training on 155600 raw words (151956 effective words) took 0.3s, 438039 effective words/s
INFO - 2023-11-27 12:09:41,349: EPOCH 5: training on 155600 raw words (151992 effective words) took 0.3s, 456434 effective words/s
INFO - 2023-11-27 12:09:41,748: EPOCH 6: training on 155600 raw words (151948 effective words) took 0.4s, 382347 effective words/s
INFO - 2023-11-27 12:09:42,145: EPOCH 7: training on 155600 raw words (151931 effective words) took 0.4s, 385771 effective words/s
INFO - 2023-11-27 12:09:42,604: EPOCH 8: training on 155600 raw words (151971 effective words) took 0.5s, 333845 effective words/s
INFO - 2023-11-27 12:09:42,975: EPOCH 9: training on 155600 raw words (152000 effective words) took 0.4s, 413191 effective words/s
INFO - 2023-11-27 12:09:43,375: EPOCH 10: training on 155600 raw words (151997 effective words) took 0.4s, 382497 effective words/s
INFO - 2023-11-27 12:09:43,776: EPOCH 11: training on 155600 raw words (151930 effective words) took 0.4s, 381460 effective words/s
INFO - 2023-11-27 12:09:44,172: EPOCH 12: training on 155600 raw words (152004 effective words) took 0.4s, 386185 effective words/s
INFO - 2023-11-27 12:09:44,578: EPOCH 13: training on 155600 raw words (151962 effective words) took 0.4s, 376491 effective words/s
INFO - 2023-11-27 12:09:44,976: EPOCH 14: training on 155600 raw words (151995 effective words) took 0.4s, 385058 effective words/s
INFO - 2023-11-27 12:09:45,363: EPOCH 15: training on 155600 raw words (151951 effective words) took 0.4s, 395015 effective words/s
INFO - 2023-11-27 12:09:45,764: EPOCH 16: training on 155600 raw words (151981 effective words) took 0.4s, 383073 effective words/s
INFO - 2023-11-27 12:09:46,168: EPOCH 17: training on 155600 raw words (151909 effective words) took 0.4s, 379053 effective words/s
INFO - 2023-11-27 12:09:46,572: EPOCH 18: training on 155600 raw words (151976 effective words) took 0.4s, 378054 effective words/s
INFO - 2023-11-27 12:09:46,943: EPOCH 19: training on 155600 raw words (152043 effective words) took 0.4s, 412353 effective words/s
INFO - 2023-11-27 12:09:46,944: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039412 effective words) took 7.7s, 395372 effective words/s', 'datetime': '2023-11-27T12:09:46.943937', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:46,944: collecting all words and their counts
INFO - 2023-11-27 12:09:46,944: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:46,967: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:46,967: Updating model with new vocabulary
INFO - 2023-11-27 12:09:46,978: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:46.978210', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:46,992: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:46,993: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:09:46,993: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152085.87400379393 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:09:46.993176', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:47,014: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:47,014: updating layer weights
INFO - 2023-11-27 12:09:47,015: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:47.015497', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:47,015: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:47,016: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:47.015991', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:47,344: EPOCH 0: training on 155600 raw words (152092 effective words) took 0.3s, 466444 effective words/s
INFO - 2023-11-27 12:09:47,707: EPOCH 1: training on 155600 raw words (152050 effective words) took 0.4s, 421566 effective words/s
INFO - 2023-11-27 12:09:48,111: EPOCH 2: training on 155600 raw words (152191 effective words) took 0.4s, 379198 effective words/s
INFO - 2023-11-27 12:09:48,526: EPOCH 3: training on 155600 raw words (151983 effective words) took 0.4s, 370340 effective words/s
INFO - 2023-11-27 12:09:48,902: EPOCH 4: training on 155600 raw words (152090 effective words) took 0.4s, 412637 effective words/s
INFO - 2023-11-27 12:09:49,260: EPOCH 5: training on 155600 raw words (152147 effective words) took 0.4s, 427121 effective words/s
INFO - 2023-11-27 12:09:49,615: EPOCH 6: training on 155600 raw words (152116 effective words) took 0.4s, 431323 effective words/s
INFO - 2023-11-27 12:09:49,970: EPOCH 7: training on 155600 raw words (152016 effective words) took 0.4s, 431991 effective words/s
INFO - 2023-11-27 12:09:50,287: EPOCH 8: training on 155600 raw words (152177 effective words) took 0.3s, 483536 effective words/s
INFO - 2023-11-27 12:09:50,624: EPOCH 9: training on 155600 raw words (152127 effective words) took 0.3s, 454582 effective words/s
INFO - 2023-11-27 12:09:50,942: EPOCH 10: training on 155600 raw words (152064 effective words) took 0.3s, 481744 effective words/s
INFO - 2023-11-27 12:09:51,273: EPOCH 11: training on 155600 raw words (152133 effective words) took 0.3s, 462373 effective words/s
INFO - 2023-11-27 12:09:51,670: EPOCH 12: training on 155600 raw words (152090 effective words) took 0.4s, 385168 effective words/s
INFO - 2023-11-27 12:09:51,993: EPOCH 13: training on 155600 raw words (152069 effective words) took 0.3s, 484757 effective words/s
INFO - 2023-11-27 12:09:52,314: EPOCH 14: training on 155600 raw words (152091 effective words) took 0.3s, 478121 effective words/s
INFO - 2023-11-27 12:09:52,630: EPOCH 15: training on 155600 raw words (152125 effective words) took 0.3s, 484955 effective words/s
INFO - 2023-11-27 12:09:52,961: EPOCH 16: training on 155600 raw words (152230 effective words) took 0.3s, 463341 effective words/s
INFO - 2023-11-27 12:09:53,297: EPOCH 17: training on 155600 raw words (152081 effective words) took 0.3s, 455156 effective words/s
INFO - 2023-11-27 12:09:53,622: EPOCH 18: training on 155600 raw words (152116 effective words) took 0.3s, 471372 effective words/s
INFO - 2023-11-27 12:09:53,943: EPOCH 19: training on 155600 raw words (152120 effective words) took 0.3s, 476947 effective words/s
INFO - 2023-11-27 12:09:53,944: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3042108 effective words) took 6.9s, 439110 effective words/s', 'datetime': '2023-11-27T12:09:53.944044', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:53,944: collecting all words and their counts
INFO - 2023-11-27 12:09:53,944: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:09:53,966: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:09:53,967: Updating model with new vocabulary
INFO - 2023-11-27 12:09:53,977: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:09:53.976998', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:53,989: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:09:53,989: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:09:53,989: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151877.47237829704 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:09:53.989287', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:09:54,008: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:09:54,008: updating layer weights
INFO - 2023-11-27 12:09:54,008: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:09:54.008587', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:09:54,008: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:09:54,008: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:09:54.008796', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:09:54,458: EPOCH 0: training on 155600 raw words (151881 effective words) took 0.4s, 341890 effective words/s
INFO - 2023-11-27 12:09:54,969: EPOCH 1: training on 155600 raw words (151862 effective words) took 0.5s, 298690 effective words/s
INFO - 2023-11-27 12:09:55,411: EPOCH 2: training on 155600 raw words (151977 effective words) took 0.4s, 346232 effective words/s
INFO - 2023-11-27 12:09:55,861: EPOCH 3: training on 155600 raw words (151929 effective words) took 0.4s, 340150 effective words/s
INFO - 2023-11-27 12:09:56,337: EPOCH 4: training on 155600 raw words (151985 effective words) took 0.5s, 321645 effective words/s
INFO - 2023-11-27 12:09:56,811: EPOCH 5: training on 155600 raw words (151908 effective words) took 0.5s, 322787 effective words/s
INFO - 2023-11-27 12:09:57,283: EPOCH 6: training on 155600 raw words (151817 effective words) took 0.5s, 323569 effective words/s
INFO - 2023-11-27 12:09:57,745: EPOCH 7: training on 155600 raw words (151961 effective words) took 0.5s, 330633 effective words/s
INFO - 2023-11-27 12:09:58,200: EPOCH 8: training on 155600 raw words (151873 effective words) took 0.5s, 336251 effective words/s
INFO - 2023-11-27 12:09:58,665: EPOCH 9: training on 155600 raw words (151870 effective words) took 0.5s, 328809 effective words/s
INFO - 2023-11-27 12:09:59,117: EPOCH 10: training on 155600 raw words (151840 effective words) took 0.4s, 338144 effective words/s
INFO - 2023-11-27 12:09:59,598: EPOCH 11: training on 155600 raw words (151827 effective words) took 0.5s, 318259 effective words/s
INFO - 2023-11-27 12:10:00,112: EPOCH 12: training on 155600 raw words (151890 effective words) took 0.5s, 297145 effective words/s
INFO - 2023-11-27 12:10:00,631: EPOCH 13: training on 155600 raw words (151945 effective words) took 0.5s, 294235 effective words/s
INFO - 2023-11-27 12:10:01,154: EPOCH 14: training on 155600 raw words (151959 effective words) took 0.5s, 292639 effective words/s
INFO - 2023-11-27 12:10:01,686: EPOCH 15: training on 155600 raw words (151846 effective words) took 0.5s, 286661 effective words/s
INFO - 2023-11-27 12:10:02,206: EPOCH 16: training on 155600 raw words (151871 effective words) took 0.5s, 294277 effective words/s
INFO - 2023-11-27 12:10:02,726: EPOCH 17: training on 155600 raw words (151851 effective words) took 0.5s, 293905 effective words/s
INFO - 2023-11-27 12:10:03,248: EPOCH 18: training on 155600 raw words (151860 effective words) took 0.5s, 292980 effective words/s
INFO - 2023-11-27 12:10:03,624: EPOCH 19: training on 155600 raw words (151844 effective words) took 0.4s, 406302 effective words/s
INFO - 2023-11-27 12:10:03,624: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037796 effective words) took 9.6s, 315910 effective words/s', 'datetime': '2023-11-27T12:10:03.624944', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:03,625: collecting all words and their counts
INFO - 2023-11-27 12:10:03,625: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:03,651: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:03,651: Updating model with new vocabulary
INFO - 2023-11-27 12:10:03,663: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:03.663430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:03,679: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:03,679: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:10:03,682: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151870.22906626982 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:10:03.682379', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:03,702: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:03,702: updating layer weights
INFO - 2023-11-27 12:10:03,702: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:03.702615', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:03,702: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:03,702: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:03.702821', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:04,051: EPOCH 0: training on 155600 raw words (151888 effective words) took 0.3s, 437881 effective words/s
INFO - 2023-11-27 12:10:04,401: EPOCH 1: training on 155600 raw words (151880 effective words) took 0.3s, 437587 effective words/s
INFO - 2023-11-27 12:10:04,732: EPOCH 2: training on 155600 raw words (151811 effective words) took 0.3s, 461517 effective words/s
INFO - 2023-11-27 12:10:05,080: EPOCH 3: training on 155600 raw words (151841 effective words) took 0.3s, 439979 effective words/s
INFO - 2023-11-27 12:10:05,442: EPOCH 4: training on 155600 raw words (151857 effective words) took 0.4s, 422066 effective words/s
INFO - 2023-11-27 12:10:05,787: EPOCH 5: training on 155600 raw words (151924 effective words) took 0.3s, 443176 effective words/s
INFO - 2023-11-27 12:10:06,152: EPOCH 6: training on 155600 raw words (151814 effective words) took 0.4s, 418571 effective words/s
INFO - 2023-11-27 12:10:06,500: EPOCH 7: training on 155600 raw words (151846 effective words) took 0.3s, 440525 effective words/s
INFO - 2023-11-27 12:10:06,813: EPOCH 8: training on 155600 raw words (151845 effective words) took 0.3s, 488323 effective words/s
INFO - 2023-11-27 12:10:07,149: EPOCH 9: training on 155600 raw words (151802 effective words) took 0.3s, 454811 effective words/s
INFO - 2023-11-27 12:10:07,475: EPOCH 10: training on 155600 raw words (151857 effective words) took 0.3s, 468630 effective words/s
INFO - 2023-11-27 12:10:07,796: EPOCH 11: training on 155600 raw words (151874 effective words) took 0.3s, 477544 effective words/s
INFO - 2023-11-27 12:10:08,122: EPOCH 12: training on 155600 raw words (151938 effective words) took 0.3s, 469585 effective words/s
INFO - 2023-11-27 12:10:08,443: EPOCH 13: training on 155600 raw words (151931 effective words) took 0.3s, 477664 effective words/s
INFO - 2023-11-27 12:10:08,753: EPOCH 14: training on 155600 raw words (151853 effective words) took 0.3s, 493310 effective words/s
INFO - 2023-11-27 12:10:09,132: EPOCH 15: training on 155600 raw words (151891 effective words) took 0.4s, 402924 effective words/s
INFO - 2023-11-27 12:10:09,488: EPOCH 16: training on 155600 raw words (151848 effective words) took 0.4s, 430041 effective words/s
INFO - 2023-11-27 12:10:09,844: EPOCH 17: training on 155600 raw words (151858 effective words) took 0.4s, 430084 effective words/s
INFO - 2023-11-27 12:10:10,202: EPOCH 18: training on 155600 raw words (151876 effective words) took 0.4s, 427638 effective words/s
INFO - 2023-11-27 12:10:10,553: EPOCH 19: training on 155600 raw words (151844 effective words) took 0.3s, 435454 effective words/s
INFO - 2023-11-27 12:10:10,553: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037278 effective words) took 6.9s, 443342 effective words/s', 'datetime': '2023-11-27T12:10:10.553780', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:10,553: collecting all words and their counts
INFO - 2023-11-27 12:10:10,554: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:10,580: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:10,580: Updating model with new vocabulary
INFO - 2023-11-27 12:10:10,592: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:10.592191', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:10,606: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:10,606: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:10:10,606: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151931.1086028386 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:10:10.606540', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:10,628: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:10,629: updating layer weights
INFO - 2023-11-27 12:10:10,629: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:10.629597', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:10,629: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:10,629: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:10.629953', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:11,019: EPOCH 0: training on 155600 raw words (151992 effective words) took 0.4s, 393408 effective words/s
INFO - 2023-11-27 12:10:11,428: EPOCH 1: training on 155600 raw words (151883 effective words) took 0.4s, 373450 effective words/s
INFO - 2023-11-27 12:10:11,778: EPOCH 2: training on 155600 raw words (151902 effective words) took 0.3s, 436884 effective words/s
INFO - 2023-11-27 12:10:12,152: EPOCH 3: training on 155600 raw words (152074 effective words) took 0.4s, 409812 effective words/s
INFO - 2023-11-27 12:10:12,504: EPOCH 4: training on 155600 raw words (151862 effective words) took 0.4s, 433749 effective words/s
INFO - 2023-11-27 12:10:12,890: EPOCH 5: training on 155600 raw words (151965 effective words) took 0.4s, 396280 effective words/s
INFO - 2023-11-27 12:10:13,250: EPOCH 6: training on 155600 raw words (151894 effective words) took 0.4s, 424455 effective words/s
INFO - 2023-11-27 12:10:13,606: EPOCH 7: training on 155600 raw words (151833 effective words) took 0.4s, 428543 effective words/s
INFO - 2023-11-27 12:10:14,004: EPOCH 8: training on 155600 raw words (151907 effective words) took 0.4s, 384746 effective words/s
INFO - 2023-11-27 12:10:14,371: EPOCH 9: training on 155600 raw words (151985 effective words) took 0.4s, 417187 effective words/s
INFO - 2023-11-27 12:10:14,785: EPOCH 10: training on 155600 raw words (152049 effective words) took 0.4s, 370359 effective words/s
INFO - 2023-11-27 12:10:15,138: EPOCH 11: training on 155600 raw words (151883 effective words) took 0.4s, 432370 effective words/s
INFO - 2023-11-27 12:10:15,506: EPOCH 12: training on 155600 raw words (151914 effective words) took 0.4s, 417016 effective words/s
INFO - 2023-11-27 12:10:15,885: EPOCH 13: training on 155600 raw words (151880 effective words) took 0.4s, 402298 effective words/s
INFO - 2023-11-27 12:10:16,254: EPOCH 14: training on 155600 raw words (151856 effective words) took 0.4s, 414983 effective words/s
INFO - 2023-11-27 12:10:16,639: EPOCH 15: training on 155600 raw words (151913 effective words) took 0.4s, 397675 effective words/s
INFO - 2023-11-27 12:10:16,990: EPOCH 16: training on 155600 raw words (152022 effective words) took 0.3s, 436263 effective words/s
INFO - 2023-11-27 12:10:17,359: EPOCH 17: training on 155600 raw words (151986 effective words) took 0.4s, 415007 effective words/s
INFO - 2023-11-27 12:10:17,713: EPOCH 18: training on 155600 raw words (151919 effective words) took 0.4s, 431580 effective words/s
INFO - 2023-11-27 12:10:18,084: EPOCH 19: training on 155600 raw words (151900 effective words) took 0.4s, 411953 effective words/s
INFO - 2023-11-27 12:10:18,085: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038619 effective words) took 7.5s, 407587 effective words/s', 'datetime': '2023-11-27T12:10:18.085233', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:18,085: collecting all words and their counts
INFO - 2023-11-27 12:10:18,085: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:18,111: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:18,112: Updating model with new vocabulary
INFO - 2023-11-27 12:10:18,123: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:18.123249', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:18,135: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:18,136: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:10:18,136: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152013.6878171877 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:10:18.136240', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:18,157: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:18,157: updating layer weights
INFO - 2023-11-27 12:10:18,157: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:18.157594', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:18,157: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:18,157: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:18.157874', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:18,571: EPOCH 0: training on 155600 raw words (151967 effective words) took 0.4s, 369286 effective words/s
INFO - 2023-11-27 12:10:18,989: EPOCH 1: training on 155600 raw words (152023 effective words) took 0.4s, 366151 effective words/s
INFO - 2023-11-27 12:10:19,423: EPOCH 2: training on 155600 raw words (152038 effective words) took 0.4s, 353262 effective words/s
INFO - 2023-11-27 12:10:19,847: EPOCH 3: training on 155600 raw words (152009 effective words) took 0.4s, 360547 effective words/s
INFO - 2023-11-27 12:10:20,329: EPOCH 4: training on 155600 raw words (152024 effective words) took 0.5s, 317794 effective words/s
INFO - 2023-11-27 12:10:20,759: EPOCH 5: training on 155600 raw words (151875 effective words) took 0.4s, 355484 effective words/s
INFO - 2023-11-27 12:10:21,199: EPOCH 6: training on 155600 raw words (152026 effective words) took 0.4s, 348447 effective words/s
INFO - 2023-11-27 12:10:21,642: EPOCH 7: training on 155600 raw words (152064 effective words) took 0.4s, 345294 effective words/s
INFO - 2023-11-27 12:10:22,168: EPOCH 8: training on 155600 raw words (151908 effective words) took 0.5s, 291004 effective words/s
INFO - 2023-11-27 12:10:22,643: EPOCH 9: training on 155600 raw words (151986 effective words) took 0.5s, 321481 effective words/s
INFO - 2023-11-27 12:10:23,076: EPOCH 10: training on 155600 raw words (152071 effective words) took 0.4s, 353700 effective words/s
INFO - 2023-11-27 12:10:23,824: EPOCH 11: training on 155600 raw words (151992 effective words) took 0.7s, 204539 effective words/s
INFO - 2023-11-27 12:10:24,394: EPOCH 12: training on 155600 raw words (151966 effective words) took 0.6s, 268981 effective words/s
INFO - 2023-11-27 12:10:24,862: EPOCH 13: training on 155600 raw words (152052 effective words) took 0.5s, 328179 effective words/s
INFO - 2023-11-27 12:10:25,306: EPOCH 14: training on 155600 raw words (152001 effective words) took 0.4s, 345046 effective words/s
INFO - 2023-11-27 12:10:25,756: EPOCH 15: training on 155600 raw words (151953 effective words) took 0.4s, 340068 effective words/s
INFO - 2023-11-27 12:10:26,211: EPOCH 16: training on 155600 raw words (152059 effective words) took 0.5s, 336165 effective words/s
INFO - 2023-11-27 12:10:26,808: EPOCH 17: training on 155600 raw words (151989 effective words) took 0.6s, 256096 effective words/s
INFO - 2023-11-27 12:10:27,270: EPOCH 18: training on 155600 raw words (152028 effective words) took 0.5s, 331712 effective words/s
INFO - 2023-11-27 12:10:27,658: EPOCH 19: training on 155600 raw words (151958 effective words) took 0.4s, 394682 effective words/s
INFO - 2023-11-27 12:10:27,658: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039989 effective words) took 9.5s, 319977 effective words/s', 'datetime': '2023-11-27T12:10:27.658651', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:27,659: collecting all words and their counts
INFO - 2023-11-27 12:10:27,659: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:27,697: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:27,697: Updating model with new vocabulary
INFO - 2023-11-27 12:10:27,716: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:27.716908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:27,732: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:27,733: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:10:27,733: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152036.82642825448 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:10:27.733098', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:27,754: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:27,754: updating layer weights
INFO - 2023-11-27 12:10:27,755: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:27.755377', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:27,755: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:27,755: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:27.755631', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:28,201: EPOCH 0: training on 155600 raw words (152097 effective words) took 0.4s, 343489 effective words/s
INFO - 2023-11-27 12:10:28,556: EPOCH 1: training on 155600 raw words (152042 effective words) took 0.4s, 431651 effective words/s
INFO - 2023-11-27 12:10:28,905: EPOCH 2: training on 155600 raw words (152109 effective words) took 0.3s, 440355 effective words/s
INFO - 2023-11-27 12:10:29,261: EPOCH 3: training on 155600 raw words (152053 effective words) took 0.4s, 429271 effective words/s
INFO - 2023-11-27 12:10:29,607: EPOCH 4: training on 155600 raw words (152089 effective words) took 0.3s, 441771 effective words/s
INFO - 2023-11-27 12:10:29,974: EPOCH 5: training on 155600 raw words (152003 effective words) took 0.4s, 425495 effective words/s
INFO - 2023-11-27 12:10:30,481: EPOCH 6: training on 155600 raw words (151978 effective words) took 0.5s, 300753 effective words/s
INFO - 2023-11-27 12:10:30,881: EPOCH 7: training on 155600 raw words (152081 effective words) took 0.4s, 383024 effective words/s
INFO - 2023-11-27 12:10:31,294: EPOCH 8: training on 155600 raw words (151988 effective words) took 0.4s, 369961 effective words/s
INFO - 2023-11-27 12:10:31,667: EPOCH 9: training on 155600 raw words (152014 effective words) took 0.4s, 410068 effective words/s
INFO - 2023-11-27 12:10:32,032: EPOCH 10: training on 155600 raw words (152034 effective words) took 0.4s, 418928 effective words/s
INFO - 2023-11-27 12:10:32,486: EPOCH 11: training on 155600 raw words (152042 effective words) took 0.5s, 336843 effective words/s
INFO - 2023-11-27 12:10:32,923: EPOCH 12: training on 155600 raw words (152072 effective words) took 0.4s, 350499 effective words/s
INFO - 2023-11-27 12:10:33,413: EPOCH 13: training on 155600 raw words (152047 effective words) took 0.5s, 312634 effective words/s
INFO - 2023-11-27 12:10:33,833: EPOCH 14: training on 155600 raw words (152030 effective words) took 0.4s, 364723 effective words/s
INFO - 2023-11-27 12:10:34,253: EPOCH 15: training on 155600 raw words (151889 effective words) took 0.4s, 363978 effective words/s
INFO - 2023-11-27 12:10:34,690: EPOCH 16: training on 155600 raw words (152101 effective words) took 0.4s, 350589 effective words/s
INFO - 2023-11-27 12:10:35,069: EPOCH 17: training on 155600 raw words (152021 effective words) took 0.4s, 403522 effective words/s
INFO - 2023-11-27 12:10:35,453: EPOCH 18: training on 155600 raw words (152033 effective words) took 0.4s, 398565 effective words/s
INFO - 2023-11-27 12:10:35,835: EPOCH 19: training on 155600 raw words (152034 effective words) took 0.4s, 401415 effective words/s
INFO - 2023-11-27 12:10:35,835: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040757 effective words) took 8.1s, 376340 effective words/s', 'datetime': '2023-11-27T12:10:35.835538', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:35,835: collecting all words and their counts
INFO - 2023-11-27 12:10:35,835: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:35,860: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:35,860: Updating model with new vocabulary
INFO - 2023-11-27 12:10:35,871: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:35.871950', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:35,884: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:35,885: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:10:35,885: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151930.21946182745 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:10:35.885207', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:35,904: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:35,904: updating layer weights
INFO - 2023-11-27 12:10:35,905: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:35.905075', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:35,905: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:35,905: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:35.905353', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:36,250: EPOCH 0: training on 155600 raw words (151967 effective words) took 0.3s, 444152 effective words/s
INFO - 2023-11-27 12:10:36,600: EPOCH 1: training on 155600 raw words (151900 effective words) took 0.3s, 437510 effective words/s
INFO - 2023-11-27 12:10:36,944: EPOCH 2: training on 155600 raw words (151995 effective words) took 0.3s, 445070 effective words/s
INFO - 2023-11-27 12:10:37,333: EPOCH 3: training on 155600 raw words (152020 effective words) took 0.4s, 393180 effective words/s
INFO - 2023-11-27 12:10:37,667: EPOCH 4: training on 155600 raw words (151933 effective words) took 0.3s, 457914 effective words/s
INFO - 2023-11-27 12:10:38,005: EPOCH 5: training on 155600 raw words (151928 effective words) took 0.3s, 453047 effective words/s
INFO - 2023-11-27 12:10:38,352: EPOCH 6: training on 155600 raw words (152018 effective words) took 0.3s, 441622 effective words/s
INFO - 2023-11-27 12:10:38,689: EPOCH 7: training on 155600 raw words (151987 effective words) took 0.3s, 454081 effective words/s
INFO - 2023-11-27 12:10:39,036: EPOCH 8: training on 155600 raw words (151905 effective words) took 0.3s, 441589 effective words/s
INFO - 2023-11-27 12:10:39,375: EPOCH 9: training on 155600 raw words (151931 effective words) took 0.3s, 450279 effective words/s
INFO - 2023-11-27 12:10:39,713: EPOCH 10: training on 155600 raw words (151946 effective words) took 0.3s, 453516 effective words/s
INFO - 2023-11-27 12:10:40,064: EPOCH 11: training on 155600 raw words (151873 effective words) took 0.3s, 439083 effective words/s
INFO - 2023-11-27 12:10:40,399: EPOCH 12: training on 155600 raw words (151980 effective words) took 0.3s, 457937 effective words/s
INFO - 2023-11-27 12:10:40,790: EPOCH 13: training on 155600 raw words (151951 effective words) took 0.4s, 390113 effective words/s
INFO - 2023-11-27 12:10:41,133: EPOCH 14: training on 155600 raw words (151905 effective words) took 0.3s, 446850 effective words/s
INFO - 2023-11-27 12:10:41,485: EPOCH 15: training on 155600 raw words (151865 effective words) took 0.4s, 433876 effective words/s
INFO - 2023-11-27 12:10:41,825: EPOCH 16: training on 155600 raw words (151907 effective words) took 0.3s, 450143 effective words/s
INFO - 2023-11-27 12:10:42,175: EPOCH 17: training on 155600 raw words (151941 effective words) took 0.3s, 437397 effective words/s
INFO - 2023-11-27 12:10:42,533: EPOCH 18: training on 155600 raw words (151997 effective words) took 0.4s, 427686 effective words/s
INFO - 2023-11-27 12:10:42,863: EPOCH 19: training on 155600 raw words (151960 effective words) took 0.3s, 462898 effective words/s
INFO - 2023-11-27 12:10:42,864: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038909 effective words) took 7.0s, 436712 effective words/s', 'datetime': '2023-11-27T12:10:42.864101', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:42,864: collecting all words and their counts
INFO - 2023-11-27 12:10:42,864: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:42,887: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:42,887: Updating model with new vocabulary
INFO - 2023-11-27 12:10:42,898: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:42.898321', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:42,911: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:42,911: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:10:42,911: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151904.27781334694 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:10:42.911404', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:42,932: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:42,932: updating layer weights
INFO - 2023-11-27 12:10:42,933: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:42.933194', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:42,933: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:42,933: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:42.933587', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:43,299: EPOCH 0: training on 155600 raw words (151896 effective words) took 0.4s, 418967 effective words/s
INFO - 2023-11-27 12:10:43,672: EPOCH 1: training on 155600 raw words (151905 effective words) took 0.4s, 411346 effective words/s
INFO - 2023-11-27 12:10:44,064: EPOCH 2: training on 155600 raw words (151959 effective words) took 0.4s, 389684 effective words/s
INFO - 2023-11-27 12:10:44,436: EPOCH 3: training on 155600 raw words (152011 effective words) took 0.4s, 411933 effective words/s
INFO - 2023-11-27 12:10:44,925: EPOCH 4: training on 155600 raw words (151814 effective words) took 0.5s, 312112 effective words/s
INFO - 2023-11-27 12:10:45,382: EPOCH 5: training on 155600 raw words (151921 effective words) took 0.4s, 349645 effective words/s
INFO - 2023-11-27 12:10:45,882: EPOCH 6: training on 155600 raw words (151931 effective words) took 0.5s, 305557 effective words/s
INFO - 2023-11-27 12:10:46,362: EPOCH 7: training on 155600 raw words (151943 effective words) took 0.5s, 318845 effective words/s
INFO - 2023-11-27 12:10:46,836: EPOCH 8: training on 155600 raw words (151894 effective words) took 0.5s, 321963 effective words/s
INFO - 2023-11-27 12:10:47,304: EPOCH 9: training on 155600 raw words (151836 effective words) took 0.5s, 326714 effective words/s
INFO - 2023-11-27 12:10:47,802: EPOCH 10: training on 155600 raw words (151857 effective words) took 0.5s, 307125 effective words/s
INFO - 2023-11-27 12:10:48,280: EPOCH 11: training on 155600 raw words (151838 effective words) took 0.5s, 319591 effective words/s
INFO - 2023-11-27 12:10:48,759: EPOCH 12: training on 155600 raw words (151935 effective words) took 0.5s, 319552 effective words/s
INFO - 2023-11-27 12:10:49,243: EPOCH 13: training on 155600 raw words (151901 effective words) took 0.5s, 315322 effective words/s
INFO - 2023-11-27 12:10:49,747: EPOCH 14: training on 155600 raw words (151813 effective words) took 0.5s, 302753 effective words/s
INFO - 2023-11-27 12:10:50,286: EPOCH 15: training on 155600 raw words (151945 effective words) took 0.5s, 283626 effective words/s
INFO - 2023-11-27 12:10:50,776: EPOCH 16: training on 155600 raw words (151882 effective words) took 0.5s, 311923 effective words/s
INFO - 2023-11-27 12:10:51,154: EPOCH 17: training on 155600 raw words (151914 effective words) took 0.4s, 404951 effective words/s
INFO - 2023-11-27 12:10:51,616: EPOCH 18: training on 155600 raw words (151842 effective words) took 0.5s, 331104 effective words/s
INFO - 2023-11-27 12:10:51,963: EPOCH 19: training on 155600 raw words (151980 effective words) took 0.3s, 440753 effective words/s
INFO - 2023-11-27 12:10:51,963: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038017 effective words) took 9.0s, 336444 effective words/s', 'datetime': '2023-11-27T12:10:51.963539', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:51,963: collecting all words and their counts
INFO - 2023-11-27 12:10:51,963: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:51,985: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:51,985: Updating model with new vocabulary
INFO - 2023-11-27 12:10:51,995: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:51.995612', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:52,009: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:52,009: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:10:52,009: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152037.61273172 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:10:52.009562', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:52,028: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:52,028: updating layer weights
INFO - 2023-11-27 12:10:52,028: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:52.028728', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:52,028: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:52,028: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:52.028946', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:52,391: EPOCH 0: training on 155600 raw words (152119 effective words) took 0.4s, 422055 effective words/s
INFO - 2023-11-27 12:10:52,710: EPOCH 1: training on 155600 raw words (152006 effective words) took 0.3s, 480810 effective words/s
INFO - 2023-11-27 12:10:53,104: EPOCH 2: training on 155600 raw words (152012 effective words) took 0.4s, 387524 effective words/s
INFO - 2023-11-27 12:10:53,430: EPOCH 3: training on 155600 raw words (151912 effective words) took 0.3s, 468914 effective words/s
INFO - 2023-11-27 12:10:53,739: EPOCH 4: training on 155600 raw words (152003 effective words) took 0.3s, 495934 effective words/s
INFO - 2023-11-27 12:10:54,079: EPOCH 5: training on 155600 raw words (152083 effective words) took 0.3s, 450801 effective words/s
INFO - 2023-11-27 12:10:54,405: EPOCH 6: training on 155600 raw words (152105 effective words) took 0.3s, 469771 effective words/s
INFO - 2023-11-27 12:10:54,736: EPOCH 7: training on 155600 raw words (151998 effective words) took 0.3s, 461796 effective words/s
INFO - 2023-11-27 12:10:55,130: EPOCH 8: training on 155600 raw words (152018 effective words) took 0.4s, 387973 effective words/s
INFO - 2023-11-27 12:10:55,474: EPOCH 9: training on 155600 raw words (151999 effective words) took 0.3s, 445347 effective words/s
INFO - 2023-11-27 12:10:55,813: EPOCH 10: training on 155600 raw words (151975 effective words) took 0.3s, 450862 effective words/s
INFO - 2023-11-27 12:10:56,143: EPOCH 11: training on 155600 raw words (152010 effective words) took 0.3s, 464600 effective words/s
INFO - 2023-11-27 12:10:56,565: EPOCH 12: training on 155600 raw words (152028 effective words) took 0.4s, 361993 effective words/s
INFO - 2023-11-27 12:10:56,899: EPOCH 13: training on 155600 raw words (151992 effective words) took 0.3s, 459173 effective words/s
INFO - 2023-11-27 12:10:57,216: EPOCH 14: training on 155600 raw words (152064 effective words) took 0.3s, 482188 effective words/s
INFO - 2023-11-27 12:10:57,540: EPOCH 15: training on 155600 raw words (152095 effective words) took 0.3s, 473679 effective words/s
INFO - 2023-11-27 12:10:57,863: EPOCH 16: training on 155600 raw words (152031 effective words) took 0.3s, 473599 effective words/s
INFO - 2023-11-27 12:10:58,184: EPOCH 17: training on 155600 raw words (152056 effective words) took 0.3s, 477506 effective words/s
INFO - 2023-11-27 12:10:58,528: EPOCH 18: training on 155600 raw words (152041 effective words) took 0.3s, 444160 effective words/s
INFO - 2023-11-27 12:10:58,854: EPOCH 19: training on 155600 raw words (152027 effective words) took 0.3s, 470066 effective words/s
INFO - 2023-11-27 12:10:58,854: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040574 effective words) took 6.8s, 445484 effective words/s', 'datetime': '2023-11-27T12:10:58.854374', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:58,854: collecting all words and their counts
INFO - 2023-11-27 12:10:58,854: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:10:58,877: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:10:58,877: Updating model with new vocabulary
INFO - 2023-11-27 12:10:58,888: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:10:58.888396', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:58,904: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:10:58,904: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:10:58,904: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151898.54297225174 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:10:58.904878', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:10:58,926: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:10:58,926: updating layer weights
INFO - 2023-11-27 12:10:58,927: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:10:58.927717', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:10:58,928: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:10:58,928: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:10:58.928436', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:10:59,296: EPOCH 0: training on 155600 raw words (151786 effective words) took 0.4s, 416305 effective words/s
INFO - 2023-11-27 12:10:59,644: EPOCH 1: training on 155600 raw words (151955 effective words) took 0.3s, 440410 effective words/s
INFO - 2023-11-27 12:11:00,005: EPOCH 2: training on 155600 raw words (151815 effective words) took 0.4s, 423425 effective words/s
INFO - 2023-11-27 12:11:00,360: EPOCH 3: training on 155600 raw words (151993 effective words) took 0.4s, 431153 effective words/s
INFO - 2023-11-27 12:11:00,707: EPOCH 4: training on 155600 raw words (151830 effective words) took 0.3s, 441115 effective words/s
INFO - 2023-11-27 12:11:01,061: EPOCH 5: training on 155600 raw words (151955 effective words) took 0.4s, 431800 effective words/s
INFO - 2023-11-27 12:11:01,405: EPOCH 6: training on 155600 raw words (151974 effective words) took 0.3s, 445191 effective words/s
INFO - 2023-11-27 12:11:01,742: EPOCH 7: training on 155600 raw words (151871 effective words) took 0.3s, 452583 effective words/s
INFO - 2023-11-27 12:11:02,157: EPOCH 8: training on 155600 raw words (151925 effective words) took 0.4s, 368700 effective words/s
INFO - 2023-11-27 12:11:02,512: EPOCH 9: training on 155600 raw words (151842 effective words) took 0.3s, 438808 effective words/s
INFO - 2023-11-27 12:11:02,928: EPOCH 10: training on 155600 raw words (151897 effective words) took 0.4s, 367621 effective words/s
INFO - 2023-11-27 12:11:03,292: EPOCH 11: training on 155600 raw words (151883 effective words) took 0.4s, 419547 effective words/s
INFO - 2023-11-27 12:11:03,664: EPOCH 12: training on 155600 raw words (151912 effective words) took 0.4s, 411598 effective words/s
INFO - 2023-11-27 12:11:04,010: EPOCH 13: training on 155600 raw words (151864 effective words) took 0.3s, 441704 effective words/s
INFO - 2023-11-27 12:11:04,357: EPOCH 14: training on 155600 raw words (151915 effective words) took 0.3s, 441605 effective words/s
INFO - 2023-11-27 12:11:04,729: EPOCH 15: training on 155600 raw words (151901 effective words) took 0.4s, 410696 effective words/s
INFO - 2023-11-27 12:11:05,070: EPOCH 16: training on 155600 raw words (151848 effective words) took 0.3s, 458108 effective words/s
INFO - 2023-11-27 12:11:05,479: EPOCH 17: training on 155600 raw words (151821 effective words) took 0.4s, 372718 effective words/s
INFO - 2023-11-27 12:11:05,899: EPOCH 18: training on 155600 raw words (151905 effective words) took 0.4s, 364612 effective words/s
INFO - 2023-11-27 12:11:06,289: EPOCH 19: training on 155600 raw words (151947 effective words) took 0.4s, 391841 effective words/s
INFO - 2023-11-27 12:11:06,290: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037839 effective words) took 7.4s, 412663 effective words/s', 'datetime': '2023-11-27T12:11:06.290229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:06,290: collecting all words and their counts
INFO - 2023-11-27 12:11:06,290: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:06,314: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:06,314: Updating model with new vocabulary
INFO - 2023-11-27 12:11:06,324: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:06.324314', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:06,336: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:06,336: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:11:06,336: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152043.01746287697 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:11:06.336739', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:06,355: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:06,355: updating layer weights
INFO - 2023-11-27 12:11:06,355: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:06.355585', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:06,355: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:06,355: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:06.355812', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:06,826: EPOCH 0: training on 155600 raw words (152062 effective words) took 0.5s, 324525 effective words/s
INFO - 2023-11-27 12:11:07,308: EPOCH 1: training on 155600 raw words (152033 effective words) took 0.5s, 317855 effective words/s
INFO - 2023-11-27 12:11:07,787: EPOCH 2: training on 155600 raw words (151960 effective words) took 0.5s, 319561 effective words/s
INFO - 2023-11-27 12:11:08,288: EPOCH 3: training on 155600 raw words (152142 effective words) took 0.5s, 305773 effective words/s
INFO - 2023-11-27 12:11:08,819: EPOCH 4: training on 155600 raw words (152108 effective words) took 0.5s, 288174 effective words/s
INFO - 2023-11-27 12:11:09,300: EPOCH 5: training on 155600 raw words (152083 effective words) took 0.5s, 318813 effective words/s
INFO - 2023-11-27 12:11:09,750: EPOCH 6: training on 155600 raw words (151988 effective words) took 0.4s, 340458 effective words/s
INFO - 2023-11-27 12:11:10,227: EPOCH 7: training on 155600 raw words (152028 effective words) took 0.5s, 321147 effective words/s
INFO - 2023-11-27 12:11:10,549: EPOCH 8: training on 155600 raw words (152129 effective words) took 0.3s, 478833 effective words/s
INFO - 2023-11-27 12:11:10,941: EPOCH 9: training on 155600 raw words (152022 effective words) took 0.4s, 390115 effective words/s
INFO - 2023-11-27 12:11:11,312: EPOCH 10: training on 155600 raw words (152044 effective words) took 0.4s, 413060 effective words/s
INFO - 2023-11-27 12:11:11,688: EPOCH 11: training on 155600 raw words (152019 effective words) took 0.4s, 407358 effective words/s
INFO - 2023-11-27 12:11:12,090: EPOCH 12: training on 155600 raw words (152017 effective words) took 0.4s, 381446 effective words/s
INFO - 2023-11-27 12:11:12,436: EPOCH 13: training on 155600 raw words (152095 effective words) took 0.3s, 443899 effective words/s
INFO - 2023-11-27 12:11:12,807: EPOCH 14: training on 155600 raw words (151993 effective words) took 0.4s, 412752 effective words/s
INFO - 2023-11-27 12:11:13,344: EPOCH 15: training on 155600 raw words (151982 effective words) took 0.5s, 284634 effective words/s
INFO - 2023-11-27 12:11:13,898: EPOCH 16: training on 155600 raw words (151996 effective words) took 0.5s, 288872 effective words/s
INFO - 2023-11-27 12:11:14,426: EPOCH 17: training on 155600 raw words (152065 effective words) took 0.5s, 290254 effective words/s
INFO - 2023-11-27 12:11:14,982: EPOCH 18: training on 155600 raw words (152065 effective words) took 0.6s, 275669 effective words/s
INFO - 2023-11-27 12:11:15,538: EPOCH 19: training on 155600 raw words (152069 effective words) took 0.6s, 275901 effective words/s
INFO - 2023-11-27 12:11:15,538: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040900 effective words) took 9.2s, 331158 effective words/s', 'datetime': '2023-11-27T12:11:15.538579', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:15,539: collecting all words and their counts
INFO - 2023-11-27 12:11:15,539: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:15,582: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:15,583: Updating model with new vocabulary
INFO - 2023-11-27 12:11:15,613: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:15.613874', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:15,648: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:15,648: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:11:15,648: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151940.16662056214 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:11:15.648653', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:15,681: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:15,682: updating layer weights
INFO - 2023-11-27 12:11:15,683: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:15.682998', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:15,683: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:15,683: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:15.683619', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:16,228: EPOCH 0: training on 155600 raw words (151974 effective words) took 0.5s, 280806 effective words/s
INFO - 2023-11-27 12:11:16,707: EPOCH 1: training on 155600 raw words (151981 effective words) took 0.5s, 328355 effective words/s
INFO - 2023-11-27 12:11:17,173: EPOCH 2: training on 155600 raw words (151965 effective words) took 0.5s, 327978 effective words/s
INFO - 2023-11-27 12:11:17,644: EPOCH 3: training on 155600 raw words (152057 effective words) took 0.5s, 325124 effective words/s
INFO - 2023-11-27 12:11:18,118: EPOCH 4: training on 155600 raw words (152010 effective words) took 0.5s, 329810 effective words/s
INFO - 2023-11-27 12:11:18,603: EPOCH 5: training on 155600 raw words (151935 effective words) took 0.5s, 314926 effective words/s
INFO - 2023-11-27 12:11:19,052: EPOCH 6: training on 155600 raw words (151950 effective words) took 0.4s, 341695 effective words/s
INFO - 2023-11-27 12:11:19,530: EPOCH 7: training on 155600 raw words (151948 effective words) took 0.5s, 320023 effective words/s
INFO - 2023-11-27 12:11:19,983: EPOCH 8: training on 155600 raw words (151882 effective words) took 0.4s, 345222 effective words/s
INFO - 2023-11-27 12:11:20,421: EPOCH 9: training on 155600 raw words (151975 effective words) took 0.4s, 348974 effective words/s
INFO - 2023-11-27 12:11:20,859: EPOCH 10: training on 155600 raw words (151897 effective words) took 0.4s, 349590 effective words/s
INFO - 2023-11-27 12:11:21,295: EPOCH 11: training on 155600 raw words (151926 effective words) took 0.4s, 350798 effective words/s
INFO - 2023-11-27 12:11:21,725: EPOCH 12: training on 155600 raw words (151988 effective words) took 0.4s, 356405 effective words/s
INFO - 2023-11-27 12:11:22,097: EPOCH 13: training on 155600 raw words (151893 effective words) took 0.4s, 411214 effective words/s
INFO - 2023-11-27 12:11:22,464: EPOCH 14: training on 155600 raw words (151931 effective words) took 0.4s, 418122 effective words/s
INFO - 2023-11-27 12:11:22,807: EPOCH 15: training on 155600 raw words (151942 effective words) took 0.3s, 446609 effective words/s
INFO - 2023-11-27 12:11:23,192: EPOCH 16: training on 155600 raw words (152056 effective words) took 0.4s, 396863 effective words/s
INFO - 2023-11-27 12:11:23,592: EPOCH 17: training on 155600 raw words (151870 effective words) took 0.4s, 382312 effective words/s
INFO - 2023-11-27 12:11:23,962: EPOCH 18: training on 155600 raw words (151908 effective words) took 0.4s, 413231 effective words/s
INFO - 2023-11-27 12:11:24,344: EPOCH 19: training on 155600 raw words (151965 effective words) took 0.4s, 401166 effective words/s
INFO - 2023-11-27 12:11:24,344: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039053 effective words) took 8.7s, 350900 effective words/s', 'datetime': '2023-11-27T12:11:24.344577', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:24,344: collecting all words and their counts
INFO - 2023-11-27 12:11:24,345: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:24,368: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:24,368: Updating model with new vocabulary
INFO - 2023-11-27 12:11:24,378: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:24.378381', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:24,390: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:24,390: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:11:24,390: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152100.7424981852 word corpus (97.8%% of prior 155600)', 'datetime': '2023-11-27T12:11:24.390770', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:24,409: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:24,409: updating layer weights
INFO - 2023-11-27 12:11:24,409: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:24.409651', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:24,409: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:24,409: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:24.409822', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:24,728: EPOCH 0: training on 155600 raw words (152074 effective words) took 0.3s, 481192 effective words/s
INFO - 2023-11-27 12:11:25,057: EPOCH 1: training on 155600 raw words (151957 effective words) took 0.3s, 464594 effective words/s
INFO - 2023-11-27 12:11:25,389: EPOCH 2: training on 155600 raw words (152106 effective words) took 0.3s, 462456 effective words/s
INFO - 2023-11-27 12:11:25,715: EPOCH 3: training on 155600 raw words (152090 effective words) took 0.3s, 469794 effective words/s
INFO - 2023-11-27 12:11:26,056: EPOCH 4: training on 155600 raw words (152121 effective words) took 0.3s, 448399 effective words/s
INFO - 2023-11-27 12:11:26,376: EPOCH 5: training on 155600 raw words (152075 effective words) took 0.3s, 479115 effective words/s
INFO - 2023-11-27 12:11:26,754: EPOCH 6: training on 155600 raw words (152132 effective words) took 0.4s, 404836 effective words/s
INFO - 2023-11-27 12:11:27,120: EPOCH 7: training on 155600 raw words (152189 effective words) took 0.4s, 419648 effective words/s
INFO - 2023-11-27 12:11:27,477: EPOCH 8: training on 155600 raw words (152039 effective words) took 0.4s, 428090 effective words/s
INFO - 2023-11-27 12:11:27,874: EPOCH 9: training on 155600 raw words (152085 effective words) took 0.4s, 385576 effective words/s
INFO - 2023-11-27 12:11:28,203: EPOCH 10: training on 155600 raw words (152144 effective words) took 0.3s, 465838 effective words/s
INFO - 2023-11-27 12:11:28,556: EPOCH 11: training on 155600 raw words (152153 effective words) took 0.4s, 433438 effective words/s
INFO - 2023-11-27 12:11:28,926: EPOCH 12: training on 155600 raw words (152041 effective words) took 0.4s, 414288 effective words/s
INFO - 2023-11-27 12:11:29,275: EPOCH 13: training on 155600 raw words (152170 effective words) took 0.3s, 439947 effective words/s
INFO - 2023-11-27 12:11:29,649: EPOCH 14: training on 155600 raw words (152128 effective words) took 0.4s, 409541 effective words/s
INFO - 2023-11-27 12:11:30,010: EPOCH 15: training on 155600 raw words (152138 effective words) took 0.4s, 424076 effective words/s
INFO - 2023-11-27 12:11:30,381: EPOCH 16: training on 155600 raw words (152066 effective words) took 0.4s, 413222 effective words/s
INFO - 2023-11-27 12:11:30,714: EPOCH 17: training on 155600 raw words (151957 effective words) took 0.3s, 458261 effective words/s
INFO - 2023-11-27 12:11:31,080: EPOCH 18: training on 155600 raw words (152084 effective words) took 0.4s, 420729 effective words/s
INFO - 2023-11-27 12:11:31,410: EPOCH 19: training on 155600 raw words (152212 effective words) took 0.3s, 465640 effective words/s
INFO - 2023-11-27 12:11:31,410: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3041961 effective words) took 7.0s, 434517 effective words/s', 'datetime': '2023-11-27T12:11:31.410723', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:31,410: collecting all words and their counts
INFO - 2023-11-27 12:11:31,411: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:31,433: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:31,433: Updating model with new vocabulary
INFO - 2023-11-27 12:11:31,443: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:31.443169', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:31,455: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:31,455: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:11:31,455: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152012.9189510378 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:11:31.455389', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:31,474: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:31,474: updating layer weights
INFO - 2023-11-27 12:11:31,474: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:31.474866', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:31,475: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:31,475: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:31.475106', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:31,851: EPOCH 0: training on 155600 raw words (152063 effective words) took 0.4s, 411629 effective words/s
INFO - 2023-11-27 12:11:32,246: EPOCH 1: training on 155600 raw words (151957 effective words) took 0.4s, 387486 effective words/s
INFO - 2023-11-27 12:11:32,626: EPOCH 2: training on 155600 raw words (151963 effective words) took 0.4s, 403873 effective words/s
INFO - 2023-11-27 12:11:32,971: EPOCH 3: training on 155600 raw words (152012 effective words) took 0.3s, 443752 effective words/s
INFO - 2023-11-27 12:11:33,322: EPOCH 4: training on 155600 raw words (152008 effective words) took 0.3s, 436001 effective words/s
INFO - 2023-11-27 12:11:33,705: EPOCH 5: training on 155600 raw words (152021 effective words) took 0.4s, 399327 effective words/s
INFO - 2023-11-27 12:11:34,078: EPOCH 6: training on 155600 raw words (151936 effective words) took 0.4s, 410516 effective words/s
INFO - 2023-11-27 12:11:34,457: EPOCH 7: training on 155600 raw words (152093 effective words) took 0.4s, 403683 effective words/s
INFO - 2023-11-27 12:11:34,833: EPOCH 8: training on 155600 raw words (151991 effective words) took 0.4s, 406573 effective words/s
INFO - 2023-11-27 12:11:35,223: EPOCH 9: training on 155600 raw words (152049 effective words) took 0.4s, 393440 effective words/s
INFO - 2023-11-27 12:11:35,603: EPOCH 10: training on 155600 raw words (151970 effective words) took 0.4s, 402106 effective words/s
INFO - 2023-11-27 12:11:36,003: EPOCH 11: training on 155600 raw words (152058 effective words) took 0.4s, 383381 effective words/s
INFO - 2023-11-27 12:11:36,393: EPOCH 12: training on 155600 raw words (151984 effective words) took 0.4s, 392486 effective words/s
INFO - 2023-11-27 12:11:36,746: EPOCH 13: training on 155600 raw words (152059 effective words) took 0.4s, 433922 effective words/s
INFO - 2023-11-27 12:11:37,124: EPOCH 14: training on 155600 raw words (151964 effective words) took 0.4s, 404069 effective words/s
INFO - 2023-11-27 12:11:37,515: EPOCH 15: training on 155600 raw words (151997 effective words) took 0.4s, 391142 effective words/s
INFO - 2023-11-27 12:11:37,909: EPOCH 16: training on 155600 raw words (152029 effective words) took 0.4s, 388627 effective words/s
INFO - 2023-11-27 12:11:38,294: EPOCH 17: training on 155600 raw words (152018 effective words) took 0.4s, 396886 effective words/s
INFO - 2023-11-27 12:11:38,652: EPOCH 18: training on 155600 raw words (151980 effective words) took 0.4s, 427332 effective words/s
INFO - 2023-11-27 12:11:39,090: EPOCH 19: training on 155600 raw words (152056 effective words) took 0.4s, 349093 effective words/s
INFO - 2023-11-27 12:11:39,091: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040208 effective words) took 7.6s, 399189 effective words/s', 'datetime': '2023-11-27T12:11:39.091183', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:39,091: collecting all words and their counts
INFO - 2023-11-27 12:11:39,091: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:39,128: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:39,128: Updating model with new vocabulary
INFO - 2023-11-27 12:11:39,144: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:39.144419', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:39,161: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:39,161: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:11:39,161: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151791.6773613242 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:11:39.161555', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:39,187: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:39,187: updating layer weights
INFO - 2023-11-27 12:11:39,188: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:39.188077', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:39,188: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:39,188: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:39.188335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:39,616: EPOCH 0: training on 155600 raw words (151703 effective words) took 0.4s, 357286 effective words/s
INFO - 2023-11-27 12:11:40,055: EPOCH 1: training on 155600 raw words (151758 effective words) took 0.4s, 347436 effective words/s
INFO - 2023-11-27 12:11:40,500: EPOCH 2: training on 155600 raw words (151763 effective words) took 0.4s, 343913 effective words/s
INFO - 2023-11-27 12:11:40,946: EPOCH 3: training on 155600 raw words (151763 effective words) took 0.4s, 342472 effective words/s
INFO - 2023-11-27 12:11:41,419: EPOCH 4: training on 155600 raw words (151764 effective words) took 0.5s, 322860 effective words/s
INFO - 2023-11-27 12:11:41,941: EPOCH 5: training on 155600 raw words (151802 effective words) took 0.5s, 293320 effective words/s
INFO - 2023-11-27 12:11:42,437: EPOCH 6: training on 155600 raw words (151767 effective words) took 0.5s, 308312 effective words/s
INFO - 2023-11-27 12:11:42,905: EPOCH 7: training on 155600 raw words (151841 effective words) took 0.5s, 326814 effective words/s
INFO - 2023-11-27 12:11:43,399: EPOCH 8: training on 155600 raw words (151759 effective words) took 0.5s, 308795 effective words/s
INFO - 2023-11-27 12:11:43,889: EPOCH 9: training on 155600 raw words (151784 effective words) took 0.5s, 328349 effective words/s
INFO - 2023-11-27 12:11:44,437: EPOCH 10: training on 155600 raw words (151861 effective words) took 0.5s, 278330 effective words/s
INFO - 2023-11-27 12:11:44,959: EPOCH 11: training on 155600 raw words (151737 effective words) took 0.5s, 292716 effective words/s
INFO - 2023-11-27 12:11:45,495: EPOCH 12: training on 155600 raw words (151839 effective words) took 0.5s, 285763 effective words/s
INFO - 2023-11-27 12:11:46,100: EPOCH 13: training on 155600 raw words (151794 effective words) took 0.6s, 252215 effective words/s
INFO - 2023-11-27 12:11:46,690: EPOCH 14: training on 155600 raw words (151845 effective words) took 0.6s, 259345 effective words/s
INFO - 2023-11-27 12:11:47,055: EPOCH 15: training on 155600 raw words (151765 effective words) took 0.4s, 418737 effective words/s
INFO - 2023-11-27 12:11:47,455: EPOCH 16: training on 155600 raw words (151799 effective words) took 0.4s, 394308 effective words/s
INFO - 2023-11-27 12:11:47,854: EPOCH 17: training on 155600 raw words (151855 effective words) took 0.4s, 382962 effective words/s
INFO - 2023-11-27 12:11:48,244: EPOCH 18: training on 155600 raw words (151756 effective words) took 0.4s, 391913 effective words/s
INFO - 2023-11-27 12:11:48,666: EPOCH 19: training on 155600 raw words (151848 effective words) took 0.4s, 363459 effective words/s
INFO - 2023-11-27 12:11:48,667: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3035803 effective words) took 9.5s, 320281 effective words/s', 'datetime': '2023-11-27T12:11:48.667055', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:48,667: collecting all words and their counts
INFO - 2023-11-27 12:11:48,667: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:48,695: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:48,695: Updating model with new vocabulary
INFO - 2023-11-27 12:11:48,713: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:48.713116', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:48,729: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:48,729: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:11:48,729: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151959.83730151417 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:11:48.729636', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:48,757: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:48,757: updating layer weights
INFO - 2023-11-27 12:11:48,758: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:48.758208', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:48,758: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:48,758: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:48.758419', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:49,178: EPOCH 0: training on 155600 raw words (152010 effective words) took 0.4s, 364269 effective words/s
INFO - 2023-11-27 12:11:49,681: EPOCH 1: training on 155600 raw words (151963 effective words) took 0.5s, 303671 effective words/s
INFO - 2023-11-27 12:11:50,079: EPOCH 2: training on 155600 raw words (151972 effective words) took 0.4s, 385271 effective words/s
INFO - 2023-11-27 12:11:50,470: EPOCH 3: training on 155600 raw words (151962 effective words) took 0.4s, 390382 effective words/s
INFO - 2023-11-27 12:11:50,852: EPOCH 4: training on 155600 raw words (151971 effective words) took 0.4s, 400962 effective words/s
INFO - 2023-11-27 12:11:51,243: EPOCH 5: training on 155600 raw words (151921 effective words) took 0.4s, 390719 effective words/s
INFO - 2023-11-27 12:11:51,626: EPOCH 6: training on 155600 raw words (151955 effective words) took 0.4s, 399802 effective words/s
INFO - 2023-11-27 12:11:52,029: EPOCH 7: training on 155600 raw words (151943 effective words) took 0.4s, 379383 effective words/s
INFO - 2023-11-27 12:11:52,414: EPOCH 8: training on 155600 raw words (152008 effective words) took 0.4s, 397602 effective words/s
INFO - 2023-11-27 12:11:52,792: EPOCH 9: training on 155600 raw words (151960 effective words) took 0.4s, 406083 effective words/s
INFO - 2023-11-27 12:11:53,146: EPOCH 10: training on 155600 raw words (151975 effective words) took 0.4s, 431573 effective words/s
INFO - 2023-11-27 12:11:53,502: EPOCH 11: training on 155600 raw words (151938 effective words) took 0.4s, 429836 effective words/s
INFO - 2023-11-27 12:11:53,861: EPOCH 12: training on 155600 raw words (151970 effective words) took 0.4s, 425918 effective words/s
INFO - 2023-11-27 12:11:54,258: EPOCH 13: training on 155600 raw words (151936 effective words) took 0.4s, 384770 effective words/s
INFO - 2023-11-27 12:11:54,652: EPOCH 14: training on 155600 raw words (151999 effective words) took 0.4s, 389180 effective words/s
INFO - 2023-11-27 12:11:55,057: EPOCH 15: training on 155600 raw words (151958 effective words) took 0.4s, 377523 effective words/s
INFO - 2023-11-27 12:11:55,441: EPOCH 16: training on 155600 raw words (151985 effective words) took 0.4s, 402512 effective words/s
INFO - 2023-11-27 12:11:55,806: EPOCH 17: training on 155600 raw words (152063 effective words) took 0.4s, 419158 effective words/s
INFO - 2023-11-27 12:11:56,187: EPOCH 18: training on 155600 raw words (151941 effective words) took 0.4s, 401617 effective words/s
INFO - 2023-11-27 12:11:56,592: EPOCH 19: training on 155600 raw words (151874 effective words) took 0.4s, 377725 effective words/s
INFO - 2023-11-27 12:11:56,592: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039304 effective words) took 7.8s, 387962 effective words/s', 'datetime': '2023-11-27T12:11:56.592541', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:56,592: collecting all words and their counts
INFO - 2023-11-27 12:11:56,592: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:11:56,619: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:11:56,619: Updating model with new vocabulary
INFO - 2023-11-27 12:11:56,631: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:11:56.631897', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:56,644: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:11:56,644: sample=0.001 downsamples 20 most-common words
INFO - 2023-11-27 12:11:56,645: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151925.90666493712 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:11:56.645104', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:11:56,670: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:11:56,670: updating layer weights
INFO - 2023-11-27 12:11:56,671: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:11:56.671394', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:11:56,671: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:11:56,671: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:11:56.671848', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:11:57,028: EPOCH 0: training on 155600 raw words (151914 effective words) took 0.4s, 430798 effective words/s
INFO - 2023-11-27 12:11:57,392: EPOCH 1: training on 155600 raw words (151893 effective words) took 0.4s, 419552 effective words/s
INFO - 2023-11-27 12:11:57,744: EPOCH 2: training on 155600 raw words (151917 effective words) took 0.3s, 434615 effective words/s
INFO - 2023-11-27 12:11:58,107: EPOCH 3: training on 155600 raw words (151890 effective words) took 0.4s, 433357 effective words/s
INFO - 2023-11-27 12:11:58,482: EPOCH 4: training on 155600 raw words (151909 effective words) took 0.4s, 409287 effective words/s
INFO - 2023-11-27 12:11:58,853: EPOCH 5: training on 155600 raw words (151822 effective words) took 0.4s, 411970 effective words/s
INFO - 2023-11-27 12:11:59,222: EPOCH 6: training on 155600 raw words (151839 effective words) took 0.4s, 414157 effective words/s
INFO - 2023-11-27 12:11:59,597: EPOCH 7: training on 155600 raw words (151986 effective words) took 0.4s, 409691 effective words/s
INFO - 2023-11-27 12:11:59,930: EPOCH 8: training on 155600 raw words (151931 effective words) took 0.3s, 458994 effective words/s
INFO - 2023-11-27 12:12:00,259: EPOCH 9: training on 155600 raw words (151938 effective words) took 0.3s, 465796 effective words/s
INFO - 2023-11-27 12:12:00,641: EPOCH 10: training on 155600 raw words (151923 effective words) took 0.4s, 400142 effective words/s
INFO - 2023-11-27 12:12:01,001: EPOCH 11: training on 155600 raw words (151920 effective words) took 0.4s, 425154 effective words/s
INFO - 2023-11-27 12:12:01,329: EPOCH 12: training on 155600 raw words (151904 effective words) took 0.3s, 466941 effective words/s
INFO - 2023-11-27 12:12:01,683: EPOCH 13: training on 155600 raw words (152007 effective words) took 0.4s, 431791 effective words/s
INFO - 2023-11-27 12:12:02,053: EPOCH 14: training on 155600 raw words (151905 effective words) took 0.4s, 414056 effective words/s
INFO - 2023-11-27 12:12:02,419: EPOCH 15: training on 155600 raw words (151990 effective words) took 0.4s, 418277 effective words/s
INFO - 2023-11-27 12:12:02,844: EPOCH 16: training on 155600 raw words (151920 effective words) took 0.4s, 359611 effective words/s
INFO - 2023-11-27 12:12:03,291: EPOCH 17: training on 155600 raw words (151870 effective words) took 0.4s, 343071 effective words/s
INFO - 2023-11-27 12:12:03,747: EPOCH 18: training on 155600 raw words (151917 effective words) took 0.5s, 335488 effective words/s
INFO - 2023-11-27 12:12:04,223: EPOCH 19: training on 155600 raw words (151963 effective words) took 0.5s, 322352 effective words/s
INFO - 2023-11-27 12:12:04,223: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038358 effective words) took 7.6s, 402355 effective words/s', 'datetime': '2023-11-27T12:12:04.223440', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:04,223: collecting all words and their counts
INFO - 2023-11-27 12:12:04,223: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:04,257: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:04,257: Updating model with new vocabulary
INFO - 2023-11-27 12:12:04,270: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:04.270091', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:04,286: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:04,286: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:12:04,286: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151933.7395830931 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:12:04.286725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:04,312: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:04,312: updating layer weights
INFO - 2023-11-27 12:12:04,312: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:04.312742', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:04,312: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:04,313: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:04.313005', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:04,939: EPOCH 0: training on 155600 raw words (151888 effective words) took 0.6s, 249255 effective words/s
INFO - 2023-11-27 12:12:05,517: EPOCH 1: training on 155600 raw words (151968 effective words) took 0.6s, 264978 effective words/s
INFO - 2023-11-27 12:12:06,105: EPOCH 2: training on 155600 raw words (151899 effective words) took 0.6s, 260152 effective words/s
INFO - 2023-11-27 12:12:06,766: EPOCH 3: training on 155600 raw words (152021 effective words) took 0.7s, 231348 effective words/s
INFO - 2023-11-27 12:12:07,313: EPOCH 4: training on 155600 raw words (151958 effective words) took 0.5s, 279287 effective words/s
INFO - 2023-11-27 12:12:07,852: EPOCH 5: training on 155600 raw words (151946 effective words) took 0.5s, 283802 effective words/s
INFO - 2023-11-27 12:12:08,381: EPOCH 6: training on 155600 raw words (151940 effective words) took 0.5s, 289456 effective words/s
INFO - 2023-11-27 12:12:08,893: EPOCH 7: training on 155600 raw words (151979 effective words) took 0.5s, 298713 effective words/s
INFO - 2023-11-27 12:12:09,511: EPOCH 8: training on 155600 raw words (151884 effective words) took 0.6s, 254668 effective words/s
INFO - 2023-11-27 12:12:09,922: EPOCH 9: training on 155600 raw words (151958 effective words) took 0.4s, 372460 effective words/s
INFO - 2023-11-27 12:12:10,454: EPOCH 10: training on 155600 raw words (151979 effective words) took 0.5s, 287091 effective words/s
INFO - 2023-11-27 12:12:11,085: EPOCH 11: training on 155600 raw words (151900 effective words) took 0.6s, 242196 effective words/s
INFO - 2023-11-27 12:12:11,573: EPOCH 12: training on 155600 raw words (151913 effective words) took 0.5s, 313640 effective words/s
INFO - 2023-11-27 12:12:12,101: EPOCH 13: training on 155600 raw words (151944 effective words) took 0.5s, 289472 effective words/s
INFO - 2023-11-27 12:12:12,662: EPOCH 14: training on 155600 raw words (151947 effective words) took 0.6s, 272970 effective words/s
INFO - 2023-11-27 12:12:13,112: EPOCH 15: training on 155600 raw words (151929 effective words) took 0.4s, 339749 effective words/s
INFO - 2023-11-27 12:12:13,514: EPOCH 16: training on 155600 raw words (151859 effective words) took 0.4s, 379884 effective words/s
INFO - 2023-11-27 12:12:13,904: EPOCH 17: training on 155600 raw words (151964 effective words) took 0.4s, 391956 effective words/s
INFO - 2023-11-27 12:12:14,288: EPOCH 18: training on 155600 raw words (151892 effective words) took 0.4s, 399131 effective words/s
INFO - 2023-11-27 12:12:14,681: EPOCH 19: training on 155600 raw words (151983 effective words) took 0.4s, 394953 effective words/s
INFO - 2023-11-27 12:12:14,681: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038751 effective words) took 10.4s, 293080 effective words/s', 'datetime': '2023-11-27T12:12:14.681430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:14,681: collecting all words and their counts
INFO - 2023-11-27 12:12:14,681: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:14,705: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:14,706: Updating model with new vocabulary
INFO - 2023-11-27 12:12:14,717: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:14.717329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:14,731: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:14,731: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:12:14,732: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151867.77428088686 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:12:14.732100', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:14,751: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:14,751: updating layer weights
INFO - 2023-11-27 12:12:14,752: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:14.752096', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:14,752: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:14,752: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:14.752403', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:15,101: EPOCH 0: training on 155600 raw words (151873 effective words) took 0.3s, 440110 effective words/s
INFO - 2023-11-27 12:12:15,479: EPOCH 1: training on 155600 raw words (151942 effective words) took 0.4s, 403929 effective words/s
INFO - 2023-11-27 12:12:15,842: EPOCH 2: training on 155600 raw words (151892 effective words) took 0.4s, 422374 effective words/s
INFO - 2023-11-27 12:12:16,221: EPOCH 3: training on 155600 raw words (151838 effective words) took 0.4s, 403345 effective words/s
INFO - 2023-11-27 12:12:16,596: EPOCH 4: training on 155600 raw words (151887 effective words) took 0.4s, 407211 effective words/s
INFO - 2023-11-27 12:12:16,962: EPOCH 5: training on 155600 raw words (151972 effective words) took 0.4s, 418652 effective words/s
INFO - 2023-11-27 12:12:17,286: EPOCH 6: training on 155600 raw words (151891 effective words) took 0.3s, 471484 effective words/s
INFO - 2023-11-27 12:12:17,617: EPOCH 7: training on 155600 raw words (151921 effective words) took 0.3s, 461841 effective words/s
INFO - 2023-11-27 12:12:17,995: EPOCH 8: training on 155600 raw words (151903 effective words) took 0.4s, 404812 effective words/s
INFO - 2023-11-27 12:12:18,358: EPOCH 9: training on 155600 raw words (151858 effective words) took 0.4s, 422307 effective words/s
INFO - 2023-11-27 12:12:18,730: EPOCH 10: training on 155600 raw words (151862 effective words) took 0.4s, 411061 effective words/s
INFO - 2023-11-27 12:12:19,104: EPOCH 11: training on 155600 raw words (151848 effective words) took 0.4s, 409072 effective words/s
INFO - 2023-11-27 12:12:19,478: EPOCH 12: training on 155600 raw words (151809 effective words) took 0.4s, 430633 effective words/s
INFO - 2023-11-27 12:12:19,824: EPOCH 13: training on 155600 raw words (151875 effective words) took 0.3s, 440777 effective words/s
INFO - 2023-11-27 12:12:20,169: EPOCH 14: training on 155600 raw words (151837 effective words) took 0.3s, 443015 effective words/s
INFO - 2023-11-27 12:12:20,519: EPOCH 15: training on 155600 raw words (151875 effective words) took 0.3s, 438389 effective words/s
INFO - 2023-11-27 12:12:20,844: EPOCH 16: training on 155600 raw words (151861 effective words) took 0.3s, 470539 effective words/s
INFO - 2023-11-27 12:12:21,228: EPOCH 17: training on 155600 raw words (151933 effective words) took 0.4s, 398398 effective words/s
INFO - 2023-11-27 12:12:21,598: EPOCH 18: training on 155600 raw words (151871 effective words) took 0.4s, 412509 effective words/s
INFO - 2023-11-27 12:12:21,950: EPOCH 19: training on 155600 raw words (151947 effective words) took 0.3s, 435364 effective words/s
INFO - 2023-11-27 12:12:21,950: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037695 effective words) took 7.2s, 422005 effective words/s', 'datetime': '2023-11-27T12:12:21.950784', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:21,950: collecting all words and their counts
INFO - 2023-11-27 12:12:21,951: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:21,974: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:21,974: Updating model with new vocabulary
INFO - 2023-11-27 12:12:21,984: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:21.984425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:21,996: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:21,996: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:12:21,996: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152067.7283565856 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:12:21.996919', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:22,018: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:22,018: updating layer weights
INFO - 2023-11-27 12:12:22,018: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:22.018655', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:22,018: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:22,018: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:22.018937', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:22,382: EPOCH 0: training on 155600 raw words (151978 effective words) took 0.4s, 420723 effective words/s
INFO - 2023-11-27 12:12:22,766: EPOCH 1: training on 155600 raw words (152046 effective words) took 0.4s, 398394 effective words/s
INFO - 2023-11-27 12:12:23,142: EPOCH 2: training on 155600 raw words (152205 effective words) took 0.4s, 408492 effective words/s
INFO - 2023-11-27 12:12:23,514: EPOCH 3: training on 155600 raw words (152080 effective words) took 0.4s, 411369 effective words/s
INFO - 2023-11-27 12:12:23,895: EPOCH 4: training on 155600 raw words (152076 effective words) took 0.4s, 401306 effective words/s
INFO - 2023-11-27 12:12:24,286: EPOCH 5: training on 155600 raw words (152012 effective words) took 0.4s, 391631 effective words/s
INFO - 2023-11-27 12:12:24,646: EPOCH 6: training on 155600 raw words (152082 effective words) took 0.4s, 426474 effective words/s
INFO - 2023-11-27 12:12:25,061: EPOCH 7: training on 155600 raw words (151988 effective words) took 0.4s, 368083 effective words/s
INFO - 2023-11-27 12:12:25,481: EPOCH 8: training on 155600 raw words (152113 effective words) took 0.4s, 364163 effective words/s
INFO - 2023-11-27 12:12:25,888: EPOCH 9: training on 155600 raw words (152065 effective words) took 0.4s, 381292 effective words/s
INFO - 2023-11-27 12:12:26,278: EPOCH 10: training on 155600 raw words (152118 effective words) took 0.4s, 393212 effective words/s
INFO - 2023-11-27 12:12:26,648: EPOCH 11: training on 155600 raw words (152116 effective words) took 0.4s, 413652 effective words/s
INFO - 2023-11-27 12:12:27,022: EPOCH 12: training on 155600 raw words (152049 effective words) took 0.4s, 409007 effective words/s
INFO - 2023-11-27 12:12:27,376: EPOCH 13: training on 155600 raw words (152111 effective words) took 0.4s, 432995 effective words/s
INFO - 2023-11-27 12:12:27,754: EPOCH 14: training on 155600 raw words (151985 effective words) took 0.4s, 404492 effective words/s
INFO - 2023-11-27 12:12:28,117: EPOCH 15: training on 155600 raw words (152134 effective words) took 0.4s, 422556 effective words/s
INFO - 2023-11-27 12:12:28,543: EPOCH 16: training on 155600 raw words (152053 effective words) took 0.4s, 358547 effective words/s
INFO - 2023-11-27 12:12:29,035: EPOCH 17: training on 155600 raw words (152049 effective words) took 0.5s, 311402 effective words/s
INFO - 2023-11-27 12:12:29,532: EPOCH 18: training on 155600 raw words (152061 effective words) took 0.5s, 307535 effective words/s
INFO - 2023-11-27 12:12:30,029: EPOCH 19: training on 155600 raw words (152079 effective words) took 0.5s, 307834 effective words/s
INFO - 2023-11-27 12:12:30,030: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3041400 effective words) took 8.0s, 379645 effective words/s', 'datetime': '2023-11-27T12:12:30.030263', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:30,030: collecting all words and their counts
INFO - 2023-11-27 12:12:30,030: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:30,069: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:30,070: Updating model with new vocabulary
INFO - 2023-11-27 12:12:30,095: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:30.095061', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:30,114: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:30,114: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:12:30,114: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152063.2589791286 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:12:30.114545', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:30,141: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:30,141: updating layer weights
INFO - 2023-11-27 12:12:30,142: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:30.142358', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:30,142: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:30,142: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:30.142658', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:30,619: EPOCH 0: training on 155600 raw words (152051 effective words) took 0.5s, 320994 effective words/s
INFO - 2023-11-27 12:12:31,102: EPOCH 1: training on 155600 raw words (151977 effective words) took 0.5s, 316769 effective words/s
INFO - 2023-11-27 12:12:31,582: EPOCH 2: training on 155600 raw words (152146 effective words) took 0.5s, 319006 effective words/s
INFO - 2023-11-27 12:12:32,120: EPOCH 3: training on 155600 raw words (152011 effective words) took 0.5s, 284361 effective words/s
INFO - 2023-11-27 12:12:32,598: EPOCH 4: training on 155600 raw words (152102 effective words) took 0.5s, 320877 effective words/s
INFO - 2023-11-27 12:12:32,942: EPOCH 5: training on 155600 raw words (152124 effective words) took 0.3s, 444768 effective words/s
INFO - 2023-11-27 12:12:33,278: EPOCH 6: training on 155600 raw words (152210 effective words) took 0.3s, 456270 effective words/s
INFO - 2023-11-27 12:12:33,802: EPOCH 7: training on 155600 raw words (152117 effective words) took 0.5s, 292347 effective words/s
INFO - 2023-11-27 12:12:34,267: EPOCH 8: training on 155600 raw words (152118 effective words) took 0.5s, 328627 effective words/s
INFO - 2023-11-27 12:12:34,826: EPOCH 9: training on 155600 raw words (152048 effective words) took 0.6s, 274268 effective words/s
INFO - 2023-11-27 12:12:35,413: EPOCH 10: training on 155600 raw words (152049 effective words) took 0.6s, 261437 effective words/s
INFO - 2023-11-27 12:12:36,025: EPOCH 11: training on 155600 raw words (152076 effective words) took 0.6s, 250307 effective words/s
INFO - 2023-11-27 12:12:36,507: EPOCH 12: training on 155600 raw words (152080 effective words) took 0.5s, 317408 effective words/s
INFO - 2023-11-27 12:12:36,873: EPOCH 13: training on 155600 raw words (152119 effective words) took 0.4s, 418669 effective words/s
INFO - 2023-11-27 12:12:37,233: EPOCH 14: training on 155600 raw words (152030 effective words) took 0.4s, 424933 effective words/s
INFO - 2023-11-27 12:12:37,557: EPOCH 15: training on 155600 raw words (152095 effective words) took 0.3s, 472853 effective words/s
INFO - 2023-11-27 12:12:37,918: EPOCH 16: training on 155600 raw words (152095 effective words) took 0.4s, 424267 effective words/s
INFO - 2023-11-27 12:12:38,256: EPOCH 17: training on 155600 raw words (152120 effective words) took 0.3s, 453896 effective words/s
INFO - 2023-11-27 12:12:38,588: EPOCH 18: training on 155600 raw words (152067 effective words) took 0.3s, 460553 effective words/s
INFO - 2023-11-27 12:12:38,917: EPOCH 19: training on 155600 raw words (152063 effective words) took 0.3s, 466730 effective words/s
INFO - 2023-11-27 12:12:38,917: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3041698 effective words) took 8.8s, 346646 effective words/s', 'datetime': '2023-11-27T12:12:38.917470', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:38,917: collecting all words and their counts
INFO - 2023-11-27 12:12:38,918: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:38,942: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:38,942: Updating model with new vocabulary
INFO - 2023-11-27 12:12:38,952: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:38.952545', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:38,965: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:38,965: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:12:38,965: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151903.68949339888 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:12:38.965545', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:38,985: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:38,985: updating layer weights
INFO - 2023-11-27 12:12:38,985: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:38.985675', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:38,985: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:38,986: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:38.986037', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:39,340: EPOCH 0: training on 155600 raw words (151902 effective words) took 0.4s, 432004 effective words/s
INFO - 2023-11-27 12:12:39,753: EPOCH 1: training on 155600 raw words (151909 effective words) took 0.4s, 370328 effective words/s
INFO - 2023-11-27 12:12:40,104: EPOCH 2: training on 155600 raw words (151835 effective words) took 0.3s, 434330 effective words/s
INFO - 2023-11-27 12:12:40,495: EPOCH 3: training on 155600 raw words (151844 effective words) took 0.4s, 406798 effective words/s
INFO - 2023-11-27 12:12:40,842: EPOCH 4: training on 155600 raw words (151835 effective words) took 0.3s, 441330 effective words/s
INFO - 2023-11-27 12:12:41,224: EPOCH 5: training on 155600 raw words (151917 effective words) took 0.4s, 417624 effective words/s
INFO - 2023-11-27 12:12:41,574: EPOCH 6: training on 155600 raw words (151966 effective words) took 0.3s, 442792 effective words/s
INFO - 2023-11-27 12:12:41,934: EPOCH 7: training on 155600 raw words (151867 effective words) took 0.4s, 424403 effective words/s
INFO - 2023-11-27 12:12:42,287: EPOCH 8: training on 155600 raw words (151850 effective words) took 0.4s, 433850 effective words/s
INFO - 2023-11-27 12:12:42,637: EPOCH 9: training on 155600 raw words (151921 effective words) took 0.3s, 436163 effective words/s
INFO - 2023-11-27 12:12:43,039: EPOCH 10: training on 155600 raw words (151804 effective words) took 0.4s, 380161 effective words/s
INFO - 2023-11-27 12:12:43,385: EPOCH 11: training on 155600 raw words (151922 effective words) took 0.3s, 442155 effective words/s
INFO - 2023-11-27 12:12:43,782: EPOCH 12: training on 155600 raw words (151996 effective words) took 0.4s, 385109 effective words/s
INFO - 2023-11-27 12:12:44,135: EPOCH 13: training on 155600 raw words (151892 effective words) took 0.4s, 432128 effective words/s
INFO - 2023-11-27 12:12:44,510: EPOCH 14: training on 155600 raw words (151956 effective words) took 0.4s, 408271 effective words/s
INFO - 2023-11-27 12:12:44,858: EPOCH 15: training on 155600 raw words (151892 effective words) took 0.3s, 438995 effective words/s
INFO - 2023-11-27 12:12:45,249: EPOCH 16: training on 155600 raw words (151826 effective words) took 0.4s, 390783 effective words/s
INFO - 2023-11-27 12:12:45,654: EPOCH 17: training on 155600 raw words (151957 effective words) took 0.4s, 377482 effective words/s
INFO - 2023-11-27 12:12:46,002: EPOCH 18: training on 155600 raw words (151891 effective words) took 0.3s, 438371 effective words/s
INFO - 2023-11-27 12:12:46,342: EPOCH 19: training on 155600 raw words (151925 effective words) took 0.3s, 450515 effective words/s
INFO - 2023-11-27 12:12:46,342: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037907 effective words) took 7.4s, 412954 effective words/s', 'datetime': '2023-11-27T12:12:46.342696', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:46,342: collecting all words and their counts
INFO - 2023-11-27 12:12:46,343: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:46,365: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:46,365: Updating model with new vocabulary
INFO - 2023-11-27 12:12:46,375: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:46.375491', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:46,387: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:46,387: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:12:46,388: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152058.25571166756 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:12:46.388021', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:46,406: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:46,406: updating layer weights
INFO - 2023-11-27 12:12:46,406: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:46.406846', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:46,407: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:46,407: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:46.407236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:46,729: EPOCH 0: training on 155600 raw words (152021 effective words) took 0.3s, 474653 effective words/s
INFO - 2023-11-27 12:12:47,047: EPOCH 1: training on 155600 raw words (152055 effective words) took 0.3s, 481673 effective words/s
INFO - 2023-11-27 12:12:47,368: EPOCH 2: training on 155600 raw words (152017 effective words) took 0.3s, 476490 effective words/s
INFO - 2023-11-27 12:12:47,695: EPOCH 3: training on 155600 raw words (152059 effective words) took 0.3s, 469878 effective words/s
INFO - 2023-11-27 12:12:48,017: EPOCH 4: training on 155600 raw words (152081 effective words) took 0.3s, 475208 effective words/s
INFO - 2023-11-27 12:12:48,345: EPOCH 5: training on 155600 raw words (151940 effective words) took 0.3s, 466890 effective words/s
INFO - 2023-11-27 12:12:48,667: EPOCH 6: training on 155600 raw words (152065 effective words) took 0.3s, 475773 effective words/s
INFO - 2023-11-27 12:12:48,987: EPOCH 7: training on 155600 raw words (152131 effective words) took 0.3s, 479427 effective words/s
INFO - 2023-11-27 12:12:49,309: EPOCH 8: training on 155600 raw words (152047 effective words) took 0.3s, 474996 effective words/s
INFO - 2023-11-27 12:12:49,626: EPOCH 9: training on 155600 raw words (152036 effective words) took 0.3s, 483099 effective words/s
INFO - 2023-11-27 12:12:49,949: EPOCH 10: training on 155600 raw words (152043 effective words) took 0.3s, 474549 effective words/s
INFO - 2023-11-27 12:12:50,320: EPOCH 11: training on 155600 raw words (152025 effective words) took 0.4s, 411359 effective words/s
INFO - 2023-11-27 12:12:50,651: EPOCH 12: training on 155600 raw words (152109 effective words) took 0.3s, 463211 effective words/s
INFO - 2023-11-27 12:12:50,974: EPOCH 13: training on 155600 raw words (151959 effective words) took 0.3s, 474396 effective words/s
INFO - 2023-11-27 12:12:51,298: EPOCH 14: training on 155600 raw words (152048 effective words) took 0.3s, 472744 effective words/s
INFO - 2023-11-27 12:12:51,692: EPOCH 15: training on 155600 raw words (152029 effective words) took 0.4s, 388492 effective words/s
INFO - 2023-11-27 12:12:52,150: EPOCH 16: training on 155600 raw words (152230 effective words) took 0.5s, 334728 effective words/s
INFO - 2023-11-27 12:12:52,599: EPOCH 17: training on 155600 raw words (152035 effective words) took 0.4s, 341055 effective words/s
INFO - 2023-11-27 12:12:53,063: EPOCH 18: training on 155600 raw words (152057 effective words) took 0.5s, 329786 effective words/s
INFO - 2023-11-27 12:12:53,548: EPOCH 19: training on 155600 raw words (152061 effective words) took 0.5s, 318521 effective words/s
INFO - 2023-11-27 12:12:53,549: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3041048 effective words) took 7.1s, 425808 effective words/s', 'datetime': '2023-11-27T12:12:53.549191', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:53,549: collecting all words and their counts
INFO - 2023-11-27 12:12:53,549: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:12:53,582: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:12:53,583: Updating model with new vocabulary
INFO - 2023-11-27 12:12:53,601: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:12:53.601807', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:53,620: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:12:53,621: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:12:53,621: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151852.0477809862 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:12:53.621214', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:12:53,651: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:12:53,651: updating layer weights
INFO - 2023-11-27 12:12:53,651: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:12:53.651872', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:12:53,652: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:12:53,653: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:12:53.653968', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:12:54,153: EPOCH 0: training on 155600 raw words (151888 effective words) took 0.5s, 311278 effective words/s
INFO - 2023-11-27 12:12:54,673: EPOCH 1: training on 155600 raw words (151820 effective words) took 0.5s, 293497 effective words/s
INFO - 2023-11-27 12:12:55,182: EPOCH 2: training on 155600 raw words (151856 effective words) took 0.5s, 300695 effective words/s
INFO - 2023-11-27 12:12:55,686: EPOCH 3: training on 155600 raw words (151918 effective words) took 0.5s, 303408 effective words/s
INFO - 2023-11-27 12:12:56,176: EPOCH 4: training on 155600 raw words (151949 effective words) took 0.5s, 312009 effective words/s
INFO - 2023-11-27 12:12:56,677: EPOCH 5: training on 155600 raw words (151839 effective words) took 0.5s, 305106 effective words/s
INFO - 2023-11-27 12:12:57,227: EPOCH 6: training on 155600 raw words (151802 effective words) took 0.5s, 277478 effective words/s
INFO - 2023-11-27 12:12:57,752: EPOCH 7: training on 155600 raw words (151973 effective words) took 0.5s, 290780 effective words/s
INFO - 2023-11-27 12:12:58,308: EPOCH 8: training on 155600 raw words (151872 effective words) took 0.6s, 275296 effective words/s
INFO - 2023-11-27 12:12:58,850: EPOCH 9: training on 155600 raw words (151828 effective words) took 0.5s, 282133 effective words/s
INFO - 2023-11-27 12:12:59,386: EPOCH 10: training on 155600 raw words (151874 effective words) took 0.5s, 288252 effective words/s
INFO - 2023-11-27 12:12:59,919: EPOCH 11: training on 155600 raw words (151831 effective words) took 0.5s, 286923 effective words/s
INFO - 2023-11-27 12:13:00,485: EPOCH 12: training on 155600 raw words (151914 effective words) took 0.6s, 270253 effective words/s
INFO - 2023-11-27 12:13:00,979: EPOCH 13: training on 155600 raw words (151791 effective words) took 0.5s, 309659 effective words/s
INFO - 2023-11-27 12:13:01,440: EPOCH 14: training on 155600 raw words (151838 effective words) took 0.5s, 331261 effective words/s
INFO - 2023-11-27 12:13:01,909: EPOCH 15: training on 155600 raw words (151925 effective words) took 0.5s, 326656 effective words/s
INFO - 2023-11-27 12:13:02,416: EPOCH 16: training on 155600 raw words (151827 effective words) took 0.5s, 301417 effective words/s
INFO - 2023-11-27 12:13:02,916: EPOCH 17: training on 155600 raw words (151801 effective words) took 0.5s, 305687 effective words/s
INFO - 2023-11-27 12:13:03,395: EPOCH 18: training on 155600 raw words (151784 effective words) took 0.5s, 319630 effective words/s
INFO - 2023-11-27 12:13:03,900: EPOCH 19: training on 155600 raw words (151852 effective words) took 0.5s, 302932 effective words/s
INFO - 2023-11-27 12:13:03,900: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037182 effective words) took 10.2s, 296419 effective words/s', 'datetime': '2023-11-27T12:13:03.900425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:03,900: collecting all words and their counts
INFO - 2023-11-27 12:13:03,900: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:03,939: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:03,939: Updating model with new vocabulary
INFO - 2023-11-27 12:13:03,956: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:03.955996', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:03,975: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:03,975: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:13:03,975: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151893.674101289 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:13:03.975855', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:04,010: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:04,010: updating layer weights
INFO - 2023-11-27 12:13:04,010: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:04.010782', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:04,011: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:04,011: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:04.011131', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:04,502: EPOCH 0: training on 155600 raw words (151988 effective words) took 0.5s, 323603 effective words/s
INFO - 2023-11-27 12:13:04,993: EPOCH 1: training on 155600 raw words (151875 effective words) took 0.5s, 310976 effective words/s
INFO - 2023-11-27 12:13:05,533: EPOCH 2: training on 155600 raw words (151857 effective words) took 0.5s, 285604 effective words/s
INFO - 2023-11-27 12:13:06,020: EPOCH 3: training on 155600 raw words (151981 effective words) took 0.5s, 314805 effective words/s
INFO - 2023-11-27 12:13:06,482: EPOCH 4: training on 155600 raw words (151824 effective words) took 0.5s, 330799 effective words/s
INFO - 2023-11-27 12:13:06,958: EPOCH 5: training on 155600 raw words (151919 effective words) took 0.5s, 322326 effective words/s
INFO - 2023-11-27 12:13:07,414: EPOCH 6: training on 155600 raw words (151833 effective words) took 0.5s, 335710 effective words/s
INFO - 2023-11-27 12:13:07,872: EPOCH 7: training on 155600 raw words (151868 effective words) took 0.5s, 333591 effective words/s
INFO - 2023-11-27 12:13:08,282: EPOCH 8: training on 155600 raw words (151901 effective words) took 0.4s, 373844 effective words/s
INFO - 2023-11-27 12:13:08,757: EPOCH 9: training on 155600 raw words (151873 effective words) took 0.5s, 322082 effective words/s
INFO - 2023-11-27 12:13:09,170: EPOCH 10: training on 155600 raw words (151864 effective words) took 0.4s, 370821 effective words/s
INFO - 2023-11-27 12:13:09,618: EPOCH 11: training on 155600 raw words (151904 effective words) took 0.4s, 341533 effective words/s
INFO - 2023-11-27 12:13:10,037: EPOCH 12: training on 155600 raw words (151906 effective words) took 0.4s, 365098 effective words/s
INFO - 2023-11-27 12:13:10,392: EPOCH 13: training on 155600 raw words (151873 effective words) took 0.3s, 440188 effective words/s
INFO - 2023-11-27 12:13:10,786: EPOCH 14: training on 155600 raw words (151874 effective words) took 0.4s, 387994 effective words/s
INFO - 2023-11-27 12:13:11,138: EPOCH 15: training on 155600 raw words (151933 effective words) took 0.3s, 435110 effective words/s
INFO - 2023-11-27 12:13:11,494: EPOCH 16: training on 155600 raw words (151935 effective words) took 0.4s, 428850 effective words/s
INFO - 2023-11-27 12:13:11,815: EPOCH 17: training on 155600 raw words (151959 effective words) took 0.3s, 477794 effective words/s
INFO - 2023-11-27 12:13:12,146: EPOCH 18: training on 155600 raw words (151923 effective words) took 0.3s, 461959 effective words/s
INFO - 2023-11-27 12:13:12,470: EPOCH 19: training on 155600 raw words (151903 effective words) took 0.3s, 473380 effective words/s
INFO - 2023-11-27 12:13:12,470: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037993 effective words) took 8.5s, 359143 effective words/s', 'datetime': '2023-11-27T12:13:12.470315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:12,470: collecting all words and their counts
INFO - 2023-11-27 12:13:12,470: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:12,492: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:12,493: Updating model with new vocabulary
INFO - 2023-11-27 12:13:12,503: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:12.502978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:12,515: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:12,515: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:13:12,515: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151954.06845714574 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:13:12.515267', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:12,534: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:12,534: updating layer weights
INFO - 2023-11-27 12:13:12,534: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:12.534503', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:12,534: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:12,534: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:12.534693', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:12,876: EPOCH 0: training on 155600 raw words (151920 effective words) took 0.3s, 447004 effective words/s
INFO - 2023-11-27 12:13:13,221: EPOCH 1: training on 155600 raw words (151939 effective words) took 0.3s, 444417 effective words/s
INFO - 2023-11-27 12:13:13,565: EPOCH 2: training on 155600 raw words (151996 effective words) took 0.3s, 443981 effective words/s
INFO - 2023-11-27 12:13:13,913: EPOCH 3: training on 155600 raw words (151969 effective words) took 0.3s, 439620 effective words/s
INFO - 2023-11-27 12:13:14,261: EPOCH 4: training on 155600 raw words (151962 effective words) took 0.3s, 440175 effective words/s
INFO - 2023-11-27 12:13:14,607: EPOCH 5: training on 155600 raw words (151993 effective words) took 0.3s, 441445 effective words/s
INFO - 2023-11-27 12:13:14,958: EPOCH 6: training on 155600 raw words (151941 effective words) took 0.3s, 436388 effective words/s
INFO - 2023-11-27 12:13:15,295: EPOCH 7: training on 155600 raw words (151965 effective words) took 0.3s, 454285 effective words/s
INFO - 2023-11-27 12:13:15,626: EPOCH 8: training on 155600 raw words (151943 effective words) took 0.3s, 461011 effective words/s
INFO - 2023-11-27 12:13:15,982: EPOCH 9: training on 155600 raw words (151980 effective words) took 0.4s, 430459 effective words/s
INFO - 2023-11-27 12:13:16,346: EPOCH 10: training on 155600 raw words (151959 effective words) took 0.4s, 420366 effective words/s
INFO - 2023-11-27 12:13:16,705: EPOCH 11: training on 155600 raw words (151949 effective words) took 0.4s, 425879 effective words/s
INFO - 2023-11-27 12:13:17,050: EPOCH 12: training on 155600 raw words (151840 effective words) took 0.3s, 443051 effective words/s
INFO - 2023-11-27 12:13:17,395: EPOCH 13: training on 155600 raw words (151971 effective words) took 0.3s, 443905 effective words/s
INFO - 2023-11-27 12:13:17,741: EPOCH 14: training on 155600 raw words (151912 effective words) took 0.3s, 441247 effective words/s
INFO - 2023-11-27 12:13:18,096: EPOCH 15: training on 155600 raw words (151818 effective words) took 0.4s, 431248 effective words/s
INFO - 2023-11-27 12:13:18,438: EPOCH 16: training on 155600 raw words (151930 effective words) took 0.3s, 446303 effective words/s
INFO - 2023-11-27 12:13:18,781: EPOCH 17: training on 155600 raw words (151966 effective words) took 0.3s, 446503 effective words/s
INFO - 2023-11-27 12:13:19,134: EPOCH 18: training on 155600 raw words (152009 effective words) took 0.4s, 433843 effective words/s
INFO - 2023-11-27 12:13:19,487: EPOCH 19: training on 155600 raw words (151953 effective words) took 0.3s, 452341 effective words/s
INFO - 2023-11-27 12:13:19,487: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038915 effective words) took 7.0s, 437096 effective words/s', 'datetime': '2023-11-27T12:13:19.487313', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:19,487: collecting all words and their counts
INFO - 2023-11-27 12:13:19,487: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:19,509: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:19,510: Updating model with new vocabulary
INFO - 2023-11-27 12:13:19,521: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:19.521814', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:19,534: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:19,534: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:13:19,534: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151894.04528858073 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:13:19.534697', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:19,553: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:19,553: updating layer weights
INFO - 2023-11-27 12:13:19,554: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:19.554019', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:19,554: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:19,554: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:19.554232', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:19,895: EPOCH 0: training on 155600 raw words (151917 effective words) took 0.3s, 449031 effective words/s
INFO - 2023-11-27 12:13:20,223: EPOCH 1: training on 155600 raw words (151912 effective words) took 0.3s, 465463 effective words/s
INFO - 2023-11-27 12:13:20,539: EPOCH 2: training on 155600 raw words (151883 effective words) took 0.3s, 484321 effective words/s
INFO - 2023-11-27 12:13:20,858: EPOCH 3: training on 155600 raw words (151810 effective words) took 0.3s, 479681 effective words/s
INFO - 2023-11-27 12:13:21,181: EPOCH 4: training on 155600 raw words (151914 effective words) took 0.3s, 473470 effective words/s
INFO - 2023-11-27 12:13:21,509: EPOCH 5: training on 155600 raw words (151948 effective words) took 0.3s, 466454 effective words/s
INFO - 2023-11-27 12:13:21,821: EPOCH 6: training on 155600 raw words (151886 effective words) took 0.3s, 490189 effective words/s
INFO - 2023-11-27 12:13:22,134: EPOCH 7: training on 155600 raw words (151868 effective words) took 0.3s, 489464 effective words/s
INFO - 2023-11-27 12:13:22,451: EPOCH 8: training on 155600 raw words (151858 effective words) took 0.3s, 482708 effective words/s
INFO - 2023-11-27 12:13:22,772: EPOCH 9: training on 155600 raw words (151918 effective words) took 0.3s, 477242 effective words/s
INFO - 2023-11-27 12:13:23,086: EPOCH 10: training on 155600 raw words (151991 effective words) took 0.3s, 487296 effective words/s
INFO - 2023-11-27 12:13:23,495: EPOCH 11: training on 155600 raw words (151862 effective words) took 0.4s, 372903 effective words/s
INFO - 2023-11-27 12:13:23,858: EPOCH 12: training on 155600 raw words (151850 effective words) took 0.4s, 421736 effective words/s
INFO - 2023-11-27 12:13:24,292: EPOCH 13: training on 155600 raw words (151862 effective words) took 0.4s, 352058 effective words/s
INFO - 2023-11-27 12:13:24,778: EPOCH 14: training on 155600 raw words (151913 effective words) took 0.5s, 314310 effective words/s
INFO - 2023-11-27 12:13:25,187: EPOCH 15: training on 155600 raw words (151969 effective words) took 0.4s, 375275 effective words/s
INFO - 2023-11-27 12:13:25,611: EPOCH 16: training on 155600 raw words (151873 effective words) took 0.4s, 360323 effective words/s
INFO - 2023-11-27 12:13:26,067: EPOCH 17: training on 155600 raw words (151908 effective words) took 0.5s, 335388 effective words/s
INFO - 2023-11-27 12:13:26,514: EPOCH 18: training on 155600 raw words (151864 effective words) took 0.4s, 341063 effective words/s
INFO - 2023-11-27 12:13:26,936: EPOCH 19: training on 155600 raw words (151846 effective words) took 0.4s, 362495 effective words/s
INFO - 2023-11-27 12:13:26,936: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037852 effective words) took 7.4s, 411488 effective words/s', 'datetime': '2023-11-27T12:13:26.936942', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:26,937: collecting all words and their counts
INFO - 2023-11-27 12:13:26,937: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:26,970: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:26,970: Updating model with new vocabulary
INFO - 2023-11-27 12:13:26,984: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:26.984737', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:27,001: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:27,002: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:13:27,002: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151977.84212233283 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:13:27.002217', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:27,030: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:27,030: updating layer weights
INFO - 2023-11-27 12:13:27,031: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:27.031078', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:27,031: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:27,031: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:27.031430', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:27,497: EPOCH 0: training on 155600 raw words (152011 effective words) took 0.5s, 328074 effective words/s
INFO - 2023-11-27 12:13:28,005: EPOCH 1: training on 155600 raw words (151937 effective words) took 0.5s, 301238 effective words/s
INFO - 2023-11-27 12:13:28,472: EPOCH 2: training on 155600 raw words (152043 effective words) took 0.5s, 328148 effective words/s
INFO - 2023-11-27 12:13:28,928: EPOCH 3: training on 155600 raw words (151897 effective words) took 0.5s, 334972 effective words/s
INFO - 2023-11-27 12:13:29,412: EPOCH 4: training on 155600 raw words (152015 effective words) took 0.5s, 315617 effective words/s
INFO - 2023-11-27 12:13:29,899: EPOCH 5: training on 155600 raw words (151984 effective words) took 0.5s, 314331 effective words/s
INFO - 2023-11-27 12:13:30,390: EPOCH 6: training on 155600 raw words (152095 effective words) took 0.5s, 311988 effective words/s
INFO - 2023-11-27 12:13:30,883: EPOCH 7: training on 155600 raw words (151960 effective words) took 0.5s, 310396 effective words/s
INFO - 2023-11-27 12:13:31,392: EPOCH 8: training on 155600 raw words (152019 effective words) took 0.5s, 300953 effective words/s
INFO - 2023-11-27 12:13:31,910: EPOCH 9: training on 155600 raw words (152003 effective words) took 0.5s, 296052 effective words/s
INFO - 2023-11-27 12:13:32,437: EPOCH 10: training on 155600 raw words (151940 effective words) took 0.5s, 295006 effective words/s
INFO - 2023-11-27 12:13:32,851: EPOCH 11: training on 155600 raw words (151987 effective words) took 0.4s, 369694 effective words/s
INFO - 2023-11-27 12:13:33,200: EPOCH 12: training on 155600 raw words (152056 effective words) took 0.3s, 439459 effective words/s
INFO - 2023-11-27 12:13:33,550: EPOCH 13: training on 155600 raw words (152001 effective words) took 0.3s, 437459 effective words/s
INFO - 2023-11-27 12:13:33,893: EPOCH 14: training on 155600 raw words (152044 effective words) took 0.3s, 445946 effective words/s
INFO - 2023-11-27 12:13:34,250: EPOCH 15: training on 155600 raw words (151985 effective words) took 0.4s, 428518 effective words/s
INFO - 2023-11-27 12:13:34,595: EPOCH 16: training on 155600 raw words (151900 effective words) took 0.3s, 443164 effective words/s
INFO - 2023-11-27 12:13:35,095: EPOCH 17: training on 155600 raw words (151953 effective words) took 0.5s, 305704 effective words/s
INFO - 2023-11-27 12:13:35,550: EPOCH 18: training on 155600 raw words (151943 effective words) took 0.4s, 341671 effective words/s
INFO - 2023-11-27 12:13:35,921: EPOCH 19: training on 155600 raw words (151970 effective words) took 0.4s, 411545 effective words/s
INFO - 2023-11-27 12:13:35,922: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039743 effective words) took 8.9s, 341908 effective words/s', 'datetime': '2023-11-27T12:13:35.922106', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:35,922: collecting all words and their counts
INFO - 2023-11-27 12:13:35,922: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:35,946: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:35,946: Updating model with new vocabulary
INFO - 2023-11-27 12:13:35,958: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:35.958378', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:35,972: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:35,972: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:13:35,972: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151970.71568916226 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:13:35.972491', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:35,991: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:35,991: updating layer weights
INFO - 2023-11-27 12:13:35,992: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:35.992145', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:35,992: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:35,992: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:35.992444', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:36,339: EPOCH 0: training on 155600 raw words (151950 effective words) took 0.3s, 440873 effective words/s
INFO - 2023-11-27 12:13:36,684: EPOCH 1: training on 155600 raw words (151911 effective words) took 0.3s, 442278 effective words/s
INFO - 2023-11-27 12:13:37,025: EPOCH 2: training on 155600 raw words (151989 effective words) took 0.3s, 448855 effective words/s
INFO - 2023-11-27 12:13:37,359: EPOCH 3: training on 155600 raw words (151988 effective words) took 0.3s, 458359 effective words/s
INFO - 2023-11-27 12:13:37,715: EPOCH 4: training on 155600 raw words (152026 effective words) took 0.4s, 431133 effective words/s
INFO - 2023-11-27 12:13:38,074: EPOCH 5: training on 155600 raw words (151972 effective words) took 0.4s, 424976 effective words/s
INFO - 2023-11-27 12:13:38,418: EPOCH 6: training on 155600 raw words (151983 effective words) took 0.3s, 445145 effective words/s
INFO - 2023-11-27 12:13:38,785: EPOCH 7: training on 155600 raw words (151931 effective words) took 0.4s, 417954 effective words/s
INFO - 2023-11-27 12:13:39,104: EPOCH 8: training on 155600 raw words (151936 effective words) took 0.3s, 480177 effective words/s
INFO - 2023-11-27 12:13:39,441: EPOCH 9: training on 155600 raw words (151933 effective words) took 0.3s, 453856 effective words/s
INFO - 2023-11-27 12:13:39,783: EPOCH 10: training on 155600 raw words (152037 effective words) took 0.3s, 447961 effective words/s
INFO - 2023-11-27 12:13:40,123: EPOCH 11: training on 155600 raw words (151918 effective words) took 0.3s, 450253 effective words/s
INFO - 2023-11-27 12:13:40,546: EPOCH 12: training on 155600 raw words (151986 effective words) took 0.4s, 361115 effective words/s
INFO - 2023-11-27 12:13:40,961: EPOCH 13: training on 155600 raw words (151969 effective words) took 0.4s, 368566 effective words/s
INFO - 2023-11-27 12:13:41,337: EPOCH 14: training on 155600 raw words (152010 effective words) took 0.4s, 407327 effective words/s
INFO - 2023-11-27 12:13:41,711: EPOCH 15: training on 155600 raw words (152020 effective words) took 0.4s, 409705 effective words/s
INFO - 2023-11-27 12:13:42,127: EPOCH 16: training on 155600 raw words (152032 effective words) took 0.4s, 367081 effective words/s
INFO - 2023-11-27 12:13:42,490: EPOCH 17: training on 155600 raw words (151959 effective words) took 0.4s, 421885 effective words/s
INFO - 2023-11-27 12:13:42,857: EPOCH 18: training on 155600 raw words (151960 effective words) took 0.4s, 417107 effective words/s
INFO - 2023-11-27 12:13:43,213: EPOCH 19: training on 155600 raw words (151948 effective words) took 0.4s, 429231 effective words/s
INFO - 2023-11-27 12:13:43,214: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039458 effective words) took 7.2s, 420886 effective words/s', 'datetime': '2023-11-27T12:13:43.214136', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:43,214: collecting all words and their counts
INFO - 2023-11-27 12:13:43,214: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:43,244: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:43,244: Updating model with new vocabulary
INFO - 2023-11-27 12:13:43,255: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:43.255355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:43,267: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:43,268: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:13:43,268: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152034.81316321928 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:13:43.268250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:43,288: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:43,288: updating layer weights
INFO - 2023-11-27 12:13:43,289: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:43.289030', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:43,289: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:43,289: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:43.289268', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:43,743: EPOCH 0: training on 155600 raw words (152023 effective words) took 0.5s, 336664 effective words/s
INFO - 2023-11-27 12:13:44,247: EPOCH 1: training on 155600 raw words (152099 effective words) took 0.5s, 302902 effective words/s
INFO - 2023-11-27 12:13:44,732: EPOCH 2: training on 155600 raw words (152002 effective words) took 0.5s, 315756 effective words/s
INFO - 2023-11-27 12:13:45,178: EPOCH 3: training on 155600 raw words (152027 effective words) took 0.4s, 346239 effective words/s
INFO - 2023-11-27 12:13:45,604: EPOCH 4: training on 155600 raw words (152059 effective words) took 0.4s, 378046 effective words/s
INFO - 2023-11-27 12:13:46,015: EPOCH 5: training on 155600 raw words (152039 effective words) took 0.4s, 383367 effective words/s
INFO - 2023-11-27 12:13:46,427: EPOCH 6: training on 155600 raw words (152008 effective words) took 0.4s, 371154 effective words/s
INFO - 2023-11-27 12:13:46,864: EPOCH 7: training on 155600 raw words (152139 effective words) took 0.4s, 350517 effective words/s
INFO - 2023-11-27 12:13:47,275: EPOCH 8: training on 155600 raw words (152050 effective words) took 0.4s, 372157 effective words/s
INFO - 2023-11-27 12:13:47,676: EPOCH 9: training on 155600 raw words (152092 effective words) took 0.4s, 392116 effective words/s
INFO - 2023-11-27 12:13:48,295: EPOCH 10: training on 155600 raw words (151937 effective words) took 0.6s, 246886 effective words/s
INFO - 2023-11-27 12:13:48,910: EPOCH 11: training on 155600 raw words (151979 effective words) took 0.6s, 248609 effective words/s
INFO - 2023-11-27 12:13:49,480: EPOCH 12: training on 155600 raw words (152036 effective words) took 0.6s, 268372 effective words/s
INFO - 2023-11-27 12:13:50,117: EPOCH 13: training on 155600 raw words (152021 effective words) took 0.6s, 239592 effective words/s
INFO - 2023-11-27 12:13:50,693: EPOCH 14: training on 155600 raw words (152039 effective words) took 0.6s, 265840 effective words/s
INFO - 2023-11-27 12:13:51,273: EPOCH 15: training on 155600 raw words (152111 effective words) took 0.6s, 264006 effective words/s
INFO - 2023-11-27 12:13:51,846: EPOCH 16: training on 155600 raw words (151961 effective words) took 0.6s, 267060 effective words/s
INFO - 2023-11-27 12:13:52,433: EPOCH 17: training on 155600 raw words (152001 effective words) took 0.6s, 259913 effective words/s
INFO - 2023-11-27 12:13:53,043: EPOCH 18: training on 155600 raw words (151992 effective words) took 0.6s, 250575 effective words/s
INFO - 2023-11-27 12:13:53,566: EPOCH 19: training on 155600 raw words (152065 effective words) took 0.5s, 292726 effective words/s
INFO - 2023-11-27 12:13:53,567: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040680 effective words) took 10.3s, 295849 effective words/s', 'datetime': '2023-11-27T12:13:53.567222', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:53,567: collecting all words and their counts
INFO - 2023-11-27 12:13:53,567: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:13:53,606: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:13:53,606: Updating model with new vocabulary
INFO - 2023-11-27 12:13:53,622: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:13:53.622801', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:53,643: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:13:53,644: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:13:53,644: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151980.61412503096 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:13:53.644350', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:13:53,684: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:13:53,684: updating layer weights
INFO - 2023-11-27 12:13:53,685: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:13:53.685087', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:13:53,685: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:13:53,685: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:13:53.685522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:13:54,232: EPOCH 0: training on 155600 raw words (151998 effective words) took 0.5s, 280280 effective words/s
INFO - 2023-11-27 12:13:54,739: EPOCH 1: training on 155600 raw words (151971 effective words) took 0.5s, 301203 effective words/s
INFO - 2023-11-27 12:13:55,256: EPOCH 2: training on 155600 raw words (152006 effective words) took 0.5s, 295878 effective words/s
INFO - 2023-11-27 12:13:55,758: EPOCH 3: training on 155600 raw words (151939 effective words) took 0.5s, 308144 effective words/s
INFO - 2023-11-27 12:13:56,259: EPOCH 4: training on 155600 raw words (151921 effective words) took 0.5s, 305168 effective words/s
INFO - 2023-11-27 12:13:56,749: EPOCH 5: training on 155600 raw words (151962 effective words) took 0.5s, 328601 effective words/s
INFO - 2023-11-27 12:13:57,194: EPOCH 6: training on 155600 raw words (151982 effective words) took 0.4s, 343421 effective words/s
INFO - 2023-11-27 12:13:57,633: EPOCH 7: training on 155600 raw words (152015 effective words) took 0.4s, 348495 effective words/s
INFO - 2023-11-27 12:13:58,130: EPOCH 8: training on 155600 raw words (151951 effective words) took 0.5s, 307947 effective words/s
INFO - 2023-11-27 12:13:58,593: EPOCH 9: training on 155600 raw words (152027 effective words) took 0.5s, 330507 effective words/s
INFO - 2023-11-27 12:13:59,009: EPOCH 10: training on 155600 raw words (152024 effective words) took 0.4s, 373860 effective words/s
INFO - 2023-11-27 12:13:59,461: EPOCH 11: training on 155600 raw words (151973 effective words) took 0.4s, 338393 effective words/s
INFO - 2023-11-27 12:13:59,893: EPOCH 12: training on 155600 raw words (152008 effective words) took 0.4s, 358403 effective words/s
INFO - 2023-11-27 12:14:00,350: EPOCH 13: training on 155600 raw words (151984 effective words) took 0.4s, 341253 effective words/s
INFO - 2023-11-27 12:14:00,781: EPOCH 14: training on 155600 raw words (151981 effective words) took 0.4s, 355654 effective words/s
INFO - 2023-11-27 12:14:01,209: EPOCH 15: training on 155600 raw words (152017 effective words) took 0.4s, 362247 effective words/s
INFO - 2023-11-27 12:14:01,634: EPOCH 16: training on 155600 raw words (152015 effective words) took 0.4s, 360359 effective words/s
INFO - 2023-11-27 12:14:02,190: EPOCH 17: training on 155600 raw words (152019 effective words) took 0.4s, 340348 effective words/s
INFO - 2023-11-27 12:14:02,623: EPOCH 18: training on 155600 raw words (151962 effective words) took 0.4s, 353620 effective words/s
INFO - 2023-11-27 12:14:03,040: EPOCH 19: training on 155600 raw words (151953 effective words) took 0.4s, 367219 effective words/s
INFO - 2023-11-27 12:14:03,040: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039708 effective words) took 9.4s, 324944 effective words/s', 'datetime': '2023-11-27T12:14:03.040263', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:03,040: collecting all words and their counts
INFO - 2023-11-27 12:14:03,040: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:03,069: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:03,069: Updating model with new vocabulary
INFO - 2023-11-27 12:14:03,082: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:03.082707', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:03,099: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:03,099: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:14:03,100: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151912.58738825456 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:14:03.100007', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:03,126: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:03,126: updating layer weights
INFO - 2023-11-27 12:14:03,127: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:03.127128', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:03,127: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:03,127: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:03.127445', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:03,569: EPOCH 0: training on 155600 raw words (151922 effective words) took 0.4s, 346081 effective words/s
INFO - 2023-11-27 12:14:04,014: EPOCH 1: training on 155600 raw words (151929 effective words) took 0.4s, 342986 effective words/s
INFO - 2023-11-27 12:14:04,465: EPOCH 2: training on 155600 raw words (151880 effective words) took 0.4s, 339347 effective words/s
INFO - 2023-11-27 12:14:04,913: EPOCH 3: training on 155600 raw words (151989 effective words) took 0.4s, 341380 effective words/s
INFO - 2023-11-27 12:14:05,371: EPOCH 4: training on 155600 raw words (151834 effective words) took 0.5s, 333889 effective words/s
INFO - 2023-11-27 12:14:05,904: EPOCH 5: training on 155600 raw words (151931 effective words) took 0.5s, 286168 effective words/s
INFO - 2023-11-27 12:14:06,369: EPOCH 6: training on 155600 raw words (151858 effective words) took 0.5s, 332439 effective words/s
INFO - 2023-11-27 12:14:06,824: EPOCH 7: training on 155600 raw words (151968 effective words) took 0.5s, 336437 effective words/s
INFO - 2023-11-27 12:14:07,274: EPOCH 8: training on 155600 raw words (151959 effective words) took 0.4s, 339449 effective words/s
INFO - 2023-11-27 12:14:07,756: EPOCH 9: training on 155600 raw words (151945 effective words) took 0.5s, 317295 effective words/s
INFO - 2023-11-27 12:14:08,229: EPOCH 10: training on 155600 raw words (151873 effective words) took 0.5s, 323757 effective words/s
INFO - 2023-11-27 12:14:08,690: EPOCH 11: training on 155600 raw words (151910 effective words) took 0.5s, 331841 effective words/s
INFO - 2023-11-27 12:14:09,148: EPOCH 12: training on 155600 raw words (152007 effective words) took 0.5s, 334260 effective words/s
INFO - 2023-11-27 12:14:09,606: EPOCH 13: training on 155600 raw words (151912 effective words) took 0.5s, 333478 effective words/s
INFO - 2023-11-27 12:14:10,057: EPOCH 14: training on 155600 raw words (151933 effective words) took 0.4s, 339169 effective words/s
INFO - 2023-11-27 12:14:10,554: EPOCH 15: training on 155600 raw words (151981 effective words) took 0.5s, 307703 effective words/s
INFO - 2023-11-27 12:14:11,027: EPOCH 16: training on 155600 raw words (151865 effective words) took 0.5s, 323172 effective words/s
INFO - 2023-11-27 12:14:11,500: EPOCH 17: training on 155600 raw words (151977 effective words) took 0.5s, 323055 effective words/s
INFO - 2023-11-27 12:14:11,953: EPOCH 18: training on 155600 raw words (151948 effective words) took 0.4s, 338069 effective words/s
INFO - 2023-11-27 12:14:12,414: EPOCH 19: training on 155600 raw words (151937 effective words) took 0.5s, 331433 effective words/s
INFO - 2023-11-27 12:14:12,414: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038558 effective words) took 9.3s, 327177 effective words/s', 'datetime': '2023-11-27T12:14:12.414794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:12,415: collecting all words and their counts
INFO - 2023-11-27 12:14:12,415: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:12,450: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:12,450: Updating model with new vocabulary
INFO - 2023-11-27 12:14:12,467: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:12.467271', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:12,487: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:12,487: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:14:12,487: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151907.96481566853 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:14:12.487958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:12,518: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:12,518: updating layer weights
INFO - 2023-11-27 12:14:12,518: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:12.518547', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:12,518: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:12,518: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:12.518871', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:12,967: EPOCH 0: training on 155600 raw words (151831 effective words) took 0.4s, 341966 effective words/s
INFO - 2023-11-27 12:14:13,406: EPOCH 1: training on 155600 raw words (152030 effective words) took 0.4s, 348687 effective words/s
INFO - 2023-11-27 12:14:13,833: EPOCH 2: training on 155600 raw words (151891 effective words) took 0.4s, 358193 effective words/s
INFO - 2023-11-27 12:14:14,321: EPOCH 3: training on 155600 raw words (151896 effective words) took 0.5s, 313033 effective words/s
INFO - 2023-11-27 12:14:14,763: EPOCH 4: training on 155600 raw words (151961 effective words) took 0.4s, 345888 effective words/s
INFO - 2023-11-27 12:14:15,179: EPOCH 5: training on 155600 raw words (151929 effective words) took 0.4s, 367954 effective words/s
INFO - 2023-11-27 12:14:15,642: EPOCH 6: training on 155600 raw words (151968 effective words) took 0.5s, 330493 effective words/s
INFO - 2023-11-27 12:14:16,083: EPOCH 7: training on 155600 raw words (151885 effective words) took 0.4s, 346822 effective words/s
INFO - 2023-11-27 12:14:16,512: EPOCH 8: training on 155600 raw words (151928 effective words) took 0.4s, 356820 effective words/s
INFO - 2023-11-27 12:14:16,929: EPOCH 9: training on 155600 raw words (151870 effective words) took 0.4s, 366257 effective words/s
INFO - 2023-11-27 12:14:17,367: EPOCH 10: training on 155600 raw words (151888 effective words) took 0.4s, 354867 effective words/s
INFO - 2023-11-27 12:14:17,794: EPOCH 11: training on 155600 raw words (151922 effective words) took 0.4s, 358957 effective words/s
INFO - 2023-11-27 12:14:18,189: EPOCH 12: training on 155600 raw words (151886 effective words) took 0.4s, 387110 effective words/s
INFO - 2023-11-27 12:14:18,609: EPOCH 13: training on 155600 raw words (151926 effective words) took 0.4s, 364483 effective words/s
INFO - 2023-11-27 12:14:19,020: EPOCH 14: training on 155600 raw words (151892 effective words) took 0.4s, 372366 effective words/s
INFO - 2023-11-27 12:14:19,439: EPOCH 15: training on 155600 raw words (151867 effective words) took 0.4s, 365049 effective words/s
INFO - 2023-11-27 12:14:19,856: EPOCH 16: training on 155600 raw words (151922 effective words) took 0.4s, 367368 effective words/s
INFO - 2023-11-27 12:14:20,324: EPOCH 17: training on 155600 raw words (151882 effective words) took 0.5s, 326823 effective words/s
INFO - 2023-11-27 12:14:20,731: EPOCH 18: training on 155600 raw words (151858 effective words) took 0.4s, 375140 effective words/s
INFO - 2023-11-27 12:14:21,158: EPOCH 19: training on 155600 raw words (151855 effective words) took 0.4s, 359125 effective words/s
INFO - 2023-11-27 12:14:21,158: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038087 effective words) took 8.6s, 351659 effective words/s', 'datetime': '2023-11-27T12:14:21.158336', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:21,158: collecting all words and their counts
INFO - 2023-11-27 12:14:21,158: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:21,190: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:21,190: Updating model with new vocabulary
INFO - 2023-11-27 12:14:21,204: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:21.204829', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:21,221: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:21,222: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:14:21,222: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151935.53922793735 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:14:21.222193', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:21,249: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:21,249: updating layer weights
INFO - 2023-11-27 12:14:21,249: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:21.249777', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:21,249: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:21,250: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:21.250310', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:21,711: EPOCH 0: training on 155600 raw words (151841 effective words) took 0.5s, 332310 effective words/s
INFO - 2023-11-27 12:14:22,170: EPOCH 1: training on 155600 raw words (151965 effective words) took 0.5s, 333047 effective words/s
INFO - 2023-11-27 12:14:22,588: EPOCH 2: training on 155600 raw words (151985 effective words) took 0.4s, 366478 effective words/s
INFO - 2023-11-27 12:14:23,061: EPOCH 3: training on 155600 raw words (151918 effective words) took 0.5s, 322956 effective words/s
INFO - 2023-11-27 12:14:23,529: EPOCH 4: training on 155600 raw words (151879 effective words) took 0.5s, 327223 effective words/s
INFO - 2023-11-27 12:14:23,960: EPOCH 5: training on 155600 raw words (151989 effective words) took 0.4s, 355758 effective words/s
INFO - 2023-11-27 12:14:24,392: EPOCH 6: training on 155600 raw words (151923 effective words) took 0.4s, 353208 effective words/s
INFO - 2023-11-27 12:14:24,835: EPOCH 7: training on 155600 raw words (152005 effective words) took 0.4s, 346541 effective words/s
INFO - 2023-11-27 12:14:25,275: EPOCH 8: training on 155600 raw words (151969 effective words) took 0.4s, 347600 effective words/s
INFO - 2023-11-27 12:14:25,740: EPOCH 9: training on 155600 raw words (151922 effective words) took 0.5s, 328823 effective words/s
INFO - 2023-11-27 12:14:26,242: EPOCH 10: training on 155600 raw words (152017 effective words) took 0.5s, 304658 effective words/s
INFO - 2023-11-27 12:14:26,666: EPOCH 11: training on 155600 raw words (151927 effective words) took 0.4s, 360365 effective words/s
INFO - 2023-11-27 12:14:27,136: EPOCH 12: training on 155600 raw words (151916 effective words) took 0.5s, 326124 effective words/s
INFO - 2023-11-27 12:14:27,574: EPOCH 13: training on 155600 raw words (151939 effective words) took 0.4s, 349609 effective words/s
INFO - 2023-11-27 12:14:28,043: EPOCH 14: training on 155600 raw words (151855 effective words) took 0.5s, 325210 effective words/s
INFO - 2023-11-27 12:14:28,479: EPOCH 15: training on 155600 raw words (151965 effective words) took 0.4s, 351350 effective words/s
INFO - 2023-11-27 12:14:28,887: EPOCH 16: training on 155600 raw words (151900 effective words) took 0.4s, 374297 effective words/s
INFO - 2023-11-27 12:14:29,267: EPOCH 17: training on 155600 raw words (151986 effective words) took 0.4s, 403520 effective words/s
INFO - 2023-11-27 12:14:29,641: EPOCH 18: training on 155600 raw words (151931 effective words) took 0.4s, 409792 effective words/s
INFO - 2023-11-27 12:14:30,023: EPOCH 19: training on 155600 raw words (151943 effective words) took 0.4s, 400052 effective words/s
INFO - 2023-11-27 12:14:30,023: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038775 effective words) took 8.8s, 346389 effective words/s', 'datetime': '2023-11-27T12:14:30.023535', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:30,023: collecting all words and their counts
INFO - 2023-11-27 12:14:30,023: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:30,049: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:30,049: Updating model with new vocabulary
INFO - 2023-11-27 12:14:30,062: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:30.062905', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:30,082: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:30,082: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:14:30,082: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152041.5449736697 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:14:30.082598', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:30,105: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:30,105: updating layer weights
INFO - 2023-11-27 12:14:30,105: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:30.105533', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:30,105: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:30,105: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:30.105763', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:30,420: EPOCH 0: training on 155600 raw words (152095 effective words) took 0.3s, 486359 effective words/s
INFO - 2023-11-27 12:14:30,734: EPOCH 1: training on 155600 raw words (152092 effective words) took 0.3s, 488231 effective words/s
INFO - 2023-11-27 12:14:31,075: EPOCH 2: training on 155600 raw words (152077 effective words) took 0.3s, 449514 effective words/s
INFO - 2023-11-27 12:14:31,400: EPOCH 3: training on 155600 raw words (152141 effective words) took 0.3s, 471038 effective words/s
INFO - 2023-11-27 12:14:31,724: EPOCH 4: training on 155600 raw words (152065 effective words) took 0.3s, 473900 effective words/s
INFO - 2023-11-27 12:14:32,055: EPOCH 5: training on 155600 raw words (151981 effective words) took 0.3s, 462044 effective words/s
INFO - 2023-11-27 12:14:32,415: EPOCH 6: training on 155600 raw words (152044 effective words) took 0.4s, 425803 effective words/s
INFO - 2023-11-27 12:14:32,767: EPOCH 7: training on 155600 raw words (152069 effective words) took 0.3s, 434892 effective words/s
INFO - 2023-11-27 12:14:33,116: EPOCH 8: training on 155600 raw words (152037 effective words) took 0.3s, 439320 effective words/s
INFO - 2023-11-27 12:14:33,440: EPOCH 9: training on 155600 raw words (152067 effective words) took 0.3s, 472317 effective words/s
INFO - 2023-11-27 12:14:33,781: EPOCH 10: training on 155600 raw words (152026 effective words) took 0.3s, 447965 effective words/s
INFO - 2023-11-27 12:14:34,115: EPOCH 11: training on 155600 raw words (152001 effective words) took 0.3s, 458998 effective words/s
INFO - 2023-11-27 12:14:34,467: EPOCH 12: training on 155600 raw words (152025 effective words) took 0.3s, 435253 effective words/s
INFO - 2023-11-27 12:14:34,797: EPOCH 13: training on 155600 raw words (152044 effective words) took 0.3s, 463879 effective words/s
INFO - 2023-11-27 12:14:35,165: EPOCH 14: training on 155600 raw words (152017 effective words) took 0.4s, 415704 effective words/s
INFO - 2023-11-27 12:14:35,509: EPOCH 15: training on 155600 raw words (152075 effective words) took 0.3s, 445279 effective words/s
INFO - 2023-11-27 12:14:35,848: EPOCH 16: training on 155600 raw words (152039 effective words) took 0.3s, 451948 effective words/s
INFO - 2023-11-27 12:14:36,196: EPOCH 17: training on 155600 raw words (151995 effective words) took 0.3s, 439309 effective words/s
INFO - 2023-11-27 12:14:36,549: EPOCH 18: training on 155600 raw words (152108 effective words) took 0.4s, 434532 effective words/s
INFO - 2023-11-27 12:14:36,889: EPOCH 19: training on 155600 raw words (151996 effective words) took 0.3s, 449993 effective words/s
INFO - 2023-11-27 12:14:36,889: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3040994 effective words) took 6.8s, 448265 effective words/s', 'datetime': '2023-11-27T12:14:36.889789', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:36,889: collecting all words and their counts
INFO - 2023-11-27 12:14:36,890: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:36,911: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:36,912: Updating model with new vocabulary
INFO - 2023-11-27 12:14:36,922: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:36.922088', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:36,934: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:36,934: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:14:36,934: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151938.04908942123 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:14:36.934711', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:36,955: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:36,955: updating layer weights
INFO - 2023-11-27 12:14:36,955: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:36.955612', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:36,955: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:36,955: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:36.955928', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:37,321: EPOCH 0: training on 155600 raw words (151913 effective words) took 0.4s, 418243 effective words/s
INFO - 2023-11-27 12:14:37,726: EPOCH 1: training on 155600 raw words (151989 effective words) took 0.4s, 377494 effective words/s
INFO - 2023-11-27 12:14:38,079: EPOCH 2: training on 155600 raw words (152018 effective words) took 0.4s, 433700 effective words/s
INFO - 2023-11-27 12:14:38,453: EPOCH 3: training on 155600 raw words (151902 effective words) took 0.4s, 408773 effective words/s
INFO - 2023-11-27 12:14:38,813: EPOCH 4: training on 155600 raw words (151982 effective words) took 0.4s, 425315 effective words/s
INFO - 2023-11-27 12:14:39,167: EPOCH 5: training on 155600 raw words (151825 effective words) took 0.4s, 432891 effective words/s
INFO - 2023-11-27 12:14:39,572: EPOCH 6: training on 155600 raw words (151941 effective words) took 0.4s, 377307 effective words/s
INFO - 2023-11-27 12:14:39,916: EPOCH 7: training on 155600 raw words (151934 effective words) took 0.3s, 444303 effective words/s
INFO - 2023-11-27 12:14:40,366: EPOCH 8: training on 155600 raw words (151809 effective words) took 0.4s, 339485 effective words/s
INFO - 2023-11-27 12:14:40,769: EPOCH 9: training on 155600 raw words (151994 effective words) took 0.4s, 379560 effective words/s
INFO - 2023-11-27 12:14:41,130: EPOCH 10: training on 155600 raw words (151932 effective words) took 0.4s, 424185 effective words/s
INFO - 2023-11-27 12:14:41,474: EPOCH 11: training on 155600 raw words (151951 effective words) took 0.3s, 444943 effective words/s
INFO - 2023-11-27 12:14:41,841: EPOCH 12: training on 155600 raw words (151938 effective words) took 0.4s, 417145 effective words/s
INFO - 2023-11-27 12:14:42,225: EPOCH 13: training on 155600 raw words (151984 effective words) took 0.4s, 398538 effective words/s
INFO - 2023-11-27 12:14:42,596: EPOCH 14: training on 155600 raw words (151931 effective words) took 0.4s, 411671 effective words/s
INFO - 2023-11-27 12:14:42,965: EPOCH 15: training on 155600 raw words (151994 effective words) took 0.4s, 415054 effective words/s
INFO - 2023-11-27 12:14:43,325: EPOCH 16: training on 155600 raw words (151947 effective words) took 0.4s, 424394 effective words/s
INFO - 2023-11-27 12:14:43,697: EPOCH 17: training on 155600 raw words (152020 effective words) took 0.4s, 411183 effective words/s
INFO - 2023-11-27 12:14:44,068: EPOCH 18: training on 155600 raw words (151920 effective words) took 0.4s, 412486 effective words/s
INFO - 2023-11-27 12:14:44,558: EPOCH 19: training on 155600 raw words (151903 effective words) took 0.5s, 311113 effective words/s
INFO - 2023-11-27 12:14:44,558: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038827 effective words) took 7.6s, 399701 effective words/s', 'datetime': '2023-11-27T12:14:44.558799', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:44,559: collecting all words and their counts
INFO - 2023-11-27 12:14:44,559: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:44,599: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:44,599: Updating model with new vocabulary
INFO - 2023-11-27 12:14:44,617: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:44.617637', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:44,644: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:44,645: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:14:44,645: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 152009.8982176069 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:14:44.645269', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:44,675: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:44,676: updating layer weights
INFO - 2023-11-27 12:14:44,676: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:44.676645', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:44,676: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:44,677: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:44.677026', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:45,166: EPOCH 0: training on 155600 raw words (152011 effective words) took 0.5s, 313063 effective words/s
INFO - 2023-11-27 12:14:45,609: EPOCH 1: training on 155600 raw words (152077 effective words) took 0.4s, 346053 effective words/s
INFO - 2023-11-27 12:14:46,061: EPOCH 2: training on 155600 raw words (152015 effective words) took 0.4s, 339211 effective words/s
INFO - 2023-11-27 12:14:46,525: EPOCH 3: training on 155600 raw words (151950 effective words) took 0.5s, 329692 effective words/s
INFO - 2023-11-27 12:14:47,016: EPOCH 4: training on 155600 raw words (152050 effective words) took 0.5s, 312140 effective words/s
INFO - 2023-11-27 12:14:47,479: EPOCH 5: training on 155600 raw words (151954 effective words) took 0.5s, 330599 effective words/s
INFO - 2023-11-27 12:14:47,944: EPOCH 6: training on 155600 raw words (151923 effective words) took 0.5s, 329307 effective words/s
INFO - 2023-11-27 12:14:48,422: EPOCH 7: training on 155600 raw words (152015 effective words) took 0.5s, 319836 effective words/s
INFO - 2023-11-27 12:14:48,909: EPOCH 8: training on 155600 raw words (151999 effective words) took 0.5s, 314401 effective words/s
INFO - 2023-11-27 12:14:49,374: EPOCH 9: training on 155600 raw words (151955 effective words) took 0.5s, 335696 effective words/s
INFO - 2023-11-27 12:14:49,833: EPOCH 10: training on 155600 raw words (152021 effective words) took 0.5s, 333575 effective words/s
INFO - 2023-11-27 12:14:50,289: EPOCH 11: training on 155600 raw words (152039 effective words) took 0.5s, 336766 effective words/s
INFO - 2023-11-27 12:14:50,749: EPOCH 12: training on 155600 raw words (151996 effective words) took 0.5s, 332739 effective words/s
INFO - 2023-11-27 12:14:51,231: EPOCH 13: training on 155600 raw words (151992 effective words) took 0.5s, 317908 effective words/s
INFO - 2023-11-27 12:14:51,683: EPOCH 14: training on 155600 raw words (152002 effective words) took 0.4s, 338135 effective words/s
INFO - 2023-11-27 12:14:52,144: EPOCH 15: training on 155600 raw words (152060 effective words) took 0.5s, 332530 effective words/s
INFO - 2023-11-27 12:14:52,615: EPOCH 16: training on 155600 raw words (151935 effective words) took 0.5s, 324898 effective words/s
INFO - 2023-11-27 12:14:53,088: EPOCH 17: training on 155600 raw words (151971 effective words) took 0.5s, 323327 effective words/s
INFO - 2023-11-27 12:14:53,534: EPOCH 18: training on 155600 raw words (152031 effective words) took 0.4s, 343235 effective words/s
INFO - 2023-11-27 12:14:54,000: EPOCH 19: training on 155600 raw words (151961 effective words) took 0.5s, 328706 effective words/s
INFO - 2023-11-27 12:14:54,001: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039957 effective words) took 9.3s, 326039 effective words/s', 'datetime': '2023-11-27T12:14:54.001124', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:54,001: collecting all words and their counts
INFO - 2023-11-27 12:14:54,001: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:14:54,037: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:14:54,037: Updating model with new vocabulary
INFO - 2023-11-27 12:14:54,052: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:14:54.052489', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:54,071: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:14:54,071: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:14:54,071: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151926.10354766576 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:14:54.071422', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:14:54,100: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:14:54,100: updating layer weights
INFO - 2023-11-27 12:14:54,100: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:14:54.100545', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:14:54,100: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:14:54,100: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:14:54.100931', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:14:54,586: EPOCH 0: training on 155600 raw words (152010 effective words) took 0.5s, 318959 effective words/s
INFO - 2023-11-27 12:14:55,030: EPOCH 1: training on 155600 raw words (151950 effective words) took 0.4s, 348935 effective words/s
INFO - 2023-11-27 12:14:55,471: EPOCH 2: training on 155600 raw words (151962 effective words) took 0.4s, 346717 effective words/s
INFO - 2023-11-27 12:14:55,929: EPOCH 3: training on 155600 raw words (151882 effective words) took 0.5s, 334265 effective words/s
INFO - 2023-11-27 12:14:56,392: EPOCH 4: training on 155600 raw words (151951 effective words) took 0.5s, 330292 effective words/s
INFO - 2023-11-27 12:14:56,851: EPOCH 5: training on 155600 raw words (151899 effective words) took 0.5s, 333703 effective words/s
INFO - 2023-11-27 12:14:57,328: EPOCH 6: training on 155600 raw words (151997 effective words) took 0.5s, 320720 effective words/s
INFO - 2023-11-27 12:14:57,813: EPOCH 7: training on 155600 raw words (151935 effective words) took 0.5s, 315530 effective words/s
INFO - 2023-11-27 12:14:58,285: EPOCH 8: training on 155600 raw words (151858 effective words) took 0.5s, 324188 effective words/s
INFO - 2023-11-27 12:14:58,752: EPOCH 9: training on 155600 raw words (152005 effective words) took 0.5s, 327979 effective words/s
INFO - 2023-11-27 12:14:59,210: EPOCH 10: training on 155600 raw words (151792 effective words) took 0.5s, 333435 effective words/s
INFO - 2023-11-27 12:14:59,673: EPOCH 11: training on 155600 raw words (152061 effective words) took 0.5s, 330477 effective words/s
INFO - 2023-11-27 12:15:00,148: EPOCH 12: training on 155600 raw words (151857 effective words) took 0.5s, 322413 effective words/s
INFO - 2023-11-27 12:15:00,623: EPOCH 13: training on 155600 raw words (151937 effective words) took 0.5s, 322353 effective words/s
INFO - 2023-11-27 12:15:01,092: EPOCH 14: training on 155600 raw words (151980 effective words) took 0.5s, 325802 effective words/s
INFO - 2023-11-27 12:15:01,526: EPOCH 15: training on 155600 raw words (151840 effective words) took 0.4s, 354212 effective words/s
INFO - 2023-11-27 12:15:01,988: EPOCH 16: training on 155600 raw words (151975 effective words) took 0.5s, 331265 effective words/s
INFO - 2023-11-27 12:15:02,456: EPOCH 17: training on 155600 raw words (151866 effective words) took 0.5s, 326757 effective words/s
INFO - 2023-11-27 12:15:02,931: EPOCH 18: training on 155600 raw words (151894 effective words) took 0.5s, 321448 effective words/s
INFO - 2023-11-27 12:15:03,405: EPOCH 19: training on 155600 raw words (152035 effective words) took 0.5s, 323980 effective words/s
INFO - 2023-11-27 12:15:03,405: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3038686 effective words) took 9.3s, 326574 effective words/s', 'datetime': '2023-11-27T12:15:03.405811', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:03,406: collecting all words and their counts
INFO - 2023-11-27 12:15:03,406: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:15:03,440: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:15:03,440: Updating model with new vocabulary
INFO - 2023-11-27 12:15:03,456: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:15:03.456248', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:03,475: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:15:03,475: sample=0.001 downsamples 23 most-common words
INFO - 2023-11-27 12:15:03,475: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151885.14040850315 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:15:03.475629', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:03,506: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:15:03,506: updating layer weights
INFO - 2023-11-27 12:15:03,507: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:15:03.507265', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:15:03,507: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:15:03,507: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:15:03.507659', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:03,950: EPOCH 0: training on 155600 raw words (151854 effective words) took 0.4s, 345999 effective words/s
INFO - 2023-11-27 12:15:04,411: EPOCH 1: training on 155600 raw words (151845 effective words) took 0.5s, 331606 effective words/s
INFO - 2023-11-27 12:15:04,893: EPOCH 2: training on 155600 raw words (151839 effective words) took 0.5s, 317533 effective words/s
INFO - 2023-11-27 12:15:05,362: EPOCH 3: training on 155600 raw words (151876 effective words) took 0.5s, 326228 effective words/s
INFO - 2023-11-27 12:15:05,889: EPOCH 4: training on 155600 raw words (151936 effective words) took 0.5s, 290257 effective words/s
INFO - 2023-11-27 12:15:06,328: EPOCH 5: training on 155600 raw words (151904 effective words) took 0.4s, 348549 effective words/s
INFO - 2023-11-27 12:15:06,735: EPOCH 6: training on 155600 raw words (151793 effective words) took 0.4s, 376167 effective words/s
INFO - 2023-11-27 12:15:07,203: EPOCH 7: training on 155600 raw words (151932 effective words) took 0.5s, 326391 effective words/s
INFO - 2023-11-27 12:15:07,674: EPOCH 8: training on 155600 raw words (151922 effective words) took 0.5s, 325047 effective words/s
INFO - 2023-11-27 12:15:08,136: EPOCH 9: training on 155600 raw words (151854 effective words) took 0.5s, 331263 effective words/s
INFO - 2023-11-27 12:15:08,541: EPOCH 10: training on 155600 raw words (151900 effective words) took 0.4s, 377872 effective words/s
INFO - 2023-11-27 12:15:08,959: EPOCH 11: training on 155600 raw words (151855 effective words) took 0.4s, 365038 effective words/s
INFO - 2023-11-27 12:15:09,320: EPOCH 12: training on 155600 raw words (151972 effective words) took 0.4s, 424295 effective words/s
INFO - 2023-11-27 12:15:09,669: EPOCH 13: training on 155600 raw words (151883 effective words) took 0.3s, 439208 effective words/s
INFO - 2023-11-27 12:15:10,031: EPOCH 14: training on 155600 raw words (151910 effective words) took 0.4s, 422009 effective words/s
INFO - 2023-11-27 12:15:10,378: EPOCH 15: training on 155600 raw words (151874 effective words) took 0.3s, 440934 effective words/s
INFO - 2023-11-27 12:15:10,710: EPOCH 16: training on 155600 raw words (151898 effective words) took 0.3s, 461685 effective words/s
INFO - 2023-11-27 12:15:11,050: EPOCH 17: training on 155600 raw words (151940 effective words) took 0.3s, 449884 effective words/s
INFO - 2023-11-27 12:15:11,366: EPOCH 18: training on 155600 raw words (151886 effective words) took 0.3s, 484186 effective words/s
INFO - 2023-11-27 12:15:11,720: EPOCH 19: training on 155600 raw words (151860 effective words) took 0.4s, 431430 effective words/s
INFO - 2023-11-27 12:15:11,720: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037733 effective words) took 8.2s, 369900 effective words/s', 'datetime': '2023-11-27T12:15:11.720286', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:11,720: collecting all words and their counts
INFO - 2023-11-27 12:15:11,720: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:15:11,743: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:15:11,743: Updating model with new vocabulary
INFO - 2023-11-27 12:15:11,753: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:15:11.753352', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:11,765: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:15:11,765: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:15:11,765: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151892.89757198188 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:15:11.765976', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:11,785: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:15:11,786: updating layer weights
INFO - 2023-11-27 12:15:11,786: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:15:11.786286', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:15:11,786: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:15:11,786: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:15:11.786500', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:12,132: EPOCH 0: training on 155600 raw words (151936 effective words) took 0.3s, 447299 effective words/s
INFO - 2023-11-27 12:15:12,483: EPOCH 1: training on 155600 raw words (151820 effective words) took 0.3s, 435556 effective words/s
INFO - 2023-11-27 12:15:12,830: EPOCH 2: training on 155600 raw words (151958 effective words) took 0.3s, 441325 effective words/s
INFO - 2023-11-27 12:15:13,179: EPOCH 3: training on 155600 raw words (151933 effective words) took 0.3s, 438555 effective words/s
INFO - 2023-11-27 12:15:13,559: EPOCH 4: training on 155600 raw words (151869 effective words) took 0.4s, 401856 effective words/s
INFO - 2023-11-27 12:15:13,916: EPOCH 5: training on 155600 raw words (151845 effective words) took 0.4s, 429694 effective words/s
INFO - 2023-11-27 12:15:14,296: EPOCH 6: training on 155600 raw words (151907 effective words) took 0.4s, 403041 effective words/s
INFO - 2023-11-27 12:15:14,659: EPOCH 7: training on 155600 raw words (151918 effective words) took 0.4s, 421415 effective words/s
INFO - 2023-11-27 12:15:15,002: EPOCH 8: training on 155600 raw words (151826 effective words) took 0.3s, 444435 effective words/s
INFO - 2023-11-27 12:15:15,344: EPOCH 9: training on 155600 raw words (151917 effective words) took 0.3s, 447566 effective words/s
INFO - 2023-11-27 12:15:15,691: EPOCH 10: training on 155600 raw words (151918 effective words) took 0.3s, 441134 effective words/s
INFO - 2023-11-27 12:15:16,023: EPOCH 11: training on 155600 raw words (151842 effective words) took 0.3s, 460523 effective words/s
INFO - 2023-11-27 12:15:16,370: EPOCH 12: training on 155600 raw words (151919 effective words) took 0.3s, 440153 effective words/s
INFO - 2023-11-27 12:15:16,708: EPOCH 13: training on 155600 raw words (151918 effective words) took 0.3s, 452327 effective words/s
INFO - 2023-11-27 12:15:17,051: EPOCH 14: training on 155600 raw words (151856 effective words) took 0.3s, 446791 effective words/s
INFO - 2023-11-27 12:15:17,396: EPOCH 15: training on 155600 raw words (151855 effective words) took 0.3s, 443297 effective words/s
INFO - 2023-11-27 12:15:17,737: EPOCH 16: training on 155600 raw words (151844 effective words) took 0.3s, 447654 effective words/s
INFO - 2023-11-27 12:15:18,079: EPOCH 17: training on 155600 raw words (151906 effective words) took 0.3s, 447447 effective words/s
INFO - 2023-11-27 12:15:18,412: EPOCH 18: training on 155600 raw words (151899 effective words) took 0.3s, 458978 effective words/s
INFO - 2023-11-27 12:15:18,770: EPOCH 19: training on 155600 raw words (151981 effective words) took 0.4s, 426850 effective words/s
INFO - 2023-11-27 12:15:18,770: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037867 effective words) took 7.0s, 434958 effective words/s', 'datetime': '2023-11-27T12:15:18.770927', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:18,771: collecting all words and their counts
INFO - 2023-11-27 12:15:18,771: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:15:18,794: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:15:18,794: Updating model with new vocabulary
INFO - 2023-11-27 12:15:18,804: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:15:18.804576', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:18,816: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:15:18,816: sample=0.001 downsamples 21 most-common words
INFO - 2023-11-27 12:15:18,817: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151859.43005885993 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:15:18.817070', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:18,836: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:15:18,836: updating layer weights
INFO - 2023-11-27 12:15:18,836: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:15:18.836780', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:15:18,836: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:15:18,837: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:15:18.836996', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:19,178: EPOCH 0: training on 155600 raw words (151888 effective words) took 0.3s, 449744 effective words/s
INFO - 2023-11-27 12:15:19,523: EPOCH 1: training on 155600 raw words (151804 effective words) took 0.3s, 442423 effective words/s
INFO - 2023-11-27 12:15:19,879: EPOCH 2: training on 155600 raw words (151812 effective words) took 0.4s, 429534 effective words/s
INFO - 2023-11-27 12:15:20,217: EPOCH 3: training on 155600 raw words (151895 effective words) took 0.3s, 452752 effective words/s
INFO - 2023-11-27 12:15:20,534: EPOCH 4: training on 155600 raw words (151849 effective words) took 0.3s, 482602 effective words/s
INFO - 2023-11-27 12:15:20,843: EPOCH 5: training on 155600 raw words (151832 effective words) took 0.3s, 495307 effective words/s
INFO - 2023-11-27 12:15:21,188: EPOCH 6: training on 155600 raw words (151880 effective words) took 0.3s, 443431 effective words/s
INFO - 2023-11-27 12:15:21,503: EPOCH 7: training on 155600 raw words (151810 effective words) took 0.3s, 486444 effective words/s
INFO - 2023-11-27 12:15:21,823: EPOCH 8: training on 155600 raw words (151798 effective words) took 0.3s, 478200 effective words/s
INFO - 2023-11-27 12:15:22,205: EPOCH 9: training on 155600 raw words (151814 effective words) took 0.4s, 399532 effective words/s
INFO - 2023-11-27 12:15:22,545: EPOCH 10: training on 155600 raw words (151884 effective words) took 0.3s, 450163 effective words/s
INFO - 2023-11-27 12:15:22,891: EPOCH 11: training on 155600 raw words (151902 effective words) took 0.3s, 441009 effective words/s
INFO - 2023-11-27 12:15:23,260: EPOCH 12: training on 155600 raw words (151819 effective words) took 0.4s, 415076 effective words/s
INFO - 2023-11-27 12:15:23,678: EPOCH 13: training on 155600 raw words (151838 effective words) took 0.4s, 365088 effective words/s
INFO - 2023-11-27 12:15:24,032: EPOCH 14: training on 155600 raw words (151870 effective words) took 0.4s, 432872 effective words/s
INFO - 2023-11-27 12:15:24,361: EPOCH 15: training on 155600 raw words (151829 effective words) took 0.3s, 464150 effective words/s
INFO - 2023-11-27 12:15:24,727: EPOCH 16: training on 155600 raw words (151824 effective words) took 0.4s, 417841 effective words/s
INFO - 2023-11-27 12:15:25,134: EPOCH 17: training on 155600 raw words (151819 effective words) took 0.4s, 375467 effective words/s
INFO - 2023-11-27 12:15:25,575: EPOCH 18: training on 155600 raw words (151853 effective words) took 0.4s, 347008 effective words/s
INFO - 2023-11-27 12:15:26,010: EPOCH 19: training on 155600 raw words (151856 effective words) took 0.4s, 352225 effective words/s
INFO - 2023-11-27 12:15:26,010: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3036876 effective words) took 7.2s, 423352 effective words/s', 'datetime': '2023-11-27T12:15:26.010529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:26,010: collecting all words and their counts
INFO - 2023-11-27 12:15:26,011: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:15:26,045: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:15:26,045: Updating model with new vocabulary
INFO - 2023-11-27 12:15:26,062: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:15:26.062371', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:26,080: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:15:26,080: sample=0.001 downsamples 22 most-common words
INFO - 2023-11-27 12:15:26,081: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151956.60205903533 word corpus (97.7%% of prior 155600)', 'datetime': '2023-11-27T12:15:26.081100', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:26,106: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:15:26,106: updating layer weights
INFO - 2023-11-27 12:15:26,107: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:15:26.106990', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:15:26,107: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:15:26,107: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:15:26.107263', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:26,579: EPOCH 0: training on 155600 raw words (151949 effective words) took 0.5s, 323891 effective words/s
INFO - 2023-11-27 12:15:26,974: EPOCH 1: training on 155600 raw words (151906 effective words) took 0.4s, 387025 effective words/s
INFO - 2023-11-27 12:15:27,337: EPOCH 2: training on 155600 raw words (151902 effective words) took 0.4s, 422311 effective words/s
INFO - 2023-11-27 12:15:27,810: EPOCH 3: training on 155600 raw words (151965 effective words) took 0.5s, 322874 effective words/s
INFO - 2023-11-27 12:15:28,306: EPOCH 4: training on 155600 raw words (151971 effective words) took 0.5s, 308693 effective words/s
INFO - 2023-11-27 12:15:28,799: EPOCH 5: training on 155600 raw words (152038 effective words) took 0.5s, 310365 effective words/s
INFO - 2023-11-27 12:15:29,324: EPOCH 6: training on 155600 raw words (151918 effective words) took 0.5s, 291016 effective words/s
INFO - 2023-11-27 12:15:29,829: EPOCH 7: training on 155600 raw words (151965 effective words) took 0.5s, 302555 effective words/s
INFO - 2023-11-27 12:15:30,285: EPOCH 8: training on 155600 raw words (151979 effective words) took 0.5s, 335793 effective words/s
INFO - 2023-11-27 12:15:30,753: EPOCH 9: training on 155600 raw words (151919 effective words) took 0.5s, 326032 effective words/s
INFO - 2023-11-27 12:15:31,227: EPOCH 10: training on 155600 raw words (152028 effective words) took 0.5s, 323688 effective words/s
INFO - 2023-11-27 12:15:31,699: EPOCH 11: training on 155600 raw words (151955 effective words) took 0.5s, 323948 effective words/s
INFO - 2023-11-27 12:15:32,185: EPOCH 12: training on 155600 raw words (151899 effective words) took 0.5s, 314057 effective words/s
INFO - 2023-11-27 12:15:32,701: EPOCH 13: training on 155600 raw words (151964 effective words) took 0.5s, 296243 effective words/s
INFO - 2023-11-27 12:15:33,210: EPOCH 14: training on 155600 raw words (151952 effective words) took 0.5s, 300479 effective words/s
INFO - 2023-11-27 12:15:33,655: EPOCH 15: training on 155600 raw words (152001 effective words) took 0.4s, 344237 effective words/s
INFO - 2023-11-27 12:15:34,026: EPOCH 16: training on 155600 raw words (152086 effective words) took 0.4s, 413186 effective words/s
INFO - 2023-11-27 12:15:34,399: EPOCH 17: training on 155600 raw words (152025 effective words) took 0.4s, 409098 effective words/s
INFO - 2023-11-27 12:15:34,740: EPOCH 18: training on 155600 raw words (152026 effective words) took 0.3s, 449404 effective words/s
INFO - 2023-11-27 12:15:35,118: EPOCH 19: training on 155600 raw words (151885 effective words) took 0.4s, 403527 effective words/s
INFO - 2023-11-27 12:15:35,119: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3039333 effective words) took 9.0s, 337262 effective words/s', 'datetime': '2023-11-27T12:15:35.119185', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:35,119: collecting all words and their counts
INFO - 2023-11-27 12:15:35,119: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-27 12:15:35,144: collected 3890 word types from a corpus of 155600 raw words and 3890 sentences
INFO - 2023-11-27 12:15:35,144: Updating model with new vocabulary
INFO - 2023-11-27 12:15:35,156: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 3890) and increased the count of 3890 pre-existing words (100.00% of original 3890)', 'datetime': '2023-11-27T12:15:35.156813', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:35,170: deleting the raw counts dictionary of 3890 items
INFO - 2023-11-27 12:15:35,170: sample=0.001 downsamples 24 most-common words
INFO - 2023-11-27 12:15:35,170: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 151886.08706760814 word corpus (97.6%% of prior 155600)', 'datetime': '2023-11-27T12:15:35.170561', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-27 12:15:35,192: estimated required memory for 3890 words and 128 dimensions: 5928360 bytes
INFO - 2023-11-27 12:15:35,193: updating layer weights
INFO - 2023-11-27 12:15:35,193: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-27T12:15:35.193439', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-27 12:15:35,193: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-27 12:15:35,193: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 3890 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-27T12:15:35.193719', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:35,539: EPOCH 0: training on 155600 raw words (151796 effective words) took 0.3s, 443015 effective words/s
INFO - 2023-11-27 12:15:35,887: EPOCH 1: training on 155600 raw words (151915 effective words) took 0.3s, 439595 effective words/s
INFO - 2023-11-27 12:15:36,233: EPOCH 2: training on 155600 raw words (151942 effective words) took 0.3s, 443247 effective words/s
INFO - 2023-11-27 12:15:36,556: EPOCH 3: training on 155600 raw words (151901 effective words) took 0.3s, 473603 effective words/s
INFO - 2023-11-27 12:15:36,892: EPOCH 4: training on 155600 raw words (151897 effective words) took 0.3s, 456009 effective words/s
INFO - 2023-11-27 12:15:37,243: EPOCH 5: training on 155600 raw words (151830 effective words) took 0.3s, 443727 effective words/s
INFO - 2023-11-27 12:15:37,572: EPOCH 6: training on 155600 raw words (151874 effective words) took 0.3s, 465700 effective words/s
INFO - 2023-11-27 12:15:37,921: EPOCH 7: training on 155600 raw words (151849 effective words) took 0.3s, 437684 effective words/s
INFO - 2023-11-27 12:15:38,252: EPOCH 8: training on 155600 raw words (151882 effective words) took 0.3s, 463630 effective words/s
INFO - 2023-11-27 12:15:38,610: EPOCH 9: training on 155600 raw words (151899 effective words) took 0.4s, 427252 effective words/s
INFO - 2023-11-27 12:15:38,958: EPOCH 10: training on 155600 raw words (151930 effective words) took 0.3s, 441425 effective words/s
INFO - 2023-11-27 12:15:39,309: EPOCH 11: training on 155600 raw words (151887 effective words) took 0.3s, 435038 effective words/s
INFO - 2023-11-27 12:15:39,634: EPOCH 12: training on 155600 raw words (151932 effective words) took 0.3s, 470641 effective words/s
INFO - 2023-11-27 12:15:40,005: EPOCH 13: training on 155600 raw words (151907 effective words) took 0.4s, 412379 effective words/s
INFO - 2023-11-27 12:15:40,363: EPOCH 14: training on 155600 raw words (151895 effective words) took 0.4s, 427071 effective words/s
INFO - 2023-11-27 12:15:40,722: EPOCH 15: training on 155600 raw words (151862 effective words) took 0.4s, 426292 effective words/s
INFO - 2023-11-27 12:15:41,093: EPOCH 16: training on 155600 raw words (151867 effective words) took 0.4s, 412768 effective words/s
INFO - 2023-11-27 12:15:41,470: EPOCH 17: training on 155600 raw words (151869 effective words) took 0.4s, 406760 effective words/s
INFO - 2023-11-27 12:15:41,874: EPOCH 18: training on 155600 raw words (151942 effective words) took 0.4s, 379006 effective words/s
INFO - 2023-11-27 12:15:42,238: EPOCH 19: training on 155600 raw words (151885 effective words) took 0.4s, 419852 effective words/s
INFO - 2023-11-27 12:15:42,238: Word2Vec lifecycle event {'msg': 'training on 3112000 raw words (3037761 effective words) took 7.0s, 431191 effective words/s', 'datetime': '2023-11-27T12:15:42.238882', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-27 12:15:42,242: storing 3890x128 projection weights into ppi.txt
