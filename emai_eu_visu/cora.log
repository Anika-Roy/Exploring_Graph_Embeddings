INFO - 2023-11-28 03:30:53,194: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.05>', 'datetime': '2023-11-28T03:30:53.181200', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'created'}
INFO - 2023-11-28 03:30:53,195: collecting all words and their counts
INFO - 2023-11-28 03:30:53,195: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:30:53,203: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:30:53,203: Creating a fresh vocabulary
INFO - 2023-11-28 03:30:53,207: Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1005 unique words (100.00% of original 1005, drops 0)', 'datetime': '2023-11-28T03:30:53.207786', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:53,207: Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 40200 word corpus (100.00% of original 40200, drops 0)', 'datetime': '2023-11-28T03:30:53.207957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:53,212: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:30:53,213: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:30:53,213: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37315.64774596598 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:30:53.213321', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:53,221: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:30:53,221: resetting layer weights
INFO - 2023-11-28 03:30:53,222: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-28T03:30:53.222117', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
INFO - 2023-11-28 03:30:53,222: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:30:53.222253', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:30:53,354: EPOCH 0: training on 40200 raw words (37281 effective words) took 0.1s, 292845 effective words/s
INFO - 2023-11-28 03:30:53,483: EPOCH 1: training on 40200 raw words (37350 effective words) took 0.1s, 292846 effective words/s
INFO - 2023-11-28 03:30:53,615: EPOCH 2: training on 40200 raw words (37258 effective words) took 0.1s, 289074 effective words/s
INFO - 2023-11-28 03:30:53,748: EPOCH 3: training on 40200 raw words (37264 effective words) took 0.1s, 284197 effective words/s
INFO - 2023-11-28 03:30:53,876: EPOCH 4: training on 40200 raw words (37302 effective words) took 0.1s, 298418 effective words/s
INFO - 2023-11-28 03:30:54,011: EPOCH 5: training on 40200 raw words (37195 effective words) took 0.1s, 280135 effective words/s
INFO - 2023-11-28 03:30:54,138: EPOCH 6: training on 40200 raw words (37365 effective words) took 0.1s, 299807 effective words/s
INFO - 2023-11-28 03:30:54,270: EPOCH 7: training on 40200 raw words (37345 effective words) took 0.1s, 288905 effective words/s
INFO - 2023-11-28 03:30:54,400: EPOCH 8: training on 40200 raw words (37356 effective words) took 0.1s, 291448 effective words/s
INFO - 2023-11-28 03:30:54,535: EPOCH 9: training on 40200 raw words (37276 effective words) took 0.1s, 282403 effective words/s
INFO - 2023-11-28 03:30:54,670: EPOCH 10: training on 40200 raw words (37311 effective words) took 0.1s, 280664 effective words/s
INFO - 2023-11-28 03:30:54,804: EPOCH 11: training on 40200 raw words (37339 effective words) took 0.1s, 295344 effective words/s
INFO - 2023-11-28 03:30:54,938: EPOCH 12: training on 40200 raw words (37364 effective words) took 0.1s, 283700 effective words/s
INFO - 2023-11-28 03:30:55,073: EPOCH 13: training on 40200 raw words (37252 effective words) took 0.1s, 280341 effective words/s
INFO - 2023-11-28 03:30:55,208: EPOCH 14: training on 40200 raw words (37350 effective words) took 0.1s, 281406 effective words/s
INFO - 2023-11-28 03:30:55,339: EPOCH 15: training on 40200 raw words (37341 effective words) took 0.1s, 291356 effective words/s
INFO - 2023-11-28 03:30:55,468: EPOCH 16: training on 40200 raw words (37260 effective words) took 0.1s, 294939 effective words/s
INFO - 2023-11-28 03:30:55,600: EPOCH 17: training on 40200 raw words (37324 effective words) took 0.1s, 287572 effective words/s
INFO - 2023-11-28 03:30:55,726: EPOCH 18: training on 40200 raw words (37310 effective words) took 0.1s, 301116 effective words/s
INFO - 2023-11-28 03:30:55,863: EPOCH 19: training on 40200 raw words (37315 effective words) took 0.1s, 278812 effective words/s
INFO - 2023-11-28 03:30:55,863: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746158 effective words) took 2.6s, 282523 effective words/s', 'datetime': '2023-11-28T03:30:55.863590', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:30:55,863: collecting all words and their counts
INFO - 2023-11-28 03:30:55,863: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:30:55,869: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:30:55,869: Updating model with new vocabulary
INFO - 2023-11-28 03:30:55,873: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:30:55.873010', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:55,876: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:30:55,877: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:30:55,877: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37409.02408347557 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:30:55.877214', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:55,883: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:30:55,883: updating layer weights
INFO - 2023-11-28 03:30:55,884: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:30:55.883978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:30:55,884: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:30:55,884: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:30:55.884213', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:30:56,021: EPOCH 0: training on 40200 raw words (37458 effective words) took 0.1s, 277449 effective words/s
INFO - 2023-11-28 03:30:56,154: EPOCH 1: training on 40200 raw words (37380 effective words) took 0.1s, 285736 effective words/s
INFO - 2023-11-28 03:30:56,295: EPOCH 2: training on 40200 raw words (37371 effective words) took 0.1s, 270168 effective words/s
INFO - 2023-11-28 03:30:56,432: EPOCH 3: training on 40200 raw words (37421 effective words) took 0.1s, 277756 effective words/s
INFO - 2023-11-28 03:30:56,574: EPOCH 4: training on 40200 raw words (37402 effective words) took 0.1s, 266622 effective words/s
INFO - 2023-11-28 03:30:56,715: EPOCH 5: training on 40200 raw words (37388 effective words) took 0.1s, 269403 effective words/s
INFO - 2023-11-28 03:30:56,855: EPOCH 6: training on 40200 raw words (37368 effective words) took 0.1s, 272204 effective words/s
INFO - 2023-11-28 03:30:57,022: EPOCH 7: training on 40200 raw words (37315 effective words) took 0.2s, 227144 effective words/s
INFO - 2023-11-28 03:30:57,156: EPOCH 8: training on 40200 raw words (37419 effective words) took 0.1s, 283051 effective words/s
INFO - 2023-11-28 03:30:57,297: EPOCH 9: training on 40200 raw words (37414 effective words) took 0.1s, 270908 effective words/s
INFO - 2023-11-28 03:30:57,440: EPOCH 10: training on 40200 raw words (37412 effective words) took 0.1s, 265578 effective words/s
INFO - 2023-11-28 03:30:57,582: EPOCH 11: training on 40200 raw words (37506 effective words) took 0.1s, 268266 effective words/s
INFO - 2023-11-28 03:30:57,725: EPOCH 12: training on 40200 raw words (37404 effective words) took 0.1s, 265448 effective words/s
INFO - 2023-11-28 03:30:57,864: EPOCH 13: training on 40200 raw words (37418 effective words) took 0.1s, 273856 effective words/s
INFO - 2023-11-28 03:30:58,010: EPOCH 14: training on 40200 raw words (37349 effective words) took 0.1s, 260884 effective words/s
INFO - 2023-11-28 03:30:58,150: EPOCH 15: training on 40200 raw words (37385 effective words) took 0.1s, 271575 effective words/s
INFO - 2023-11-28 03:30:58,294: EPOCH 16: training on 40200 raw words (37441 effective words) took 0.1s, 264056 effective words/s
INFO - 2023-11-28 03:30:58,444: EPOCH 17: training on 40200 raw words (37394 effective words) took 0.1s, 251709 effective words/s
INFO - 2023-11-28 03:30:58,583: EPOCH 18: training on 40200 raw words (37417 effective words) took 0.1s, 275582 effective words/s
INFO - 2023-11-28 03:30:58,720: EPOCH 19: training on 40200 raw words (37387 effective words) took 0.1s, 277014 effective words/s
INFO - 2023-11-28 03:30:58,720: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748049 effective words) took 2.8s, 263734 effective words/s', 'datetime': '2023-11-28T03:30:58.720678', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:30:58,720: collecting all words and their counts
INFO - 2023-11-28 03:30:58,721: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:30:58,727: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:30:58,727: Updating model with new vocabulary
INFO - 2023-11-28 03:30:58,731: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:30:58.731415', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:58,735: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:30:58,735: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:30:58,735: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37276.16234683334 word corpus (92.7%% of prior 40200)', 'datetime': '2023-11-28T03:30:58.735513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:30:58,742: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:30:58,742: updating layer weights
INFO - 2023-11-28 03:30:58,742: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:30:58.742367', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:30:58,742: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:30:58,742: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:30:58.742609', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:30:58,879: EPOCH 0: training on 40200 raw words (37267 effective words) took 0.1s, 278205 effective words/s
INFO - 2023-11-28 03:30:59,025: EPOCH 1: training on 40200 raw words (37272 effective words) took 0.1s, 260280 effective words/s
INFO - 2023-11-28 03:30:59,167: EPOCH 2: training on 40200 raw words (37304 effective words) took 0.1s, 270013 effective words/s
INFO - 2023-11-28 03:30:59,318: EPOCH 3: training on 40200 raw words (37242 effective words) took 0.1s, 253866 effective words/s
INFO - 2023-11-28 03:30:59,459: EPOCH 4: training on 40200 raw words (37260 effective words) took 0.1s, 270955 effective words/s
INFO - 2023-11-28 03:30:59,607: EPOCH 5: training on 40200 raw words (37264 effective words) took 0.1s, 263648 effective words/s
INFO - 2023-11-28 03:30:59,727: EPOCH 6: training on 40200 raw words (37216 effective words) took 0.1s, 315951 effective words/s
INFO - 2023-11-28 03:30:59,858: EPOCH 7: training on 40200 raw words (37231 effective words) took 0.1s, 288503 effective words/s
INFO - 2023-11-28 03:30:59,992: EPOCH 8: training on 40200 raw words (37315 effective words) took 0.1s, 283693 effective words/s
INFO - 2023-11-28 03:31:00,124: EPOCH 9: training on 40200 raw words (37249 effective words) took 0.1s, 288391 effective words/s
INFO - 2023-11-28 03:31:00,257: EPOCH 10: training on 40200 raw words (37332 effective words) took 0.1s, 284799 effective words/s
INFO - 2023-11-28 03:31:00,390: EPOCH 11: training on 40200 raw words (37337 effective words) took 0.1s, 286599 effective words/s
INFO - 2023-11-28 03:31:00,524: EPOCH 12: training on 40200 raw words (37312 effective words) took 0.1s, 281972 effective words/s
INFO - 2023-11-28 03:31:00,654: EPOCH 13: training on 40200 raw words (37311 effective words) took 0.1s, 293392 effective words/s
INFO - 2023-11-28 03:31:00,790: EPOCH 14: training on 40200 raw words (37276 effective words) took 0.1s, 278937 effective words/s
INFO - 2023-11-28 03:31:00,925: EPOCH 15: training on 40200 raw words (37221 effective words) took 0.1s, 280992 effective words/s
INFO - 2023-11-28 03:31:01,058: EPOCH 16: training on 40200 raw words (37286 effective words) took 0.1s, 284440 effective words/s
INFO - 2023-11-28 03:31:01,193: EPOCH 17: training on 40200 raw words (37297 effective words) took 0.1s, 282144 effective words/s
INFO - 2023-11-28 03:31:01,326: EPOCH 18: training on 40200 raw words (37247 effective words) took 0.1s, 285882 effective words/s
INFO - 2023-11-28 03:31:01,456: EPOCH 19: training on 40200 raw words (37278 effective words) took 0.1s, 292291 effective words/s
INFO - 2023-11-28 03:31:01,456: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745517 effective words) took 2.7s, 274734 effective words/s', 'datetime': '2023-11-28T03:31:01.456395', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:01,456: collecting all words and their counts
INFO - 2023-11-28 03:31:01,456: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:01,463: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:01,463: Updating model with new vocabulary
INFO - 2023-11-28 03:31:01,466: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:01.466250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:01,469: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:01,469: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:31:01,469: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37420.896281346606 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:01.469961', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:01,475: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:01,475: updating layer weights
INFO - 2023-11-28 03:31:01,475: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:01.475842', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:01,475: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:01,476: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:01.476055', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:01,612: EPOCH 0: training on 40200 raw words (37345 effective words) took 0.1s, 278587 effective words/s
INFO - 2023-11-28 03:31:01,754: EPOCH 1: training on 40200 raw words (37452 effective words) took 0.1s, 268561 effective words/s
INFO - 2023-11-28 03:31:01,895: EPOCH 2: training on 40200 raw words (37447 effective words) took 0.1s, 268295 effective words/s
INFO - 2023-11-28 03:31:02,040: EPOCH 3: training on 40200 raw words (37411 effective words) took 0.1s, 262707 effective words/s
INFO - 2023-11-28 03:31:02,177: EPOCH 4: training on 40200 raw words (37401 effective words) took 0.1s, 277876 effective words/s
INFO - 2023-11-28 03:31:02,321: EPOCH 5: training on 40200 raw words (37361 effective words) took 0.1s, 263167 effective words/s
INFO - 2023-11-28 03:31:02,463: EPOCH 6: training on 40200 raw words (37481 effective words) took 0.1s, 268807 effective words/s
INFO - 2023-11-28 03:31:02,608: EPOCH 7: training on 40200 raw words (37378 effective words) took 0.1s, 263280 effective words/s
INFO - 2023-11-28 03:31:02,752: EPOCH 8: training on 40200 raw words (37389 effective words) took 0.1s, 263815 effective words/s
INFO - 2023-11-28 03:31:02,889: EPOCH 9: training on 40200 raw words (37438 effective words) took 0.1s, 278868 effective words/s
INFO - 2023-11-28 03:31:03,028: EPOCH 10: training on 40200 raw words (37490 effective words) took 0.1s, 273831 effective words/s
INFO - 2023-11-28 03:31:03,172: EPOCH 11: training on 40200 raw words (37465 effective words) took 0.1s, 263790 effective words/s
INFO - 2023-11-28 03:31:03,314: EPOCH 12: training on 40200 raw words (37420 effective words) took 0.1s, 268740 effective words/s
INFO - 2023-11-28 03:31:03,456: EPOCH 13: training on 40200 raw words (37468 effective words) took 0.1s, 266839 effective words/s
INFO - 2023-11-28 03:31:03,598: EPOCH 14: training on 40200 raw words (37409 effective words) took 0.1s, 269502 effective words/s
INFO - 2023-11-28 03:31:03,741: EPOCH 15: training on 40200 raw words (37448 effective words) took 0.1s, 266130 effective words/s
INFO - 2023-11-28 03:31:03,884: EPOCH 16: training on 40200 raw words (37417 effective words) took 0.1s, 265275 effective words/s
INFO - 2023-11-28 03:31:04,024: EPOCH 17: training on 40200 raw words (37442 effective words) took 0.1s, 272273 effective words/s
INFO - 2023-11-28 03:31:04,167: EPOCH 18: training on 40200 raw words (37386 effective words) took 0.1s, 265306 effective words/s
INFO - 2023-11-28 03:31:04,306: EPOCH 19: training on 40200 raw words (37416 effective words) took 0.1s, 272899 effective words/s
INFO - 2023-11-28 03:31:04,307: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748464 effective words) took 2.8s, 264384 effective words/s', 'datetime': '2023-11-28T03:31:04.307143', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:04,307: collecting all words and their counts
INFO - 2023-11-28 03:31:04,307: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:04,314: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:04,314: Updating model with new vocabulary
INFO - 2023-11-28 03:31:04,317: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:04.317221', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:04,320: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:04,320: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:31:04,320: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37433.438021315145 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:04.320857', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:04,328: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:04,328: updating layer weights
INFO - 2023-11-28 03:31:04,328: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:04.328617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:04,328: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:04,329: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:04.329110', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:04,468: EPOCH 0: training on 40200 raw words (37441 effective words) took 0.1s, 284786 effective words/s
INFO - 2023-11-28 03:31:04,594: EPOCH 1: training on 40200 raw words (37400 effective words) took 0.1s, 302674 effective words/s
INFO - 2023-11-28 03:31:04,732: EPOCH 2: training on 40200 raw words (37497 effective words) took 0.1s, 275809 effective words/s
INFO - 2023-11-28 03:31:04,861: EPOCH 3: training on 40200 raw words (37443 effective words) took 0.1s, 293801 effective words/s
INFO - 2023-11-28 03:31:05,009: EPOCH 4: training on 40200 raw words (37467 effective words) took 0.1s, 266318 effective words/s
INFO - 2023-11-28 03:31:05,141: EPOCH 5: training on 40200 raw words (37441 effective words) took 0.1s, 288519 effective words/s
INFO - 2023-11-28 03:31:05,277: EPOCH 6: training on 40200 raw words (37416 effective words) took 0.1s, 281762 effective words/s
INFO - 2023-11-28 03:31:05,412: EPOCH 7: training on 40200 raw words (37383 effective words) took 0.1s, 281165 effective words/s
INFO - 2023-11-28 03:31:05,546: EPOCH 8: training on 40200 raw words (37398 effective words) took 0.1s, 283779 effective words/s
INFO - 2023-11-28 03:31:05,683: EPOCH 9: training on 40200 raw words (37408 effective words) took 0.1s, 277211 effective words/s
INFO - 2023-11-28 03:31:05,812: EPOCH 10: training on 40200 raw words (37435 effective words) took 0.1s, 296246 effective words/s
INFO - 2023-11-28 03:31:05,944: EPOCH 11: training on 40200 raw words (37405 effective words) took 0.1s, 286973 effective words/s
INFO - 2023-11-28 03:31:06,085: EPOCH 12: training on 40200 raw words (37435 effective words) took 0.1s, 270093 effective words/s
INFO - 2023-11-28 03:31:06,221: EPOCH 13: training on 40200 raw words (37417 effective words) took 0.1s, 281548 effective words/s
INFO - 2023-11-28 03:31:06,356: EPOCH 14: training on 40200 raw words (37441 effective words) took 0.1s, 282445 effective words/s
INFO - 2023-11-28 03:31:06,492: EPOCH 15: training on 40200 raw words (37502 effective words) took 0.1s, 279241 effective words/s
INFO - 2023-11-28 03:31:06,617: EPOCH 16: training on 40200 raw words (37386 effective words) took 0.1s, 304851 effective words/s
INFO - 2023-11-28 03:31:06,752: EPOCH 17: training on 40200 raw words (37422 effective words) took 0.1s, 282588 effective words/s
INFO - 2023-11-28 03:31:06,888: EPOCH 18: training on 40200 raw words (37447 effective words) took 0.1s, 278713 effective words/s
INFO - 2023-11-28 03:31:07,024: EPOCH 19: training on 40200 raw words (37445 effective words) took 0.1s, 280701 effective words/s
INFO - 2023-11-28 03:31:07,025: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748629 effective words) took 2.7s, 277713 effective words/s', 'datetime': '2023-11-28T03:31:07.025083', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:07,025: collecting all words and their counts
INFO - 2023-11-28 03:31:07,025: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:07,032: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:07,032: Updating model with new vocabulary
INFO - 2023-11-28 03:31:07,036: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:07.036322', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:07,040: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:07,040: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:31:07,040: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37358.0635150452 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:07.040305', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:07,045: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:07,045: updating layer weights
INFO - 2023-11-28 03:31:07,046: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:07.046105', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:07,046: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:07,046: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:07.046425', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:07,190: EPOCH 0: training on 40200 raw words (37324 effective words) took 0.1s, 263131 effective words/s
INFO - 2023-11-28 03:31:07,332: EPOCH 1: training on 40200 raw words (37348 effective words) took 0.1s, 268030 effective words/s
INFO - 2023-11-28 03:31:07,476: EPOCH 2: training on 40200 raw words (37297 effective words) took 0.1s, 262039 effective words/s
INFO - 2023-11-28 03:31:07,626: EPOCH 3: training on 40200 raw words (37454 effective words) took 0.1s, 254056 effective words/s
INFO - 2023-11-28 03:31:07,764: EPOCH 4: training on 40200 raw words (37354 effective words) took 0.1s, 276493 effective words/s
INFO - 2023-11-28 03:31:07,907: EPOCH 5: training on 40200 raw words (37312 effective words) took 0.1s, 264931 effective words/s
INFO - 2023-11-28 03:31:08,049: EPOCH 6: training on 40200 raw words (37346 effective words) took 0.1s, 266387 effective words/s
INFO - 2023-11-28 03:31:08,188: EPOCH 7: training on 40200 raw words (37413 effective words) took 0.1s, 274622 effective words/s
INFO - 2023-11-28 03:31:08,322: EPOCH 8: training on 40200 raw words (37308 effective words) took 0.1s, 283075 effective words/s
INFO - 2023-11-28 03:31:08,463: EPOCH 9: training on 40200 raw words (37322 effective words) took 0.1s, 268117 effective words/s
INFO - 2023-11-28 03:31:08,604: EPOCH 10: training on 40200 raw words (37341 effective words) took 0.1s, 269837 effective words/s
INFO - 2023-11-28 03:31:08,745: EPOCH 11: training on 40200 raw words (37313 effective words) took 0.1s, 279024 effective words/s
INFO - 2023-11-28 03:31:08,886: EPOCH 12: training on 40200 raw words (37359 effective words) took 0.1s, 269368 effective words/s
INFO - 2023-11-28 03:31:09,030: EPOCH 13: training on 40200 raw words (37327 effective words) took 0.1s, 265156 effective words/s
INFO - 2023-11-28 03:31:09,172: EPOCH 14: training on 40200 raw words (37318 effective words) took 0.1s, 266713 effective words/s
INFO - 2023-11-28 03:31:09,310: EPOCH 15: training on 40200 raw words (37317 effective words) took 0.1s, 274076 effective words/s
INFO - 2023-11-28 03:31:09,450: EPOCH 16: training on 40200 raw words (37390 effective words) took 0.1s, 270953 effective words/s
INFO - 2023-11-28 03:31:09,589: EPOCH 17: training on 40200 raw words (37342 effective words) took 0.1s, 274819 effective words/s
INFO - 2023-11-28 03:31:09,723: EPOCH 18: training on 40200 raw words (37340 effective words) took 0.1s, 281905 effective words/s
INFO - 2023-11-28 03:31:09,864: EPOCH 19: training on 40200 raw words (37338 effective words) took 0.1s, 268820 effective words/s
INFO - 2023-11-28 03:31:09,865: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746863 effective words) took 2.8s, 264976 effective words/s', 'datetime': '2023-11-28T03:31:09.865136', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:09,865: collecting all words and their counts
INFO - 2023-11-28 03:31:09,865: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:09,872: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:09,872: Updating model with new vocabulary
INFO - 2023-11-28 03:31:09,875: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:09.875478', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:09,878: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:09,878: sample=0.001 downsamples 70 most-common words
INFO - 2023-11-28 03:31:09,878: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37407.24162767634 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:09.878766', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:09,884: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:09,884: updating layer weights
INFO - 2023-11-28 03:31:09,884: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:09.884812', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:09,884: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:09,885: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:09.884992', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:10,024: EPOCH 0: training on 40200 raw words (37507 effective words) took 0.1s, 284400 effective words/s
INFO - 2023-11-28 03:31:10,162: EPOCH 1: training on 40200 raw words (37479 effective words) took 0.1s, 276205 effective words/s
INFO - 2023-11-28 03:31:10,297: EPOCH 2: training on 40200 raw words (37379 effective words) took 0.1s, 282033 effective words/s
INFO - 2023-11-28 03:31:10,433: EPOCH 3: training on 40200 raw words (37434 effective words) took 0.1s, 279520 effective words/s
INFO - 2023-11-28 03:31:10,566: EPOCH 4: training on 40200 raw words (37397 effective words) took 0.1s, 286770 effective words/s
INFO - 2023-11-28 03:31:10,698: EPOCH 5: training on 40200 raw words (37331 effective words) took 0.1s, 287349 effective words/s
INFO - 2023-11-28 03:31:10,836: EPOCH 6: training on 40200 raw words (37399 effective words) took 0.1s, 276765 effective words/s
INFO - 2023-11-28 03:31:10,969: EPOCH 7: training on 40200 raw words (37368 effective words) took 0.1s, 285127 effective words/s
INFO - 2023-11-28 03:31:11,104: EPOCH 8: training on 40200 raw words (37418 effective words) took 0.1s, 282806 effective words/s
INFO - 2023-11-28 03:31:11,240: EPOCH 9: training on 40200 raw words (37428 effective words) took 0.1s, 281134 effective words/s
INFO - 2023-11-28 03:31:11,373: EPOCH 10: training on 40200 raw words (37433 effective words) took 0.1s, 284963 effective words/s
INFO - 2023-11-28 03:31:11,510: EPOCH 11: training on 40200 raw words (37560 effective words) took 0.1s, 278403 effective words/s
INFO - 2023-11-28 03:31:11,671: EPOCH 12: training on 40200 raw words (37421 effective words) took 0.2s, 237466 effective words/s
INFO - 2023-11-28 03:31:11,797: EPOCH 13: training on 40200 raw words (37396 effective words) took 0.1s, 300933 effective words/s
INFO - 2023-11-28 03:31:11,931: EPOCH 14: training on 40200 raw words (37495 effective words) took 0.1s, 284643 effective words/s
INFO - 2023-11-28 03:31:12,059: EPOCH 15: training on 40200 raw words (37414 effective words) took 0.1s, 298629 effective words/s
INFO - 2023-11-28 03:31:12,194: EPOCH 16: training on 40200 raw words (37420 effective words) took 0.1s, 281580 effective words/s
INFO - 2023-11-28 03:31:12,323: EPOCH 17: training on 40200 raw words (37512 effective words) took 0.1s, 296222 effective words/s
INFO - 2023-11-28 03:31:12,451: EPOCH 18: training on 40200 raw words (37398 effective words) took 0.1s, 298463 effective words/s
INFO - 2023-11-28 03:31:12,585: EPOCH 19: training on 40200 raw words (37448 effective words) took 0.1s, 283957 effective words/s
INFO - 2023-11-28 03:31:12,586: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748637 effective words) took 2.7s, 277179 effective words/s', 'datetime': '2023-11-28T03:31:12.586027', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:12,586: collecting all words and their counts
INFO - 2023-11-28 03:31:12,586: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:12,593: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:12,593: Updating model with new vocabulary
INFO - 2023-11-28 03:31:12,597: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:12.597204', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:12,601: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:12,601: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:31:12,601: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37423.72785439556 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:12.601329', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:12,607: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:12,607: updating layer weights
INFO - 2023-11-28 03:31:12,607: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:12.607702', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:12,607: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:12,607: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:12.607850', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:12,750: EPOCH 0: training on 40200 raw words (37452 effective words) took 0.1s, 268235 effective words/s
INFO - 2023-11-28 03:31:12,886: EPOCH 1: training on 40200 raw words (37428 effective words) took 0.1s, 278987 effective words/s
INFO - 2023-11-28 03:31:13,026: EPOCH 2: training on 40200 raw words (37465 effective words) took 0.1s, 272284 effective words/s
INFO - 2023-11-28 03:31:13,169: EPOCH 3: training on 40200 raw words (37445 effective words) took 0.1s, 266530 effective words/s
INFO - 2023-11-28 03:31:13,310: EPOCH 4: training on 40200 raw words (37414 effective words) took 0.1s, 269553 effective words/s
INFO - 2023-11-28 03:31:13,453: EPOCH 5: training on 40200 raw words (37387 effective words) took 0.1s, 266615 effective words/s
INFO - 2023-11-28 03:31:13,590: EPOCH 6: training on 40200 raw words (37379 effective words) took 0.1s, 276614 effective words/s
INFO - 2023-11-28 03:31:13,731: EPOCH 7: training on 40200 raw words (37382 effective words) took 0.1s, 268593 effective words/s
INFO - 2023-11-28 03:31:13,875: EPOCH 8: training on 40200 raw words (37427 effective words) took 0.1s, 264250 effective words/s
INFO - 2023-11-28 03:31:14,019: EPOCH 9: training on 40200 raw words (37425 effective words) took 0.1s, 264817 effective words/s
INFO - 2023-11-28 03:31:14,161: EPOCH 10: training on 40200 raw words (37381 effective words) took 0.1s, 268648 effective words/s
INFO - 2023-11-28 03:31:14,300: EPOCH 11: training on 40200 raw words (37359 effective words) took 0.1s, 272848 effective words/s
INFO - 2023-11-28 03:31:14,439: EPOCH 12: training on 40200 raw words (37399 effective words) took 0.1s, 272836 effective words/s
INFO - 2023-11-28 03:31:14,579: EPOCH 13: training on 40200 raw words (37465 effective words) took 0.1s, 273286 effective words/s
INFO - 2023-11-28 03:31:14,723: EPOCH 14: training on 40200 raw words (37476 effective words) took 0.1s, 264064 effective words/s
INFO - 2023-11-28 03:31:14,858: EPOCH 15: training on 40200 raw words (37426 effective words) took 0.1s, 280277 effective words/s
INFO - 2023-11-28 03:31:14,998: EPOCH 16: training on 40200 raw words (37414 effective words) took 0.1s, 272203 effective words/s
INFO - 2023-11-28 03:31:15,138: EPOCH 17: training on 40200 raw words (37434 effective words) took 0.1s, 273146 effective words/s
INFO - 2023-11-28 03:31:15,277: EPOCH 18: training on 40200 raw words (37409 effective words) took 0.1s, 272753 effective words/s
INFO - 2023-11-28 03:31:15,413: EPOCH 19: training on 40200 raw words (37422 effective words) took 0.1s, 280329 effective words/s
INFO - 2023-11-28 03:31:15,413: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748389 effective words) took 2.8s, 266730 effective words/s', 'datetime': '2023-11-28T03:31:15.413751', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:15,413: collecting all words and their counts
INFO - 2023-11-28 03:31:15,414: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:15,420: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:15,420: Updating model with new vocabulary
INFO - 2023-11-28 03:31:15,423: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:15.423567', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:15,426: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:15,427: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:31:15,427: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37295.23162180254 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:31:15.427098', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:15,432: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:15,432: updating layer weights
INFO - 2023-11-28 03:31:15,432: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:15.432509', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:15,432: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:15,432: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:15.432767', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:15,565: EPOCH 0: training on 40200 raw words (37264 effective words) took 0.1s, 286103 effective words/s
INFO - 2023-11-28 03:31:15,704: EPOCH 1: training on 40200 raw words (37246 effective words) took 0.1s, 271943 effective words/s
INFO - 2023-11-28 03:31:15,828: EPOCH 2: training on 40200 raw words (37223 effective words) took 0.1s, 304747 effective words/s
INFO - 2023-11-28 03:31:15,966: EPOCH 3: training on 40200 raw words (37286 effective words) took 0.1s, 274874 effective words/s
INFO - 2023-11-28 03:31:16,103: EPOCH 4: training on 40200 raw words (37238 effective words) took 0.1s, 277693 effective words/s
INFO - 2023-11-28 03:31:16,240: EPOCH 5: training on 40200 raw words (37265 effective words) took 0.1s, 277357 effective words/s
INFO - 2023-11-28 03:31:16,374: EPOCH 6: training on 40200 raw words (37204 effective words) took 0.1s, 282756 effective words/s
INFO - 2023-11-28 03:31:16,509: EPOCH 7: training on 40200 raw words (37305 effective words) took 0.1s, 280708 effective words/s
INFO - 2023-11-28 03:31:16,636: EPOCH 8: training on 40200 raw words (37292 effective words) took 0.1s, 297934 effective words/s
INFO - 2023-11-28 03:31:16,767: EPOCH 9: training on 40200 raw words (37248 effective words) took 0.1s, 289551 effective words/s
INFO - 2023-11-28 03:31:16,897: EPOCH 10: training on 40200 raw words (37383 effective words) took 0.1s, 293481 effective words/s
INFO - 2023-11-28 03:31:17,030: EPOCH 11: training on 40200 raw words (37284 effective words) took 0.1s, 284962 effective words/s
INFO - 2023-11-28 03:31:17,168: EPOCH 12: training on 40200 raw words (37365 effective words) took 0.1s, 276392 effective words/s
INFO - 2023-11-28 03:31:17,303: EPOCH 13: training on 40200 raw words (37263 effective words) took 0.1s, 293272 effective words/s
INFO - 2023-11-28 03:31:17,440: EPOCH 14: training on 40200 raw words (37332 effective words) took 0.1s, 277111 effective words/s
INFO - 2023-11-28 03:31:17,572: EPOCH 15: training on 40200 raw words (37299 effective words) took 0.1s, 287467 effective words/s
INFO - 2023-11-28 03:31:17,710: EPOCH 16: training on 40200 raw words (37290 effective words) took 0.1s, 274299 effective words/s
INFO - 2023-11-28 03:31:17,839: EPOCH 17: training on 40200 raw words (37332 effective words) took 0.1s, 295339 effective words/s
INFO - 2023-11-28 03:31:17,971: EPOCH 18: training on 40200 raw words (37320 effective words) took 0.1s, 287502 effective words/s
INFO - 2023-11-28 03:31:18,115: EPOCH 19: training on 40200 raw words (37188 effective words) took 0.1s, 262248 effective words/s
INFO - 2023-11-28 03:31:18,115: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745627 effective words) took 2.7s, 277939 effective words/s', 'datetime': '2023-11-28T03:31:18.115613', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:18,115: collecting all words and their counts
INFO - 2023-11-28 03:31:18,116: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:18,122: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:18,122: Updating model with new vocabulary
INFO - 2023-11-28 03:31:18,126: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:18.126128', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:18,129: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:18,129: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:31:18,129: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37299.42248793796 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:31:18.129889', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:18,135: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:18,135: updating layer weights
INFO - 2023-11-28 03:31:18,135: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:18.135468', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:18,135: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:18,135: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:18.135722', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:18,278: EPOCH 0: training on 40200 raw words (37379 effective words) took 0.1s, 267024 effective words/s
INFO - 2023-11-28 03:31:18,417: EPOCH 1: training on 40200 raw words (37291 effective words) took 0.1s, 274173 effective words/s
INFO - 2023-11-28 03:31:18,558: EPOCH 2: training on 40200 raw words (37280 effective words) took 0.1s, 268219 effective words/s
INFO - 2023-11-28 03:31:18,701: EPOCH 3: training on 40200 raw words (37233 effective words) took 0.1s, 273424 effective words/s
INFO - 2023-11-28 03:31:18,835: EPOCH 4: training on 40200 raw words (37269 effective words) took 0.1s, 282250 effective words/s
INFO - 2023-11-28 03:31:18,973: EPOCH 5: training on 40200 raw words (37246 effective words) took 0.1s, 275285 effective words/s
INFO - 2023-11-28 03:31:19,114: EPOCH 6: training on 40200 raw words (37226 effective words) took 0.1s, 277674 effective words/s
INFO - 2023-11-28 03:31:19,255: EPOCH 7: training on 40200 raw words (37256 effective words) took 0.1s, 268462 effective words/s
INFO - 2023-11-28 03:31:19,398: EPOCH 8: training on 40200 raw words (37266 effective words) took 0.1s, 266214 effective words/s
INFO - 2023-11-28 03:31:19,543: EPOCH 9: training on 40200 raw words (37299 effective words) took 0.1s, 261511 effective words/s
INFO - 2023-11-28 03:31:19,685: EPOCH 10: training on 40200 raw words (37345 effective words) took 0.1s, 267444 effective words/s
INFO - 2023-11-28 03:31:19,829: EPOCH 11: training on 40200 raw words (37288 effective words) took 0.1s, 264208 effective words/s
INFO - 2023-11-28 03:31:19,967: EPOCH 12: training on 40200 raw words (37301 effective words) took 0.1s, 274297 effective words/s
INFO - 2023-11-28 03:31:20,099: EPOCH 13: training on 40200 raw words (37322 effective words) took 0.1s, 286625 effective words/s
INFO - 2023-11-28 03:31:20,229: EPOCH 14: training on 40200 raw words (37321 effective words) took 0.1s, 293324 effective words/s
INFO - 2023-11-28 03:31:20,370: EPOCH 15: training on 40200 raw words (37265 effective words) took 0.1s, 268172 effective words/s
INFO - 2023-11-28 03:31:20,513: EPOCH 16: training on 40200 raw words (37311 effective words) took 0.1s, 274297 effective words/s
INFO - 2023-11-28 03:31:20,654: EPOCH 17: training on 40200 raw words (37376 effective words) took 0.1s, 270312 effective words/s
INFO - 2023-11-28 03:31:20,793: EPOCH 18: training on 40200 raw words (37315 effective words) took 0.1s, 272396 effective words/s
INFO - 2023-11-28 03:31:20,935: EPOCH 19: training on 40200 raw words (37230 effective words) took 0.1s, 267612 effective words/s
INFO - 2023-11-28 03:31:20,935: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745819 effective words) took 2.8s, 266403 effective words/s', 'datetime': '2023-11-28T03:31:20.935432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:20,935: collecting all words and their counts
INFO - 2023-11-28 03:31:20,935: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:20,942: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:20,942: Updating model with new vocabulary
INFO - 2023-11-28 03:31:20,945: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:20.945808', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:20,949: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:20,949: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:31:20,949: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37340.99975049088 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:20.949523', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:20,955: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:20,955: updating layer weights
INFO - 2023-11-28 03:31:20,956: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:20.955973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:20,956: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:20,956: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:20.956186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:21,093: EPOCH 0: training on 40200 raw words (37337 effective words) took 0.1s, 277699 effective words/s
INFO - 2023-11-28 03:31:21,225: EPOCH 1: training on 40200 raw words (37311 effective words) took 0.1s, 286191 effective words/s
INFO - 2023-11-28 03:31:21,360: EPOCH 2: training on 40200 raw words (37299 effective words) took 0.1s, 281348 effective words/s
INFO - 2023-11-28 03:31:21,492: EPOCH 3: training on 40200 raw words (37274 effective words) took 0.1s, 286877 effective words/s
INFO - 2023-11-28 03:31:21,626: EPOCH 4: training on 40200 raw words (37335 effective words) took 0.1s, 284996 effective words/s
INFO - 2023-11-28 03:31:21,754: EPOCH 5: training on 40200 raw words (37338 effective words) took 0.1s, 295233 effective words/s
INFO - 2023-11-28 03:31:21,891: EPOCH 6: training on 40200 raw words (37371 effective words) took 0.1s, 278804 effective words/s
INFO - 2023-11-28 03:31:22,027: EPOCH 7: training on 40200 raw words (37341 effective words) took 0.1s, 277551 effective words/s
INFO - 2023-11-28 03:31:22,162: EPOCH 8: training on 40200 raw words (37333 effective words) took 0.1s, 280893 effective words/s
INFO - 2023-11-28 03:31:22,292: EPOCH 9: training on 40200 raw words (37371 effective words) took 0.1s, 293665 effective words/s
INFO - 2023-11-28 03:31:22,427: EPOCH 10: training on 40200 raw words (37263 effective words) took 0.1s, 282012 effective words/s
INFO - 2023-11-28 03:31:22,558: EPOCH 11: training on 40200 raw words (37349 effective words) took 0.1s, 288382 effective words/s
INFO - 2023-11-28 03:31:22,693: EPOCH 12: training on 40200 raw words (37391 effective words) took 0.1s, 283201 effective words/s
INFO - 2023-11-28 03:31:22,824: EPOCH 13: training on 40200 raw words (37387 effective words) took 0.1s, 290698 effective words/s
INFO - 2023-11-28 03:31:22,961: EPOCH 14: training on 40200 raw words (37342 effective words) took 0.1s, 287684 effective words/s
INFO - 2023-11-28 03:31:23,092: EPOCH 15: training on 40200 raw words (37332 effective words) took 0.1s, 289685 effective words/s
INFO - 2023-11-28 03:31:23,228: EPOCH 16: training on 40200 raw words (37280 effective words) took 0.1s, 278567 effective words/s
INFO - 2023-11-28 03:31:23,360: EPOCH 17: training on 40200 raw words (37378 effective words) took 0.1s, 287038 effective words/s
INFO - 2023-11-28 03:31:23,494: EPOCH 18: training on 40200 raw words (37381 effective words) took 0.1s, 283261 effective words/s
INFO - 2023-11-28 03:31:23,629: EPOCH 19: training on 40200 raw words (37257 effective words) took 0.1s, 281100 effective words/s
INFO - 2023-11-28 03:31:23,629: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746670 effective words) took 2.7s, 279290 effective words/s', 'datetime': '2023-11-28T03:31:23.629779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:23,629: collecting all words and their counts
INFO - 2023-11-28 03:31:23,630: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:23,637: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:23,637: Updating model with new vocabulary
INFO - 2023-11-28 03:31:23,640: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:23.640721', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:23,646: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:23,646: sample=0.001 downsamples 80 most-common words
INFO - 2023-11-28 03:31:23,646: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37448.351653405654 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:31:23.646280', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:23,654: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:23,654: updating layer weights
INFO - 2023-11-28 03:31:23,654: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:23.654717', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:23,654: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:23,655: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:23.654979', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:23,797: EPOCH 0: training on 40200 raw words (37500 effective words) took 0.1s, 268118 effective words/s
INFO - 2023-11-28 03:31:23,937: EPOCH 1: training on 40200 raw words (37472 effective words) took 0.1s, 270887 effective words/s
INFO - 2023-11-28 03:31:24,077: EPOCH 2: training on 40200 raw words (37430 effective words) took 0.1s, 272607 effective words/s
INFO - 2023-11-28 03:31:24,217: EPOCH 3: training on 40200 raw words (37354 effective words) took 0.1s, 270061 effective words/s
INFO - 2023-11-28 03:31:24,350: EPOCH 4: training on 40200 raw words (37462 effective words) took 0.1s, 295659 effective words/s
INFO - 2023-11-28 03:31:24,492: EPOCH 5: training on 40200 raw words (37465 effective words) took 0.1s, 266859 effective words/s
INFO - 2023-11-28 03:31:24,631: EPOCH 6: training on 40200 raw words (37425 effective words) took 0.1s, 274728 effective words/s
INFO - 2023-11-28 03:31:24,774: EPOCH 7: training on 40200 raw words (37427 effective words) took 0.1s, 270523 effective words/s
INFO - 2023-11-28 03:31:24,918: EPOCH 8: training on 40200 raw words (37494 effective words) took 0.1s, 264193 effective words/s
INFO - 2023-11-28 03:31:25,063: EPOCH 9: training on 40200 raw words (37402 effective words) took 0.1s, 261750 effective words/s
INFO - 2023-11-28 03:31:25,205: EPOCH 10: training on 40200 raw words (37523 effective words) took 0.1s, 268736 effective words/s
INFO - 2023-11-28 03:31:25,340: EPOCH 11: training on 40200 raw words (37452 effective words) took 0.1s, 281133 effective words/s
INFO - 2023-11-28 03:31:25,478: EPOCH 12: training on 40200 raw words (37431 effective words) took 0.1s, 275908 effective words/s
INFO - 2023-11-28 03:31:25,618: EPOCH 13: training on 40200 raw words (37400 effective words) took 0.1s, 270825 effective words/s
INFO - 2023-11-28 03:31:25,760: EPOCH 14: training on 40200 raw words (37423 effective words) took 0.1s, 268548 effective words/s
INFO - 2023-11-28 03:31:25,904: EPOCH 15: training on 40200 raw words (37417 effective words) took 0.1s, 263789 effective words/s
INFO - 2023-11-28 03:31:26,041: EPOCH 16: training on 40200 raw words (37383 effective words) took 0.1s, 276263 effective words/s
INFO - 2023-11-28 03:31:26,182: EPOCH 17: training on 40200 raw words (37435 effective words) took 0.1s, 271068 effective words/s
INFO - 2023-11-28 03:31:26,324: EPOCH 18: training on 40200 raw words (37476 effective words) took 0.1s, 266799 effective words/s
INFO - 2023-11-28 03:31:26,468: EPOCH 19: training on 40200 raw words (37450 effective words) took 0.1s, 265077 effective words/s
INFO - 2023-11-28 03:31:26,468: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748821 effective words) took 2.8s, 266140 effective words/s', 'datetime': '2023-11-28T03:31:26.468735', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:26,468: collecting all words and their counts
INFO - 2023-11-28 03:31:26,469: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:26,477: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:26,477: Updating model with new vocabulary
INFO - 2023-11-28 03:31:26,480: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:26.480811', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:26,484: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:26,484: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:31:26,484: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37435.23674534502 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:26.484727', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:26,492: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:26,492: updating layer weights
INFO - 2023-11-28 03:31:26,493: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:26.493098', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:26,493: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:26,493: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:26.493327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:26,625: EPOCH 0: training on 40200 raw words (37356 effective words) took 0.1s, 288603 effective words/s
INFO - 2023-11-28 03:31:26,757: EPOCH 1: training on 40200 raw words (37450 effective words) took 0.1s, 287381 effective words/s
INFO - 2023-11-28 03:31:26,886: EPOCH 2: training on 40200 raw words (37475 effective words) took 0.1s, 295050 effective words/s
INFO - 2023-11-28 03:31:27,023: EPOCH 3: training on 40200 raw words (37496 effective words) took 0.1s, 279810 effective words/s
INFO - 2023-11-28 03:31:27,147: EPOCH 4: training on 40200 raw words (37378 effective words) took 0.1s, 305844 effective words/s
INFO - 2023-11-28 03:31:27,282: EPOCH 5: training on 40200 raw words (37518 effective words) took 0.1s, 282529 effective words/s
INFO - 2023-11-28 03:31:27,416: EPOCH 6: training on 40200 raw words (37415 effective words) took 0.1s, 284426 effective words/s
INFO - 2023-11-28 03:31:27,552: EPOCH 7: training on 40200 raw words (37467 effective words) took 0.1s, 280579 effective words/s
INFO - 2023-11-28 03:31:27,687: EPOCH 8: training on 40200 raw words (37426 effective words) took 0.1s, 282398 effective words/s
INFO - 2023-11-28 03:31:27,815: EPOCH 9: training on 40200 raw words (37523 effective words) took 0.1s, 297848 effective words/s
INFO - 2023-11-28 03:31:27,942: EPOCH 10: training on 40200 raw words (37426 effective words) took 0.1s, 298935 effective words/s
INFO - 2023-11-28 03:31:28,069: EPOCH 11: training on 40200 raw words (37381 effective words) took 0.1s, 300184 effective words/s
INFO - 2023-11-28 03:31:28,199: EPOCH 12: training on 40200 raw words (37422 effective words) took 0.1s, 293038 effective words/s
INFO - 2023-11-28 03:31:28,337: EPOCH 13: training on 40200 raw words (37344 effective words) took 0.1s, 276017 effective words/s
INFO - 2023-11-28 03:31:28,468: EPOCH 14: training on 40200 raw words (37423 effective words) took 0.1s, 290541 effective words/s
INFO - 2023-11-28 03:31:28,602: EPOCH 15: training on 40200 raw words (37455 effective words) took 0.1s, 292092 effective words/s
INFO - 2023-11-28 03:31:28,736: EPOCH 16: training on 40200 raw words (37390 effective words) took 0.1s, 281775 effective words/s
INFO - 2023-11-28 03:31:28,868: EPOCH 17: training on 40200 raw words (37394 effective words) took 0.1s, 287991 effective words/s
INFO - 2023-11-28 03:31:29,005: EPOCH 18: training on 40200 raw words (37535 effective words) took 0.1s, 279329 effective words/s
INFO - 2023-11-28 03:31:29,129: EPOCH 19: training on 40200 raw words (37367 effective words) took 0.1s, 305882 effective words/s
INFO - 2023-11-28 03:31:29,129: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748641 effective words) took 2.6s, 283951 effective words/s', 'datetime': '2023-11-28T03:31:29.129956', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:29,130: collecting all words and their counts
INFO - 2023-11-28 03:31:29,130: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:29,137: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:29,137: Updating model with new vocabulary
INFO - 2023-11-28 03:31:29,140: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:29.140401', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:29,143: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:29,143: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:31:29,143: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37392.239390045026 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:31:29.143647', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:29,148: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:29,148: updating layer weights
INFO - 2023-11-28 03:31:29,148: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:29.148573', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:29,148: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:29,148: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:29.148698', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:29,290: EPOCH 0: training on 40200 raw words (37403 effective words) took 0.1s, 268076 effective words/s
INFO - 2023-11-28 03:31:29,430: EPOCH 1: training on 40200 raw words (37440 effective words) took 0.1s, 271105 effective words/s
INFO - 2023-11-28 03:31:29,573: EPOCH 2: training on 40200 raw words (37470 effective words) took 0.1s, 266433 effective words/s
INFO - 2023-11-28 03:31:29,713: EPOCH 3: training on 40200 raw words (37384 effective words) took 0.1s, 272821 effective words/s
INFO - 2023-11-28 03:31:29,878: EPOCH 4: training on 40200 raw words (37366 effective words) took 0.2s, 229447 effective words/s
INFO - 2023-11-28 03:31:30,016: EPOCH 5: training on 40200 raw words (37384 effective words) took 0.1s, 276083 effective words/s
INFO - 2023-11-28 03:31:30,157: EPOCH 6: training on 40200 raw words (37397 effective words) took 0.1s, 268638 effective words/s
INFO - 2023-11-28 03:31:30,290: EPOCH 7: training on 40200 raw words (37347 effective words) took 0.1s, 284813 effective words/s
INFO - 2023-11-28 03:31:30,436: EPOCH 8: training on 40200 raw words (37436 effective words) took 0.1s, 259860 effective words/s
INFO - 2023-11-28 03:31:30,579: EPOCH 9: training on 40200 raw words (37329 effective words) took 0.1s, 265805 effective words/s
INFO - 2023-11-28 03:31:30,715: EPOCH 10: training on 40200 raw words (37481 effective words) took 0.1s, 280237 effective words/s
INFO - 2023-11-28 03:31:30,857: EPOCH 11: training on 40200 raw words (37385 effective words) took 0.1s, 267625 effective words/s
INFO - 2023-11-28 03:31:30,992: EPOCH 12: training on 40200 raw words (37391 effective words) took 0.1s, 281726 effective words/s
INFO - 2023-11-28 03:31:31,135: EPOCH 13: training on 40200 raw words (37390 effective words) took 0.1s, 266028 effective words/s
INFO - 2023-11-28 03:31:31,278: EPOCH 14: training on 40200 raw words (37394 effective words) took 0.1s, 265198 effective words/s
INFO - 2023-11-28 03:31:31,414: EPOCH 15: training on 40200 raw words (37480 effective words) took 0.1s, 281837 effective words/s
INFO - 2023-11-28 03:31:31,554: EPOCH 16: training on 40200 raw words (37364 effective words) took 0.1s, 271134 effective words/s
INFO - 2023-11-28 03:31:31,697: EPOCH 17: training on 40200 raw words (37428 effective words) took 0.1s, 264836 effective words/s
INFO - 2023-11-28 03:31:31,841: EPOCH 18: training on 40200 raw words (37308 effective words) took 0.1s, 263018 effective words/s
INFO - 2023-11-28 03:31:31,972: EPOCH 19: training on 40200 raw words (37352 effective words) took 0.1s, 289746 effective words/s
INFO - 2023-11-28 03:31:31,972: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747929 effective words) took 2.8s, 264832 effective words/s', 'datetime': '2023-11-28T03:31:31.972948', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:31,973: collecting all words and their counts
INFO - 2023-11-28 03:31:31,973: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:31,980: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:31,980: Updating model with new vocabulary
INFO - 2023-11-28 03:31:31,983: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:31.983755', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:31,987: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:31,988: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:31:31,988: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37329.79627750799 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:31.988161', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:31,994: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:31,994: updating layer weights
INFO - 2023-11-28 03:31:31,994: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:31.994707', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:31,994: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:31,994: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:31.994924', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:32,132: EPOCH 0: training on 40200 raw words (37324 effective words) took 0.1s, 275162 effective words/s
INFO - 2023-11-28 03:31:32,269: EPOCH 1: training on 40200 raw words (37274 effective words) took 0.1s, 277437 effective words/s
INFO - 2023-11-28 03:31:32,404: EPOCH 2: training on 40200 raw words (37426 effective words) took 0.1s, 281838 effective words/s
INFO - 2023-11-28 03:31:32,541: EPOCH 3: training on 40200 raw words (37446 effective words) took 0.1s, 277803 effective words/s
INFO - 2023-11-28 03:31:32,669: EPOCH 4: training on 40200 raw words (37335 effective words) took 0.1s, 296909 effective words/s
INFO - 2023-11-28 03:31:32,803: EPOCH 5: training on 40200 raw words (37336 effective words) took 0.1s, 284294 effective words/s
INFO - 2023-11-28 03:31:32,932: EPOCH 6: training on 40200 raw words (37377 effective words) took 0.1s, 294279 effective words/s
INFO - 2023-11-28 03:31:33,073: EPOCH 7: training on 40200 raw words (37330 effective words) took 0.1s, 268627 effective words/s
INFO - 2023-11-28 03:31:33,201: EPOCH 8: training on 40200 raw words (37440 effective words) took 0.1s, 297201 effective words/s
INFO - 2023-11-28 03:31:33,335: EPOCH 9: training on 40200 raw words (37262 effective words) took 0.1s, 283708 effective words/s
INFO - 2023-11-28 03:31:33,469: EPOCH 10: training on 40200 raw words (37292 effective words) took 0.1s, 283178 effective words/s
INFO - 2023-11-28 03:31:33,597: EPOCH 11: training on 40200 raw words (37365 effective words) took 0.1s, 296903 effective words/s
INFO - 2023-11-28 03:31:33,732: EPOCH 12: training on 40200 raw words (37315 effective words) took 0.1s, 279908 effective words/s
INFO - 2023-11-28 03:31:33,865: EPOCH 13: training on 40200 raw words (37369 effective words) took 0.1s, 285633 effective words/s
INFO - 2023-11-28 03:31:34,000: EPOCH 14: training on 40200 raw words (37366 effective words) took 0.1s, 282355 effective words/s
INFO - 2023-11-28 03:31:34,137: EPOCH 15: training on 40200 raw words (37312 effective words) took 0.1s, 284393 effective words/s
INFO - 2023-11-28 03:31:34,272: EPOCH 16: training on 40200 raw words (37397 effective words) took 0.1s, 283078 effective words/s
INFO - 2023-11-28 03:31:34,407: EPOCH 17: training on 40200 raw words (37307 effective words) took 0.1s, 280753 effective words/s
INFO - 2023-11-28 03:31:34,544: EPOCH 18: training on 40200 raw words (37336 effective words) took 0.1s, 277534 effective words/s
INFO - 2023-11-28 03:31:34,678: EPOCH 19: training on 40200 raw words (37351 effective words) took 0.1s, 282680 effective words/s
INFO - 2023-11-28 03:31:34,678: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746960 effective words) took 2.7s, 278324 effective words/s', 'datetime': '2023-11-28T03:31:34.678812', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:34,678: collecting all words and their counts
INFO - 2023-11-28 03:31:34,679: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:34,686: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:34,686: Updating model with new vocabulary
INFO - 2023-11-28 03:31:34,689: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:34.689718', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:34,693: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:34,693: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:31:34,693: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37282.82796015334 word corpus (92.7%% of prior 40200)', 'datetime': '2023-11-28T03:31:34.693376', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:34,699: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:34,699: updating layer weights
INFO - 2023-11-28 03:31:34,700: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:34.700096', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:34,700: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:34,700: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:34.700374', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:34,844: EPOCH 0: training on 40200 raw words (37276 effective words) took 0.1s, 263079 effective words/s
INFO - 2023-11-28 03:31:34,988: EPOCH 1: training on 40200 raw words (37251 effective words) took 0.1s, 262968 effective words/s
INFO - 2023-11-28 03:31:35,125: EPOCH 2: training on 40200 raw words (37254 effective words) took 0.1s, 276106 effective words/s
INFO - 2023-11-28 03:31:35,267: EPOCH 3: training on 40200 raw words (37323 effective words) took 0.1s, 267030 effective words/s
INFO - 2023-11-28 03:31:35,408: EPOCH 4: training on 40200 raw words (37381 effective words) took 0.1s, 269051 effective words/s
INFO - 2023-11-28 03:31:35,549: EPOCH 5: training on 40200 raw words (37333 effective words) took 0.1s, 268845 effective words/s
INFO - 2023-11-28 03:31:35,693: EPOCH 6: training on 40200 raw words (37321 effective words) took 0.1s, 262914 effective words/s
INFO - 2023-11-28 03:31:35,829: EPOCH 7: training on 40200 raw words (37215 effective words) took 0.1s, 278760 effective words/s
INFO - 2023-11-28 03:31:35,968: EPOCH 8: training on 40200 raw words (37289 effective words) took 0.1s, 272871 effective words/s
INFO - 2023-11-28 03:31:36,113: EPOCH 9: training on 40200 raw words (37290 effective words) took 0.1s, 261135 effective words/s
INFO - 2023-11-28 03:31:36,257: EPOCH 10: training on 40200 raw words (37212 effective words) took 0.1s, 262323 effective words/s
INFO - 2023-11-28 03:31:36,397: EPOCH 11: training on 40200 raw words (37311 effective words) took 0.1s, 271083 effective words/s
INFO - 2023-11-28 03:31:36,538: EPOCH 12: training on 40200 raw words (37241 effective words) took 0.1s, 268428 effective words/s
INFO - 2023-11-28 03:31:36,690: EPOCH 13: training on 40200 raw words (37227 effective words) took 0.2s, 247327 effective words/s
INFO - 2023-11-28 03:31:36,843: EPOCH 14: training on 40200 raw words (37233 effective words) took 0.1s, 248620 effective words/s
INFO - 2023-11-28 03:31:36,985: EPOCH 15: training on 40200 raw words (37292 effective words) took 0.1s, 266846 effective words/s
INFO - 2023-11-28 03:31:37,125: EPOCH 16: training on 40200 raw words (37270 effective words) took 0.1s, 278770 effective words/s
INFO - 2023-11-28 03:31:37,265: EPOCH 17: training on 40200 raw words (37340 effective words) took 0.1s, 270798 effective words/s
INFO - 2023-11-28 03:31:37,410: EPOCH 18: training on 40200 raw words (37238 effective words) took 0.1s, 261930 effective words/s
INFO - 2023-11-28 03:31:37,552: EPOCH 19: training on 40200 raw words (37232 effective words) took 0.1s, 266287 effective words/s
INFO - 2023-11-28 03:31:37,552: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745529 effective words) took 2.9s, 261399 effective words/s', 'datetime': '2023-11-28T03:31:37.552665', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:37,552: collecting all words and their counts
INFO - 2023-11-28 03:31:37,553: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:37,559: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:37,559: Updating model with new vocabulary
INFO - 2023-11-28 03:31:37,562: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:37.562950', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:37,566: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:37,566: sample=0.001 downsamples 67 most-common words
INFO - 2023-11-28 03:31:37,566: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37452.263120241136 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:31:37.566411', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:37,572: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:37,572: updating layer weights
INFO - 2023-11-28 03:31:37,572: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:37.572631', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:37,572: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:37,572: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:37.572857', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:37,703: EPOCH 0: training on 40200 raw words (37396 effective words) took 0.1s, 291235 effective words/s
INFO - 2023-11-28 03:31:37,839: EPOCH 1: training on 40200 raw words (37447 effective words) took 0.1s, 280740 effective words/s
INFO - 2023-11-28 03:31:37,975: EPOCH 2: training on 40200 raw words (37426 effective words) took 0.1s, 279751 effective words/s
INFO - 2023-11-28 03:31:38,109: EPOCH 3: training on 40200 raw words (37476 effective words) took 0.1s, 283193 effective words/s
INFO - 2023-11-28 03:31:38,245: EPOCH 4: training on 40200 raw words (37404 effective words) took 0.1s, 280968 effective words/s
INFO - 2023-11-28 03:31:38,372: EPOCH 5: training on 40200 raw words (37435 effective words) took 0.1s, 309730 effective words/s
INFO - 2023-11-28 03:31:38,506: EPOCH 6: training on 40200 raw words (37445 effective words) took 0.1s, 292738 effective words/s
INFO - 2023-11-28 03:31:38,638: EPOCH 7: training on 40200 raw words (37423 effective words) took 0.1s, 288948 effective words/s
INFO - 2023-11-28 03:31:38,775: EPOCH 8: training on 40200 raw words (37406 effective words) took 0.1s, 277490 effective words/s
INFO - 2023-11-28 03:31:38,904: EPOCH 9: training on 40200 raw words (37467 effective words) took 0.1s, 296472 effective words/s
INFO - 2023-11-28 03:31:39,041: EPOCH 10: training on 40200 raw words (37446 effective words) took 0.1s, 277037 effective words/s
INFO - 2023-11-28 03:31:39,173: EPOCH 11: training on 40200 raw words (37435 effective words) took 0.1s, 290032 effective words/s
INFO - 2023-11-28 03:31:39,309: EPOCH 12: training on 40200 raw words (37420 effective words) took 0.1s, 278480 effective words/s
INFO - 2023-11-28 03:31:39,450: EPOCH 13: training on 40200 raw words (37399 effective words) took 0.1s, 270023 effective words/s
INFO - 2023-11-28 03:31:39,584: EPOCH 14: training on 40200 raw words (37447 effective words) took 0.1s, 283420 effective words/s
INFO - 2023-11-28 03:31:39,722: EPOCH 15: training on 40200 raw words (37420 effective words) took 0.1s, 276451 effective words/s
INFO - 2023-11-28 03:31:39,858: EPOCH 16: training on 40200 raw words (37461 effective words) took 0.1s, 280138 effective words/s
INFO - 2023-11-28 03:31:39,987: EPOCH 17: training on 40200 raw words (37354 effective words) took 0.1s, 295589 effective words/s
INFO - 2023-11-28 03:31:40,116: EPOCH 18: training on 40200 raw words (37476 effective words) took 0.1s, 295155 effective words/s
INFO - 2023-11-28 03:31:40,249: EPOCH 19: training on 40200 raw words (37423 effective words) took 0.1s, 285929 effective words/s
INFO - 2023-11-28 03:31:40,250: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748606 effective words) took 2.7s, 279621 effective words/s', 'datetime': '2023-11-28T03:31:40.250182', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:40,250: collecting all words and their counts
INFO - 2023-11-28 03:31:40,250: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:40,257: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:40,257: Updating model with new vocabulary
INFO - 2023-11-28 03:31:40,260: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:40.260745', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:40,264: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:40,264: sample=0.001 downsamples 77 most-common words
INFO - 2023-11-28 03:31:40,264: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37203.46110044952 word corpus (92.5%% of prior 40200)', 'datetime': '2023-11-28T03:31:40.264422', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:40,270: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:40,270: updating layer weights
INFO - 2023-11-28 03:31:40,270: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:40.270698', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:40,270: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:40,270: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:40.270897', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:40,413: EPOCH 0: training on 40200 raw words (37293 effective words) took 0.1s, 265801 effective words/s
INFO - 2023-11-28 03:31:40,558: EPOCH 1: training on 40200 raw words (37195 effective words) took 0.1s, 261094 effective words/s
INFO - 2023-11-28 03:31:40,695: EPOCH 2: training on 40200 raw words (37188 effective words) took 0.1s, 274364 effective words/s
INFO - 2023-11-28 03:31:40,833: EPOCH 3: training on 40200 raw words (37276 effective words) took 0.1s, 275061 effective words/s
INFO - 2023-11-28 03:31:40,971: EPOCH 4: training on 40200 raw words (37236 effective words) took 0.1s, 273667 effective words/s
INFO - 2023-11-28 03:31:41,111: EPOCH 5: training on 40200 raw words (37217 effective words) took 0.1s, 270003 effective words/s
INFO - 2023-11-28 03:31:41,245: EPOCH 6: training on 40200 raw words (37159 effective words) took 0.1s, 281558 effective words/s
INFO - 2023-11-28 03:31:41,389: EPOCH 7: training on 40200 raw words (37190 effective words) took 0.1s, 262242 effective words/s
INFO - 2023-11-28 03:31:41,534: EPOCH 8: training on 40200 raw words (37227 effective words) took 0.1s, 262012 effective words/s
INFO - 2023-11-28 03:31:41,678: EPOCH 9: training on 40200 raw words (37154 effective words) took 0.1s, 260814 effective words/s
INFO - 2023-11-28 03:31:41,821: EPOCH 10: training on 40200 raw words (37251 effective words) took 0.1s, 265062 effective words/s
INFO - 2023-11-28 03:31:41,959: EPOCH 11: training on 40200 raw words (37222 effective words) took 0.1s, 275094 effective words/s
INFO - 2023-11-28 03:31:42,100: EPOCH 12: training on 40200 raw words (37211 effective words) took 0.1s, 268539 effective words/s
INFO - 2023-11-28 03:31:42,241: EPOCH 13: training on 40200 raw words (37284 effective words) took 0.1s, 267643 effective words/s
INFO - 2023-11-28 03:31:42,383: EPOCH 14: training on 40200 raw words (37152 effective words) took 0.1s, 265781 effective words/s
INFO - 2023-11-28 03:31:42,528: EPOCH 15: training on 40200 raw words (37187 effective words) took 0.1s, 260404 effective words/s
INFO - 2023-11-28 03:31:42,672: EPOCH 16: training on 40200 raw words (37288 effective words) took 0.1s, 263615 effective words/s
INFO - 2023-11-28 03:31:42,812: EPOCH 17: training on 40200 raw words (37175 effective words) took 0.1s, 270163 effective words/s
INFO - 2023-11-28 03:31:42,955: EPOCH 18: training on 40200 raw words (37196 effective words) took 0.1s, 262980 effective words/s
INFO - 2023-11-28 03:31:43,102: EPOCH 19: training on 40200 raw words (37266 effective words) took 0.1s, 258139 effective words/s
INFO - 2023-11-28 03:31:43,102: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (744367 effective words) took 2.8s, 262891 effective words/s', 'datetime': '2023-11-28T03:31:43.102476', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:43,102: collecting all words and their counts
INFO - 2023-11-28 03:31:43,102: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:43,108: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:43,108: Updating model with new vocabulary
INFO - 2023-11-28 03:31:43,112: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:43.112037', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:43,115: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:43,115: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:31:43,115: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37325.77353849914 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:43.115667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:43,121: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:43,121: updating layer weights
INFO - 2023-11-28 03:31:43,122: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:43.122173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:43,122: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:43,122: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:43.122416', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:43,252: EPOCH 0: training on 40200 raw words (37320 effective words) took 0.1s, 291373 effective words/s
INFO - 2023-11-28 03:31:43,388: EPOCH 1: training on 40200 raw words (37363 effective words) took 0.1s, 279629 effective words/s
INFO - 2023-11-28 03:31:43,518: EPOCH 2: training on 40200 raw words (37264 effective words) took 0.1s, 292578 effective words/s
INFO - 2023-11-28 03:31:43,655: EPOCH 3: training on 40200 raw words (37262 effective words) took 0.1s, 277720 effective words/s
INFO - 2023-11-28 03:31:43,790: EPOCH 4: training on 40200 raw words (37348 effective words) took 0.1s, 281768 effective words/s
INFO - 2023-11-28 03:31:43,928: EPOCH 5: training on 40200 raw words (37389 effective words) took 0.1s, 276660 effective words/s
INFO - 2023-11-28 03:31:44,055: EPOCH 6: training on 40200 raw words (37261 effective words) took 0.1s, 300624 effective words/s
INFO - 2023-11-28 03:31:44,195: EPOCH 7: training on 40200 raw words (37353 effective words) took 0.1s, 271071 effective words/s
INFO - 2023-11-28 03:31:44,335: EPOCH 8: training on 40200 raw words (37332 effective words) took 0.1s, 269899 effective words/s
INFO - 2023-11-28 03:31:44,474: EPOCH 9: training on 40200 raw words (37311 effective words) took 0.1s, 272751 effective words/s
INFO - 2023-11-28 03:31:44,612: EPOCH 10: training on 40200 raw words (37327 effective words) took 0.1s, 275150 effective words/s
INFO - 2023-11-28 03:31:44,748: EPOCH 11: training on 40200 raw words (37264 effective words) took 0.1s, 278429 effective words/s
INFO - 2023-11-28 03:31:44,885: EPOCH 12: training on 40200 raw words (37395 effective words) took 0.1s, 278262 effective words/s
INFO - 2023-11-28 03:31:45,021: EPOCH 13: training on 40200 raw words (37347 effective words) took 0.1s, 278772 effective words/s
INFO - 2023-11-28 03:31:45,158: EPOCH 14: training on 40200 raw words (37355 effective words) took 0.1s, 276650 effective words/s
INFO - 2023-11-28 03:31:45,289: EPOCH 15: training on 40200 raw words (37317 effective words) took 0.1s, 291247 effective words/s
INFO - 2023-11-28 03:31:45,424: EPOCH 16: training on 40200 raw words (37359 effective words) took 0.1s, 280368 effective words/s
INFO - 2023-11-28 03:31:45,561: EPOCH 17: training on 40200 raw words (37359 effective words) took 0.1s, 277715 effective words/s
INFO - 2023-11-28 03:31:45,692: EPOCH 18: training on 40200 raw words (37353 effective words) took 0.1s, 291037 effective words/s
INFO - 2023-11-28 03:31:45,831: EPOCH 19: training on 40200 raw words (37409 effective words) took 0.1s, 272259 effective words/s
INFO - 2023-11-28 03:31:45,832: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746688 effective words) took 2.7s, 275585 effective words/s', 'datetime': '2023-11-28T03:31:45.831999', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:45,832: collecting all words and their counts
INFO - 2023-11-28 03:31:45,832: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:45,839: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:45,839: Updating model with new vocabulary
INFO - 2023-11-28 03:31:45,843: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:45.843321', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:45,847: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:45,847: sample=0.001 downsamples 80 most-common words
INFO - 2023-11-28 03:31:45,847: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37341.00120760231 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:45.847513', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:45,853: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:45,853: updating layer weights
INFO - 2023-11-28 03:31:45,853: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:45.853781', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:45,853: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:45,853: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:45.853980', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:46,000: EPOCH 0: training on 40200 raw words (37310 effective words) took 0.1s, 258687 effective words/s
INFO - 2023-11-28 03:31:46,147: EPOCH 1: training on 40200 raw words (37390 effective words) took 0.1s, 258064 effective words/s
INFO - 2023-11-28 03:31:46,291: EPOCH 2: training on 40200 raw words (37325 effective words) took 0.1s, 263151 effective words/s
INFO - 2023-11-28 03:31:46,434: EPOCH 3: training on 40200 raw words (37247 effective words) took 0.1s, 265571 effective words/s
INFO - 2023-11-28 03:31:46,575: EPOCH 4: training on 40200 raw words (37375 effective words) took 0.1s, 269048 effective words/s
INFO - 2023-11-28 03:31:46,720: EPOCH 5: training on 40200 raw words (37312 effective words) took 0.1s, 261131 effective words/s
INFO - 2023-11-28 03:31:46,863: EPOCH 6: training on 40200 raw words (37416 effective words) took 0.1s, 266318 effective words/s
INFO - 2023-11-28 03:31:47,001: EPOCH 7: training on 40200 raw words (37271 effective words) took 0.1s, 274967 effective words/s
INFO - 2023-11-28 03:31:47,140: EPOCH 8: training on 40200 raw words (37361 effective words) took 0.1s, 273360 effective words/s
INFO - 2023-11-28 03:31:47,283: EPOCH 9: training on 40200 raw words (37355 effective words) took 0.1s, 266279 effective words/s
INFO - 2023-11-28 03:31:47,419: EPOCH 10: training on 40200 raw words (37387 effective words) took 0.1s, 278269 effective words/s
INFO - 2023-11-28 03:31:47,564: EPOCH 11: training on 40200 raw words (37454 effective words) took 0.1s, 263051 effective words/s
INFO - 2023-11-28 03:31:47,705: EPOCH 12: training on 40200 raw words (37336 effective words) took 0.1s, 267773 effective words/s
INFO - 2023-11-28 03:31:47,858: EPOCH 13: training on 40200 raw words (37285 effective words) took 0.2s, 247790 effective words/s
INFO - 2023-11-28 03:31:47,993: EPOCH 14: training on 40200 raw words (37353 effective words) took 0.1s, 281598 effective words/s
INFO - 2023-11-28 03:31:48,128: EPOCH 15: training on 40200 raw words (37309 effective words) took 0.1s, 280974 effective words/s
INFO - 2023-11-28 03:31:48,270: EPOCH 16: training on 40200 raw words (37378 effective words) took 0.1s, 267365 effective words/s
INFO - 2023-11-28 03:31:48,414: EPOCH 17: training on 40200 raw words (37373 effective words) took 0.1s, 263746 effective words/s
INFO - 2023-11-28 03:31:48,556: EPOCH 18: training on 40200 raw words (37350 effective words) took 0.1s, 267183 effective words/s
INFO - 2023-11-28 03:31:48,696: EPOCH 19: training on 40200 raw words (37274 effective words) took 0.1s, 269578 effective words/s
INFO - 2023-11-28 03:31:48,696: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746861 effective words) took 2.8s, 262739 effective words/s', 'datetime': '2023-11-28T03:31:48.696680', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:48,696: collecting all words and their counts
INFO - 2023-11-28 03:31:48,697: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:48,703: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:48,703: Updating model with new vocabulary
INFO - 2023-11-28 03:31:48,707: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:48.707117', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:48,711: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:48,711: sample=0.001 downsamples 82 most-common words
INFO - 2023-11-28 03:31:48,711: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37317.23425905689 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:31:48.711674', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:48,718: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:48,718: updating layer weights
INFO - 2023-11-28 03:31:48,718: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:48.718266', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:48,718: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:48,718: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:48.718444', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:48,848: EPOCH 0: training on 40200 raw words (37281 effective words) took 0.1s, 305109 effective words/s
INFO - 2023-11-28 03:31:48,989: EPOCH 1: training on 40200 raw words (37291 effective words) took 0.1s, 269168 effective words/s
INFO - 2023-11-28 03:31:49,117: EPOCH 2: training on 40200 raw words (37360 effective words) took 0.1s, 297605 effective words/s
INFO - 2023-11-28 03:31:49,252: EPOCH 3: training on 40200 raw words (37361 effective words) took 0.1s, 280170 effective words/s
INFO - 2023-11-28 03:31:49,388: EPOCH 4: training on 40200 raw words (37332 effective words) took 0.1s, 279697 effective words/s
INFO - 2023-11-28 03:31:49,520: EPOCH 5: training on 40200 raw words (37437 effective words) took 0.1s, 288288 effective words/s
INFO - 2023-11-28 03:31:49,659: EPOCH 6: training on 40200 raw words (37292 effective words) took 0.1s, 272402 effective words/s
INFO - 2023-11-28 03:31:49,795: EPOCH 7: training on 40200 raw words (37318 effective words) took 0.1s, 279593 effective words/s
INFO - 2023-11-28 03:31:49,936: EPOCH 8: training on 40200 raw words (37334 effective words) took 0.1s, 269801 effective words/s
INFO - 2023-11-28 03:31:50,074: EPOCH 9: training on 40200 raw words (37322 effective words) took 0.1s, 274744 effective words/s
INFO - 2023-11-28 03:31:50,207: EPOCH 10: training on 40200 raw words (37301 effective words) took 0.1s, 285334 effective words/s
INFO - 2023-11-28 03:31:50,342: EPOCH 11: training on 40200 raw words (37316 effective words) took 0.1s, 291237 effective words/s
INFO - 2023-11-28 03:31:50,478: EPOCH 12: training on 40200 raw words (37281 effective words) took 0.1s, 279925 effective words/s
INFO - 2023-11-28 03:31:50,612: EPOCH 13: training on 40200 raw words (37336 effective words) took 0.1s, 282207 effective words/s
INFO - 2023-11-28 03:31:50,747: EPOCH 14: training on 40200 raw words (37371 effective words) took 0.1s, 294929 effective words/s
INFO - 2023-11-28 03:31:50,882: EPOCH 15: training on 40200 raw words (37359 effective words) took 0.1s, 279393 effective words/s
INFO - 2023-11-28 03:31:51,016: EPOCH 16: training on 40200 raw words (37326 effective words) took 0.1s, 283967 effective words/s
INFO - 2023-11-28 03:31:51,152: EPOCH 17: training on 40200 raw words (37313 effective words) took 0.1s, 279164 effective words/s
INFO - 2023-11-28 03:31:51,289: EPOCH 18: training on 40200 raw words (37340 effective words) took 0.1s, 277298 effective words/s
INFO - 2023-11-28 03:31:51,423: EPOCH 19: training on 40200 raw words (37339 effective words) took 0.1s, 283960 effective words/s
INFO - 2023-11-28 03:31:51,423: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746610 effective words) took 2.7s, 276030 effective words/s', 'datetime': '2023-11-28T03:31:51.423372', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:51,423: collecting all words and their counts
INFO - 2023-11-28 03:31:51,423: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:51,430: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:51,430: Updating model with new vocabulary
INFO - 2023-11-28 03:31:51,433: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:51.433445', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:51,437: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:51,437: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:31:51,437: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37338.2881192402 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:31:51.437446', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:51,445: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:51,445: updating layer weights
INFO - 2023-11-28 03:31:51,446: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:51.446173', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:51,446: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:51,446: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:51.446435', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:51,581: EPOCH 0: training on 40200 raw words (37281 effective words) took 0.1s, 280328 effective words/s
INFO - 2023-11-28 03:31:51,722: EPOCH 1: training on 40200 raw words (37363 effective words) took 0.1s, 268181 effective words/s
INFO - 2023-11-28 03:31:51,867: EPOCH 2: training on 40200 raw words (37430 effective words) took 0.1s, 263444 effective words/s
INFO - 2023-11-28 03:31:52,039: EPOCH 3: training on 40200 raw words (37379 effective words) took 0.2s, 219687 effective words/s
INFO - 2023-11-28 03:31:52,174: EPOCH 4: training on 40200 raw words (37331 effective words) took 0.1s, 280476 effective words/s
INFO - 2023-11-28 03:31:52,321: EPOCH 5: training on 40200 raw words (37429 effective words) took 0.1s, 258269 effective words/s
INFO - 2023-11-28 03:31:52,465: EPOCH 6: training on 40200 raw words (37352 effective words) took 0.1s, 263846 effective words/s
INFO - 2023-11-28 03:31:52,597: EPOCH 7: training on 40200 raw words (37297 effective words) took 0.1s, 287199 effective words/s
INFO - 2023-11-28 03:31:52,744: EPOCH 8: training on 40200 raw words (37327 effective words) took 0.1s, 258506 effective words/s
INFO - 2023-11-28 03:31:52,890: EPOCH 9: training on 40200 raw words (37320 effective words) took 0.1s, 258881 effective words/s
INFO - 2023-11-28 03:31:53,028: EPOCH 10: training on 40200 raw words (37348 effective words) took 0.1s, 274667 effective words/s
INFO - 2023-11-28 03:31:53,171: EPOCH 11: training on 40200 raw words (37334 effective words) took 0.1s, 264716 effective words/s
INFO - 2023-11-28 03:31:53,320: EPOCH 12: training on 40200 raw words (37362 effective words) took 0.1s, 255504 effective words/s
INFO - 2023-11-28 03:31:53,457: EPOCH 13: training on 40200 raw words (37320 effective words) took 0.1s, 275987 effective words/s
INFO - 2023-11-28 03:31:53,598: EPOCH 14: training on 40200 raw words (37338 effective words) took 0.1s, 270174 effective words/s
INFO - 2023-11-28 03:31:53,742: EPOCH 15: training on 40200 raw words (37351 effective words) took 0.1s, 262950 effective words/s
INFO - 2023-11-28 03:31:53,887: EPOCH 16: training on 40200 raw words (37322 effective words) took 0.1s, 261979 effective words/s
INFO - 2023-11-28 03:31:54,029: EPOCH 17: training on 40200 raw words (37305 effective words) took 0.1s, 267704 effective words/s
INFO - 2023-11-28 03:31:54,174: EPOCH 18: training on 40200 raw words (37394 effective words) took 0.1s, 261935 effective words/s
INFO - 2023-11-28 03:31:54,317: EPOCH 19: training on 40200 raw words (37379 effective words) took 0.1s, 265541 effective words/s
INFO - 2023-11-28 03:31:54,317: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746962 effective words) took 2.9s, 260167 effective words/s', 'datetime': '2023-11-28T03:31:54.317641', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:54,317: collecting all words and their counts
INFO - 2023-11-28 03:31:54,318: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:54,324: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:54,324: Updating model with new vocabulary
INFO - 2023-11-28 03:31:54,327: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:54.327969', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:54,332: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:54,332: sample=0.001 downsamples 69 most-common words
INFO - 2023-11-28 03:31:54,332: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37424.02334142245 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:31:54.332510', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:54,338: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:54,338: updating layer weights
INFO - 2023-11-28 03:31:54,338: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:54.338327', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:54,338: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:54,338: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:54.338522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:54,478: EPOCH 0: training on 40200 raw words (37423 effective words) took 0.1s, 271032 effective words/s
INFO - 2023-11-28 03:31:54,614: EPOCH 1: training on 40200 raw words (37410 effective words) took 0.1s, 280681 effective words/s
INFO - 2023-11-28 03:31:54,750: EPOCH 2: training on 40200 raw words (37433 effective words) took 0.1s, 279235 effective words/s
INFO - 2023-11-28 03:31:54,888: EPOCH 3: training on 40200 raw words (37399 effective words) took 0.1s, 275785 effective words/s
INFO - 2023-11-28 03:31:55,015: EPOCH 4: training on 40200 raw words (37404 effective words) took 0.1s, 302292 effective words/s
INFO - 2023-11-28 03:31:55,151: EPOCH 5: training on 40200 raw words (37447 effective words) took 0.1s, 280061 effective words/s
INFO - 2023-11-28 03:31:55,290: EPOCH 6: training on 40200 raw words (37449 effective words) took 0.1s, 273406 effective words/s
INFO - 2023-11-28 03:31:55,428: EPOCH 7: training on 40200 raw words (37412 effective words) took 0.1s, 275727 effective words/s
INFO - 2023-11-28 03:31:55,553: EPOCH 8: training on 40200 raw words (37394 effective words) took 0.1s, 304142 effective words/s
INFO - 2023-11-28 03:31:55,688: EPOCH 9: training on 40200 raw words (37390 effective words) took 0.1s, 281150 effective words/s
INFO - 2023-11-28 03:31:55,816: EPOCH 10: training on 40200 raw words (37414 effective words) took 0.1s, 297251 effective words/s
INFO - 2023-11-28 03:31:55,949: EPOCH 11: training on 40200 raw words (37490 effective words) took 0.1s, 286459 effective words/s
INFO - 2023-11-28 03:31:56,072: EPOCH 12: training on 40200 raw words (37400 effective words) took 0.1s, 309736 effective words/s
INFO - 2023-11-28 03:31:56,209: EPOCH 13: training on 40200 raw words (37409 effective words) took 0.1s, 277872 effective words/s
INFO - 2023-11-28 03:31:56,346: EPOCH 14: training on 40200 raw words (37435 effective words) took 0.1s, 276425 effective words/s
INFO - 2023-11-28 03:31:56,486: EPOCH 15: training on 40200 raw words (37443 effective words) took 0.1s, 273128 effective words/s
INFO - 2023-11-28 03:31:56,614: EPOCH 16: training on 40200 raw words (37403 effective words) took 0.1s, 296143 effective words/s
INFO - 2023-11-28 03:31:56,745: EPOCH 17: training on 40200 raw words (37397 effective words) took 0.1s, 289586 effective words/s
INFO - 2023-11-28 03:31:56,866: EPOCH 18: training on 40200 raw words (37441 effective words) took 0.1s, 314668 effective words/s
INFO - 2023-11-28 03:31:57,004: EPOCH 19: training on 40200 raw words (37422 effective words) took 0.1s, 274714 effective words/s
INFO - 2023-11-28 03:31:57,005: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748415 effective words) took 2.7s, 280687 effective words/s', 'datetime': '2023-11-28T03:31:57.005002', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:57,005: collecting all words and their counts
INFO - 2023-11-28 03:31:57,005: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:57,010: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:57,011: Updating model with new vocabulary
INFO - 2023-11-28 03:31:57,013: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:57.013879', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:57,017: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:57,017: sample=0.001 downsamples 77 most-common words
INFO - 2023-11-28 03:31:57,017: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37293.44270726788 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:31:57.017385', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:57,022: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:57,022: updating layer weights
INFO - 2023-11-28 03:31:57,023: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:57.023048', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:57,023: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:57,023: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:57.023260', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:57,160: EPOCH 0: training on 40200 raw words (37241 effective words) took 0.1s, 282971 effective words/s
INFO - 2023-11-28 03:31:57,306: EPOCH 1: training on 40200 raw words (37301 effective words) took 0.1s, 260596 effective words/s
INFO - 2023-11-28 03:31:57,451: EPOCH 2: training on 40200 raw words (37311 effective words) took 0.1s, 260820 effective words/s
INFO - 2023-11-28 03:31:57,589: EPOCH 3: training on 40200 raw words (37248 effective words) took 0.1s, 273431 effective words/s
INFO - 2023-11-28 03:31:57,724: EPOCH 4: training on 40200 raw words (37327 effective words) took 0.1s, 282302 effective words/s
INFO - 2023-11-28 03:31:57,864: EPOCH 5: training on 40200 raw words (37221 effective words) took 0.1s, 268790 effective words/s
INFO - 2023-11-28 03:31:58,010: EPOCH 6: training on 40200 raw words (37208 effective words) took 0.1s, 259793 effective words/s
INFO - 2023-11-28 03:31:58,155: EPOCH 7: training on 40200 raw words (37352 effective words) took 0.1s, 261607 effective words/s
INFO - 2023-11-28 03:31:58,289: EPOCH 8: training on 40200 raw words (37295 effective words) took 0.1s, 282813 effective words/s
INFO - 2023-11-28 03:31:58,432: EPOCH 9: training on 40200 raw words (37354 effective words) took 0.1s, 265691 effective words/s
INFO - 2023-11-28 03:31:58,576: EPOCH 10: training on 40200 raw words (37304 effective words) took 0.1s, 262659 effective words/s
INFO - 2023-11-28 03:31:58,723: EPOCH 11: training on 40200 raw words (37299 effective words) took 0.1s, 258681 effective words/s
INFO - 2023-11-28 03:31:58,867: EPOCH 12: training on 40200 raw words (37255 effective words) took 0.1s, 262502 effective words/s
INFO - 2023-11-28 03:31:59,012: EPOCH 13: training on 40200 raw words (37299 effective words) took 0.1s, 262111 effective words/s
INFO - 2023-11-28 03:31:59,160: EPOCH 14: training on 40200 raw words (37264 effective words) took 0.1s, 255127 effective words/s
INFO - 2023-11-28 03:31:59,299: EPOCH 15: training on 40200 raw words (37265 effective words) took 0.1s, 272838 effective words/s
INFO - 2023-11-28 03:31:59,446: EPOCH 16: training on 40200 raw words (37280 effective words) took 0.1s, 256687 effective words/s
INFO - 2023-11-28 03:31:59,589: EPOCH 17: training on 40200 raw words (37269 effective words) took 0.1s, 264341 effective words/s
INFO - 2023-11-28 03:31:59,728: EPOCH 18: training on 40200 raw words (37322 effective words) took 0.1s, 272908 effective words/s
INFO - 2023-11-28 03:31:59,865: EPOCH 19: training on 40200 raw words (37235 effective words) took 0.1s, 275955 effective words/s
INFO - 2023-11-28 03:31:59,866: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745650 effective words) took 2.8s, 262312 effective words/s', 'datetime': '2023-11-28T03:31:59.865977', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:31:59,866: collecting all words and their counts
INFO - 2023-11-28 03:31:59,866: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:31:59,872: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:31:59,872: Updating model with new vocabulary
INFO - 2023-11-28 03:31:59,875: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:31:59.875481', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:59,878: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:31:59,878: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:31:59,878: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37405.23893544666 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:31:59.878927', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:31:59,884: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:31:59,884: updating layer weights
INFO - 2023-11-28 03:31:59,884: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:31:59.884539', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:31:59,884: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:31:59,884: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:31:59.884742', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:00,023: EPOCH 0: training on 40200 raw words (37361 effective words) took 0.1s, 273416 effective words/s
INFO - 2023-11-28 03:32:00,150: EPOCH 1: training on 40200 raw words (37408 effective words) took 0.1s, 298751 effective words/s
INFO - 2023-11-28 03:32:00,289: EPOCH 2: training on 40200 raw words (37452 effective words) took 0.1s, 273895 effective words/s
INFO - 2023-11-28 03:32:00,415: EPOCH 3: training on 40200 raw words (37412 effective words) took 0.1s, 302708 effective words/s
INFO - 2023-11-28 03:32:00,552: EPOCH 4: training on 40200 raw words (37444 effective words) took 0.1s, 278365 effective words/s
INFO - 2023-11-28 03:32:00,688: EPOCH 5: training on 40200 raw words (37435 effective words) took 0.1s, 279424 effective words/s
INFO - 2023-11-28 03:32:00,823: EPOCH 6: training on 40200 raw words (37448 effective words) took 0.1s, 282545 effective words/s
INFO - 2023-11-28 03:32:00,954: EPOCH 7: training on 40200 raw words (37397 effective words) took 0.1s, 290372 effective words/s
INFO - 2023-11-28 03:32:01,091: EPOCH 8: training on 40200 raw words (37428 effective words) took 0.1s, 279015 effective words/s
INFO - 2023-11-28 03:32:01,229: EPOCH 9: training on 40200 raw words (37366 effective words) took 0.1s, 274098 effective words/s
INFO - 2023-11-28 03:32:01,372: EPOCH 10: training on 40200 raw words (37403 effective words) took 0.1s, 266750 effective words/s
INFO - 2023-11-28 03:32:01,502: EPOCH 11: training on 40200 raw words (37345 effective words) took 0.1s, 291802 effective words/s
INFO - 2023-11-28 03:32:01,638: EPOCH 12: training on 40200 raw words (37338 effective words) took 0.1s, 278034 effective words/s
INFO - 2023-11-28 03:32:01,775: EPOCH 13: training on 40200 raw words (37393 effective words) took 0.1s, 277880 effective words/s
INFO - 2023-11-28 03:32:01,904: EPOCH 14: training on 40200 raw words (37443 effective words) took 0.1s, 295720 effective words/s
INFO - 2023-11-28 03:32:02,040: EPOCH 15: training on 40200 raw words (37379 effective words) took 0.1s, 280294 effective words/s
INFO - 2023-11-28 03:32:02,168: EPOCH 16: training on 40200 raw words (37439 effective words) took 0.1s, 296574 effective words/s
INFO - 2023-11-28 03:32:02,304: EPOCH 17: training on 40200 raw words (37340 effective words) took 0.1s, 279415 effective words/s
INFO - 2023-11-28 03:32:02,444: EPOCH 18: training on 40200 raw words (37450 effective words) took 0.1s, 271388 effective words/s
INFO - 2023-11-28 03:32:02,579: EPOCH 19: training on 40200 raw words (37368 effective words) took 0.1s, 282771 effective words/s
INFO - 2023-11-28 03:32:02,579: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748049 effective words) took 2.7s, 277611 effective words/s', 'datetime': '2023-11-28T03:32:02.579439', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:02,579: collecting all words and their counts
INFO - 2023-11-28 03:32:02,579: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:02,586: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:02,586: Updating model with new vocabulary
INFO - 2023-11-28 03:32:02,590: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:02.590432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:02,594: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:02,594: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:32:02,594: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37365.85031605356 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:32:02.594352', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:02,600: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:02,600: updating layer weights
INFO - 2023-11-28 03:32:02,600: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:02.600827', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:02,600: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:02,601: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:02.601019', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:02,831: EPOCH 0: training on 40200 raw words (37389 effective words) took 0.2s, 164069 effective words/s
INFO - 2023-11-28 03:32:02,970: EPOCH 1: training on 40200 raw words (37326 effective words) took 0.1s, 272164 effective words/s
INFO - 2023-11-28 03:32:03,121: EPOCH 2: training on 40200 raw words (37358 effective words) took 0.1s, 250845 effective words/s
INFO - 2023-11-28 03:32:03,256: EPOCH 3: training on 40200 raw words (37361 effective words) took 0.1s, 282742 effective words/s
INFO - 2023-11-28 03:32:03,397: EPOCH 4: training on 40200 raw words (37352 effective words) took 0.1s, 268577 effective words/s
INFO - 2023-11-28 03:32:03,540: EPOCH 5: training on 40200 raw words (37405 effective words) took 0.1s, 264785 effective words/s
INFO - 2023-11-28 03:32:03,679: EPOCH 6: training on 40200 raw words (37393 effective words) took 0.1s, 275062 effective words/s
INFO - 2023-11-28 03:32:03,816: EPOCH 7: training on 40200 raw words (37393 effective words) took 0.1s, 275301 effective words/s
INFO - 2023-11-28 03:32:03,957: EPOCH 8: training on 40200 raw words (37372 effective words) took 0.1s, 268948 effective words/s
INFO - 2023-11-28 03:32:04,091: EPOCH 9: training on 40200 raw words (37392 effective words) took 0.1s, 284689 effective words/s
INFO - 2023-11-28 03:32:04,237: EPOCH 10: training on 40200 raw words (37366 effective words) took 0.1s, 259761 effective words/s
INFO - 2023-11-28 03:32:04,381: EPOCH 11: training on 40200 raw words (37336 effective words) took 0.1s, 264493 effective words/s
INFO - 2023-11-28 03:32:04,525: EPOCH 12: training on 40200 raw words (37309 effective words) took 0.1s, 263383 effective words/s
INFO - 2023-11-28 03:32:04,668: EPOCH 13: training on 40200 raw words (37348 effective words) took 0.1s, 264029 effective words/s
INFO - 2023-11-28 03:32:04,812: EPOCH 14: training on 40200 raw words (37285 effective words) took 0.1s, 263617 effective words/s
INFO - 2023-11-28 03:32:04,953: EPOCH 15: training on 40200 raw words (37313 effective words) took 0.1s, 268900 effective words/s
INFO - 2023-11-28 03:32:05,095: EPOCH 16: training on 40200 raw words (37395 effective words) took 0.1s, 268062 effective words/s
INFO - 2023-11-28 03:32:05,240: EPOCH 17: training on 40200 raw words (37337 effective words) took 0.1s, 262540 effective words/s
INFO - 2023-11-28 03:32:05,385: EPOCH 18: training on 40200 raw words (37370 effective words) took 0.1s, 261649 effective words/s
INFO - 2023-11-28 03:32:05,527: EPOCH 19: training on 40200 raw words (37451 effective words) took 0.1s, 271458 effective words/s
INFO - 2023-11-28 03:32:05,528: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747251 effective words) took 2.9s, 255304 effective words/s', 'datetime': '2023-11-28T03:32:05.528041', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:05,528: collecting all words and their counts
INFO - 2023-11-28 03:32:05,528: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:05,534: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:05,534: Updating model with new vocabulary
INFO - 2023-11-28 03:32:05,537: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:05.537689', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:05,541: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:05,541: sample=0.001 downsamples 77 most-common words
INFO - 2023-11-28 03:32:05,541: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37317.568943835075 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:32:05.541282', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:05,546: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:05,546: updating layer weights
INFO - 2023-11-28 03:32:05,546: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:05.546895', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:05,547: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:05,547: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:05.547108', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:05,680: EPOCH 0: training on 40200 raw words (37323 effective words) took 0.1s, 285027 effective words/s
INFO - 2023-11-28 03:32:05,813: EPOCH 1: training on 40200 raw words (37387 effective words) took 0.1s, 286150 effective words/s
INFO - 2023-11-28 03:32:05,945: EPOCH 2: training on 40200 raw words (37277 effective words) took 0.1s, 284944 effective words/s
INFO - 2023-11-28 03:32:06,081: EPOCH 3: training on 40200 raw words (37298 effective words) took 0.1s, 280804 effective words/s
INFO - 2023-11-28 03:32:06,224: EPOCH 4: training on 40200 raw words (37342 effective words) took 0.1s, 265414 effective words/s
INFO - 2023-11-28 03:32:06,358: EPOCH 5: training on 40200 raw words (37391 effective words) took 0.1s, 282907 effective words/s
INFO - 2023-11-28 03:32:06,493: EPOCH 6: training on 40200 raw words (37322 effective words) took 0.1s, 282346 effective words/s
INFO - 2023-11-28 03:32:06,624: EPOCH 7: training on 40200 raw words (37250 effective words) took 0.1s, 289725 effective words/s
INFO - 2023-11-28 03:32:06,760: EPOCH 8: training on 40200 raw words (37359 effective words) took 0.1s, 279804 effective words/s
INFO - 2023-11-28 03:32:06,896: EPOCH 9: training on 40200 raw words (37266 effective words) took 0.1s, 278187 effective words/s
INFO - 2023-11-28 03:32:07,034: EPOCH 10: training on 40200 raw words (37308 effective words) took 0.1s, 277550 effective words/s
INFO - 2023-11-28 03:32:07,164: EPOCH 11: training on 40200 raw words (37302 effective words) took 0.1s, 290642 effective words/s
INFO - 2023-11-28 03:32:07,299: EPOCH 12: training on 40200 raw words (37267 effective words) took 0.1s, 286794 effective words/s
INFO - 2023-11-28 03:32:07,435: EPOCH 13: training on 40200 raw words (37338 effective words) took 0.1s, 280845 effective words/s
INFO - 2023-11-28 03:32:07,572: EPOCH 14: training on 40200 raw words (37258 effective words) took 0.1s, 277319 effective words/s
INFO - 2023-11-28 03:32:07,710: EPOCH 15: training on 40200 raw words (37320 effective words) took 0.1s, 274231 effective words/s
INFO - 2023-11-28 03:32:07,842: EPOCH 16: training on 40200 raw words (37294 effective words) took 0.1s, 295427 effective words/s
INFO - 2023-11-28 03:32:07,979: EPOCH 17: training on 40200 raw words (37328 effective words) took 0.1s, 277276 effective words/s
INFO - 2023-11-28 03:32:08,121: EPOCH 18: training on 40200 raw words (37293 effective words) took 0.1s, 267010 effective words/s
INFO - 2023-11-28 03:32:08,256: EPOCH 19: training on 40200 raw words (37330 effective words) took 0.1s, 281339 effective words/s
INFO - 2023-11-28 03:32:08,256: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746253 effective words) took 2.7s, 275438 effective words/s', 'datetime': '2023-11-28T03:32:08.256559', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:08,256: collecting all words and their counts
INFO - 2023-11-28 03:32:08,256: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:08,263: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:08,263: Updating model with new vocabulary
INFO - 2023-11-28 03:32:08,267: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:08.267186', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:08,271: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:08,271: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:32:08,271: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37423.56385663859 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:08.271290', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:08,277: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:08,277: updating layer weights
INFO - 2023-11-28 03:32:08,278: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:08.278017', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:08,278: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:08,278: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:08.278201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:08,421: EPOCH 0: training on 40200 raw words (37402 effective words) took 0.1s, 265180 effective words/s
INFO - 2023-11-28 03:32:08,563: EPOCH 1: training on 40200 raw words (37531 effective words) took 0.1s, 268910 effective words/s
INFO - 2023-11-28 03:32:08,716: EPOCH 2: training on 40200 raw words (37485 effective words) took 0.2s, 249369 effective words/s
INFO - 2023-11-28 03:32:08,860: EPOCH 3: training on 40200 raw words (37444 effective words) took 0.1s, 265670 effective words/s
INFO - 2023-11-28 03:32:09,002: EPOCH 4: training on 40200 raw words (37357 effective words) took 0.1s, 265696 effective words/s
INFO - 2023-11-28 03:32:09,146: EPOCH 5: training on 40200 raw words (37465 effective words) took 0.1s, 266177 effective words/s
INFO - 2023-11-28 03:32:09,292: EPOCH 6: training on 40200 raw words (37438 effective words) took 0.1s, 261638 effective words/s
INFO - 2023-11-28 03:32:09,435: EPOCH 7: training on 40200 raw words (37499 effective words) took 0.1s, 265396 effective words/s
INFO - 2023-11-28 03:32:09,583: EPOCH 8: training on 40200 raw words (37498 effective words) took 0.1s, 258163 effective words/s
INFO - 2023-11-28 03:32:09,727: EPOCH 9: training on 40200 raw words (37426 effective words) took 0.1s, 264679 effective words/s
INFO - 2023-11-28 03:32:09,876: EPOCH 10: training on 40200 raw words (37480 effective words) took 0.1s, 254997 effective words/s
INFO - 2023-11-28 03:32:10,018: EPOCH 11: training on 40200 raw words (37384 effective words) took 0.1s, 267448 effective words/s
INFO - 2023-11-28 03:32:10,149: EPOCH 12: training on 40200 raw words (37446 effective words) took 0.1s, 292555 effective words/s
INFO - 2023-11-28 03:32:10,293: EPOCH 13: training on 40200 raw words (37340 effective words) took 0.1s, 263766 effective words/s
INFO - 2023-11-28 03:32:10,436: EPOCH 14: training on 40200 raw words (37397 effective words) took 0.1s, 264734 effective words/s
INFO - 2023-11-28 03:32:10,574: EPOCH 15: training on 40200 raw words (37337 effective words) took 0.1s, 275469 effective words/s
INFO - 2023-11-28 03:32:10,715: EPOCH 16: training on 40200 raw words (37373 effective words) took 0.1s, 269299 effective words/s
INFO - 2023-11-28 03:32:10,858: EPOCH 17: training on 40200 raw words (37551 effective words) took 0.1s, 266548 effective words/s
INFO - 2023-11-28 03:32:10,995: EPOCH 18: training on 40200 raw words (37374 effective words) took 0.1s, 288223 effective words/s
INFO - 2023-11-28 03:32:11,131: EPOCH 19: training on 40200 raw words (37487 effective words) took 0.1s, 280079 effective words/s
INFO - 2023-11-28 03:32:11,131: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748714 effective words) took 2.9s, 262385 effective words/s', 'datetime': '2023-11-28T03:32:11.131796', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:11,131: collecting all words and their counts
INFO - 2023-11-28 03:32:11,132: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:11,138: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:11,138: Updating model with new vocabulary
INFO - 2023-11-28 03:32:11,142: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:11.142436', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:11,146: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:11,146: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:32:11,146: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37319.655583448315 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:32:11.146358', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:11,152: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:11,152: updating layer weights
INFO - 2023-11-28 03:32:11,152: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:11.152515', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:11,152: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:11,152: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:11.152734', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:11,290: EPOCH 0: training on 40200 raw words (37247 effective words) took 0.1s, 276448 effective words/s
INFO - 2023-11-28 03:32:11,424: EPOCH 1: training on 40200 raw words (37326 effective words) took 0.1s, 283116 effective words/s
INFO - 2023-11-28 03:32:11,562: EPOCH 2: training on 40200 raw words (37208 effective words) took 0.1s, 274217 effective words/s
INFO - 2023-11-28 03:32:11,700: EPOCH 3: training on 40200 raw words (37326 effective words) took 0.1s, 274292 effective words/s
INFO - 2023-11-28 03:32:11,839: EPOCH 4: training on 40200 raw words (37393 effective words) took 0.1s, 273812 effective words/s
INFO - 2023-11-28 03:32:11,969: EPOCH 5: training on 40200 raw words (37333 effective words) took 0.1s, 292890 effective words/s
INFO - 2023-11-28 03:32:12,104: EPOCH 6: training on 40200 raw words (37368 effective words) took 0.1s, 280830 effective words/s
INFO - 2023-11-28 03:32:12,244: EPOCH 7: training on 40200 raw words (37337 effective words) took 0.1s, 270654 effective words/s
INFO - 2023-11-28 03:32:12,364: EPOCH 8: training on 40200 raw words (37293 effective words) took 0.1s, 315833 effective words/s
INFO - 2023-11-28 03:32:12,497: EPOCH 9: training on 40200 raw words (37283 effective words) took 0.1s, 286070 effective words/s
INFO - 2023-11-28 03:32:12,631: EPOCH 10: training on 40200 raw words (37305 effective words) took 0.1s, 283735 effective words/s
INFO - 2023-11-28 03:32:12,761: EPOCH 11: training on 40200 raw words (37284 effective words) took 0.1s, 302833 effective words/s
INFO - 2023-11-28 03:32:12,891: EPOCH 12: training on 40200 raw words (37328 effective words) took 0.1s, 292785 effective words/s
INFO - 2023-11-28 03:32:13,026: EPOCH 13: training on 40200 raw words (37298 effective words) took 0.1s, 281528 effective words/s
INFO - 2023-11-28 03:32:13,162: EPOCH 14: training on 40200 raw words (37260 effective words) took 0.1s, 278444 effective words/s
INFO - 2023-11-28 03:32:13,299: EPOCH 15: training on 40200 raw words (37351 effective words) took 0.1s, 277012 effective words/s
INFO - 2023-11-28 03:32:13,422: EPOCH 16: training on 40200 raw words (37340 effective words) took 0.1s, 309281 effective words/s
INFO - 2023-11-28 03:32:13,562: EPOCH 17: training on 40200 raw words (37281 effective words) took 0.1s, 272250 effective words/s
INFO - 2023-11-28 03:32:13,699: EPOCH 18: training on 40200 raw words (37273 effective words) took 0.1s, 275726 effective words/s
INFO - 2023-11-28 03:32:13,838: EPOCH 19: training on 40200 raw words (37312 effective words) took 0.1s, 274625 effective words/s
INFO - 2023-11-28 03:32:13,838: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746146 effective words) took 2.7s, 277838 effective words/s', 'datetime': '2023-11-28T03:32:13.838445', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:13,838: collecting all words and their counts
INFO - 2023-11-28 03:32:13,838: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:13,845: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:13,845: Updating model with new vocabulary
INFO - 2023-11-28 03:32:13,848: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:13.848688', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:13,853: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:13,853: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:32:13,853: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37414.987260505484 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:13.853678', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:13,860: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:13,860: updating layer weights
INFO - 2023-11-28 03:32:13,861: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:13.860999', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:13,861: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:13,861: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:13.861196', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:13,997: EPOCH 0: training on 40200 raw words (37403 effective words) took 0.1s, 280269 effective words/s
INFO - 2023-11-28 03:32:14,140: EPOCH 1: training on 40200 raw words (37432 effective words) took 0.1s, 265137 effective words/s
INFO - 2023-11-28 03:32:14,288: EPOCH 2: training on 40200 raw words (37358 effective words) took 0.1s, 259113 effective words/s
INFO - 2023-11-28 03:32:14,425: EPOCH 3: training on 40200 raw words (37301 effective words) took 0.1s, 276906 effective words/s
INFO - 2023-11-28 03:32:14,567: EPOCH 4: training on 40200 raw words (37431 effective words) took 0.1s, 269034 effective words/s
INFO - 2023-11-28 03:32:14,710: EPOCH 5: training on 40200 raw words (37380 effective words) took 0.1s, 265037 effective words/s
INFO - 2023-11-28 03:32:14,845: EPOCH 6: training on 40200 raw words (37416 effective words) took 0.1s, 283026 effective words/s
INFO - 2023-11-28 03:32:14,987: EPOCH 7: training on 40200 raw words (37462 effective words) took 0.1s, 266871 effective words/s
INFO - 2023-11-28 03:32:15,125: EPOCH 8: training on 40200 raw words (37465 effective words) took 0.1s, 278001 effective words/s
INFO - 2023-11-28 03:32:15,271: EPOCH 9: training on 40200 raw words (37495 effective words) took 0.1s, 260893 effective words/s
INFO - 2023-11-28 03:32:15,408: EPOCH 10: training on 40200 raw words (37332 effective words) took 0.1s, 277849 effective words/s
INFO - 2023-11-28 03:32:15,550: EPOCH 11: training on 40200 raw words (37462 effective words) took 0.1s, 267626 effective words/s
INFO - 2023-11-28 03:32:15,694: EPOCH 12: training on 40200 raw words (37446 effective words) took 0.1s, 264319 effective words/s
INFO - 2023-11-28 03:32:15,827: EPOCH 13: training on 40200 raw words (37468 effective words) took 0.1s, 285921 effective words/s
INFO - 2023-11-28 03:32:15,966: EPOCH 14: training on 40200 raw words (37405 effective words) took 0.1s, 273432 effective words/s
INFO - 2023-11-28 03:32:16,112: EPOCH 15: training on 40200 raw words (37379 effective words) took 0.1s, 261621 effective words/s
INFO - 2023-11-28 03:32:16,252: EPOCH 16: training on 40200 raw words (37388 effective words) took 0.1s, 270650 effective words/s
INFO - 2023-11-28 03:32:16,392: EPOCH 17: training on 40200 raw words (37434 effective words) took 0.1s, 271990 effective words/s
INFO - 2023-11-28 03:32:16,536: EPOCH 18: training on 40200 raw words (37409 effective words) took 0.1s, 263965 effective words/s
INFO - 2023-11-28 03:32:16,672: EPOCH 19: training on 40200 raw words (37415 effective words) took 0.1s, 278132 effective words/s
INFO - 2023-11-28 03:32:16,673: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748281 effective words) took 2.8s, 266114 effective words/s', 'datetime': '2023-11-28T03:32:16.673191', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:16,673: collecting all words and their counts
INFO - 2023-11-28 03:32:16,673: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:16,680: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:16,680: Updating model with new vocabulary
INFO - 2023-11-28 03:32:16,683: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:16.683724', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:16,687: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:16,687: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:32:16,687: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37295.32340853513 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:32:16.687757', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:16,694: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:16,694: updating layer weights
INFO - 2023-11-28 03:32:16,694: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:16.694449', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:16,694: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:16,694: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:16.694658', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:16,829: EPOCH 0: training on 40200 raw words (37318 effective words) took 0.1s, 280963 effective words/s
INFO - 2023-11-28 03:32:16,962: EPOCH 1: training on 40200 raw words (37260 effective words) took 0.1s, 285832 effective words/s
INFO - 2023-11-28 03:32:17,097: EPOCH 2: training on 40200 raw words (37237 effective words) took 0.1s, 282150 effective words/s
INFO - 2023-11-28 03:32:17,229: EPOCH 3: training on 40200 raw words (37351 effective words) took 0.1s, 287514 effective words/s
INFO - 2023-11-28 03:32:17,358: EPOCH 4: training on 40200 raw words (37316 effective words) took 0.1s, 293776 effective words/s
INFO - 2023-11-28 03:32:17,492: EPOCH 5: training on 40200 raw words (37311 effective words) took 0.1s, 282551 effective words/s
INFO - 2023-11-28 03:32:17,629: EPOCH 6: training on 40200 raw words (37249 effective words) took 0.1s, 276437 effective words/s
INFO - 2023-11-28 03:32:17,764: EPOCH 7: training on 40200 raw words (37307 effective words) took 0.1s, 282318 effective words/s
INFO - 2023-11-28 03:32:17,895: EPOCH 8: training on 40200 raw words (37303 effective words) took 0.1s, 289316 effective words/s
INFO - 2023-11-28 03:32:18,032: EPOCH 9: training on 40200 raw words (37296 effective words) took 0.1s, 276610 effective words/s
INFO - 2023-11-28 03:32:18,161: EPOCH 10: training on 40200 raw words (37354 effective words) took 0.1s, 295312 effective words/s
INFO - 2023-11-28 03:32:18,295: EPOCH 11: training on 40200 raw words (37334 effective words) took 0.1s, 283115 effective words/s
INFO - 2023-11-28 03:32:18,433: EPOCH 12: training on 40200 raw words (37274 effective words) took 0.1s, 276356 effective words/s
INFO - 2023-11-28 03:32:18,570: EPOCH 13: training on 40200 raw words (37355 effective words) took 0.1s, 286514 effective words/s
INFO - 2023-11-28 03:32:18,706: EPOCH 14: training on 40200 raw words (37323 effective words) took 0.1s, 279373 effective words/s
INFO - 2023-11-28 03:32:18,836: EPOCH 15: training on 40200 raw words (37273 effective words) took 0.1s, 293640 effective words/s
INFO - 2023-11-28 03:32:18,968: EPOCH 16: training on 40200 raw words (37282 effective words) took 0.1s, 287374 effective words/s
INFO - 2023-11-28 03:32:19,108: EPOCH 17: training on 40200 raw words (37337 effective words) took 0.1s, 270956 effective words/s
INFO - 2023-11-28 03:32:19,244: EPOCH 18: training on 40200 raw words (37264 effective words) took 0.1s, 278852 effective words/s
INFO - 2023-11-28 03:32:19,381: EPOCH 19: training on 40200 raw words (37377 effective words) took 0.1s, 278898 effective words/s
INFO - 2023-11-28 03:32:19,381: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746121 effective words) took 2.7s, 277719 effective words/s', 'datetime': '2023-11-28T03:32:19.381386', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:19,381: collecting all words and their counts
INFO - 2023-11-28 03:32:19,381: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:19,388: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:19,388: Updating model with new vocabulary
INFO - 2023-11-28 03:32:19,393: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:19.393751', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:19,398: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:19,399: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:32:19,399: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37408.64581453828 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:19.399183', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:19,407: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:19,407: updating layer weights
INFO - 2023-11-28 03:32:19,407: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:19.407591', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:19,407: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:19,407: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:19.407831', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:19,548: EPOCH 0: training on 40200 raw words (37361 effective words) took 0.1s, 270348 effective words/s
INFO - 2023-11-28 03:32:19,691: EPOCH 1: training on 40200 raw words (37449 effective words) took 0.1s, 266374 effective words/s
INFO - 2023-11-28 03:32:19,833: EPOCH 2: training on 40200 raw words (37412 effective words) took 0.1s, 267718 effective words/s
INFO - 2023-11-28 03:32:19,984: EPOCH 3: training on 40200 raw words (37471 effective words) took 0.1s, 252382 effective words/s
INFO - 2023-11-28 03:32:20,122: EPOCH 4: training on 40200 raw words (37313 effective words) took 0.1s, 275779 effective words/s
INFO - 2023-11-28 03:32:20,262: EPOCH 5: training on 40200 raw words (37429 effective words) took 0.1s, 270604 effective words/s
INFO - 2023-11-28 03:32:20,407: EPOCH 6: training on 40200 raw words (37443 effective words) took 0.1s, 262472 effective words/s
INFO - 2023-11-28 03:32:20,540: EPOCH 7: training on 40200 raw words (37421 effective words) took 0.1s, 287702 effective words/s
INFO - 2023-11-28 03:32:20,678: EPOCH 8: training on 40200 raw words (37343 effective words) took 0.1s, 274992 effective words/s
INFO - 2023-11-28 03:32:20,817: EPOCH 9: training on 40200 raw words (37365 effective words) took 0.1s, 272401 effective words/s
INFO - 2023-11-28 03:32:20,957: EPOCH 10: training on 40200 raw words (37416 effective words) took 0.1s, 272547 effective words/s
INFO - 2023-11-28 03:32:21,097: EPOCH 11: training on 40200 raw words (37390 effective words) took 0.1s, 271428 effective words/s
INFO - 2023-11-28 03:32:21,239: EPOCH 12: training on 40200 raw words (37416 effective words) took 0.1s, 268637 effective words/s
INFO - 2023-11-28 03:32:21,373: EPOCH 13: training on 40200 raw words (37425 effective words) took 0.1s, 284502 effective words/s
INFO - 2023-11-28 03:32:21,507: EPOCH 14: training on 40200 raw words (37385 effective words) took 0.1s, 282625 effective words/s
INFO - 2023-11-28 03:32:21,649: EPOCH 15: training on 40200 raw words (37399 effective words) took 0.1s, 266744 effective words/s
INFO - 2023-11-28 03:32:21,794: EPOCH 16: training on 40200 raw words (37407 effective words) took 0.1s, 263987 effective words/s
INFO - 2023-11-28 03:32:21,935: EPOCH 17: training on 40200 raw words (37429 effective words) took 0.1s, 268124 effective words/s
INFO - 2023-11-28 03:32:22,079: EPOCH 18: training on 40200 raw words (37345 effective words) took 0.1s, 265327 effective words/s
INFO - 2023-11-28 03:32:22,223: EPOCH 19: training on 40200 raw words (37363 effective words) took 0.1s, 263686 effective words/s
INFO - 2023-11-28 03:32:22,223: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747982 effective words) took 2.8s, 265652 effective words/s', 'datetime': '2023-11-28T03:32:22.223578', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:22,223: collecting all words and their counts
INFO - 2023-11-28 03:32:22,223: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:22,229: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:22,229: Updating model with new vocabulary
INFO - 2023-11-28 03:32:22,232: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:22.232580', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:22,235: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:22,235: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:32:22,235: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37308.64443740154 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:32:22.235934', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:22,240: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:22,240: updating layer weights
INFO - 2023-11-28 03:32:22,241: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:22.241082', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:22,241: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:22,241: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:22.241285', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:22,374: EPOCH 0: training on 40200 raw words (37308 effective words) took 0.1s, 290843 effective words/s
INFO - 2023-11-28 03:32:22,511: EPOCH 1: training on 40200 raw words (37350 effective words) took 0.1s, 277994 effective words/s
INFO - 2023-11-28 03:32:22,647: EPOCH 2: training on 40200 raw words (37369 effective words) took 0.1s, 279759 effective words/s
INFO - 2023-11-28 03:32:22,782: EPOCH 3: training on 40200 raw words (37243 effective words) took 0.1s, 281576 effective words/s
INFO - 2023-11-28 03:32:22,912: EPOCH 4: training on 40200 raw words (37300 effective words) took 0.1s, 291634 effective words/s
INFO - 2023-11-28 03:32:23,046: EPOCH 5: training on 40200 raw words (37279 effective words) took 0.1s, 282343 effective words/s
INFO - 2023-11-28 03:32:23,182: EPOCH 6: training on 40200 raw words (37281 effective words) took 0.1s, 279201 effective words/s
INFO - 2023-11-28 03:32:23,316: EPOCH 7: training on 40200 raw words (37323 effective words) took 0.1s, 284389 effective words/s
INFO - 2023-11-28 03:32:23,444: EPOCH 8: training on 40200 raw words (37366 effective words) took 0.1s, 297143 effective words/s
INFO - 2023-11-28 03:32:23,583: EPOCH 9: training on 40200 raw words (37353 effective words) took 0.1s, 273694 effective words/s
INFO - 2023-11-28 03:32:23,718: EPOCH 10: training on 40200 raw words (37271 effective words) took 0.1s, 279644 effective words/s
INFO - 2023-11-28 03:32:23,844: EPOCH 11: training on 40200 raw words (37311 effective words) took 0.1s, 315538 effective words/s
INFO - 2023-11-28 03:32:23,977: EPOCH 12: training on 40200 raw words (37282 effective words) took 0.1s, 284282 effective words/s
INFO - 2023-11-28 03:32:24,108: EPOCH 13: training on 40200 raw words (37265 effective words) took 0.1s, 289336 effective words/s
INFO - 2023-11-28 03:32:24,240: EPOCH 14: training on 40200 raw words (37354 effective words) took 0.1s, 288418 effective words/s
INFO - 2023-11-28 03:32:24,370: EPOCH 15: training on 40200 raw words (37379 effective words) took 0.1s, 292351 effective words/s
INFO - 2023-11-28 03:32:24,505: EPOCH 16: training on 40200 raw words (37329 effective words) took 0.1s, 281953 effective words/s
INFO - 2023-11-28 03:32:24,637: EPOCH 17: training on 40200 raw words (37335 effective words) took 0.1s, 287766 effective words/s
INFO - 2023-11-28 03:32:24,771: EPOCH 18: training on 40200 raw words (37316 effective words) took 0.1s, 282469 effective words/s
INFO - 2023-11-28 03:32:24,907: EPOCH 19: training on 40200 raw words (37273 effective words) took 0.1s, 280495 effective words/s
INFO - 2023-11-28 03:32:24,907: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746287 effective words) took 2.7s, 279903 effective words/s', 'datetime': '2023-11-28T03:32:24.907619', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:24,907: collecting all words and their counts
INFO - 2023-11-28 03:32:24,908: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:24,914: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:24,914: Updating model with new vocabulary
INFO - 2023-11-28 03:32:24,918: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:24.917989', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:24,921: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:24,921: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:32:24,921: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37485.237045035596 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:32:24.921440', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:24,926: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:24,926: updating layer weights
INFO - 2023-11-28 03:32:24,927: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:24.927112', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:24,927: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:24,927: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:24.927282', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:25,070: EPOCH 0: training on 40200 raw words (37462 effective words) took 0.1s, 266778 effective words/s
INFO - 2023-11-28 03:32:25,214: EPOCH 1: training on 40200 raw words (37501 effective words) took 0.1s, 263862 effective words/s
INFO - 2023-11-28 03:32:25,357: EPOCH 2: training on 40200 raw words (37426 effective words) took 0.1s, 265682 effective words/s
INFO - 2023-11-28 03:32:25,502: EPOCH 3: training on 40200 raw words (37443 effective words) took 0.1s, 262128 effective words/s
INFO - 2023-11-28 03:32:25,644: EPOCH 4: training on 40200 raw words (37468 effective words) took 0.1s, 268799 effective words/s
INFO - 2023-11-28 03:32:25,783: EPOCH 5: training on 40200 raw words (37530 effective words) took 0.1s, 275315 effective words/s
INFO - 2023-11-28 03:32:25,922: EPOCH 6: training on 40200 raw words (37384 effective words) took 0.1s, 273731 effective words/s
INFO - 2023-11-28 03:32:26,064: EPOCH 7: training on 40200 raw words (37527 effective words) took 0.1s, 267063 effective words/s
INFO - 2023-11-28 03:32:26,206: EPOCH 8: training on 40200 raw words (37464 effective words) took 0.1s, 267843 effective words/s
INFO - 2023-11-28 03:32:26,346: EPOCH 9: training on 40200 raw words (37544 effective words) took 0.1s, 272660 effective words/s
INFO - 2023-11-28 03:32:26,492: EPOCH 10: training on 40200 raw words (37483 effective words) took 0.1s, 261381 effective words/s
INFO - 2023-11-28 03:32:26,631: EPOCH 11: training on 40200 raw words (37444 effective words) took 0.1s, 273276 effective words/s
INFO - 2023-11-28 03:32:26,773: EPOCH 12: training on 40200 raw words (37554 effective words) took 0.1s, 269592 effective words/s
INFO - 2023-11-28 03:32:26,917: EPOCH 13: training on 40200 raw words (37528 effective words) took 0.1s, 265338 effective words/s
INFO - 2023-11-28 03:32:27,058: EPOCH 14: training on 40200 raw words (37513 effective words) took 0.1s, 270434 effective words/s
INFO - 2023-11-28 03:32:27,200: EPOCH 15: training on 40200 raw words (37494 effective words) took 0.1s, 268483 effective words/s
INFO - 2023-11-28 03:32:27,344: EPOCH 16: training on 40200 raw words (37563 effective words) took 0.1s, 265028 effective words/s
INFO - 2023-11-28 03:32:27,484: EPOCH 17: training on 40200 raw words (37505 effective words) took 0.1s, 270985 effective words/s
INFO - 2023-11-28 03:32:27,621: EPOCH 18: training on 40200 raw words (37522 effective words) took 0.1s, 280189 effective words/s
INFO - 2023-11-28 03:32:27,765: EPOCH 19: training on 40200 raw words (37465 effective words) took 0.1s, 264241 effective words/s
INFO - 2023-11-28 03:32:27,765: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (749820 effective words) took 2.8s, 264205 effective words/s', 'datetime': '2023-11-28T03:32:27.765418', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:27,765: collecting all words and their counts
INFO - 2023-11-28 03:32:27,765: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:27,773: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:27,773: Updating model with new vocabulary
INFO - 2023-11-28 03:32:27,777: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:27.777205', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:27,780: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:27,780: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:32:27,780: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37431.57225264973 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:27.780782', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:27,786: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:27,786: updating layer weights
INFO - 2023-11-28 03:32:27,786: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:27.786951', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:27,787: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:27,787: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:27.787120', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:27,925: EPOCH 0: training on 40200 raw words (37420 effective words) took 0.1s, 276418 effective words/s
INFO - 2023-11-28 03:32:28,062: EPOCH 1: training on 40200 raw words (37375 effective words) took 0.1s, 277681 effective words/s
INFO - 2023-11-28 03:32:28,195: EPOCH 2: training on 40200 raw words (37430 effective words) took 0.1s, 284846 effective words/s
INFO - 2023-11-28 03:32:28,322: EPOCH 3: training on 40200 raw words (37541 effective words) took 0.1s, 300682 effective words/s
INFO - 2023-11-28 03:32:28,448: EPOCH 4: training on 40200 raw words (37463 effective words) took 0.1s, 316955 effective words/s
INFO - 2023-11-28 03:32:28,582: EPOCH 5: training on 40200 raw words (37469 effective words) took 0.1s, 291414 effective words/s
INFO - 2023-11-28 03:32:28,721: EPOCH 6: training on 40200 raw words (37426 effective words) took 0.1s, 281111 effective words/s
INFO - 2023-11-28 03:32:28,850: EPOCH 7: training on 40200 raw words (37445 effective words) took 0.1s, 295082 effective words/s
INFO - 2023-11-28 03:32:28,985: EPOCH 8: training on 40200 raw words (37419 effective words) took 0.1s, 282590 effective words/s
INFO - 2023-11-28 03:32:29,114: EPOCH 9: training on 40200 raw words (37445 effective words) took 0.1s, 294315 effective words/s
INFO - 2023-11-28 03:32:29,242: EPOCH 10: training on 40200 raw words (37397 effective words) took 0.1s, 298603 effective words/s
INFO - 2023-11-28 03:32:29,378: EPOCH 11: training on 40200 raw words (37499 effective words) took 0.1s, 280094 effective words/s
INFO - 2023-11-28 03:32:29,517: EPOCH 12: training on 40200 raw words (37419 effective words) took 0.1s, 273747 effective words/s
INFO - 2023-11-28 03:32:29,654: EPOCH 13: training on 40200 raw words (37409 effective words) took 0.1s, 279528 effective words/s
INFO - 2023-11-28 03:32:29,790: EPOCH 14: training on 40200 raw words (37429 effective words) took 0.1s, 279388 effective words/s
INFO - 2023-11-28 03:32:29,925: EPOCH 15: training on 40200 raw words (37414 effective words) took 0.1s, 281744 effective words/s
INFO - 2023-11-28 03:32:30,061: EPOCH 16: training on 40200 raw words (37437 effective words) took 0.1s, 281156 effective words/s
INFO - 2023-11-28 03:32:30,199: EPOCH 17: training on 40200 raw words (37350 effective words) took 0.1s, 274978 effective words/s
INFO - 2023-11-28 03:32:30,329: EPOCH 18: training on 40200 raw words (37440 effective words) took 0.1s, 293887 effective words/s
INFO - 2023-11-28 03:32:30,463: EPOCH 19: training on 40200 raw words (37540 effective words) took 0.1s, 283872 effective words/s
INFO - 2023-11-28 03:32:30,463: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748767 effective words) took 2.7s, 279742 effective words/s', 'datetime': '2023-11-28T03:32:30.463859', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:30,464: collecting all words and their counts
INFO - 2023-11-28 03:32:30,464: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:30,471: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:30,471: Updating model with new vocabulary
INFO - 2023-11-28 03:32:30,474: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:30.474347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:30,478: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:30,478: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:32:30,478: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37327.83053808629 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:32:30.478355', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:30,483: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:30,483: updating layer weights
INFO - 2023-11-28 03:32:30,484: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:30.483999', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:30,484: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:30,484: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:30.484172', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:30,630: EPOCH 0: training on 40200 raw words (37290 effective words) took 0.1s, 259561 effective words/s
INFO - 2023-11-28 03:32:30,768: EPOCH 1: training on 40200 raw words (37294 effective words) took 0.1s, 273607 effective words/s
INFO - 2023-11-28 03:32:30,910: EPOCH 2: training on 40200 raw words (37333 effective words) took 0.1s, 269354 effective words/s
INFO - 2023-11-28 03:32:31,049: EPOCH 3: training on 40200 raw words (37362 effective words) took 0.1s, 273216 effective words/s
INFO - 2023-11-28 03:32:31,185: EPOCH 4: training on 40200 raw words (37238 effective words) took 0.1s, 276335 effective words/s
INFO - 2023-11-28 03:32:31,328: EPOCH 5: training on 40200 raw words (37373 effective words) took 0.1s, 266624 effective words/s
INFO - 2023-11-28 03:32:31,465: EPOCH 6: training on 40200 raw words (37358 effective words) took 0.1s, 276531 effective words/s
INFO - 2023-11-28 03:32:31,605: EPOCH 7: training on 40200 raw words (37277 effective words) took 0.1s, 271855 effective words/s
INFO - 2023-11-28 03:32:31,746: EPOCH 8: training on 40200 raw words (37311 effective words) took 0.1s, 268269 effective words/s
INFO - 2023-11-28 03:32:31,884: EPOCH 9: training on 40200 raw words (37343 effective words) took 0.1s, 276897 effective words/s
INFO - 2023-11-28 03:32:32,028: EPOCH 10: training on 40200 raw words (37333 effective words) took 0.1s, 263612 effective words/s
INFO - 2023-11-28 03:32:32,171: EPOCH 11: training on 40200 raw words (37336 effective words) took 0.1s, 265291 effective words/s
INFO - 2023-11-28 03:32:32,316: EPOCH 12: training on 40200 raw words (37375 effective words) took 0.1s, 263389 effective words/s
INFO - 2023-11-28 03:32:32,451: EPOCH 13: training on 40200 raw words (37367 effective words) took 0.1s, 280106 effective words/s
INFO - 2023-11-28 03:32:32,594: EPOCH 14: training on 40200 raw words (37369 effective words) took 0.1s, 266176 effective words/s
INFO - 2023-11-28 03:32:32,736: EPOCH 15: training on 40200 raw words (37306 effective words) took 0.1s, 268082 effective words/s
INFO - 2023-11-28 03:32:32,873: EPOCH 16: training on 40200 raw words (37226 effective words) took 0.1s, 276971 effective words/s
INFO - 2023-11-28 03:32:33,014: EPOCH 17: training on 40200 raw words (37384 effective words) took 0.1s, 268914 effective words/s
INFO - 2023-11-28 03:32:33,147: EPOCH 18: training on 40200 raw words (37412 effective words) took 0.1s, 285946 effective words/s
INFO - 2023-11-28 03:32:33,288: EPOCH 19: training on 40200 raw words (37391 effective words) took 0.1s, 269883 effective words/s
INFO - 2023-11-28 03:32:33,288: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746678 effective words) took 2.8s, 266276 effective words/s', 'datetime': '2023-11-28T03:32:33.288442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:33,288: collecting all words and their counts
INFO - 2023-11-28 03:32:33,288: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:33,295: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:33,295: Updating model with new vocabulary
INFO - 2023-11-28 03:32:33,298: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:33.298794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:33,303: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:33,304: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:32:33,304: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37329.628397536 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:32:33.304125', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:33,310: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:33,310: updating layer weights
INFO - 2023-11-28 03:32:33,310: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:33.310390', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:33,310: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:33,310: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:33.310587', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:33,448: EPOCH 0: training on 40200 raw words (37377 effective words) took 0.1s, 276735 effective words/s
INFO - 2023-11-28 03:32:33,584: EPOCH 1: training on 40200 raw words (37369 effective words) took 0.1s, 279939 effective words/s
INFO - 2023-11-28 03:32:33,722: EPOCH 2: training on 40200 raw words (37330 effective words) took 0.1s, 275048 effective words/s
INFO - 2023-11-28 03:32:33,858: EPOCH 3: training on 40200 raw words (37373 effective words) took 0.1s, 277486 effective words/s
INFO - 2023-11-28 03:32:33,992: EPOCH 4: training on 40200 raw words (37323 effective words) took 0.1s, 284834 effective words/s
INFO - 2023-11-28 03:32:34,127: EPOCH 5: training on 40200 raw words (37371 effective words) took 0.1s, 280638 effective words/s
INFO - 2023-11-28 03:32:34,262: EPOCH 6: training on 40200 raw words (37346 effective words) took 0.1s, 283005 effective words/s
INFO - 2023-11-28 03:32:34,393: EPOCH 7: training on 40200 raw words (37288 effective words) took 0.1s, 290549 effective words/s
INFO - 2023-11-28 03:32:34,525: EPOCH 8: training on 40200 raw words (37324 effective words) took 0.1s, 298375 effective words/s
INFO - 2023-11-28 03:32:34,659: EPOCH 9: training on 40200 raw words (37283 effective words) took 0.1s, 283151 effective words/s
INFO - 2023-11-28 03:32:34,796: EPOCH 10: training on 40200 raw words (37269 effective words) took 0.1s, 277388 effective words/s
INFO - 2023-11-28 03:32:34,931: EPOCH 11: training on 40200 raw words (37324 effective words) took 0.1s, 294498 effective words/s
INFO - 2023-11-28 03:32:35,065: EPOCH 12: training on 40200 raw words (37326 effective words) took 0.1s, 283768 effective words/s
INFO - 2023-11-28 03:32:35,200: EPOCH 13: training on 40200 raw words (37334 effective words) took 0.1s, 281144 effective words/s
INFO - 2023-11-28 03:32:35,334: EPOCH 14: training on 40200 raw words (37444 effective words) took 0.1s, 285701 effective words/s
INFO - 2023-11-28 03:32:35,470: EPOCH 15: training on 40200 raw words (37302 effective words) took 0.1s, 279179 effective words/s
INFO - 2023-11-28 03:32:35,606: EPOCH 16: training on 40200 raw words (37293 effective words) took 0.1s, 277872 effective words/s
INFO - 2023-11-28 03:32:35,741: EPOCH 17: training on 40200 raw words (37342 effective words) took 0.1s, 281685 effective words/s
INFO - 2023-11-28 03:32:35,876: EPOCH 18: training on 40200 raw words (37321 effective words) took 0.1s, 283742 effective words/s
INFO - 2023-11-28 03:32:36,018: EPOCH 19: training on 40200 raw words (37335 effective words) took 0.1s, 267099 effective words/s
INFO - 2023-11-28 03:32:36,018: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746674 effective words) took 2.7s, 275728 effective words/s', 'datetime': '2023-11-28T03:32:36.018722', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:36,018: collecting all words and their counts
INFO - 2023-11-28 03:32:36,019: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:36,025: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:36,025: Updating model with new vocabulary
INFO - 2023-11-28 03:32:36,028: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:36.028191', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:36,031: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:36,031: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:32:36,031: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37400.99534807589 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:32:36.031522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:36,036: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:36,036: updating layer weights
INFO - 2023-11-28 03:32:36,036: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:36.036958', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:36,037: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:36,037: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:36.037160', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:36,173: EPOCH 0: training on 40200 raw words (37359 effective words) took 0.1s, 278584 effective words/s
INFO - 2023-11-28 03:32:36,317: EPOCH 1: training on 40200 raw words (37390 effective words) took 0.1s, 263439 effective words/s
INFO - 2023-11-28 03:32:36,455: EPOCH 2: training on 40200 raw words (37423 effective words) took 0.1s, 276944 effective words/s
INFO - 2023-11-28 03:32:36,602: EPOCH 3: training on 40200 raw words (37366 effective words) took 0.1s, 257426 effective words/s
INFO - 2023-11-28 03:32:36,734: EPOCH 4: training on 40200 raw words (37439 effective words) took 0.1s, 289958 effective words/s
INFO - 2023-11-28 03:32:36,870: EPOCH 5: training on 40200 raw words (37478 effective words) took 0.1s, 278802 effective words/s
INFO - 2023-11-28 03:32:37,013: EPOCH 6: training on 40200 raw words (37362 effective words) took 0.1s, 265561 effective words/s
INFO - 2023-11-28 03:32:37,152: EPOCH 7: training on 40200 raw words (37384 effective words) took 0.1s, 273578 effective words/s
INFO - 2023-11-28 03:32:37,295: EPOCH 8: training on 40200 raw words (37432 effective words) took 0.1s, 265905 effective words/s
INFO - 2023-11-28 03:32:37,465: EPOCH 9: training on 40200 raw words (37436 effective words) took 0.2s, 224011 effective words/s
INFO - 2023-11-28 03:32:37,597: EPOCH 10: training on 40200 raw words (37408 effective words) took 0.1s, 287800 effective words/s
INFO - 2023-11-28 03:32:37,738: EPOCH 11: training on 40200 raw words (37377 effective words) took 0.1s, 269843 effective words/s
INFO - 2023-11-28 03:32:37,880: EPOCH 12: training on 40200 raw words (37439 effective words) took 0.1s, 267504 effective words/s
INFO - 2023-11-28 03:32:38,030: EPOCH 13: training on 40200 raw words (37437 effective words) took 0.1s, 254758 effective words/s
INFO - 2023-11-28 03:32:38,166: EPOCH 14: training on 40200 raw words (37407 effective words) took 0.1s, 278831 effective words/s
INFO - 2023-11-28 03:32:38,307: EPOCH 15: training on 40200 raw words (37451 effective words) took 0.1s, 270845 effective words/s
INFO - 2023-11-28 03:32:38,449: EPOCH 16: training on 40200 raw words (37385 effective words) took 0.1s, 267152 effective words/s
INFO - 2023-11-28 03:32:38,591: EPOCH 17: training on 40200 raw words (37433 effective words) took 0.1s, 276836 effective words/s
INFO - 2023-11-28 03:32:38,726: EPOCH 18: training on 40200 raw words (37459 effective words) took 0.1s, 283080 effective words/s
INFO - 2023-11-28 03:32:38,865: EPOCH 19: training on 40200 raw words (37355 effective words) took 0.1s, 272280 effective words/s
INFO - 2023-11-28 03:32:38,865: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748220 effective words) took 2.8s, 264525 effective words/s', 'datetime': '2023-11-28T03:32:38.865811', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:38,865: collecting all words and their counts
INFO - 2023-11-28 03:32:38,866: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:38,872: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:38,872: Updating model with new vocabulary
INFO - 2023-11-28 03:32:38,875: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:38.875467', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:38,879: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:38,879: sample=0.001 downsamples 66 most-common words
INFO - 2023-11-28 03:32:38,879: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37444.90416506136 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:38.879388', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:38,884: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:38,884: updating layer weights
INFO - 2023-11-28 03:32:38,884: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:38.884957', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:38,885: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:38,885: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:38.885154', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:39,010: EPOCH 0: training on 40200 raw words (37456 effective words) took 0.1s, 304032 effective words/s
INFO - 2023-11-28 03:32:39,136: EPOCH 1: training on 40200 raw words (37435 effective words) took 0.1s, 315779 effective words/s
INFO - 2023-11-28 03:32:39,268: EPOCH 2: training on 40200 raw words (37346 effective words) took 0.1s, 287895 effective words/s
INFO - 2023-11-28 03:32:39,405: EPOCH 3: training on 40200 raw words (37401 effective words) took 0.1s, 278438 effective words/s
INFO - 2023-11-28 03:32:39,541: EPOCH 4: training on 40200 raw words (37358 effective words) took 0.1s, 279299 effective words/s
INFO - 2023-11-28 03:32:39,675: EPOCH 5: training on 40200 raw words (37445 effective words) took 0.1s, 285058 effective words/s
INFO - 2023-11-28 03:32:39,810: EPOCH 6: training on 40200 raw words (37441 effective words) took 0.1s, 281023 effective words/s
INFO - 2023-11-28 03:32:39,943: EPOCH 7: training on 40200 raw words (37442 effective words) took 0.1s, 286960 effective words/s
INFO - 2023-11-28 03:32:40,078: EPOCH 8: training on 40200 raw words (37416 effective words) took 0.1s, 281984 effective words/s
INFO - 2023-11-28 03:32:40,213: EPOCH 9: training on 40200 raw words (37443 effective words) took 0.1s, 283049 effective words/s
INFO - 2023-11-28 03:32:40,339: EPOCH 10: training on 40200 raw words (37358 effective words) took 0.1s, 301261 effective words/s
INFO - 2023-11-28 03:32:40,475: EPOCH 11: training on 40200 raw words (37497 effective words) took 0.1s, 281131 effective words/s
INFO - 2023-11-28 03:32:40,606: EPOCH 12: training on 40200 raw words (37467 effective words) took 0.1s, 291945 effective words/s
INFO - 2023-11-28 03:32:40,743: EPOCH 13: training on 40200 raw words (37404 effective words) took 0.1s, 278143 effective words/s
INFO - 2023-11-28 03:32:40,876: EPOCH 14: training on 40200 raw words (37453 effective words) took 0.1s, 286894 effective words/s
INFO - 2023-11-28 03:32:41,006: EPOCH 15: training on 40200 raw words (37457 effective words) took 0.1s, 293327 effective words/s
INFO - 2023-11-28 03:32:41,131: EPOCH 16: training on 40200 raw words (37514 effective words) took 0.1s, 303864 effective words/s
INFO - 2023-11-28 03:32:41,274: EPOCH 17: training on 40200 raw words (37447 effective words) took 0.1s, 267659 effective words/s
INFO - 2023-11-28 03:32:41,409: EPOCH 18: training on 40200 raw words (37498 effective words) took 0.1s, 281971 effective words/s
INFO - 2023-11-28 03:32:41,545: EPOCH 19: training on 40200 raw words (37407 effective words) took 0.1s, 281107 effective words/s
INFO - 2023-11-28 03:32:41,545: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748685 effective words) took 2.7s, 281453 effective words/s', 'datetime': '2023-11-28T03:32:41.545336', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:41,545: collecting all words and their counts
INFO - 2023-11-28 03:32:41,545: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:41,552: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:41,552: Updating model with new vocabulary
INFO - 2023-11-28 03:32:41,556: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:41.556335', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:41,560: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:41,560: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:32:41,560: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37417.51332455551 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:41.560371', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:41,566: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:41,566: updating layer weights
INFO - 2023-11-28 03:32:41,566: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:41.566652', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:41,566: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:41,566: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:41.566848', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:41,710: EPOCH 0: training on 40200 raw words (37469 effective words) took 0.1s, 264131 effective words/s
INFO - 2023-11-28 03:32:41,848: EPOCH 1: training on 40200 raw words (37393 effective words) took 0.1s, 276544 effective words/s
INFO - 2023-11-28 03:32:41,995: EPOCH 2: training on 40200 raw words (37443 effective words) took 0.1s, 259855 effective words/s
INFO - 2023-11-28 03:32:42,137: EPOCH 3: training on 40200 raw words (37438 effective words) took 0.1s, 266699 effective words/s
INFO - 2023-11-28 03:32:42,283: EPOCH 4: training on 40200 raw words (37380 effective words) took 0.1s, 260033 effective words/s
INFO - 2023-11-28 03:32:42,419: EPOCH 5: training on 40200 raw words (37461 effective words) took 0.1s, 279908 effective words/s
INFO - 2023-11-28 03:32:42,565: EPOCH 6: training on 40200 raw words (37383 effective words) took 0.1s, 261300 effective words/s
INFO - 2023-11-28 03:32:42,709: EPOCH 7: training on 40200 raw words (37368 effective words) took 0.1s, 263649 effective words/s
INFO - 2023-11-28 03:32:42,853: EPOCH 8: training on 40200 raw words (37408 effective words) took 0.1s, 264235 effective words/s
INFO - 2023-11-28 03:32:42,998: EPOCH 9: training on 40200 raw words (37386 effective words) took 0.1s, 262110 effective words/s
INFO - 2023-11-28 03:32:43,131: EPOCH 10: training on 40200 raw words (37461 effective words) took 0.1s, 286052 effective words/s
INFO - 2023-11-28 03:32:43,274: EPOCH 11: training on 40200 raw words (37467 effective words) took 0.1s, 266919 effective words/s
INFO - 2023-11-28 03:32:43,418: EPOCH 12: training on 40200 raw words (37496 effective words) took 0.1s, 265215 effective words/s
INFO - 2023-11-28 03:32:43,562: EPOCH 13: training on 40200 raw words (37361 effective words) took 0.1s, 263780 effective words/s
INFO - 2023-11-28 03:32:43,703: EPOCH 14: training on 40200 raw words (37412 effective words) took 0.1s, 275999 effective words/s
INFO - 2023-11-28 03:32:43,848: EPOCH 15: training on 40200 raw words (37348 effective words) took 0.1s, 262842 effective words/s
INFO - 2023-11-28 03:32:43,986: EPOCH 16: training on 40200 raw words (37365 effective words) took 0.1s, 280798 effective words/s
INFO - 2023-11-28 03:32:44,126: EPOCH 17: training on 40200 raw words (37406 effective words) took 0.1s, 271730 effective words/s
INFO - 2023-11-28 03:32:44,273: EPOCH 18: training on 40200 raw words (37455 effective words) took 0.1s, 259196 effective words/s
INFO - 2023-11-28 03:32:44,409: EPOCH 19: training on 40200 raw words (37460 effective words) took 0.1s, 279042 effective words/s
INFO - 2023-11-28 03:32:44,409: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748360 effective words) took 2.8s, 263249 effective words/s', 'datetime': '2023-11-28T03:32:44.409741', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:44,409: collecting all words and their counts
INFO - 2023-11-28 03:32:44,410: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:44,416: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:44,416: Updating model with new vocabulary
INFO - 2023-11-28 03:32:44,419: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:44.419610', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:44,423: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:44,423: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:32:44,423: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37407.97062329648 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:44.423628', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:44,429: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:44,429: updating layer weights
INFO - 2023-11-28 03:32:44,429: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:44.429750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:44,429: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:44,430: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:44.430009', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:44,567: EPOCH 0: training on 40200 raw words (37440 effective words) took 0.1s, 279860 effective words/s
INFO - 2023-11-28 03:32:44,704: EPOCH 1: training on 40200 raw words (37406 effective words) took 0.1s, 277422 effective words/s
INFO - 2023-11-28 03:32:44,846: EPOCH 2: training on 40200 raw words (37389 effective words) took 0.1s, 267628 effective words/s
INFO - 2023-11-28 03:32:44,981: EPOCH 3: training on 40200 raw words (37416 effective words) took 0.1s, 283834 effective words/s
INFO - 2023-11-28 03:32:45,117: EPOCH 4: training on 40200 raw words (37423 effective words) took 0.1s, 280026 effective words/s
INFO - 2023-11-28 03:32:45,250: EPOCH 5: training on 40200 raw words (37511 effective words) took 0.1s, 286229 effective words/s
INFO - 2023-11-28 03:32:45,394: EPOCH 6: training on 40200 raw words (37448 effective words) took 0.1s, 264254 effective words/s
INFO - 2023-11-28 03:32:45,529: EPOCH 7: training on 40200 raw words (37403 effective words) took 0.1s, 283384 effective words/s
INFO - 2023-11-28 03:32:45,666: EPOCH 8: training on 40200 raw words (37375 effective words) took 0.1s, 277328 effective words/s
INFO - 2023-11-28 03:32:45,805: EPOCH 9: training on 40200 raw words (37477 effective words) took 0.1s, 273993 effective words/s
INFO - 2023-11-28 03:32:45,940: EPOCH 10: training on 40200 raw words (37414 effective words) took 0.1s, 281033 effective words/s
INFO - 2023-11-28 03:32:46,073: EPOCH 11: training on 40200 raw words (37420 effective words) took 0.1s, 286263 effective words/s
INFO - 2023-11-28 03:32:46,209: EPOCH 12: training on 40200 raw words (37432 effective words) took 0.1s, 290916 effective words/s
INFO - 2023-11-28 03:32:46,344: EPOCH 13: training on 40200 raw words (37347 effective words) took 0.1s, 281872 effective words/s
INFO - 2023-11-28 03:32:46,479: EPOCH 14: training on 40200 raw words (37426 effective words) took 0.1s, 281151 effective words/s
INFO - 2023-11-28 03:32:46,622: EPOCH 15: training on 40200 raw words (37469 effective words) took 0.1s, 266400 effective words/s
INFO - 2023-11-28 03:32:46,757: EPOCH 16: training on 40200 raw words (37375 effective words) took 0.1s, 283357 effective words/s
INFO - 2023-11-28 03:32:46,890: EPOCH 17: training on 40200 raw words (37372 effective words) took 0.1s, 285191 effective words/s
INFO - 2023-11-28 03:32:47,020: EPOCH 18: training on 40200 raw words (37384 effective words) took 0.1s, 293597 effective words/s
INFO - 2023-11-28 03:32:47,157: EPOCH 19: training on 40200 raw words (37389 effective words) took 0.1s, 277752 effective words/s
INFO - 2023-11-28 03:32:47,157: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748316 effective words) took 2.7s, 274344 effective words/s', 'datetime': '2023-11-28T03:32:47.157803', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:47,158: collecting all words and their counts
INFO - 2023-11-28 03:32:47,158: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:47,164: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:47,164: Updating model with new vocabulary
INFO - 2023-11-28 03:32:47,167: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:47.167918', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:47,172: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:47,172: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:32:47,172: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37421.563797156385 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:47.172564', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:47,179: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:47,179: updating layer weights
INFO - 2023-11-28 03:32:47,180: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:47.180121', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:47,180: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:47,180: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:47.180370', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:47,317: EPOCH 0: training on 40200 raw words (37410 effective words) took 0.1s, 277557 effective words/s
INFO - 2023-11-28 03:32:47,461: EPOCH 1: training on 40200 raw words (37436 effective words) took 0.1s, 263789 effective words/s
INFO - 2023-11-28 03:32:47,606: EPOCH 2: training on 40200 raw words (37488 effective words) took 0.1s, 263984 effective words/s
INFO - 2023-11-28 03:32:47,748: EPOCH 3: training on 40200 raw words (37465 effective words) took 0.1s, 268180 effective words/s
INFO - 2023-11-28 03:32:47,889: EPOCH 4: training on 40200 raw words (37452 effective words) took 0.1s, 269949 effective words/s
INFO - 2023-11-28 03:32:48,030: EPOCH 5: training on 40200 raw words (37499 effective words) took 0.1s, 271408 effective words/s
INFO - 2023-11-28 03:32:48,167: EPOCH 6: training on 40200 raw words (37434 effective words) took 0.1s, 277556 effective words/s
INFO - 2023-11-28 03:32:48,308: EPOCH 7: training on 40200 raw words (37382 effective words) took 0.1s, 269168 effective words/s
INFO - 2023-11-28 03:32:48,456: EPOCH 8: training on 40200 raw words (37498 effective words) took 0.1s, 257798 effective words/s
INFO - 2023-11-28 03:32:48,597: EPOCH 9: training on 40200 raw words (37428 effective words) took 0.1s, 271314 effective words/s
INFO - 2023-11-28 03:32:48,739: EPOCH 10: training on 40200 raw words (37413 effective words) took 0.1s, 272785 effective words/s
INFO - 2023-11-28 03:32:48,883: EPOCH 11: training on 40200 raw words (37353 effective words) took 0.1s, 263291 effective words/s
INFO - 2023-11-28 03:32:49,027: EPOCH 12: training on 40200 raw words (37466 effective words) took 0.1s, 265304 effective words/s
INFO - 2023-11-28 03:32:49,167: EPOCH 13: training on 40200 raw words (37484 effective words) took 0.1s, 271495 effective words/s
INFO - 2023-11-28 03:32:49,297: EPOCH 14: training on 40200 raw words (37312 effective words) took 0.1s, 291843 effective words/s
INFO - 2023-11-28 03:32:49,438: EPOCH 15: training on 40200 raw words (37403 effective words) took 0.1s, 270984 effective words/s
INFO - 2023-11-28 03:32:49,578: EPOCH 16: training on 40200 raw words (37337 effective words) took 0.1s, 272144 effective words/s
INFO - 2023-11-28 03:32:49,728: EPOCH 17: training on 40200 raw words (37420 effective words) took 0.1s, 253050 effective words/s
INFO - 2023-11-28 03:32:49,863: EPOCH 18: training on 40200 raw words (37437 effective words) took 0.1s, 282013 effective words/s
INFO - 2023-11-28 03:32:50,003: EPOCH 19: training on 40200 raw words (37518 effective words) took 0.1s, 271694 effective words/s
INFO - 2023-11-28 03:32:50,003: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748635 effective words) took 2.8s, 265163 effective words/s', 'datetime': '2023-11-28T03:32:50.003798', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:50,003: collecting all words and their counts
INFO - 2023-11-28 03:32:50,004: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:50,011: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:50,011: Updating model with new vocabulary
INFO - 2023-11-28 03:32:50,013: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:50.013938', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:50,017: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:50,017: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:32:50,017: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37435.44933392755 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:50.017360', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:50,023: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:50,023: updating layer weights
INFO - 2023-11-28 03:32:50,023: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:50.023325', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:50,023: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:50,023: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:50.023566', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:50,153: EPOCH 0: training on 40200 raw words (37328 effective words) took 0.1s, 292837 effective words/s
INFO - 2023-11-28 03:32:50,284: EPOCH 1: training on 40200 raw words (37460 effective words) took 0.1s, 289843 effective words/s
INFO - 2023-11-28 03:32:50,425: EPOCH 2: training on 40200 raw words (37464 effective words) took 0.1s, 270216 effective words/s
INFO - 2023-11-28 03:32:50,561: EPOCH 3: training on 40200 raw words (37491 effective words) took 0.1s, 280971 effective words/s
INFO - 2023-11-28 03:32:50,695: EPOCH 4: training on 40200 raw words (37473 effective words) took 0.1s, 285880 effective words/s
INFO - 2023-11-28 03:32:50,831: EPOCH 5: training on 40200 raw words (37427 effective words) took 0.1s, 279809 effective words/s
INFO - 2023-11-28 03:32:50,957: EPOCH 6: training on 40200 raw words (37459 effective words) took 0.1s, 300373 effective words/s
INFO - 2023-11-28 03:32:51,092: EPOCH 7: training on 40200 raw words (37424 effective words) took 0.1s, 282364 effective words/s
INFO - 2023-11-28 03:32:51,228: EPOCH 8: training on 40200 raw words (37493 effective words) took 0.1s, 282186 effective words/s
INFO - 2023-11-28 03:32:51,363: EPOCH 9: training on 40200 raw words (37469 effective words) took 0.1s, 281848 effective words/s
INFO - 2023-11-28 03:32:51,490: EPOCH 10: training on 40200 raw words (37402 effective words) took 0.1s, 301261 effective words/s
INFO - 2023-11-28 03:32:51,623: EPOCH 11: training on 40200 raw words (37337 effective words) took 0.1s, 286029 effective words/s
INFO - 2023-11-28 03:32:51,759: EPOCH 12: training on 40200 raw words (37388 effective words) took 0.1s, 286973 effective words/s
INFO - 2023-11-28 03:32:51,896: EPOCH 13: training on 40200 raw words (37372 effective words) took 0.1s, 279429 effective words/s
INFO - 2023-11-28 03:32:52,028: EPOCH 14: training on 40200 raw words (37493 effective words) took 0.1s, 289607 effective words/s
INFO - 2023-11-28 03:32:52,164: EPOCH 15: training on 40200 raw words (37424 effective words) took 0.1s, 278605 effective words/s
INFO - 2023-11-28 03:32:52,303: EPOCH 16: training on 40200 raw words (37385 effective words) took 0.1s, 273757 effective words/s
INFO - 2023-11-28 03:32:52,436: EPOCH 17: training on 40200 raw words (37423 effective words) took 0.1s, 286315 effective words/s
INFO - 2023-11-28 03:32:52,571: EPOCH 18: training on 40200 raw words (37411 effective words) took 0.1s, 281478 effective words/s
INFO - 2023-11-28 03:32:52,708: EPOCH 19: training on 40200 raw words (37491 effective words) took 0.1s, 278692 effective words/s
INFO - 2023-11-28 03:32:52,708: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748614 effective words) took 2.7s, 278807 effective words/s', 'datetime': '2023-11-28T03:32:52.708760', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:52,708: collecting all words and their counts
INFO - 2023-11-28 03:32:52,709: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:52,715: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:52,715: Updating model with new vocabulary
INFO - 2023-11-28 03:32:52,719: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:52.719309', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:52,723: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:52,723: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:32:52,723: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37325.519861206274 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:32:52.723250', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:52,729: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:52,729: updating layer weights
INFO - 2023-11-28 03:32:52,729: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:52.729825', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:52,729: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:52,730: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:52.730009', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:52,866: EPOCH 0: training on 40200 raw words (37307 effective words) took 0.1s, 278403 effective words/s
INFO - 2023-11-28 03:32:53,003: EPOCH 1: training on 40200 raw words (37315 effective words) took 0.1s, 276855 effective words/s
INFO - 2023-11-28 03:32:53,146: EPOCH 2: training on 40200 raw words (37318 effective words) took 0.1s, 265394 effective words/s
INFO - 2023-11-28 03:32:53,290: EPOCH 3: training on 40200 raw words (37322 effective words) took 0.1s, 263163 effective words/s
INFO - 2023-11-28 03:32:53,442: EPOCH 4: training on 40200 raw words (37394 effective words) took 0.1s, 250817 effective words/s
INFO - 2023-11-28 03:32:53,584: EPOCH 5: training on 40200 raw words (37340 effective words) took 0.1s, 266754 effective words/s
INFO - 2023-11-28 03:32:53,726: EPOCH 6: training on 40200 raw words (37294 effective words) took 0.1s, 267068 effective words/s
INFO - 2023-11-28 03:32:53,864: EPOCH 7: training on 40200 raw words (37333 effective words) took 0.1s, 276204 effective words/s
INFO - 2023-11-28 03:32:54,000: EPOCH 8: training on 40200 raw words (37331 effective words) took 0.1s, 277885 effective words/s
INFO - 2023-11-28 03:32:54,142: EPOCH 9: training on 40200 raw words (37391 effective words) took 0.1s, 269483 effective words/s
INFO - 2023-11-28 03:32:54,285: EPOCH 10: training on 40200 raw words (37309 effective words) took 0.1s, 264409 effective words/s
INFO - 2023-11-28 03:32:54,424: EPOCH 11: training on 40200 raw words (37314 effective words) took 0.1s, 272883 effective words/s
INFO - 2023-11-28 03:32:54,567: EPOCH 12: training on 40200 raw words (37362 effective words) took 0.1s, 265428 effective words/s
INFO - 2023-11-28 03:32:54,708: EPOCH 13: training on 40200 raw words (37314 effective words) took 0.1s, 269389 effective words/s
INFO - 2023-11-28 03:32:54,855: EPOCH 14: training on 40200 raw words (37302 effective words) took 0.1s, 259168 effective words/s
INFO - 2023-11-28 03:32:54,992: EPOCH 15: training on 40200 raw words (37259 effective words) took 0.1s, 275793 effective words/s
INFO - 2023-11-28 03:32:55,135: EPOCH 16: training on 40200 raw words (37303 effective words) took 0.1s, 265138 effective words/s
INFO - 2023-11-28 03:32:55,276: EPOCH 17: training on 40200 raw words (37341 effective words) took 0.1s, 269078 effective words/s
INFO - 2023-11-28 03:32:55,422: EPOCH 18: training on 40200 raw words (37289 effective words) took 0.1s, 259231 effective words/s
INFO - 2023-11-28 03:32:55,564: EPOCH 19: training on 40200 raw words (37359 effective words) took 0.1s, 268561 effective words/s
INFO - 2023-11-28 03:32:55,565: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746497 effective words) took 2.8s, 263308 effective words/s', 'datetime': '2023-11-28T03:32:55.565193', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:55,565: collecting all words and their counts
INFO - 2023-11-28 03:32:55,565: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:55,572: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:55,572: Updating model with new vocabulary
INFO - 2023-11-28 03:32:55,575: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:55.575602', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:55,579: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:55,579: sample=0.001 downsamples 69 most-common words
INFO - 2023-11-28 03:32:55,579: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37378.87328672882 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:32:55.579276', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:55,585: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:55,585: updating layer weights
INFO - 2023-11-28 03:32:55,585: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:55.585764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:55,585: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:55,586: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:55.585993', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:55,722: EPOCH 0: training on 40200 raw words (37404 effective words) took 0.1s, 279591 effective words/s
INFO - 2023-11-28 03:32:55,856: EPOCH 1: training on 40200 raw words (37453 effective words) took 0.1s, 283803 effective words/s
INFO - 2023-11-28 03:32:55,990: EPOCH 2: training on 40200 raw words (37419 effective words) took 0.1s, 284017 effective words/s
INFO - 2023-11-28 03:32:56,128: EPOCH 3: training on 40200 raw words (37458 effective words) took 0.1s, 275459 effective words/s
INFO - 2023-11-28 03:32:56,261: EPOCH 4: training on 40200 raw words (37301 effective words) took 0.1s, 286884 effective words/s
INFO - 2023-11-28 03:32:56,396: EPOCH 5: training on 40200 raw words (37449 effective words) took 0.1s, 280577 effective words/s
INFO - 2023-11-28 03:32:56,534: EPOCH 6: training on 40200 raw words (37277 effective words) took 0.1s, 276987 effective words/s
INFO - 2023-11-28 03:32:56,665: EPOCH 7: training on 40200 raw words (37442 effective words) took 0.1s, 290137 effective words/s
INFO - 2023-11-28 03:32:56,798: EPOCH 8: training on 40200 raw words (37384 effective words) took 0.1s, 286068 effective words/s
INFO - 2023-11-28 03:32:56,930: EPOCH 9: training on 40200 raw words (37368 effective words) took 0.1s, 289412 effective words/s
INFO - 2023-11-28 03:32:57,059: EPOCH 10: training on 40200 raw words (37306 effective words) took 0.1s, 293999 effective words/s
INFO - 2023-11-28 03:32:57,195: EPOCH 11: training on 40200 raw words (37459 effective words) took 0.1s, 279825 effective words/s
INFO - 2023-11-28 03:32:57,329: EPOCH 12: training on 40200 raw words (37427 effective words) took 0.1s, 284949 effective words/s
INFO - 2023-11-28 03:32:57,464: EPOCH 13: training on 40200 raw words (37327 effective words) took 0.1s, 280269 effective words/s
INFO - 2023-11-28 03:32:57,601: EPOCH 14: training on 40200 raw words (37366 effective words) took 0.1s, 279373 effective words/s
INFO - 2023-11-28 03:32:57,753: EPOCH 15: training on 40200 raw words (37425 effective words) took 0.2s, 249184 effective words/s
INFO - 2023-11-28 03:32:57,882: EPOCH 16: training on 40200 raw words (37363 effective words) took 0.1s, 294903 effective words/s
INFO - 2023-11-28 03:32:58,015: EPOCH 17: training on 40200 raw words (37476 effective words) took 0.1s, 286119 effective words/s
INFO - 2023-11-28 03:32:58,154: EPOCH 18: training on 40200 raw words (37385 effective words) took 0.1s, 274434 effective words/s
INFO - 2023-11-28 03:32:58,288: EPOCH 19: training on 40200 raw words (37349 effective words) took 0.1s, 284249 effective words/s
INFO - 2023-11-28 03:32:58,288: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747838 effective words) took 2.7s, 276705 effective words/s', 'datetime': '2023-11-28T03:32:58.288772', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:58,289: collecting all words and their counts
INFO - 2023-11-28 03:32:58,289: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:32:58,296: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:32:58,296: Updating model with new vocabulary
INFO - 2023-11-28 03:32:58,299: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:32:58.299965', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:58,303: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:32:58,303: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:32:58,303: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37432.962773437604 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:32:58.303485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:32:58,309: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:32:58,309: updating layer weights
INFO - 2023-11-28 03:32:58,309: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:32:58.309526', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:32:58,309: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:32:58,309: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:32:58.309704', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:32:58,454: EPOCH 0: training on 40200 raw words (37490 effective words) took 0.1s, 263189 effective words/s
INFO - 2023-11-28 03:32:58,595: EPOCH 1: training on 40200 raw words (37464 effective words) took 0.1s, 270493 effective words/s
INFO - 2023-11-28 03:32:58,728: EPOCH 2: training on 40200 raw words (37455 effective words) took 0.1s, 286654 effective words/s
INFO - 2023-11-28 03:32:58,868: EPOCH 3: training on 40200 raw words (37459 effective words) took 0.1s, 272506 effective words/s
INFO - 2023-11-28 03:32:59,011: EPOCH 4: training on 40200 raw words (37370 effective words) took 0.1s, 266760 effective words/s
INFO - 2023-11-28 03:32:59,154: EPOCH 5: training on 40200 raw words (37423 effective words) took 0.1s, 266258 effective words/s
INFO - 2023-11-28 03:32:59,295: EPOCH 6: training on 40200 raw words (37379 effective words) took 0.1s, 278138 effective words/s
INFO - 2023-11-28 03:32:59,439: EPOCH 7: training on 40200 raw words (37408 effective words) took 0.1s, 263716 effective words/s
INFO - 2023-11-28 03:32:59,582: EPOCH 8: training on 40200 raw words (37318 effective words) took 0.1s, 266191 effective words/s
INFO - 2023-11-28 03:32:59,726: EPOCH 9: training on 40200 raw words (37398 effective words) took 0.1s, 263612 effective words/s
INFO - 2023-11-28 03:32:59,861: EPOCH 10: training on 40200 raw words (37428 effective words) took 0.1s, 282859 effective words/s
INFO - 2023-11-28 03:33:00,007: EPOCH 11: training on 40200 raw words (37352 effective words) took 0.1s, 260387 effective words/s
INFO - 2023-11-28 03:33:00,153: EPOCH 12: training on 40200 raw words (37387 effective words) took 0.1s, 261422 effective words/s
INFO - 2023-11-28 03:33:00,296: EPOCH 13: training on 40200 raw words (37486 effective words) took 0.1s, 266255 effective words/s
INFO - 2023-11-28 03:33:00,428: EPOCH 14: training on 40200 raw words (37443 effective words) took 0.1s, 289154 effective words/s
INFO - 2023-11-28 03:33:00,564: EPOCH 15: training on 40200 raw words (37349 effective words) took 0.1s, 278469 effective words/s
INFO - 2023-11-28 03:33:00,698: EPOCH 16: training on 40200 raw words (37443 effective words) took 0.1s, 283435 effective words/s
INFO - 2023-11-28 03:33:00,837: EPOCH 17: training on 40200 raw words (37429 effective words) took 0.1s, 273667 effective words/s
INFO - 2023-11-28 03:33:00,977: EPOCH 18: training on 40200 raw words (37384 effective words) took 0.1s, 270756 effective words/s
INFO - 2023-11-28 03:33:01,119: EPOCH 19: training on 40200 raw words (37457 effective words) took 0.1s, 278355 effective words/s
INFO - 2023-11-28 03:33:01,119: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748322 effective words) took 2.8s, 266346 effective words/s', 'datetime': '2023-11-28T03:33:01.119432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:01,119: collecting all words and their counts
INFO - 2023-11-28 03:33:01,119: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:01,126: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:01,126: Updating model with new vocabulary
INFO - 2023-11-28 03:33:01,130: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:01.130197', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:01,133: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:01,133: sample=0.001 downsamples 77 most-common words
INFO - 2023-11-28 03:33:01,133: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37322.15536055419 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:33:01.133524', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:01,138: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:01,138: updating layer weights
INFO - 2023-11-28 03:33:01,139: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:01.139156', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:01,139: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:01,139: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:01.139331', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:01,273: EPOCH 0: training on 40200 raw words (37334 effective words) took 0.1s, 284045 effective words/s
INFO - 2023-11-28 03:33:01,411: EPOCH 1: training on 40200 raw words (37311 effective words) took 0.1s, 274544 effective words/s
INFO - 2023-11-28 03:33:01,543: EPOCH 2: training on 40200 raw words (37269 effective words) took 0.1s, 287086 effective words/s
INFO - 2023-11-28 03:33:01,674: EPOCH 3: training on 40200 raw words (37299 effective words) took 0.1s, 290021 effective words/s
INFO - 2023-11-28 03:33:01,808: EPOCH 4: training on 40200 raw words (37351 effective words) took 0.1s, 289242 effective words/s
INFO - 2023-11-28 03:33:01,943: EPOCH 5: training on 40200 raw words (37404 effective words) took 0.1s, 282417 effective words/s
INFO - 2023-11-28 03:33:02,077: EPOCH 6: training on 40200 raw words (37319 effective words) took 0.1s, 282385 effective words/s
INFO - 2023-11-28 03:33:02,210: EPOCH 7: training on 40200 raw words (37274 effective words) took 0.1s, 285263 effective words/s
INFO - 2023-11-28 03:33:02,344: EPOCH 8: training on 40200 raw words (37295 effective words) took 0.1s, 283391 effective words/s
INFO - 2023-11-28 03:33:02,478: EPOCH 9: training on 40200 raw words (37269 effective words) took 0.1s, 283528 effective words/s
INFO - 2023-11-28 03:33:02,606: EPOCH 10: training on 40200 raw words (37363 effective words) took 0.1s, 295638 effective words/s
INFO - 2023-11-28 03:33:02,737: EPOCH 11: training on 40200 raw words (37289 effective words) took 0.1s, 290050 effective words/s
INFO - 2023-11-28 03:33:02,867: EPOCH 12: training on 40200 raw words (37364 effective words) took 0.1s, 292826 effective words/s
INFO - 2023-11-28 03:33:03,001: EPOCH 13: training on 40200 raw words (37335 effective words) took 0.1s, 284115 effective words/s
INFO - 2023-11-28 03:33:03,132: EPOCH 14: training on 40200 raw words (37343 effective words) took 0.1s, 290522 effective words/s
INFO - 2023-11-28 03:33:03,270: EPOCH 15: training on 40200 raw words (37314 effective words) took 0.1s, 275590 effective words/s
INFO - 2023-11-28 03:33:03,403: EPOCH 16: training on 40200 raw words (37314 effective words) took 0.1s, 285883 effective words/s
INFO - 2023-11-28 03:33:03,542: EPOCH 17: training on 40200 raw words (37234 effective words) took 0.1s, 272329 effective words/s
INFO - 2023-11-28 03:33:03,676: EPOCH 18: training on 40200 raw words (37307 effective words) took 0.1s, 284256 effective words/s
INFO - 2023-11-28 03:33:03,811: EPOCH 19: training on 40200 raw words (37275 effective words) took 0.1s, 280217 effective words/s
INFO - 2023-11-28 03:33:03,812: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746263 effective words) took 2.7s, 279221 effective words/s', 'datetime': '2023-11-28T03:33:03.812099', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:03,814: collecting all words and their counts
INFO - 2023-11-28 03:33:03,815: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:03,821: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:03,821: Updating model with new vocabulary
INFO - 2023-11-28 03:33:03,825: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:03.825111', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:03,828: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:03,828: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:33:03,829: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37395.2292207844 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:33:03.829045', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:03,835: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:03,835: updating layer weights
INFO - 2023-11-28 03:33:03,835: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:03.835357', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:03,835: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:03,835: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:03.835703', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:03,979: EPOCH 0: training on 40200 raw words (37442 effective words) took 0.1s, 273795 effective words/s
INFO - 2023-11-28 03:33:04,123: EPOCH 1: training on 40200 raw words (37342 effective words) took 0.1s, 264513 effective words/s
INFO - 2023-11-28 03:33:04,259: EPOCH 2: training on 40200 raw words (37357 effective words) took 0.1s, 280242 effective words/s
INFO - 2023-11-28 03:33:04,399: EPOCH 3: training on 40200 raw words (37336 effective words) took 0.1s, 270907 effective words/s
INFO - 2023-11-28 03:33:04,541: EPOCH 4: training on 40200 raw words (37428 effective words) took 0.1s, 267972 effective words/s
INFO - 2023-11-28 03:33:04,686: EPOCH 5: training on 40200 raw words (37438 effective words) took 0.1s, 263085 effective words/s
INFO - 2023-11-28 03:33:04,828: EPOCH 6: training on 40200 raw words (37437 effective words) took 0.1s, 267089 effective words/s
INFO - 2023-11-28 03:33:04,969: EPOCH 7: training on 40200 raw words (37347 effective words) took 0.1s, 268925 effective words/s
INFO - 2023-11-28 03:33:05,111: EPOCH 8: training on 40200 raw words (37395 effective words) took 0.1s, 268103 effective words/s
INFO - 2023-11-28 03:33:05,250: EPOCH 9: training on 40200 raw words (37371 effective words) took 0.1s, 274192 effective words/s
INFO - 2023-11-28 03:33:05,392: EPOCH 10: training on 40200 raw words (37439 effective words) took 0.1s, 267212 effective words/s
INFO - 2023-11-28 03:33:05,538: EPOCH 11: training on 40200 raw words (37369 effective words) took 0.1s, 260458 effective words/s
INFO - 2023-11-28 03:33:05,671: EPOCH 12: training on 40200 raw words (37390 effective words) took 0.1s, 285866 effective words/s
INFO - 2023-11-28 03:33:05,804: EPOCH 13: training on 40200 raw words (37397 effective words) took 0.1s, 286435 effective words/s
INFO - 2023-11-28 03:33:05,945: EPOCH 14: training on 40200 raw words (37453 effective words) took 0.1s, 269365 effective words/s
INFO - 2023-11-28 03:33:06,088: EPOCH 15: training on 40200 raw words (37393 effective words) took 0.1s, 265506 effective words/s
INFO - 2023-11-28 03:33:06,228: EPOCH 16: training on 40200 raw words (37366 effective words) took 0.1s, 272546 effective words/s
INFO - 2023-11-28 03:33:06,377: EPOCH 17: training on 40200 raw words (37402 effective words) took 0.1s, 255649 effective words/s
INFO - 2023-11-28 03:33:06,521: EPOCH 18: training on 40200 raw words (37386 effective words) took 0.1s, 263378 effective words/s
INFO - 2023-11-28 03:33:06,667: EPOCH 19: training on 40200 raw words (37400 effective words) took 0.1s, 260364 effective words/s
INFO - 2023-11-28 03:33:06,667: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747888 effective words) took 2.8s, 264101 effective words/s', 'datetime': '2023-11-28T03:33:06.667646', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:06,667: collecting all words and their counts
INFO - 2023-11-28 03:33:06,668: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:06,675: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:06,675: Updating model with new vocabulary
INFO - 2023-11-28 03:33:06,678: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:06.678607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:06,681: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:06,682: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:33:06,682: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37220.32412112686 word corpus (92.6%% of prior 40200)', 'datetime': '2023-11-28T03:33:06.682132', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:06,687: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:06,688: updating layer weights
INFO - 2023-11-28 03:33:06,688: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:06.688203', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:06,688: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:06,688: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:06.688401', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:06,827: EPOCH 0: training on 40200 raw words (37199 effective words) took 0.1s, 272014 effective words/s
INFO - 2023-11-28 03:33:06,956: EPOCH 1: training on 40200 raw words (37224 effective words) took 0.1s, 294476 effective words/s
INFO - 2023-11-28 03:33:07,082: EPOCH 2: training on 40200 raw words (37229 effective words) took 0.1s, 300551 effective words/s
INFO - 2023-11-28 03:33:07,213: EPOCH 3: training on 40200 raw words (37214 effective words) took 0.1s, 290000 effective words/s
INFO - 2023-11-28 03:33:07,350: EPOCH 4: training on 40200 raw words (37256 effective words) took 0.1s, 275694 effective words/s
INFO - 2023-11-28 03:33:07,491: EPOCH 5: training on 40200 raw words (37266 effective words) took 0.1s, 269811 effective words/s
INFO - 2023-11-28 03:33:07,625: EPOCH 6: training on 40200 raw words (37276 effective words) took 0.1s, 289302 effective words/s
INFO - 2023-11-28 03:33:07,759: EPOCH 7: training on 40200 raw words (37253 effective words) took 0.1s, 285481 effective words/s
INFO - 2023-11-28 03:33:07,884: EPOCH 8: training on 40200 raw words (37188 effective words) took 0.1s, 301205 effective words/s
INFO - 2023-11-28 03:33:08,020: EPOCH 9: training on 40200 raw words (37259 effective words) took 0.1s, 279145 effective words/s
INFO - 2023-11-28 03:33:08,177: EPOCH 10: training on 40200 raw words (37286 effective words) took 0.2s, 241742 effective words/s
INFO - 2023-11-28 03:33:08,312: EPOCH 11: training on 40200 raw words (37272 effective words) took 0.1s, 293033 effective words/s
INFO - 2023-11-28 03:33:08,440: EPOCH 12: training on 40200 raw words (37267 effective words) took 0.1s, 295618 effective words/s
INFO - 2023-11-28 03:33:08,576: EPOCH 13: training on 40200 raw words (37252 effective words) took 0.1s, 278667 effective words/s
INFO - 2023-11-28 03:33:08,710: EPOCH 14: training on 40200 raw words (37207 effective words) took 0.1s, 282753 effective words/s
INFO - 2023-11-28 03:33:08,846: EPOCH 15: training on 40200 raw words (37327 effective words) took 0.1s, 280871 effective words/s
INFO - 2023-11-28 03:33:08,982: EPOCH 16: training on 40200 raw words (37242 effective words) took 0.1s, 284247 effective words/s
INFO - 2023-11-28 03:33:09,115: EPOCH 17: training on 40200 raw words (37272 effective words) took 0.1s, 286600 effective words/s
INFO - 2023-11-28 03:33:09,248: EPOCH 18: training on 40200 raw words (37255 effective words) took 0.1s, 285590 effective words/s
INFO - 2023-11-28 03:33:09,376: EPOCH 19: training on 40200 raw words (37185 effective words) took 0.1s, 294597 effective words/s
INFO - 2023-11-28 03:33:09,376: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (744929 effective words) took 2.7s, 277106 effective words/s', 'datetime': '2023-11-28T03:33:09.376764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:09,376: collecting all words and their counts
INFO - 2023-11-28 03:33:09,377: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:09,384: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:09,384: Updating model with new vocabulary
INFO - 2023-11-28 03:33:09,387: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:09.387165', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:09,390: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:09,390: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:33:09,390: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37334.24209575508 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:33:09.390911', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:09,396: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:09,396: updating layer weights
INFO - 2023-11-28 03:33:09,396: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:09.396474', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:09,396: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:09,396: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:09.396636', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:09,541: EPOCH 0: training on 40200 raw words (37310 effective words) took 0.1s, 261405 effective words/s
INFO - 2023-11-28 03:33:09,686: EPOCH 1: training on 40200 raw words (37361 effective words) took 0.1s, 262956 effective words/s
INFO - 2023-11-28 03:33:09,832: EPOCH 2: training on 40200 raw words (37309 effective words) took 0.1s, 259132 effective words/s
INFO - 2023-11-28 03:33:09,969: EPOCH 3: training on 40200 raw words (37348 effective words) took 0.1s, 276461 effective words/s
INFO - 2023-11-28 03:33:10,107: EPOCH 4: training on 40200 raw words (37354 effective words) took 0.1s, 275978 effective words/s
INFO - 2023-11-28 03:33:10,250: EPOCH 5: training on 40200 raw words (37332 effective words) took 0.1s, 265888 effective words/s
INFO - 2023-11-28 03:33:10,390: EPOCH 6: training on 40200 raw words (37372 effective words) took 0.1s, 271682 effective words/s
INFO - 2023-11-28 03:33:10,531: EPOCH 7: training on 40200 raw words (37246 effective words) took 0.1s, 268007 effective words/s
INFO - 2023-11-28 03:33:10,672: EPOCH 8: training on 40200 raw words (37392 effective words) took 0.1s, 268780 effective words/s
INFO - 2023-11-28 03:33:10,816: EPOCH 9: training on 40200 raw words (37346 effective words) took 0.1s, 264741 effective words/s
INFO - 2023-11-28 03:33:10,955: EPOCH 10: training on 40200 raw words (37400 effective words) took 0.1s, 273088 effective words/s
INFO - 2023-11-28 03:33:11,096: EPOCH 11: training on 40200 raw words (37391 effective words) took 0.1s, 270088 effective words/s
INFO - 2023-11-28 03:33:11,241: EPOCH 12: training on 40200 raw words (37365 effective words) took 0.1s, 262242 effective words/s
INFO - 2023-11-28 03:33:11,377: EPOCH 13: training on 40200 raw words (37286 effective words) took 0.1s, 278471 effective words/s
INFO - 2023-11-28 03:33:11,518: EPOCH 14: training on 40200 raw words (37286 effective words) took 0.1s, 268857 effective words/s
INFO - 2023-11-28 03:33:11,661: EPOCH 15: training on 40200 raw words (37343 effective words) took 0.1s, 274075 effective words/s
INFO - 2023-11-28 03:33:11,805: EPOCH 16: training on 40200 raw words (37346 effective words) took 0.1s, 264925 effective words/s
INFO - 2023-11-28 03:33:11,945: EPOCH 17: training on 40200 raw words (37271 effective words) took 0.1s, 269030 effective words/s
INFO - 2023-11-28 03:33:12,081: EPOCH 18: training on 40200 raw words (37352 effective words) took 0.1s, 281228 effective words/s
INFO - 2023-11-28 03:33:12,222: EPOCH 19: training on 40200 raw words (37300 effective words) took 0.1s, 268724 effective words/s
INFO - 2023-11-28 03:33:12,222: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746710 effective words) took 2.8s, 264268 effective words/s', 'datetime': '2023-11-28T03:33:12.222349', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:12,222: collecting all words and their counts
INFO - 2023-11-28 03:33:12,222: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:12,229: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:12,229: Updating model with new vocabulary
INFO - 2023-11-28 03:33:12,232: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:12.232617', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:12,236: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:12,236: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:33:12,236: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37432.42929841349 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:33:12.236442', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:12,242: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:12,242: updating layer weights
INFO - 2023-11-28 03:33:12,243: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:12.243059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:12,243: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:12,243: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:12.243236', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:12,376: EPOCH 0: training on 40200 raw words (37456 effective words) took 0.1s, 300695 effective words/s
INFO - 2023-11-28 03:33:12,505: EPOCH 1: training on 40200 raw words (37402 effective words) took 0.1s, 305165 effective words/s
INFO - 2023-11-28 03:33:12,634: EPOCH 2: training on 40200 raw words (37429 effective words) took 0.1s, 294465 effective words/s
INFO - 2023-11-28 03:33:12,774: EPOCH 3: training on 40200 raw words (37433 effective words) took 0.1s, 272349 effective words/s
INFO - 2023-11-28 03:33:12,904: EPOCH 4: training on 40200 raw words (37456 effective words) took 0.1s, 294698 effective words/s
INFO - 2023-11-28 03:33:13,036: EPOCH 5: training on 40200 raw words (37459 effective words) took 0.1s, 287370 effective words/s
INFO - 2023-11-28 03:33:13,175: EPOCH 6: training on 40200 raw words (37422 effective words) took 0.1s, 274398 effective words/s
INFO - 2023-11-28 03:33:13,312: EPOCH 7: training on 40200 raw words (37334 effective words) took 0.1s, 277722 effective words/s
INFO - 2023-11-28 03:33:13,440: EPOCH 8: training on 40200 raw words (37445 effective words) took 0.1s, 298581 effective words/s
INFO - 2023-11-28 03:33:13,576: EPOCH 9: training on 40200 raw words (37440 effective words) took 0.1s, 279338 effective words/s
INFO - 2023-11-28 03:33:13,713: EPOCH 10: training on 40200 raw words (37413 effective words) took 0.1s, 279112 effective words/s
INFO - 2023-11-28 03:33:13,846: EPOCH 11: training on 40200 raw words (37458 effective words) took 0.1s, 285495 effective words/s
INFO - 2023-11-28 03:33:13,973: EPOCH 12: training on 40200 raw words (37432 effective words) took 0.1s, 307293 effective words/s
INFO - 2023-11-28 03:33:14,108: EPOCH 13: training on 40200 raw words (37473 effective words) took 0.1s, 284333 effective words/s
INFO - 2023-11-28 03:33:14,242: EPOCH 14: training on 40200 raw words (37470 effective words) took 0.1s, 284613 effective words/s
INFO - 2023-11-28 03:33:14,374: EPOCH 15: training on 40200 raw words (37445 effective words) took 0.1s, 288860 effective words/s
INFO - 2023-11-28 03:33:14,511: EPOCH 16: training on 40200 raw words (37470 effective words) took 0.1s, 280085 effective words/s
INFO - 2023-11-28 03:33:14,646: EPOCH 17: training on 40200 raw words (37390 effective words) took 0.1s, 280031 effective words/s
INFO - 2023-11-28 03:33:14,783: EPOCH 18: training on 40200 raw words (37467 effective words) took 0.1s, 289599 effective words/s
INFO - 2023-11-28 03:33:14,916: EPOCH 19: training on 40200 raw words (37462 effective words) took 0.1s, 286539 effective words/s
INFO - 2023-11-28 03:33:14,916: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748756 effective words) took 2.7s, 280083 effective words/s', 'datetime': '2023-11-28T03:33:14.916681', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:14,916: collecting all words and their counts
INFO - 2023-11-28 03:33:14,917: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:14,923: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:14,923: Updating model with new vocabulary
INFO - 2023-11-28 03:33:14,927: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:14.927778', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:14,933: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:14,933: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:33:14,933: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37348.94844111914 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:33:14.933705', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:14,942: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:14,943: updating layer weights
INFO - 2023-11-28 03:33:14,943: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:14.943409', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:14,943: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:14,943: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:14.943694', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:15,080: EPOCH 0: training on 40200 raw words (37299 effective words) took 0.1s, 278733 effective words/s
INFO - 2023-11-28 03:33:15,235: EPOCH 1: training on 40200 raw words (37386 effective words) took 0.2s, 244042 effective words/s
INFO - 2023-11-28 03:33:15,374: EPOCH 2: training on 40200 raw words (37330 effective words) took 0.1s, 272740 effective words/s
INFO - 2023-11-28 03:33:15,514: EPOCH 3: training on 40200 raw words (37429 effective words) took 0.1s, 272260 effective words/s
INFO - 2023-11-28 03:33:15,654: EPOCH 4: training on 40200 raw words (37396 effective words) took 0.1s, 272044 effective words/s
INFO - 2023-11-28 03:33:15,796: EPOCH 5: training on 40200 raw words (37419 effective words) took 0.1s, 266667 effective words/s
INFO - 2023-11-28 03:33:15,943: EPOCH 6: training on 40200 raw words (37379 effective words) took 0.1s, 258320 effective words/s
INFO - 2023-11-28 03:33:16,089: EPOCH 7: training on 40200 raw words (37418 effective words) took 0.1s, 260877 effective words/s
INFO - 2023-11-28 03:33:16,233: EPOCH 8: training on 40200 raw words (37425 effective words) took 0.1s, 264751 effective words/s
INFO - 2023-11-28 03:33:16,383: EPOCH 9: training on 40200 raw words (37255 effective words) took 0.1s, 251713 effective words/s
INFO - 2023-11-28 03:33:16,525: EPOCH 10: training on 40200 raw words (37355 effective words) took 0.1s, 266854 effective words/s
INFO - 2023-11-28 03:33:16,679: EPOCH 11: training on 40200 raw words (37377 effective words) took 0.2s, 246499 effective words/s
INFO - 2023-11-28 03:33:16,818: EPOCH 12: training on 40200 raw words (37324 effective words) took 0.1s, 274389 effective words/s
INFO - 2023-11-28 03:33:16,959: EPOCH 13: training on 40200 raw words (37377 effective words) took 0.1s, 267730 effective words/s
INFO - 2023-11-28 03:33:17,103: EPOCH 14: training on 40200 raw words (37348 effective words) took 0.1s, 264627 effective words/s
INFO - 2023-11-28 03:33:17,246: EPOCH 15: training on 40200 raw words (37390 effective words) took 0.1s, 265765 effective words/s
INFO - 2023-11-28 03:33:17,388: EPOCH 16: training on 40200 raw words (37392 effective words) took 0.1s, 266519 effective words/s
INFO - 2023-11-28 03:33:17,531: EPOCH 17: training on 40200 raw words (37278 effective words) took 0.1s, 266428 effective words/s
INFO - 2023-11-28 03:33:17,670: EPOCH 18: training on 40200 raw words (37354 effective words) took 0.1s, 272926 effective words/s
INFO - 2023-11-28 03:33:17,825: EPOCH 19: training on 40200 raw words (37428 effective words) took 0.2s, 244863 effective words/s
INFO - 2023-11-28 03:33:17,826: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747359 effective words) took 2.9s, 259290 effective words/s', 'datetime': '2023-11-28T03:33:17.826153', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:17,826: collecting all words and their counts
INFO - 2023-11-28 03:33:17,826: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:17,832: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:17,832: Updating model with new vocabulary
INFO - 2023-11-28 03:33:17,835: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:17.835794', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:17,839: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:17,839: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:33:17,839: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37454.05827516884 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:33:17.839818', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:17,844: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:17,844: updating layer weights
INFO - 2023-11-28 03:33:17,845: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:17.845078', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:17,845: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:17,845: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:17.845235', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:17,976: EPOCH 0: training on 40200 raw words (37502 effective words) took 0.1s, 290758 effective words/s
INFO - 2023-11-28 03:33:18,110: EPOCH 1: training on 40200 raw words (37474 effective words) took 0.1s, 285172 effective words/s
INFO - 2023-11-28 03:33:18,244: EPOCH 2: training on 40200 raw words (37416 effective words) took 0.1s, 283375 effective words/s
INFO - 2023-11-28 03:33:18,389: EPOCH 3: training on 40200 raw words (37475 effective words) took 0.1s, 263909 effective words/s
INFO - 2023-11-28 03:33:18,517: EPOCH 4: training on 40200 raw words (37505 effective words) took 0.1s, 296826 effective words/s
INFO - 2023-11-28 03:33:18,650: EPOCH 5: training on 40200 raw words (37478 effective words) took 0.1s, 287339 effective words/s
INFO - 2023-11-28 03:33:18,786: EPOCH 6: training on 40200 raw words (37433 effective words) took 0.1s, 279440 effective words/s
INFO - 2023-11-28 03:33:18,932: EPOCH 7: training on 40200 raw words (37426 effective words) took 0.1s, 260702 effective words/s
INFO - 2023-11-28 03:33:19,073: EPOCH 8: training on 40200 raw words (37403 effective words) took 0.1s, 270956 effective words/s
INFO - 2023-11-28 03:33:19,206: EPOCH 9: training on 40200 raw words (37446 effective words) took 0.1s, 289594 effective words/s
INFO - 2023-11-28 03:33:19,343: EPOCH 10: training on 40200 raw words (37474 effective words) took 0.1s, 277393 effective words/s
INFO - 2023-11-28 03:33:19,484: EPOCH 11: training on 40200 raw words (37394 effective words) took 0.1s, 268850 effective words/s
INFO - 2023-11-28 03:33:19,617: EPOCH 12: training on 40200 raw words (37428 effective words) took 0.1s, 287214 effective words/s
INFO - 2023-11-28 03:33:19,750: EPOCH 13: training on 40200 raw words (37355 effective words) took 0.1s, 286855 effective words/s
INFO - 2023-11-28 03:33:19,879: EPOCH 14: training on 40200 raw words (37441 effective words) took 0.1s, 295598 effective words/s
INFO - 2023-11-28 03:33:20,009: EPOCH 15: training on 40200 raw words (37380 effective words) took 0.1s, 293421 effective words/s
INFO - 2023-11-28 03:33:20,144: EPOCH 16: training on 40200 raw words (37462 effective words) took 0.1s, 281499 effective words/s
INFO - 2023-11-28 03:33:20,289: EPOCH 17: training on 40200 raw words (37480 effective words) took 0.1s, 262860 effective words/s
INFO - 2023-11-28 03:33:20,423: EPOCH 18: training on 40200 raw words (37510 effective words) took 0.1s, 285029 effective words/s
INFO - 2023-11-28 03:33:20,559: EPOCH 19: training on 40200 raw words (37377 effective words) took 0.1s, 279878 effective words/s
INFO - 2023-11-28 03:33:20,560: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748859 effective words) took 2.7s, 275837 effective words/s', 'datetime': '2023-11-28T03:33:20.560187', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:20,560: collecting all words and their counts
INFO - 2023-11-28 03:33:20,560: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:20,566: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:20,566: Updating model with new vocabulary
INFO - 2023-11-28 03:33:20,569: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:20.569029', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:20,573: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:20,573: sample=0.001 downsamples 79 most-common words
INFO - 2023-11-28 03:33:20,573: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37253.62621668432 word corpus (92.7%% of prior 40200)', 'datetime': '2023-11-28T03:33:20.573227', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:20,579: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:20,579: updating layer weights
INFO - 2023-11-28 03:33:20,579: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:20.579289', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:20,579: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:20,579: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:20.579700', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:20,721: EPOCH 0: training on 40200 raw words (37281 effective words) took 0.1s, 267422 effective words/s
INFO - 2023-11-28 03:33:20,865: EPOCH 1: training on 40200 raw words (37296 effective words) took 0.1s, 263522 effective words/s
INFO - 2023-11-28 03:33:21,007: EPOCH 2: training on 40200 raw words (37204 effective words) took 0.1s, 267368 effective words/s
INFO - 2023-11-28 03:33:21,144: EPOCH 3: training on 40200 raw words (37333 effective words) took 0.1s, 277269 effective words/s
INFO - 2023-11-28 03:33:21,280: EPOCH 4: training on 40200 raw words (37230 effective words) took 0.1s, 277600 effective words/s
INFO - 2023-11-28 03:33:21,421: EPOCH 5: training on 40200 raw words (37413 effective words) took 0.1s, 269845 effective words/s
INFO - 2023-11-28 03:33:21,569: EPOCH 6: training on 40200 raw words (37256 effective words) took 0.1s, 256376 effective words/s
INFO - 2023-11-28 03:33:21,701: EPOCH 7: training on 40200 raw words (37228 effective words) took 0.1s, 285963 effective words/s
INFO - 2023-11-28 03:33:21,843: EPOCH 8: training on 40200 raw words (37277 effective words) took 0.1s, 266735 effective words/s
INFO - 2023-11-28 03:33:21,986: EPOCH 9: training on 40200 raw words (37299 effective words) took 0.1s, 266359 effective words/s
INFO - 2023-11-28 03:33:22,129: EPOCH 10: training on 40200 raw words (37207 effective words) took 0.1s, 263192 effective words/s
INFO - 2023-11-28 03:33:22,272: EPOCH 11: training on 40200 raw words (37330 effective words) took 0.1s, 265994 effective words/s
INFO - 2023-11-28 03:33:22,414: EPOCH 12: training on 40200 raw words (37251 effective words) took 0.1s, 274683 effective words/s
INFO - 2023-11-28 03:33:22,554: EPOCH 13: training on 40200 raw words (37269 effective words) took 0.1s, 271530 effective words/s
INFO - 2023-11-28 03:33:22,691: EPOCH 14: training on 40200 raw words (37252 effective words) took 0.1s, 275819 effective words/s
INFO - 2023-11-28 03:33:22,834: EPOCH 15: training on 40200 raw words (37229 effective words) took 0.1s, 265108 effective words/s
INFO - 2023-11-28 03:33:22,973: EPOCH 16: training on 40200 raw words (37247 effective words) took 0.1s, 271854 effective words/s
INFO - 2023-11-28 03:33:23,112: EPOCH 17: training on 40200 raw words (37229 effective words) took 0.1s, 273456 effective words/s
INFO - 2023-11-28 03:33:23,252: EPOCH 18: training on 40200 raw words (37337 effective words) took 0.1s, 269887 effective words/s
INFO - 2023-11-28 03:33:23,385: EPOCH 19: training on 40200 raw words (37245 effective words) took 0.1s, 285139 effective words/s
INFO - 2023-11-28 03:33:23,385: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745413 effective words) took 2.8s, 265642 effective words/s', 'datetime': '2023-11-28T03:33:23.385912', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:23,386: collecting all words and their counts
INFO - 2023-11-28 03:33:23,386: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:23,392: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:23,392: Updating model with new vocabulary
INFO - 2023-11-28 03:33:23,395: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:23.395402', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:23,399: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:23,399: sample=0.001 downsamples 77 most-common words
INFO - 2023-11-28 03:33:23,399: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37410.03547872868 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:33:23.399279', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:23,405: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:23,405: updating layer weights
INFO - 2023-11-28 03:33:23,405: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:23.405378', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:23,405: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:23,405: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:23.405552', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:23,531: EPOCH 0: training on 40200 raw words (37312 effective words) took 0.1s, 313392 effective words/s
INFO - 2023-11-28 03:33:23,657: EPOCH 1: training on 40200 raw words (37394 effective words) took 0.1s, 301193 effective words/s
INFO - 2023-11-28 03:33:23,791: EPOCH 2: training on 40200 raw words (37381 effective words) took 0.1s, 285026 effective words/s
INFO - 2023-11-28 03:33:23,919: EPOCH 3: training on 40200 raw words (37419 effective words) took 0.1s, 297920 effective words/s
INFO - 2023-11-28 03:33:24,050: EPOCH 4: training on 40200 raw words (37399 effective words) took 0.1s, 290179 effective words/s
INFO - 2023-11-28 03:33:24,191: EPOCH 5: training on 40200 raw words (37402 effective words) took 0.1s, 270048 effective words/s
INFO - 2023-11-28 03:33:24,321: EPOCH 6: training on 40200 raw words (37457 effective words) took 0.1s, 293203 effective words/s
INFO - 2023-11-28 03:33:24,462: EPOCH 7: training on 40200 raw words (37349 effective words) took 0.1s, 269819 effective words/s
INFO - 2023-11-28 03:33:24,594: EPOCH 8: training on 40200 raw words (37369 effective words) took 0.1s, 287397 effective words/s
INFO - 2023-11-28 03:33:24,726: EPOCH 9: training on 40200 raw words (37435 effective words) took 0.1s, 288968 effective words/s
INFO - 2023-11-28 03:33:24,862: EPOCH 10: training on 40200 raw words (37474 effective words) took 0.1s, 280516 effective words/s
INFO - 2023-11-28 03:33:24,996: EPOCH 11: training on 40200 raw words (37475 effective words) took 0.1s, 284551 effective words/s
INFO - 2023-11-28 03:33:25,121: EPOCH 12: training on 40200 raw words (37399 effective words) took 0.1s, 304441 effective words/s
INFO - 2023-11-28 03:33:25,256: EPOCH 13: training on 40200 raw words (37506 effective words) took 0.1s, 283341 effective words/s
INFO - 2023-11-28 03:33:25,394: EPOCH 14: training on 40200 raw words (37444 effective words) took 0.1s, 276057 effective words/s
INFO - 2023-11-28 03:33:25,531: EPOCH 15: training on 40200 raw words (37453 effective words) took 0.1s, 279008 effective words/s
INFO - 2023-11-28 03:33:25,661: EPOCH 16: training on 40200 raw words (37419 effective words) took 0.1s, 291503 effective words/s
INFO - 2023-11-28 03:33:25,797: EPOCH 17: training on 40200 raw words (37376 effective words) took 0.1s, 281127 effective words/s
INFO - 2023-11-28 03:33:25,924: EPOCH 18: training on 40200 raw words (37422 effective words) took 0.1s, 300061 effective words/s
INFO - 2023-11-28 03:33:26,057: EPOCH 19: training on 40200 raw words (37414 effective words) took 0.1s, 286888 effective words/s
INFO - 2023-11-28 03:33:26,057: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748299 effective words) took 2.7s, 282189 effective words/s', 'datetime': '2023-11-28T03:33:26.057416', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:26,057: collecting all words and their counts
INFO - 2023-11-28 03:33:26,057: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:26,064: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:26,064: Updating model with new vocabulary
INFO - 2023-11-28 03:33:26,067: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:26.067779', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:26,071: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:26,071: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:33:26,071: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37319.862824389056 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:33:26.071477', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:26,077: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:26,077: updating layer weights
INFO - 2023-11-28 03:33:26,077: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:26.077949', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:26,078: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:26,078: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:26.078140', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:26,221: EPOCH 0: training on 40200 raw words (37334 effective words) took 0.1s, 264259 effective words/s
INFO - 2023-11-28 03:33:26,421: EPOCH 1: training on 40200 raw words (37386 effective words) took 0.2s, 189249 effective words/s
INFO - 2023-11-28 03:33:26,558: EPOCH 2: training on 40200 raw words (37326 effective words) took 0.1s, 278029 effective words/s
INFO - 2023-11-28 03:33:26,696: EPOCH 3: training on 40200 raw words (37353 effective words) took 0.1s, 273970 effective words/s
INFO - 2023-11-28 03:33:26,832: EPOCH 4: training on 40200 raw words (37373 effective words) took 0.1s, 280723 effective words/s
INFO - 2023-11-28 03:33:26,970: EPOCH 5: training on 40200 raw words (37297 effective words) took 0.1s, 275030 effective words/s
INFO - 2023-11-28 03:33:27,109: EPOCH 6: training on 40200 raw words (37317 effective words) took 0.1s, 273381 effective words/s
INFO - 2023-11-28 03:33:27,246: EPOCH 7: training on 40200 raw words (37313 effective words) took 0.1s, 276949 effective words/s
INFO - 2023-11-28 03:33:27,390: EPOCH 8: training on 40200 raw words (37326 effective words) took 0.1s, 264496 effective words/s
INFO - 2023-11-28 03:33:27,528: EPOCH 9: training on 40200 raw words (37242 effective words) took 0.1s, 273160 effective words/s
INFO - 2023-11-28 03:33:27,669: EPOCH 10: training on 40200 raw words (37352 effective words) took 0.1s, 268874 effective words/s
INFO - 2023-11-28 03:33:27,807: EPOCH 11: training on 40200 raw words (37281 effective words) took 0.1s, 276219 effective words/s
INFO - 2023-11-28 03:33:27,943: EPOCH 12: training on 40200 raw words (37304 effective words) took 0.1s, 278378 effective words/s
INFO - 2023-11-28 03:33:28,079: EPOCH 13: training on 40200 raw words (37290 effective words) took 0.1s, 279092 effective words/s
INFO - 2023-11-28 03:33:28,213: EPOCH 14: training on 40200 raw words (37316 effective words) took 0.1s, 282315 effective words/s
INFO - 2023-11-28 03:33:28,355: EPOCH 15: training on 40200 raw words (37318 effective words) took 0.1s, 268126 effective words/s
INFO - 2023-11-28 03:33:28,497: EPOCH 16: training on 40200 raw words (37305 effective words) took 0.1s, 265904 effective words/s
INFO - 2023-11-28 03:33:28,631: EPOCH 17: training on 40200 raw words (37402 effective words) took 0.1s, 284176 effective words/s
INFO - 2023-11-28 03:33:28,773: EPOCH 18: training on 40200 raw words (37311 effective words) took 0.1s, 266440 effective words/s
INFO - 2023-11-28 03:33:28,913: EPOCH 19: training on 40200 raw words (37387 effective words) took 0.1s, 272731 effective words/s
INFO - 2023-11-28 03:33:28,913: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746533 effective words) took 2.8s, 263297 effective words/s', 'datetime': '2023-11-28T03:33:28.913579', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:28,913: collecting all words and their counts
INFO - 2023-11-28 03:33:28,913: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:28,921: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:28,921: Updating model with new vocabulary
INFO - 2023-11-28 03:33:28,925: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:28.925740', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:28,929: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:28,929: sample=0.001 downsamples 69 most-common words
INFO - 2023-11-28 03:33:28,929: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37363.22135793547 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:33:28.929624', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:28,935: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:28,935: updating layer weights
INFO - 2023-11-28 03:33:28,935: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:28.935932', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:28,936: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:28,936: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:28.936140', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:29,070: EPOCH 0: training on 40200 raw words (37397 effective words) took 0.1s, 284291 effective words/s
INFO - 2023-11-28 03:33:29,201: EPOCH 1: training on 40200 raw words (37351 effective words) took 0.1s, 288852 effective words/s
INFO - 2023-11-28 03:33:29,337: EPOCH 2: training on 40200 raw words (37360 effective words) took 0.1s, 280029 effective words/s
INFO - 2023-11-28 03:33:29,472: EPOCH 3: training on 40200 raw words (37426 effective words) took 0.1s, 282232 effective words/s
INFO - 2023-11-28 03:33:29,611: EPOCH 4: training on 40200 raw words (37416 effective words) took 0.1s, 273635 effective words/s
INFO - 2023-11-28 03:33:29,746: EPOCH 5: training on 40200 raw words (37381 effective words) took 0.1s, 281306 effective words/s
INFO - 2023-11-28 03:33:29,880: EPOCH 6: training on 40200 raw words (37401 effective words) took 0.1s, 283736 effective words/s
INFO - 2023-11-28 03:33:30,020: EPOCH 7: training on 40200 raw words (37397 effective words) took 0.1s, 272831 effective words/s
INFO - 2023-11-28 03:33:30,144: EPOCH 8: training on 40200 raw words (37435 effective words) took 0.1s, 309218 effective words/s
INFO - 2023-11-28 03:33:30,280: EPOCH 9: training on 40200 raw words (37295 effective words) took 0.1s, 277954 effective words/s
INFO - 2023-11-28 03:33:30,413: EPOCH 10: training on 40200 raw words (37415 effective words) took 0.1s, 287686 effective words/s
INFO - 2023-11-28 03:33:30,547: EPOCH 11: training on 40200 raw words (37346 effective words) took 0.1s, 284238 effective words/s
INFO - 2023-11-28 03:33:30,686: EPOCH 12: training on 40200 raw words (37383 effective words) took 0.1s, 273689 effective words/s
INFO - 2023-11-28 03:33:30,816: EPOCH 13: training on 40200 raw words (37379 effective words) took 0.1s, 291350 effective words/s
INFO - 2023-11-28 03:33:30,951: EPOCH 14: training on 40200 raw words (37370 effective words) took 0.1s, 284129 effective words/s
INFO - 2023-11-28 03:33:31,082: EPOCH 15: training on 40200 raw words (37412 effective words) took 0.1s, 290557 effective words/s
INFO - 2023-11-28 03:33:31,217: EPOCH 16: training on 40200 raw words (37353 effective words) took 0.1s, 280969 effective words/s
INFO - 2023-11-28 03:33:31,353: EPOCH 17: training on 40200 raw words (37290 effective words) took 0.1s, 280914 effective words/s
INFO - 2023-11-28 03:33:31,489: EPOCH 18: training on 40200 raw words (37377 effective words) took 0.1s, 278335 effective words/s
INFO - 2023-11-28 03:33:31,614: EPOCH 19: training on 40200 raw words (37381 effective words) took 0.1s, 305504 effective words/s
INFO - 2023-11-28 03:33:31,614: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747565 effective words) took 2.7s, 279096 effective words/s', 'datetime': '2023-11-28T03:33:31.614773', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:31,614: collecting all words and their counts
INFO - 2023-11-28 03:33:31,615: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:31,621: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:31,622: Updating model with new vocabulary
INFO - 2023-11-28 03:33:31,625: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:31.625076', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:31,628: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:31,628: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:33:31,628: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37376.65049262489 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:33:31.628743', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:31,634: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:31,634: updating layer weights
INFO - 2023-11-28 03:33:31,634: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:31.634557', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:31,634: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:31,634: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:31.634685', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:31,774: EPOCH 0: training on 40200 raw words (37384 effective words) took 0.1s, 271742 effective words/s
INFO - 2023-11-28 03:33:31,911: EPOCH 1: training on 40200 raw words (37384 effective words) took 0.1s, 276281 effective words/s
INFO - 2023-11-28 03:33:32,046: EPOCH 2: training on 40200 raw words (37412 effective words) took 0.1s, 282891 effective words/s
INFO - 2023-11-28 03:33:32,194: EPOCH 3: training on 40200 raw words (37278 effective words) took 0.1s, 255831 effective words/s
INFO - 2023-11-28 03:33:32,339: EPOCH 4: training on 40200 raw words (37415 effective words) took 0.1s, 262545 effective words/s
INFO - 2023-11-28 03:33:32,480: EPOCH 5: training on 40200 raw words (37400 effective words) took 0.1s, 269937 effective words/s
INFO - 2023-11-28 03:33:32,622: EPOCH 6: training on 40200 raw words (37487 effective words) took 0.1s, 267443 effective words/s
INFO - 2023-11-28 03:33:32,763: EPOCH 7: training on 40200 raw words (37360 effective words) took 0.1s, 268959 effective words/s
INFO - 2023-11-28 03:33:32,903: EPOCH 8: training on 40200 raw words (37418 effective words) took 0.1s, 272372 effective words/s
INFO - 2023-11-28 03:33:33,036: EPOCH 9: training on 40200 raw words (37425 effective words) took 0.1s, 286451 effective words/s
INFO - 2023-11-28 03:33:33,170: EPOCH 10: training on 40200 raw words (37440 effective words) took 0.1s, 282992 effective words/s
INFO - 2023-11-28 03:33:33,312: EPOCH 11: training on 40200 raw words (37362 effective words) took 0.1s, 267708 effective words/s
INFO - 2023-11-28 03:33:33,456: EPOCH 12: training on 40200 raw words (37399 effective words) took 0.1s, 265347 effective words/s
INFO - 2023-11-28 03:33:33,597: EPOCH 13: training on 40200 raw words (37418 effective words) took 0.1s, 268896 effective words/s
INFO - 2023-11-28 03:33:33,741: EPOCH 14: training on 40200 raw words (37378 effective words) took 0.1s, 265002 effective words/s
INFO - 2023-11-28 03:33:33,878: EPOCH 15: training on 40200 raw words (37399 effective words) took 0.1s, 277699 effective words/s
INFO - 2023-11-28 03:33:34,018: EPOCH 16: training on 40200 raw words (37401 effective words) took 0.1s, 270712 effective words/s
INFO - 2023-11-28 03:33:34,152: EPOCH 17: training on 40200 raw words (37409 effective words) took 0.1s, 284866 effective words/s
INFO - 2023-11-28 03:33:34,292: EPOCH 18: training on 40200 raw words (37502 effective words) took 0.1s, 272556 effective words/s
INFO - 2023-11-28 03:33:34,431: EPOCH 19: training on 40200 raw words (37416 effective words) took 0.1s, 274262 effective words/s
INFO - 2023-11-28 03:33:34,431: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748087 effective words) took 2.8s, 267481 effective words/s', 'datetime': '2023-11-28T03:33:34.431538', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:34,431: collecting all words and their counts
INFO - 2023-11-28 03:33:34,431: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:34,437: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:34,437: Updating model with new vocabulary
INFO - 2023-11-28 03:33:34,440: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:34.440973', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:34,444: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:34,444: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:33:34,444: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37465.66335898899 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:33:34.444607', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:34,450: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:34,450: updating layer weights
INFO - 2023-11-28 03:33:34,451: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:34.451098', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:34,451: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:34,451: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:34.451341', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:34,581: EPOCH 0: training on 40200 raw words (37435 effective words) took 0.1s, 292321 effective words/s
INFO - 2023-11-28 03:33:34,715: EPOCH 1: training on 40200 raw words (37465 effective words) took 0.1s, 284645 effective words/s
INFO - 2023-11-28 03:33:34,847: EPOCH 2: training on 40200 raw words (37473 effective words) took 0.1s, 289501 effective words/s
INFO - 2023-11-28 03:33:34,976: EPOCH 3: training on 40200 raw words (37497 effective words) took 0.1s, 295952 effective words/s
INFO - 2023-11-28 03:33:35,111: EPOCH 4: training on 40200 raw words (37401 effective words) took 0.1s, 288756 effective words/s
INFO - 2023-11-28 03:33:35,242: EPOCH 5: training on 40200 raw words (37477 effective words) took 0.1s, 292190 effective words/s
INFO - 2023-11-28 03:33:35,378: EPOCH 6: training on 40200 raw words (37431 effective words) took 0.1s, 281479 effective words/s
INFO - 2023-11-28 03:33:35,514: EPOCH 7: training on 40200 raw words (37463 effective words) took 0.1s, 279556 effective words/s
INFO - 2023-11-28 03:33:35,645: EPOCH 8: training on 40200 raw words (37418 effective words) took 0.1s, 291467 effective words/s
INFO - 2023-11-28 03:33:35,780: EPOCH 9: training on 40200 raw words (37480 effective words) took 0.1s, 281699 effective words/s
INFO - 2023-11-28 03:33:35,921: EPOCH 10: training on 40200 raw words (37425 effective words) took 0.1s, 271592 effective words/s
INFO - 2023-11-28 03:33:36,047: EPOCH 11: training on 40200 raw words (37505 effective words) took 0.1s, 302675 effective words/s
INFO - 2023-11-28 03:33:36,182: EPOCH 12: training on 40200 raw words (37477 effective words) took 0.1s, 280903 effective words/s
INFO - 2023-11-28 03:33:36,314: EPOCH 13: training on 40200 raw words (37481 effective words) took 0.1s, 289662 effective words/s
INFO - 2023-11-28 03:33:36,447: EPOCH 14: training on 40200 raw words (37470 effective words) took 0.1s, 287967 effective words/s
INFO - 2023-11-28 03:33:36,581: EPOCH 15: training on 40200 raw words (37495 effective words) took 0.1s, 284368 effective words/s
INFO - 2023-11-28 03:33:36,712: EPOCH 16: training on 40200 raw words (37483 effective words) took 0.1s, 291805 effective words/s
INFO - 2023-11-28 03:33:36,845: EPOCH 17: training on 40200 raw words (37519 effective words) took 0.1s, 287963 effective words/s
INFO - 2023-11-28 03:33:36,982: EPOCH 18: training on 40200 raw words (37428 effective words) took 0.1s, 284215 effective words/s
INFO - 2023-11-28 03:33:37,113: EPOCH 19: training on 40200 raw words (37531 effective words) took 0.1s, 290854 effective words/s
INFO - 2023-11-28 03:33:37,113: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (749354 effective words) took 2.7s, 281458 effective words/s', 'datetime': '2023-11-28T03:33:37.113863', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:37,114: collecting all words and their counts
INFO - 2023-11-28 03:33:37,114: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:37,121: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:37,121: Updating model with new vocabulary
INFO - 2023-11-28 03:33:37,124: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:37.124614', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:37,128: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:37,128: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:33:37,128: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37505.61835464402 word corpus (93.3%% of prior 40200)', 'datetime': '2023-11-28T03:33:37.128735', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:37,135: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:37,135: updating layer weights
INFO - 2023-11-28 03:33:37,135: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:37.135344', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:37,135: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:37,135: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:37.135529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:37,271: EPOCH 0: training on 40200 raw words (37462 effective words) took 0.1s, 281144 effective words/s
INFO - 2023-11-28 03:33:37,406: EPOCH 1: training on 40200 raw words (37549 effective words) took 0.1s, 283170 effective words/s
INFO - 2023-11-28 03:33:37,542: EPOCH 2: training on 40200 raw words (37566 effective words) took 0.1s, 282404 effective words/s
INFO - 2023-11-28 03:33:37,677: EPOCH 3: training on 40200 raw words (37445 effective words) took 0.1s, 281893 effective words/s
INFO - 2023-11-28 03:33:37,811: EPOCH 4: training on 40200 raw words (37485 effective words) took 0.1s, 283997 effective words/s
INFO - 2023-11-28 03:33:37,946: EPOCH 5: training on 40200 raw words (37429 effective words) took 0.1s, 282131 effective words/s
INFO - 2023-11-28 03:33:38,097: EPOCH 6: training on 40200 raw words (37476 effective words) took 0.1s, 252966 effective words/s
INFO - 2023-11-28 03:33:38,220: EPOCH 7: training on 40200 raw words (37522 effective words) took 0.1s, 311814 effective words/s
INFO - 2023-11-28 03:33:38,357: EPOCH 8: training on 40200 raw words (37548 effective words) took 0.1s, 279618 effective words/s
INFO - 2023-11-28 03:33:38,494: EPOCH 9: training on 40200 raw words (37553 effective words) took 0.1s, 278677 effective words/s
INFO - 2023-11-28 03:33:38,631: EPOCH 10: training on 40200 raw words (37436 effective words) took 0.1s, 279380 effective words/s
INFO - 2023-11-28 03:33:38,766: EPOCH 11: training on 40200 raw words (37559 effective words) took 0.1s, 282644 effective words/s
INFO - 2023-11-28 03:33:38,905: EPOCH 12: training on 40200 raw words (37478 effective words) took 0.1s, 274631 effective words/s
INFO - 2023-11-28 03:33:39,037: EPOCH 13: training on 40200 raw words (37559 effective words) took 0.1s, 288113 effective words/s
INFO - 2023-11-28 03:33:39,170: EPOCH 14: training on 40200 raw words (37476 effective words) took 0.1s, 288432 effective words/s
INFO - 2023-11-28 03:33:39,307: EPOCH 15: training on 40200 raw words (37508 effective words) took 0.1s, 278202 effective words/s
INFO - 2023-11-28 03:33:39,447: EPOCH 16: training on 40200 raw words (37550 effective words) took 0.1s, 272178 effective words/s
INFO - 2023-11-28 03:33:39,582: EPOCH 17: training on 40200 raw words (37522 effective words) took 0.1s, 282462 effective words/s
INFO - 2023-11-28 03:33:39,718: EPOCH 18: training on 40200 raw words (37525 effective words) took 0.1s, 282777 effective words/s
INFO - 2023-11-28 03:33:39,884: EPOCH 19: training on 40200 raw words (37484 effective words) took 0.2s, 228386 effective words/s
INFO - 2023-11-28 03:33:39,885: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (750132 effective words) took 2.7s, 272841 effective words/s', 'datetime': '2023-11-28T03:33:39.884978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:39,885: collecting all words and their counts
INFO - 2023-11-28 03:33:39,885: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:39,892: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:39,892: Updating model with new vocabulary
INFO - 2023-11-28 03:33:39,895: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:39.895059', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:39,898: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:39,898: sample=0.001 downsamples 66 most-common words
INFO - 2023-11-28 03:33:39,898: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37407.22390858836 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:33:39.898432', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:39,903: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:39,903: updating layer weights
INFO - 2023-11-28 03:33:39,903: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:39.903547', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:39,903: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:39,903: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:39.903703', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:40,039: EPOCH 0: training on 40200 raw words (37416 effective words) took 0.1s, 280448 effective words/s
INFO - 2023-11-28 03:33:40,176: EPOCH 1: training on 40200 raw words (37409 effective words) took 0.1s, 278139 effective words/s
INFO - 2023-11-28 03:33:40,309: EPOCH 2: training on 40200 raw words (37403 effective words) took 0.1s, 283806 effective words/s
INFO - 2023-11-28 03:33:40,452: EPOCH 3: training on 40200 raw words (37428 effective words) took 0.1s, 267247 effective words/s
INFO - 2023-11-28 03:33:40,600: EPOCH 4: training on 40200 raw words (37437 effective words) took 0.1s, 257393 effective words/s
INFO - 2023-11-28 03:33:40,745: EPOCH 5: training on 40200 raw words (37462 effective words) took 0.1s, 261821 effective words/s
INFO - 2023-11-28 03:33:40,891: EPOCH 6: training on 40200 raw words (37351 effective words) took 0.1s, 260043 effective words/s
INFO - 2023-11-28 03:33:41,037: EPOCH 7: training on 40200 raw words (37420 effective words) took 0.1s, 260253 effective words/s
INFO - 2023-11-28 03:33:41,177: EPOCH 8: training on 40200 raw words (37347 effective words) took 0.1s, 270690 effective words/s
INFO - 2023-11-28 03:33:41,318: EPOCH 9: training on 40200 raw words (37411 effective words) took 0.1s, 271802 effective words/s
INFO - 2023-11-28 03:33:41,458: EPOCH 10: training on 40200 raw words (37392 effective words) took 0.1s, 270095 effective words/s
INFO - 2023-11-28 03:33:41,596: EPOCH 11: training on 40200 raw words (37439 effective words) took 0.1s, 277514 effective words/s
INFO - 2023-11-28 03:33:41,740: EPOCH 12: training on 40200 raw words (37454 effective words) took 0.1s, 262365 effective words/s
INFO - 2023-11-28 03:33:41,886: EPOCH 13: training on 40200 raw words (37470 effective words) took 0.1s, 262564 effective words/s
INFO - 2023-11-28 03:33:42,026: EPOCH 14: training on 40200 raw words (37391 effective words) took 0.1s, 270340 effective words/s
INFO - 2023-11-28 03:33:42,176: EPOCH 15: training on 40200 raw words (37415 effective words) took 0.1s, 254055 effective words/s
INFO - 2023-11-28 03:33:42,322: EPOCH 16: training on 40200 raw words (37411 effective words) took 0.1s, 260486 effective words/s
INFO - 2023-11-28 03:33:42,466: EPOCH 17: training on 40200 raw words (37434 effective words) took 0.1s, 263213 effective words/s
INFO - 2023-11-28 03:33:42,613: EPOCH 18: training on 40200 raw words (37423 effective words) took 0.1s, 259169 effective words/s
INFO - 2023-11-28 03:33:42,762: EPOCH 19: training on 40200 raw words (37380 effective words) took 0.1s, 256274 effective words/s
INFO - 2023-11-28 03:33:42,762: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748293 effective words) took 2.9s, 261777 effective words/s', 'datetime': '2023-11-28T03:33:42.762316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:42,762: collecting all words and their counts
INFO - 2023-11-28 03:33:42,762: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:42,768: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:42,768: Updating model with new vocabulary
INFO - 2023-11-28 03:33:42,772: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:42.772111', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:42,776: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:42,776: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:33:42,776: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37317.756209144005 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:33:42.776426', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:42,783: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:42,783: updating layer weights
INFO - 2023-11-28 03:33:42,784: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:42.784126', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:42,784: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:42,784: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:42.784348', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:42,914: EPOCH 0: training on 40200 raw words (37300 effective words) took 0.1s, 291443 effective words/s
INFO - 2023-11-28 03:33:43,047: EPOCH 1: training on 40200 raw words (37311 effective words) took 0.1s, 286718 effective words/s
INFO - 2023-11-28 03:33:43,183: EPOCH 2: training on 40200 raw words (37326 effective words) took 0.1s, 279352 effective words/s
INFO - 2023-11-28 03:33:43,316: EPOCH 3: training on 40200 raw words (37270 effective words) took 0.1s, 286064 effective words/s
INFO - 2023-11-28 03:33:43,451: EPOCH 4: training on 40200 raw words (37366 effective words) took 0.1s, 280961 effective words/s
INFO - 2023-11-28 03:33:43,589: EPOCH 5: training on 40200 raw words (37313 effective words) took 0.1s, 274275 effective words/s
INFO - 2023-11-28 03:33:43,720: EPOCH 6: training on 40200 raw words (37321 effective words) took 0.1s, 290646 effective words/s
INFO - 2023-11-28 03:33:43,855: EPOCH 7: training on 40200 raw words (37340 effective words) took 0.1s, 280878 effective words/s
INFO - 2023-11-28 03:33:43,988: EPOCH 8: training on 40200 raw words (37276 effective words) took 0.1s, 284843 effective words/s
INFO - 2023-11-28 03:33:44,123: EPOCH 9: training on 40200 raw words (37248 effective words) took 0.1s, 281420 effective words/s
INFO - 2023-11-28 03:33:44,251: EPOCH 10: training on 40200 raw words (37355 effective words) took 0.1s, 297307 effective words/s
INFO - 2023-11-28 03:33:44,386: EPOCH 11: training on 40200 raw words (37332 effective words) took 0.1s, 281369 effective words/s
INFO - 2023-11-28 03:33:44,522: EPOCH 12: training on 40200 raw words (37340 effective words) took 0.1s, 279267 effective words/s
INFO - 2023-11-28 03:33:44,658: EPOCH 13: training on 40200 raw words (37321 effective words) took 0.1s, 279307 effective words/s
INFO - 2023-11-28 03:33:44,791: EPOCH 14: training on 40200 raw words (37337 effective words) took 0.1s, 285084 effective words/s
INFO - 2023-11-28 03:33:44,925: EPOCH 15: training on 40200 raw words (37305 effective words) took 0.1s, 284861 effective words/s
INFO - 2023-11-28 03:33:45,058: EPOCH 16: training on 40200 raw words (37289 effective words) took 0.1s, 285675 effective words/s
INFO - 2023-11-28 03:33:45,190: EPOCH 17: training on 40200 raw words (37295 effective words) took 0.1s, 287456 effective words/s
INFO - 2023-11-28 03:33:45,323: EPOCH 18: training on 40200 raw words (37355 effective words) took 0.1s, 284549 effective words/s
INFO - 2023-11-28 03:33:45,450: EPOCH 19: training on 40200 raw words (37302 effective words) took 0.1s, 300650 effective words/s
INFO - 2023-11-28 03:33:45,450: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746302 effective words) took 2.7s, 279941 effective words/s', 'datetime': '2023-11-28T03:33:45.450394', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:45,450: collecting all words and their counts
INFO - 2023-11-28 03:33:45,450: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:45,457: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:45,458: Updating model with new vocabulary
INFO - 2023-11-28 03:33:45,461: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:45.461229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:45,464: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:45,464: sample=0.001 downsamples 70 most-common words
INFO - 2023-11-28 03:33:45,464: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37383.100494956736 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:33:45.464840', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:45,470: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:45,470: updating layer weights
INFO - 2023-11-28 03:33:45,470: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:45.470757', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:45,470: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:45,470: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:45.470942', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:45,613: EPOCH 0: training on 40200 raw words (37292 effective words) took 0.1s, 266113 effective words/s
INFO - 2023-11-28 03:33:45,760: EPOCH 1: training on 40200 raw words (37412 effective words) took 0.1s, 257866 effective words/s
INFO - 2023-11-28 03:33:45,904: EPOCH 2: training on 40200 raw words (37361 effective words) took 0.1s, 265250 effective words/s
INFO - 2023-11-28 03:33:46,043: EPOCH 3: training on 40200 raw words (37377 effective words) took 0.1s, 272560 effective words/s
INFO - 2023-11-28 03:33:46,187: EPOCH 4: training on 40200 raw words (37315 effective words) took 0.1s, 263523 effective words/s
INFO - 2023-11-28 03:33:46,329: EPOCH 5: training on 40200 raw words (37385 effective words) took 0.1s, 268206 effective words/s
INFO - 2023-11-28 03:33:46,465: EPOCH 6: training on 40200 raw words (37302 effective words) took 0.1s, 278960 effective words/s
INFO - 2023-11-28 03:33:46,608: EPOCH 7: training on 40200 raw words (37443 effective words) took 0.1s, 266192 effective words/s
INFO - 2023-11-28 03:33:46,754: EPOCH 8: training on 40200 raw words (37393 effective words) took 0.1s, 261240 effective words/s
INFO - 2023-11-28 03:33:46,905: EPOCH 9: training on 40200 raw words (37418 effective words) took 0.1s, 250521 effective words/s
INFO - 2023-11-28 03:33:47,048: EPOCH 10: training on 40200 raw words (37383 effective words) took 0.1s, 266239 effective words/s
INFO - 2023-11-28 03:33:47,192: EPOCH 11: training on 40200 raw words (37343 effective words) took 0.1s, 263609 effective words/s
INFO - 2023-11-28 03:33:47,338: EPOCH 12: training on 40200 raw words (37267 effective words) took 0.1s, 260392 effective words/s
INFO - 2023-11-28 03:33:47,493: EPOCH 13: training on 40200 raw words (37339 effective words) took 0.2s, 245266 effective words/s
INFO - 2023-11-28 03:33:47,636: EPOCH 14: training on 40200 raw words (37426 effective words) took 0.1s, 265821 effective words/s
INFO - 2023-11-28 03:33:47,795: EPOCH 15: training on 40200 raw words (37337 effective words) took 0.2s, 246970 effective words/s
INFO - 2023-11-28 03:33:47,944: EPOCH 16: training on 40200 raw words (37395 effective words) took 0.1s, 255880 effective words/s
INFO - 2023-11-28 03:33:48,089: EPOCH 17: training on 40200 raw words (37387 effective words) took 0.1s, 261691 effective words/s
INFO - 2023-11-28 03:33:48,234: EPOCH 18: training on 40200 raw words (37401 effective words) took 0.1s, 262169 effective words/s
INFO - 2023-11-28 03:33:48,377: EPOCH 19: training on 40200 raw words (37456 effective words) took 0.1s, 266461 effective words/s
INFO - 2023-11-28 03:33:48,377: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747432 effective words) took 2.9s, 257127 effective words/s', 'datetime': '2023-11-28T03:33:48.377903', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:48,378: collecting all words and their counts
INFO - 2023-11-28 03:33:48,378: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:48,385: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:48,385: Updating model with new vocabulary
INFO - 2023-11-28 03:33:48,388: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:48.388201', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:48,391: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:48,391: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:33:48,391: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37385.74027518237 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:33:48.391943', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:48,397: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:48,398: updating layer weights
INFO - 2023-11-28 03:33:48,398: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:48.398205', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:48,398: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:48,398: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:48.398394', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:48,532: EPOCH 0: training on 40200 raw words (37396 effective words) took 0.1s, 284774 effective words/s
INFO - 2023-11-28 03:33:48,668: EPOCH 1: training on 40200 raw words (37342 effective words) took 0.1s, 278122 effective words/s
INFO - 2023-11-28 03:33:48,804: EPOCH 2: training on 40200 raw words (37360 effective words) took 0.1s, 291158 effective words/s
INFO - 2023-11-28 03:33:48,930: EPOCH 3: training on 40200 raw words (37421 effective words) took 0.1s, 300950 effective words/s
INFO - 2023-11-28 03:33:49,061: EPOCH 4: training on 40200 raw words (37438 effective words) took 0.1s, 290922 effective words/s
INFO - 2023-11-28 03:33:49,195: EPOCH 5: training on 40200 raw words (37425 effective words) took 0.1s, 286149 effective words/s
INFO - 2023-11-28 03:33:49,331: EPOCH 6: training on 40200 raw words (37362 effective words) took 0.1s, 278284 effective words/s
INFO - 2023-11-28 03:33:49,466: EPOCH 7: training on 40200 raw words (37376 effective words) took 0.1s, 283742 effective words/s
INFO - 2023-11-28 03:33:49,597: EPOCH 8: training on 40200 raw words (37404 effective words) took 0.1s, 289076 effective words/s
INFO - 2023-11-28 03:33:49,732: EPOCH 9: training on 40200 raw words (37311 effective words) took 0.1s, 282602 effective words/s
INFO - 2023-11-28 03:33:49,868: EPOCH 10: training on 40200 raw words (37390 effective words) took 0.1s, 280344 effective words/s
INFO - 2023-11-28 03:33:50,011: EPOCH 11: training on 40200 raw words (37388 effective words) took 0.1s, 266282 effective words/s
INFO - 2023-11-28 03:33:50,145: EPOCH 12: training on 40200 raw words (37340 effective words) took 0.1s, 283311 effective words/s
INFO - 2023-11-28 03:33:50,282: EPOCH 13: training on 40200 raw words (37394 effective words) took 0.1s, 276498 effective words/s
INFO - 2023-11-28 03:33:50,413: EPOCH 14: training on 40200 raw words (37375 effective words) took 0.1s, 291620 effective words/s
INFO - 2023-11-28 03:33:50,542: EPOCH 15: training on 40200 raw words (37396 effective words) took 0.1s, 294485 effective words/s
INFO - 2023-11-28 03:33:50,672: EPOCH 16: training on 40200 raw words (37337 effective words) took 0.1s, 291919 effective words/s
INFO - 2023-11-28 03:33:50,811: EPOCH 17: training on 40200 raw words (37304 effective words) took 0.1s, 272641 effective words/s
INFO - 2023-11-28 03:33:50,947: EPOCH 18: training on 40200 raw words (37445 effective words) took 0.1s, 280649 effective words/s
INFO - 2023-11-28 03:33:51,077: EPOCH 19: training on 40200 raw words (37323 effective words) took 0.1s, 291681 effective words/s
INFO - 2023-11-28 03:33:51,078: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747527 effective words) took 2.7s, 278973 effective words/s', 'datetime': '2023-11-28T03:33:51.078069', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:51,078: collecting all words and their counts
INFO - 2023-11-28 03:33:51,078: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:51,085: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:51,085: Updating model with new vocabulary
INFO - 2023-11-28 03:33:51,088: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:51.088888', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:51,092: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:51,092: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:33:51,092: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37362.56910201372 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:33:51.092356', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:51,097: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:51,097: updating layer weights
INFO - 2023-11-28 03:33:51,098: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:51.098003', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:51,098: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:51,098: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:51.098180', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:51,244: EPOCH 0: training on 40200 raw words (37364 effective words) took 0.1s, 259129 effective words/s
INFO - 2023-11-28 03:33:51,391: EPOCH 1: training on 40200 raw words (37343 effective words) took 0.1s, 258044 effective words/s
INFO - 2023-11-28 03:33:51,538: EPOCH 2: training on 40200 raw words (37357 effective words) took 0.1s, 259261 effective words/s
INFO - 2023-11-28 03:33:51,685: EPOCH 3: training on 40200 raw words (37394 effective words) took 0.1s, 259909 effective words/s
INFO - 2023-11-28 03:33:51,830: EPOCH 4: training on 40200 raw words (37427 effective words) took 0.1s, 260949 effective words/s
INFO - 2023-11-28 03:33:51,980: EPOCH 5: training on 40200 raw words (37407 effective words) took 0.1s, 254470 effective words/s
INFO - 2023-11-28 03:33:52,125: EPOCH 6: training on 40200 raw words (37257 effective words) took 0.1s, 260217 effective words/s
INFO - 2023-11-28 03:33:52,267: EPOCH 7: training on 40200 raw words (37375 effective words) took 0.1s, 267300 effective words/s
INFO - 2023-11-28 03:33:52,411: EPOCH 8: training on 40200 raw words (37332 effective words) took 0.1s, 264566 effective words/s
INFO - 2023-11-28 03:33:52,550: EPOCH 9: training on 40200 raw words (37403 effective words) took 0.1s, 272571 effective words/s
INFO - 2023-11-28 03:33:52,696: EPOCH 10: training on 40200 raw words (37372 effective words) took 0.1s, 260542 effective words/s
INFO - 2023-11-28 03:33:52,833: EPOCH 11: training on 40200 raw words (37314 effective words) took 0.1s, 276569 effective words/s
INFO - 2023-11-28 03:33:52,976: EPOCH 12: training on 40200 raw words (37313 effective words) took 0.1s, 265493 effective words/s
INFO - 2023-11-28 03:33:53,122: EPOCH 13: training on 40200 raw words (37370 effective words) took 0.1s, 260958 effective words/s
INFO - 2023-11-28 03:33:53,262: EPOCH 14: training on 40200 raw words (37339 effective words) took 0.1s, 272106 effective words/s
INFO - 2023-11-28 03:33:53,406: EPOCH 15: training on 40200 raw words (37441 effective words) took 0.1s, 264080 effective words/s
INFO - 2023-11-28 03:33:53,553: EPOCH 16: training on 40200 raw words (37380 effective words) took 0.1s, 258078 effective words/s
INFO - 2023-11-28 03:33:53,701: EPOCH 17: training on 40200 raw words (37408 effective words) took 0.1s, 256621 effective words/s
INFO - 2023-11-28 03:33:53,846: EPOCH 18: training on 40200 raw words (37284 effective words) took 0.1s, 261048 effective words/s
INFO - 2023-11-28 03:33:53,983: EPOCH 19: training on 40200 raw words (37342 effective words) took 0.1s, 277482 effective words/s
INFO - 2023-11-28 03:33:53,983: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747222 effective words) took 2.9s, 258961 effective words/s', 'datetime': '2023-11-28T03:33:53.983750', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:53,983: collecting all words and their counts
INFO - 2023-11-28 03:33:53,984: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:53,990: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:53,990: Updating model with new vocabulary
INFO - 2023-11-28 03:33:53,993: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:53.993922', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:53,997: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:53,997: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:33:53,997: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37269.0197145522 word corpus (92.7%% of prior 40200)', 'datetime': '2023-11-28T03:33:53.997211', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:54,002: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:54,002: updating layer weights
INFO - 2023-11-28 03:33:54,002: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:54.002786', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:54,002: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:54,002: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:54.002960', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:54,134: EPOCH 0: training on 40200 raw words (37255 effective words) took 0.1s, 295932 effective words/s
INFO - 2023-11-28 03:33:54,269: EPOCH 1: training on 40200 raw words (37287 effective words) took 0.1s, 280524 effective words/s
INFO - 2023-11-28 03:33:54,399: EPOCH 2: training on 40200 raw words (37309 effective words) took 0.1s, 292791 effective words/s
INFO - 2023-11-28 03:33:54,533: EPOCH 3: training on 40200 raw words (37227 effective words) took 0.1s, 282309 effective words/s
INFO - 2023-11-28 03:33:54,661: EPOCH 4: training on 40200 raw words (37199 effective words) took 0.1s, 295897 effective words/s
INFO - 2023-11-28 03:33:54,787: EPOCH 5: training on 40200 raw words (37283 effective words) took 0.1s, 302055 effective words/s
INFO - 2023-11-28 03:33:54,922: EPOCH 6: training on 40200 raw words (37282 effective words) took 0.1s, 282138 effective words/s
INFO - 2023-11-28 03:33:55,064: EPOCH 7: training on 40200 raw words (37286 effective words) took 0.1s, 266450 effective words/s
INFO - 2023-11-28 03:33:55,197: EPOCH 8: training on 40200 raw words (37148 effective words) took 0.1s, 284552 effective words/s
INFO - 2023-11-28 03:33:55,331: EPOCH 9: training on 40200 raw words (37201 effective words) took 0.1s, 281917 effective words/s
INFO - 2023-11-28 03:33:55,465: EPOCH 10: training on 40200 raw words (37285 effective words) took 0.1s, 284558 effective words/s
INFO - 2023-11-28 03:33:55,600: EPOCH 11: training on 40200 raw words (37315 effective words) took 0.1s, 279809 effective words/s
INFO - 2023-11-28 03:33:55,734: EPOCH 12: training on 40200 raw words (37318 effective words) took 0.1s, 284297 effective words/s
INFO - 2023-11-28 03:33:55,870: EPOCH 13: training on 40200 raw words (37255 effective words) took 0.1s, 277935 effective words/s
INFO - 2023-11-28 03:33:55,995: EPOCH 14: training on 40200 raw words (37278 effective words) took 0.1s, 305833 effective words/s
INFO - 2023-11-28 03:33:56,138: EPOCH 15: training on 40200 raw words (37340 effective words) took 0.1s, 264562 effective words/s
INFO - 2023-11-28 03:33:56,276: EPOCH 16: training on 40200 raw words (37363 effective words) took 0.1s, 274535 effective words/s
INFO - 2023-11-28 03:33:56,407: EPOCH 17: training on 40200 raw words (37327 effective words) took 0.1s, 290341 effective words/s
INFO - 2023-11-28 03:33:56,536: EPOCH 18: training on 40200 raw words (37299 effective words) took 0.1s, 294414 effective words/s
INFO - 2023-11-28 03:33:56,674: EPOCH 19: training on 40200 raw words (37278 effective words) took 0.1s, 274951 effective words/s
INFO - 2023-11-28 03:33:56,675: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745535 effective words) took 2.7s, 279027 effective words/s', 'datetime': '2023-11-28T03:33:56.674978', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:56,675: collecting all words and their counts
INFO - 2023-11-28 03:33:56,675: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:56,682: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:56,682: Updating model with new vocabulary
INFO - 2023-11-28 03:33:56,685: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:56.685819', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:56,689: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:56,689: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:33:56,689: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37324.65234993698 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:33:56.689740', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:56,695: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:56,695: updating layer weights
INFO - 2023-11-28 03:33:56,696: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:56.696118', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:56,696: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:56,696: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:56.696315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:56,841: EPOCH 0: training on 40200 raw words (37329 effective words) took 0.1s, 261967 effective words/s
INFO - 2023-11-28 03:33:56,986: EPOCH 1: training on 40200 raw words (37339 effective words) took 0.1s, 260858 effective words/s
INFO - 2023-11-28 03:33:57,129: EPOCH 2: training on 40200 raw words (37340 effective words) took 0.1s, 266241 effective words/s
INFO - 2023-11-28 03:33:57,274: EPOCH 3: training on 40200 raw words (37292 effective words) took 0.1s, 262326 effective words/s
INFO - 2023-11-28 03:33:57,420: EPOCH 4: training on 40200 raw words (37274 effective words) took 0.1s, 259043 effective words/s
INFO - 2023-11-28 03:33:57,565: EPOCH 5: training on 40200 raw words (37270 effective words) took 0.1s, 260858 effective words/s
INFO - 2023-11-28 03:33:57,709: EPOCH 6: training on 40200 raw words (37311 effective words) took 0.1s, 263051 effective words/s
INFO - 2023-11-28 03:33:57,865: EPOCH 7: training on 40200 raw words (37300 effective words) took 0.2s, 243100 effective words/s
INFO - 2023-11-28 03:33:58,010: EPOCH 8: training on 40200 raw words (37316 effective words) took 0.1s, 261531 effective words/s
INFO - 2023-11-28 03:33:58,150: EPOCH 9: training on 40200 raw words (37246 effective words) took 0.1s, 271227 effective words/s
INFO - 2023-11-28 03:33:58,294: EPOCH 10: training on 40200 raw words (37295 effective words) took 0.1s, 263160 effective words/s
INFO - 2023-11-28 03:33:58,450: EPOCH 11: training on 40200 raw words (37303 effective words) took 0.2s, 242247 effective words/s
INFO - 2023-11-28 03:33:58,593: EPOCH 12: training on 40200 raw words (37443 effective words) took 0.1s, 267476 effective words/s
INFO - 2023-11-28 03:33:58,728: EPOCH 13: training on 40200 raw words (37315 effective words) took 0.1s, 281430 effective words/s
INFO - 2023-11-28 03:33:58,877: EPOCH 14: training on 40200 raw words (37331 effective words) took 0.1s, 253199 effective words/s
INFO - 2023-11-28 03:33:59,021: EPOCH 15: training on 40200 raw words (37342 effective words) took 0.1s, 263621 effective words/s
INFO - 2023-11-28 03:33:59,168: EPOCH 16: training on 40200 raw words (37343 effective words) took 0.1s, 258018 effective words/s
INFO - 2023-11-28 03:33:59,311: EPOCH 17: training on 40200 raw words (37339 effective words) took 0.1s, 266714 effective words/s
INFO - 2023-11-28 03:33:59,455: EPOCH 18: training on 40200 raw words (37311 effective words) took 0.1s, 263571 effective words/s
INFO - 2023-11-28 03:33:59,610: EPOCH 19: training on 40200 raw words (37243 effective words) took 0.2s, 244795 effective words/s
INFO - 2023-11-28 03:33:59,610: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746282 effective words) took 2.9s, 256104 effective words/s', 'datetime': '2023-11-28T03:33:59.610428', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:59,610: collecting all words and their counts
INFO - 2023-11-28 03:33:59,610: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:33:59,617: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:33:59,617: Updating model with new vocabulary
INFO - 2023-11-28 03:33:59,621: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:33:59.621184', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:59,624: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:33:59,624: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:33:59,624: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37331.09012957715 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:33:59.624764', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:33:59,631: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:33:59,631: updating layer weights
INFO - 2023-11-28 03:33:59,631: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:33:59.631610', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:33:59,631: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:33:59,631: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:33:59.631853', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:33:59,770: EPOCH 0: training on 40200 raw words (37284 effective words) took 0.1s, 282137 effective words/s
INFO - 2023-11-28 03:33:59,905: EPOCH 1: training on 40200 raw words (37353 effective words) took 0.1s, 281660 effective words/s
INFO - 2023-11-28 03:34:00,040: EPOCH 2: training on 40200 raw words (37420 effective words) took 0.1s, 280967 effective words/s
INFO - 2023-11-28 03:34:00,173: EPOCH 3: training on 40200 raw words (37331 effective words) took 0.1s, 287240 effective words/s
INFO - 2023-11-28 03:34:00,309: EPOCH 4: training on 40200 raw words (37323 effective words) took 0.1s, 278701 effective words/s
INFO - 2023-11-28 03:34:00,445: EPOCH 5: training on 40200 raw words (37318 effective words) took 0.1s, 278408 effective words/s
INFO - 2023-11-28 03:34:00,578: EPOCH 6: training on 40200 raw words (37369 effective words) took 0.1s, 286300 effective words/s
INFO - 2023-11-28 03:34:00,709: EPOCH 7: training on 40200 raw words (37317 effective words) took 0.1s, 290288 effective words/s
INFO - 2023-11-28 03:34:00,841: EPOCH 8: training on 40200 raw words (37384 effective words) took 0.1s, 287605 effective words/s
INFO - 2023-11-28 03:34:00,990: EPOCH 9: training on 40200 raw words (37326 effective words) took 0.1s, 255492 effective words/s
INFO - 2023-11-28 03:34:01,118: EPOCH 10: training on 40200 raw words (37320 effective words) took 0.1s, 296906 effective words/s
INFO - 2023-11-28 03:34:01,247: EPOCH 11: training on 40200 raw words (37357 effective words) took 0.1s, 293522 effective words/s
INFO - 2023-11-28 03:34:01,377: EPOCH 12: training on 40200 raw words (37362 effective words) took 0.1s, 292446 effective words/s
INFO - 2023-11-28 03:34:01,512: EPOCH 13: training on 40200 raw words (37376 effective words) took 0.1s, 284390 effective words/s
INFO - 2023-11-28 03:34:01,648: EPOCH 14: training on 40200 raw words (37399 effective words) took 0.1s, 278727 effective words/s
INFO - 2023-11-28 03:34:01,780: EPOCH 15: training on 40200 raw words (37429 effective words) took 0.1s, 289703 effective words/s
INFO - 2023-11-28 03:34:01,910: EPOCH 16: training on 40200 raw words (37364 effective words) took 0.1s, 292781 effective words/s
INFO - 2023-11-28 03:34:02,055: EPOCH 17: training on 40200 raw words (37320 effective words) took 0.1s, 262278 effective words/s
INFO - 2023-11-28 03:34:02,188: EPOCH 18: training on 40200 raw words (37365 effective words) took 0.1s, 285460 effective words/s
INFO - 2023-11-28 03:34:02,323: EPOCH 19: training on 40200 raw words (37403 effective words) took 0.1s, 283109 effective words/s
INFO - 2023-11-28 03:34:02,323: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747120 effective words) took 2.7s, 277577 effective words/s', 'datetime': '2023-11-28T03:34:02.323556', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:02,323: collecting all words and their counts
INFO - 2023-11-28 03:34:02,324: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:02,331: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:02,331: Updating model with new vocabulary
INFO - 2023-11-28 03:34:02,334: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:02.334420', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:02,337: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:02,338: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:34:02,338: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37198.38801940678 word corpus (92.5%% of prior 40200)', 'datetime': '2023-11-28T03:34:02.338101', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:02,343: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:02,343: updating layer weights
INFO - 2023-11-28 03:34:02,343: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:02.343685', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:02,343: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:02,343: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:02.343848', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:02,488: EPOCH 0: training on 40200 raw words (37171 effective words) took 0.1s, 260895 effective words/s
INFO - 2023-11-28 03:34:02,635: EPOCH 1: training on 40200 raw words (37197 effective words) took 0.1s, 258441 effective words/s
INFO - 2023-11-28 03:34:02,778: EPOCH 2: training on 40200 raw words (37289 effective words) took 0.1s, 264735 effective words/s
INFO - 2023-11-28 03:34:02,916: EPOCH 3: training on 40200 raw words (37161 effective words) took 0.1s, 274463 effective words/s
INFO - 2023-11-28 03:34:03,059: EPOCH 4: training on 40200 raw words (37205 effective words) took 0.1s, 265067 effective words/s
INFO - 2023-11-28 03:34:03,202: EPOCH 5: training on 40200 raw words (37162 effective words) took 0.1s, 263609 effective words/s
INFO - 2023-11-28 03:34:03,346: EPOCH 6: training on 40200 raw words (37204 effective words) took 0.1s, 262818 effective words/s
INFO - 2023-11-28 03:34:03,488: EPOCH 7: training on 40200 raw words (37211 effective words) took 0.1s, 265615 effective words/s
INFO - 2023-11-28 03:34:03,634: EPOCH 8: training on 40200 raw words (37193 effective words) took 0.1s, 259457 effective words/s
INFO - 2023-11-28 03:34:03,777: EPOCH 9: training on 40200 raw words (37275 effective words) took 0.1s, 264890 effective words/s
INFO - 2023-11-28 03:34:03,921: EPOCH 10: training on 40200 raw words (37199 effective words) took 0.1s, 264427 effective words/s
INFO - 2023-11-28 03:34:04,080: EPOCH 11: training on 40200 raw words (37239 effective words) took 0.2s, 236373 effective words/s
INFO - 2023-11-28 03:34:04,225: EPOCH 12: training on 40200 raw words (37193 effective words) took 0.1s, 261412 effective words/s
INFO - 2023-11-28 03:34:04,367: EPOCH 13: training on 40200 raw words (37170 effective words) took 0.1s, 266146 effective words/s
INFO - 2023-11-28 03:34:04,506: EPOCH 14: training on 40200 raw words (37231 effective words) took 0.1s, 270894 effective words/s
INFO - 2023-11-28 03:34:04,649: EPOCH 15: training on 40200 raw words (37242 effective words) took 0.1s, 265491 effective words/s
INFO - 2023-11-28 03:34:04,793: EPOCH 16: training on 40200 raw words (37215 effective words) took 0.1s, 263832 effective words/s
INFO - 2023-11-28 03:34:04,934: EPOCH 17: training on 40200 raw words (37143 effective words) took 0.1s, 266054 effective words/s
INFO - 2023-11-28 03:34:05,079: EPOCH 18: training on 40200 raw words (37187 effective words) took 0.1s, 262149 effective words/s
INFO - 2023-11-28 03:34:05,222: EPOCH 19: training on 40200 raw words (37096 effective words) took 0.1s, 263880 effective words/s
INFO - 2023-11-28 03:34:05,222: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (743983 effective words) took 2.9s, 258423 effective words/s', 'datetime': '2023-11-28T03:34:05.222908', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:05,223: collecting all words and their counts
INFO - 2023-11-28 03:34:05,223: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:05,229: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:05,230: Updating model with new vocabulary
INFO - 2023-11-28 03:34:05,233: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:05.233480', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:05,236: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:05,236: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:34:05,237: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37269.22060686718 word corpus (92.7%% of prior 40200)', 'datetime': '2023-11-28T03:34:05.237017', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:05,243: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:05,243: updating layer weights
INFO - 2023-11-28 03:34:05,243: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:05.243347', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:05,243: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:05,243: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:05.243529', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:05,380: EPOCH 0: training on 40200 raw words (37287 effective words) took 0.1s, 277255 effective words/s
INFO - 2023-11-28 03:34:05,524: EPOCH 1: training on 40200 raw words (37290 effective words) took 0.1s, 263742 effective words/s
INFO - 2023-11-28 03:34:05,660: EPOCH 2: training on 40200 raw words (37243 effective words) took 0.1s, 278287 effective words/s
INFO - 2023-11-28 03:34:05,797: EPOCH 3: training on 40200 raw words (37329 effective words) took 0.1s, 285287 effective words/s
INFO - 2023-11-28 03:34:05,925: EPOCH 4: training on 40200 raw words (37172 effective words) took 0.1s, 294146 effective words/s
INFO - 2023-11-28 03:34:06,061: EPOCH 5: training on 40200 raw words (37290 effective words) took 0.1s, 290641 effective words/s
INFO - 2023-11-28 03:34:06,201: EPOCH 6: training on 40200 raw words (37270 effective words) took 0.1s, 270776 effective words/s
INFO - 2023-11-28 03:34:06,334: EPOCH 7: training on 40200 raw words (37294 effective words) took 0.1s, 284971 effective words/s
INFO - 2023-11-28 03:34:06,470: EPOCH 8: training on 40200 raw words (37291 effective words) took 0.1s, 278968 effective words/s
INFO - 2023-11-28 03:34:06,609: EPOCH 9: training on 40200 raw words (37189 effective words) took 0.1s, 274741 effective words/s
INFO - 2023-11-28 03:34:06,743: EPOCH 10: training on 40200 raw words (37251 effective words) took 0.1s, 282779 effective words/s
INFO - 2023-11-28 03:34:06,871: EPOCH 11: training on 40200 raw words (37272 effective words) took 0.1s, 297636 effective words/s
INFO - 2023-11-28 03:34:06,996: EPOCH 12: training on 40200 raw words (37290 effective words) took 0.1s, 302991 effective words/s
INFO - 2023-11-28 03:34:07,128: EPOCH 13: training on 40200 raw words (37403 effective words) took 0.1s, 288618 effective words/s
INFO - 2023-11-28 03:34:07,261: EPOCH 14: training on 40200 raw words (37183 effective words) took 0.1s, 284905 effective words/s
INFO - 2023-11-28 03:34:07,392: EPOCH 15: training on 40200 raw words (37298 effective words) took 0.1s, 289745 effective words/s
INFO - 2023-11-28 03:34:07,530: EPOCH 16: training on 40200 raw words (37281 effective words) took 0.1s, 276022 effective words/s
INFO - 2023-11-28 03:34:07,660: EPOCH 17: training on 40200 raw words (37243 effective words) took 0.1s, 291297 effective words/s
INFO - 2023-11-28 03:34:07,797: EPOCH 18: training on 40200 raw words (37276 effective words) took 0.1s, 276151 effective words/s
INFO - 2023-11-28 03:34:07,933: EPOCH 19: training on 40200 raw words (37309 effective words) took 0.1s, 279306 effective words/s
INFO - 2023-11-28 03:34:07,934: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745461 effective words) took 2.7s, 277088 effective words/s', 'datetime': '2023-11-28T03:34:07.933990', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:07,934: collecting all words and their counts
INFO - 2023-11-28 03:34:07,934: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:07,941: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:07,941: Updating model with new vocabulary
INFO - 2023-11-28 03:34:07,945: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:07.945472', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:07,949: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:07,949: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:34:07,949: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37294.40823727933 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:34:07.949176', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:07,955: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:07,955: updating layer weights
INFO - 2023-11-28 03:34:07,955: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:07.955725', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:07,955: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:07,956: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:07.956125', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:08,102: EPOCH 0: training on 40200 raw words (37302 effective words) took 0.1s, 259402 effective words/s
INFO - 2023-11-28 03:34:08,256: EPOCH 1: training on 40200 raw words (37289 effective words) took 0.2s, 245823 effective words/s
INFO - 2023-11-28 03:34:08,402: EPOCH 2: training on 40200 raw words (37214 effective words) took 0.1s, 258724 effective words/s
INFO - 2023-11-28 03:34:08,546: EPOCH 3: training on 40200 raw words (37328 effective words) took 0.1s, 263860 effective words/s
INFO - 2023-11-28 03:34:08,689: EPOCH 4: training on 40200 raw words (37265 effective words) took 0.1s, 264235 effective words/s
INFO - 2023-11-28 03:34:08,835: EPOCH 5: training on 40200 raw words (37236 effective words) took 0.1s, 259871 effective words/s
INFO - 2023-11-28 03:34:08,978: EPOCH 6: training on 40200 raw words (37272 effective words) took 0.1s, 266296 effective words/s
INFO - 2023-11-28 03:34:09,126: EPOCH 7: training on 40200 raw words (37347 effective words) took 0.1s, 255452 effective words/s
INFO - 2023-11-28 03:34:09,272: EPOCH 8: training on 40200 raw words (37253 effective words) took 0.1s, 259515 effective words/s
INFO - 2023-11-28 03:34:09,429: EPOCH 9: training on 40200 raw words (37327 effective words) took 0.2s, 241973 effective words/s
INFO - 2023-11-28 03:34:09,575: EPOCH 10: training on 40200 raw words (37235 effective words) took 0.1s, 258307 effective words/s
INFO - 2023-11-28 03:34:09,721: EPOCH 11: training on 40200 raw words (37305 effective words) took 0.1s, 261905 effective words/s
INFO - 2023-11-28 03:34:09,858: EPOCH 12: training on 40200 raw words (37273 effective words) took 0.1s, 276426 effective words/s
INFO - 2023-11-28 03:34:10,008: EPOCH 13: training on 40200 raw words (37257 effective words) took 0.1s, 253270 effective words/s
INFO - 2023-11-28 03:34:10,158: EPOCH 14: training on 40200 raw words (37311 effective words) took 0.1s, 253212 effective words/s
INFO - 2023-11-28 03:34:10,315: EPOCH 15: training on 40200 raw words (37310 effective words) took 0.2s, 241576 effective words/s
INFO - 2023-11-28 03:34:10,461: EPOCH 16: training on 40200 raw words (37291 effective words) took 0.1s, 259958 effective words/s
INFO - 2023-11-28 03:34:10,604: EPOCH 17: training on 40200 raw words (37267 effective words) took 0.1s, 264980 effective words/s
INFO - 2023-11-28 03:34:10,747: EPOCH 18: training on 40200 raw words (37343 effective words) took 0.1s, 265666 effective words/s
INFO - 2023-11-28 03:34:10,892: EPOCH 19: training on 40200 raw words (37366 effective words) took 0.1s, 261572 effective words/s
INFO - 2023-11-28 03:34:10,893: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (745791 effective words) took 2.9s, 253953 effective words/s', 'datetime': '2023-11-28T03:34:10.893025', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:10,893: collecting all words and their counts
INFO - 2023-11-28 03:34:10,893: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:10,899: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:10,899: Updating model with new vocabulary
INFO - 2023-11-28 03:34:10,902: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:10.902316', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:10,906: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:10,906: sample=0.001 downsamples 75 most-common words
INFO - 2023-11-28 03:34:10,906: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37227.12892292809 word corpus (92.6%% of prior 40200)', 'datetime': '2023-11-28T03:34:10.906485', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:10,913: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:10,914: updating layer weights
INFO - 2023-11-28 03:34:10,914: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:10.914229', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:10,914: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:10,914: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:10.914429', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:11,045: EPOCH 0: training on 40200 raw words (37184 effective words) took 0.1s, 289192 effective words/s
INFO - 2023-11-28 03:34:11,191: EPOCH 1: training on 40200 raw words (37226 effective words) took 0.1s, 257833 effective words/s
INFO - 2023-11-28 03:34:11,322: EPOCH 2: training on 40200 raw words (37212 effective words) took 0.1s, 289250 effective words/s
INFO - 2023-11-28 03:34:11,455: EPOCH 3: training on 40200 raw words (37247 effective words) took 0.1s, 286241 effective words/s
INFO - 2023-11-28 03:34:11,592: EPOCH 4: training on 40200 raw words (37258 effective words) took 0.1s, 276227 effective words/s
INFO - 2023-11-28 03:34:11,738: EPOCH 5: training on 40200 raw words (37241 effective words) took 0.1s, 259206 effective words/s
INFO - 2023-11-28 03:34:11,895: EPOCH 6: training on 40200 raw words (37296 effective words) took 0.2s, 240742 effective words/s
INFO - 2023-11-28 03:34:12,039: EPOCH 7: training on 40200 raw words (37222 effective words) took 0.1s, 264546 effective words/s
INFO - 2023-11-28 03:34:12,177: EPOCH 8: training on 40200 raw words (37193 effective words) took 0.1s, 274631 effective words/s
INFO - 2023-11-28 03:34:12,316: EPOCH 9: training on 40200 raw words (37236 effective words) took 0.1s, 272456 effective words/s
INFO - 2023-11-28 03:34:12,451: EPOCH 10: training on 40200 raw words (37199 effective words) took 0.1s, 280432 effective words/s
INFO - 2023-11-28 03:34:12,586: EPOCH 11: training on 40200 raw words (37225 effective words) took 0.1s, 297554 effective words/s
INFO - 2023-11-28 03:34:12,721: EPOCH 12: training on 40200 raw words (37176 effective words) took 0.1s, 279330 effective words/s
INFO - 2023-11-28 03:34:12,857: EPOCH 13: training on 40200 raw words (37273 effective words) took 0.1s, 279763 effective words/s
INFO - 2023-11-28 03:34:12,983: EPOCH 14: training on 40200 raw words (37240 effective words) took 0.1s, 299963 effective words/s
INFO - 2023-11-28 03:34:13,132: EPOCH 15: training on 40200 raw words (37173 effective words) took 0.1s, 255192 effective words/s
INFO - 2023-11-28 03:34:13,271: EPOCH 16: training on 40200 raw words (37164 effective words) took 0.1s, 271608 effective words/s
INFO - 2023-11-28 03:34:13,450: EPOCH 17: training on 40200 raw words (37275 effective words) took 0.2s, 211295 effective words/s
INFO - 2023-11-28 03:34:13,581: EPOCH 18: training on 40200 raw words (37206 effective words) took 0.1s, 290276 effective words/s
INFO - 2023-11-28 03:34:13,736: EPOCH 19: training on 40200 raw words (37198 effective words) took 0.2s, 243298 effective words/s
INFO - 2023-11-28 03:34:13,736: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (744444 effective words) took 2.8s, 263772 effective words/s', 'datetime': '2023-11-28T03:34:13.736841', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:13,737: collecting all words and their counts
INFO - 2023-11-28 03:34:13,737: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:13,743: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:13,743: Updating model with new vocabulary
INFO - 2023-11-28 03:34:13,746: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:13.746488', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:13,750: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:13,750: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:34:13,750: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37514.49071387142 word corpus (93.3%% of prior 40200)', 'datetime': '2023-11-28T03:34:13.750318', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:13,755: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:13,756: updating layer weights
INFO - 2023-11-28 03:34:13,756: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:13.756171', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:13,756: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:13,756: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:13.756345', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:13,892: EPOCH 0: training on 40200 raw words (37550 effective words) took 0.1s, 286102 effective words/s
INFO - 2023-11-28 03:34:14,035: EPOCH 1: training on 40200 raw words (37542 effective words) took 0.1s, 268206 effective words/s
INFO - 2023-11-28 03:34:14,180: EPOCH 2: training on 40200 raw words (37508 effective words) took 0.1s, 262398 effective words/s
INFO - 2023-11-28 03:34:14,316: EPOCH 3: training on 40200 raw words (37474 effective words) took 0.1s, 280233 effective words/s
INFO - 2023-11-28 03:34:14,462: EPOCH 4: training on 40200 raw words (37596 effective words) took 0.1s, 261819 effective words/s
INFO - 2023-11-28 03:34:14,595: EPOCH 5: training on 40200 raw words (37475 effective words) took 0.1s, 287003 effective words/s
INFO - 2023-11-28 03:34:14,728: EPOCH 6: training on 40200 raw words (37501 effective words) took 0.1s, 286230 effective words/s
INFO - 2023-11-28 03:34:14,885: EPOCH 7: training on 40200 raw words (37554 effective words) took 0.2s, 243164 effective words/s
INFO - 2023-11-28 03:34:15,024: EPOCH 8: training on 40200 raw words (37453 effective words) took 0.1s, 273304 effective words/s
INFO - 2023-11-28 03:34:15,180: EPOCH 9: training on 40200 raw words (37493 effective words) took 0.2s, 243981 effective words/s
INFO - 2023-11-28 03:34:15,322: EPOCH 10: training on 40200 raw words (37541 effective words) took 0.1s, 268510 effective words/s
INFO - 2023-11-28 03:34:15,478: EPOCH 11: training on 40200 raw words (37510 effective words) took 0.2s, 244919 effective words/s
INFO - 2023-11-28 03:34:15,616: EPOCH 12: training on 40200 raw words (37439 effective words) took 0.1s, 275381 effective words/s
INFO - 2023-11-28 03:34:15,760: EPOCH 13: training on 40200 raw words (37564 effective words) took 0.1s, 266029 effective words/s
INFO - 2023-11-28 03:34:15,901: EPOCH 14: training on 40200 raw words (37415 effective words) took 0.1s, 269516 effective words/s
INFO - 2023-11-28 03:34:16,048: EPOCH 15: training on 40200 raw words (37492 effective words) took 0.1s, 257904 effective words/s
INFO - 2023-11-28 03:34:16,192: EPOCH 16: training on 40200 raw words (37548 effective words) took 0.1s, 265754 effective words/s
INFO - 2023-11-28 03:34:16,334: EPOCH 17: training on 40200 raw words (37525 effective words) took 0.1s, 268847 effective words/s
INFO - 2023-11-28 03:34:16,478: EPOCH 18: training on 40200 raw words (37493 effective words) took 0.1s, 265149 effective words/s
INFO - 2023-11-28 03:34:16,622: EPOCH 19: training on 40200 raw words (37547 effective words) took 0.1s, 265437 effective words/s
INFO - 2023-11-28 03:34:16,622: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (750220 effective words) took 2.9s, 261774 effective words/s', 'datetime': '2023-11-28T03:34:16.622341', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:16,622: collecting all words and their counts
INFO - 2023-11-28 03:34:16,622: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:16,628: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:16,628: Updating model with new vocabulary
INFO - 2023-11-28 03:34:16,631: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:16.631116', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:16,635: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:16,635: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:34:16,635: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37363.36635830023 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:34:16.635511', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:16,641: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:16,641: updating layer weights
INFO - 2023-11-28 03:34:16,641: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:16.641486', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:16,641: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:16,641: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:16.641653', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:16,781: EPOCH 0: training on 40200 raw words (37407 effective words) took 0.1s, 278288 effective words/s
INFO - 2023-11-28 03:34:16,925: EPOCH 1: training on 40200 raw words (37371 effective words) took 0.1s, 263327 effective words/s
INFO - 2023-11-28 03:34:17,059: EPOCH 2: training on 40200 raw words (37396 effective words) took 0.1s, 285064 effective words/s
INFO - 2023-11-28 03:34:17,209: EPOCH 3: training on 40200 raw words (37362 effective words) took 0.1s, 252173 effective words/s
INFO - 2023-11-28 03:34:17,346: EPOCH 4: training on 40200 raw words (37309 effective words) took 0.1s, 278237 effective words/s
INFO - 2023-11-28 03:34:17,484: EPOCH 5: training on 40200 raw words (37377 effective words) took 0.1s, 275824 effective words/s
INFO - 2023-11-28 03:34:17,622: EPOCH 6: training on 40200 raw words (37355 effective words) took 0.1s, 276339 effective words/s
INFO - 2023-11-28 03:34:17,749: EPOCH 7: training on 40200 raw words (37243 effective words) took 0.1s, 298143 effective words/s
INFO - 2023-11-28 03:34:17,882: EPOCH 8: training on 40200 raw words (37363 effective words) took 0.1s, 286425 effective words/s
INFO - 2023-11-28 03:34:18,014: EPOCH 9: training on 40200 raw words (37415 effective words) took 0.1s, 288376 effective words/s
INFO - 2023-11-28 03:34:18,147: EPOCH 10: training on 40200 raw words (37383 effective words) took 0.1s, 285523 effective words/s
INFO - 2023-11-28 03:34:18,285: EPOCH 11: training on 40200 raw words (37415 effective words) took 0.1s, 276233 effective words/s
INFO - 2023-11-28 03:34:18,426: EPOCH 12: training on 40200 raw words (37431 effective words) took 0.1s, 269734 effective words/s
INFO - 2023-11-28 03:34:18,554: EPOCH 13: training on 40200 raw words (37323 effective words) took 0.1s, 295891 effective words/s
INFO - 2023-11-28 03:34:18,695: EPOCH 14: training on 40200 raw words (37341 effective words) took 0.1s, 270309 effective words/s
INFO - 2023-11-28 03:34:18,828: EPOCH 15: training on 40200 raw words (37449 effective words) took 0.1s, 286476 effective words/s
INFO - 2023-11-28 03:34:18,966: EPOCH 16: training on 40200 raw words (37392 effective words) took 0.1s, 279978 effective words/s
INFO - 2023-11-28 03:34:19,103: EPOCH 17: training on 40200 raw words (37357 effective words) took 0.1s, 284027 effective words/s
INFO - 2023-11-28 03:34:19,230: EPOCH 18: training on 40200 raw words (37368 effective words) took 0.1s, 298879 effective words/s
INFO - 2023-11-28 03:34:19,363: EPOCH 19: training on 40200 raw words (37272 effective words) took 0.1s, 287386 effective words/s
INFO - 2023-11-28 03:34:19,363: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (747329 effective words) took 2.7s, 274603 effective words/s', 'datetime': '2023-11-28T03:34:19.363257', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:19,363: collecting all words and their counts
INFO - 2023-11-28 03:34:19,363: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:19,369: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:19,369: Updating model with new vocabulary
INFO - 2023-11-28 03:34:19,373: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:19.373065', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:19,376: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:19,376: sample=0.001 downsamples 71 most-common words
INFO - 2023-11-28 03:34:19,376: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37405.27690186303 word corpus (93.0%% of prior 40200)', 'datetime': '2023-11-28T03:34:19.376601', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:19,382: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:19,382: updating layer weights
INFO - 2023-11-28 03:34:19,382: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:19.382651', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:19,382: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:19,382: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:19.382822', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:19,523: EPOCH 0: training on 40200 raw words (37466 effective words) took 0.1s, 269640 effective words/s
INFO - 2023-11-28 03:34:19,668: EPOCH 1: training on 40200 raw words (37400 effective words) took 0.1s, 262816 effective words/s
INFO - 2023-11-28 03:34:19,811: EPOCH 2: training on 40200 raw words (37461 effective words) took 0.1s, 267019 effective words/s
INFO - 2023-11-28 03:34:19,964: EPOCH 3: training on 40200 raw words (37393 effective words) took 0.2s, 247845 effective words/s
INFO - 2023-11-28 03:34:20,098: EPOCH 4: training on 40200 raw words (37501 effective words) took 0.1s, 285271 effective words/s
INFO - 2023-11-28 03:34:20,237: EPOCH 5: training on 40200 raw words (37442 effective words) took 0.1s, 274207 effective words/s
INFO - 2023-11-28 03:34:20,392: EPOCH 6: training on 40200 raw words (37414 effective words) took 0.2s, 244778 effective words/s
INFO - 2023-11-28 03:34:20,530: EPOCH 7: training on 40200 raw words (37431 effective words) took 0.1s, 275503 effective words/s
INFO - 2023-11-28 03:34:20,675: EPOCH 8: training on 40200 raw words (37356 effective words) took 0.1s, 261965 effective words/s
INFO - 2023-11-28 03:34:20,810: EPOCH 9: training on 40200 raw words (37444 effective words) took 0.1s, 281115 effective words/s
INFO - 2023-11-28 03:34:20,948: EPOCH 10: training on 40200 raw words (37405 effective words) took 0.1s, 276618 effective words/s
INFO - 2023-11-28 03:34:21,087: EPOCH 11: training on 40200 raw words (37373 effective words) took 0.1s, 273787 effective words/s
INFO - 2023-11-28 03:34:21,250: EPOCH 12: training on 40200 raw words (37390 effective words) took 0.2s, 232307 effective words/s
INFO - 2023-11-28 03:34:21,402: EPOCH 13: training on 40200 raw words (37381 effective words) took 0.1s, 251065 effective words/s
INFO - 2023-11-28 03:34:21,546: EPOCH 14: training on 40200 raw words (37373 effective words) took 0.1s, 269440 effective words/s
INFO - 2023-11-28 03:34:21,702: EPOCH 15: training on 40200 raw words (37406 effective words) took 0.2s, 243137 effective words/s
INFO - 2023-11-28 03:34:21,840: EPOCH 16: training on 40200 raw words (37385 effective words) took 0.1s, 275516 effective words/s
INFO - 2023-11-28 03:34:21,976: EPOCH 17: training on 40200 raw words (37380 effective words) took 0.1s, 279779 effective words/s
INFO - 2023-11-28 03:34:22,110: EPOCH 18: training on 40200 raw words (37396 effective words) took 0.1s, 284635 effective words/s
INFO - 2023-11-28 03:34:22,260: EPOCH 19: training on 40200 raw words (37398 effective words) took 0.1s, 253118 effective words/s
INFO - 2023-11-28 03:34:22,260: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748195 effective words) took 2.9s, 260019 effective words/s', 'datetime': '2023-11-28T03:34:22.260397', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:22,260: collecting all words and their counts
INFO - 2023-11-28 03:34:22,260: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:22,267: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:22,267: Updating model with new vocabulary
INFO - 2023-11-28 03:34:22,270: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:22.270522', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:22,273: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:22,274: sample=0.001 downsamples 74 most-common words
INFO - 2023-11-28 03:34:22,274: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37418.347933667115 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:34:22.274099', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:22,279: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:22,279: updating layer weights
INFO - 2023-11-28 03:34:22,279: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:22.279919', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:22,280: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:22,280: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:22.280104', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:22,423: EPOCH 0: training on 40200 raw words (37430 effective words) took 0.1s, 264870 effective words/s
INFO - 2023-11-28 03:34:22,563: EPOCH 1: training on 40200 raw words (37366 effective words) took 0.1s, 272544 effective words/s
INFO - 2023-11-28 03:34:22,693: EPOCH 2: training on 40200 raw words (37366 effective words) took 0.1s, 291310 effective words/s
INFO - 2023-11-28 03:34:22,830: EPOCH 3: training on 40200 raw words (37464 effective words) took 0.1s, 278990 effective words/s
INFO - 2023-11-28 03:34:22,979: EPOCH 4: training on 40200 raw words (37424 effective words) took 0.1s, 254877 effective words/s
INFO - 2023-11-28 03:34:23,115: EPOCH 5: training on 40200 raw words (37427 effective words) took 0.1s, 281795 effective words/s
INFO - 2023-11-28 03:34:23,248: EPOCH 6: training on 40200 raw words (37455 effective words) took 0.1s, 285076 effective words/s
INFO - 2023-11-28 03:34:23,382: EPOCH 7: training on 40200 raw words (37352 effective words) took 0.1s, 284600 effective words/s
INFO - 2023-11-28 03:34:23,520: EPOCH 8: training on 40200 raw words (37400 effective words) took 0.1s, 275925 effective words/s
INFO - 2023-11-28 03:34:23,652: EPOCH 9: training on 40200 raw words (37461 effective words) took 0.1s, 288801 effective words/s
INFO - 2023-11-28 03:34:23,789: EPOCH 10: training on 40200 raw words (37393 effective words) took 0.1s, 277771 effective words/s
INFO - 2023-11-28 03:34:23,926: EPOCH 11: training on 40200 raw words (37393 effective words) took 0.1s, 277859 effective words/s
INFO - 2023-11-28 03:34:24,078: EPOCH 12: training on 40200 raw words (37398 effective words) took 0.1s, 249633 effective words/s
INFO - 2023-11-28 03:34:24,212: EPOCH 13: training on 40200 raw words (37497 effective words) took 0.1s, 286795 effective words/s
INFO - 2023-11-28 03:34:24,349: EPOCH 14: training on 40200 raw words (37412 effective words) took 0.1s, 277419 effective words/s
INFO - 2023-11-28 03:34:24,492: EPOCH 15: training on 40200 raw words (37376 effective words) took 0.1s, 265678 effective words/s
INFO - 2023-11-28 03:34:24,631: EPOCH 16: training on 40200 raw words (37421 effective words) took 0.1s, 273278 effective words/s
INFO - 2023-11-28 03:34:24,764: EPOCH 17: training on 40200 raw words (37425 effective words) took 0.1s, 286188 effective words/s
INFO - 2023-11-28 03:34:24,897: EPOCH 18: training on 40200 raw words (37385 effective words) took 0.1s, 286619 effective words/s
INFO - 2023-11-28 03:34:25,041: EPOCH 19: training on 40200 raw words (37442 effective words) took 0.1s, 263733 effective words/s
INFO - 2023-11-28 03:34:25,041: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748287 effective words) took 2.8s, 270973 effective words/s', 'datetime': '2023-11-28T03:34:25.041707', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:25,041: collecting all words and their counts
INFO - 2023-11-28 03:34:25,042: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:25,048: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:25,048: Updating model with new vocabulary
INFO - 2023-11-28 03:34:25,052: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:25.052200', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:25,056: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:25,056: sample=0.001 downsamples 78 most-common words
INFO - 2023-11-28 03:34:25,056: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37330.35011213475 word corpus (92.9%% of prior 40200)', 'datetime': '2023-11-28T03:34:25.056165', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:25,062: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:25,062: updating layer weights
INFO - 2023-11-28 03:34:25,062: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:25.062955', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:25,063: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:25,063: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:25.063184', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:25,223: EPOCH 0: training on 40200 raw words (37325 effective words) took 0.2s, 236629 effective words/s
INFO - 2023-11-28 03:34:25,358: EPOCH 1: training on 40200 raw words (37408 effective words) took 0.1s, 292527 effective words/s
INFO - 2023-11-28 03:34:25,500: EPOCH 2: training on 40200 raw words (37377 effective words) took 0.1s, 267676 effective words/s
INFO - 2023-11-28 03:34:25,643: EPOCH 3: training on 40200 raw words (37303 effective words) took 0.1s, 265734 effective words/s
INFO - 2023-11-28 03:34:25,787: EPOCH 4: training on 40200 raw words (37435 effective words) took 0.1s, 263789 effective words/s
INFO - 2023-11-28 03:34:25,929: EPOCH 5: training on 40200 raw words (37347 effective words) took 0.1s, 268176 effective words/s
INFO - 2023-11-28 03:34:26,066: EPOCH 6: training on 40200 raw words (37344 effective words) took 0.1s, 277099 effective words/s
INFO - 2023-11-28 03:34:26,201: EPOCH 7: training on 40200 raw words (37334 effective words) took 0.1s, 280109 effective words/s
INFO - 2023-11-28 03:34:26,341: EPOCH 8: training on 40200 raw words (37333 effective words) took 0.1s, 273052 effective words/s
INFO - 2023-11-28 03:34:26,481: EPOCH 9: training on 40200 raw words (37260 effective words) took 0.1s, 269347 effective words/s
INFO - 2023-11-28 03:34:26,627: EPOCH 10: training on 40200 raw words (37298 effective words) took 0.1s, 260432 effective words/s
INFO - 2023-11-28 03:34:26,763: EPOCH 11: training on 40200 raw words (37291 effective words) took 0.1s, 278371 effective words/s
INFO - 2023-11-28 03:34:26,903: EPOCH 12: training on 40200 raw words (37336 effective words) took 0.1s, 271073 effective words/s
INFO - 2023-11-28 03:34:27,051: EPOCH 13: training on 40200 raw words (37341 effective words) took 0.1s, 257085 effective words/s
INFO - 2023-11-28 03:34:27,195: EPOCH 14: training on 40200 raw words (37313 effective words) took 0.1s, 263152 effective words/s
INFO - 2023-11-28 03:34:27,335: EPOCH 15: training on 40200 raw words (37342 effective words) took 0.1s, 270975 effective words/s
INFO - 2023-11-28 03:34:27,469: EPOCH 16: training on 40200 raw words (37219 effective words) took 0.1s, 281558 effective words/s
INFO - 2023-11-28 03:34:27,614: EPOCH 17: training on 40200 raw words (37286 effective words) took 0.1s, 262659 effective words/s
INFO - 2023-11-28 03:34:27,754: EPOCH 18: training on 40200 raw words (37299 effective words) took 0.1s, 270426 effective words/s
INFO - 2023-11-28 03:34:27,896: EPOCH 19: training on 40200 raw words (37307 effective words) took 0.1s, 266848 effective words/s
INFO - 2023-11-28 03:34:27,897: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746498 effective words) took 2.8s, 263429 effective words/s', 'datetime': '2023-11-28T03:34:27.897066', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:27,897: collecting all words and their counts
INFO - 2023-11-28 03:34:27,897: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:27,904: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:27,904: Updating model with new vocabulary
INFO - 2023-11-28 03:34:27,907: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:27.907667', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:27,911: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:27,911: sample=0.001 downsamples 72 most-common words
INFO - 2023-11-28 03:34:27,911: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37419.60584138549 word corpus (93.1%% of prior 40200)', 'datetime': '2023-11-28T03:34:27.911516', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:27,917: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:27,917: updating layer weights
INFO - 2023-11-28 03:34:27,917: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:27.917831', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:27,917: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:27,918: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:27.918024', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:28,056: EPOCH 0: training on 40200 raw words (37424 effective words) took 0.1s, 275944 effective words/s
INFO - 2023-11-28 03:34:28,196: EPOCH 1: training on 40200 raw words (37353 effective words) took 0.1s, 271527 effective words/s
INFO - 2023-11-28 03:34:28,360: EPOCH 2: training on 40200 raw words (37403 effective words) took 0.2s, 232218 effective words/s
INFO - 2023-11-28 03:34:28,493: EPOCH 3: training on 40200 raw words (37426 effective words) took 0.1s, 296696 effective words/s
INFO - 2023-11-28 03:34:28,633: EPOCH 4: training on 40200 raw words (37442 effective words) took 0.1s, 271676 effective words/s
INFO - 2023-11-28 03:34:28,775: EPOCH 5: training on 40200 raw words (37427 effective words) took 0.1s, 267950 effective words/s
INFO - 2023-11-28 03:34:28,909: EPOCH 6: training on 40200 raw words (37417 effective words) took 0.1s, 284365 effective words/s
INFO - 2023-11-28 03:34:29,041: EPOCH 7: training on 40200 raw words (37331 effective words) took 0.1s, 287078 effective words/s
INFO - 2023-11-28 03:34:29,176: EPOCH 8: training on 40200 raw words (37393 effective words) took 0.1s, 281863 effective words/s
INFO - 2023-11-28 03:34:29,314: EPOCH 9: training on 40200 raw words (37429 effective words) took 0.1s, 277213 effective words/s
INFO - 2023-11-28 03:34:29,447: EPOCH 10: training on 40200 raw words (37439 effective words) took 0.1s, 286109 effective words/s
INFO - 2023-11-28 03:34:29,584: EPOCH 11: training on 40200 raw words (37460 effective words) took 0.1s, 279005 effective words/s
INFO - 2023-11-28 03:34:29,725: EPOCH 12: training on 40200 raw words (37414 effective words) took 0.1s, 270750 effective words/s
INFO - 2023-11-28 03:34:29,867: EPOCH 13: training on 40200 raw words (37377 effective words) took 0.1s, 267606 effective words/s
INFO - 2023-11-28 03:34:30,015: EPOCH 14: training on 40200 raw words (37411 effective words) took 0.1s, 258088 effective words/s
INFO - 2023-11-28 03:34:30,147: EPOCH 15: training on 40200 raw words (37426 effective words) took 0.1s, 288396 effective words/s
INFO - 2023-11-28 03:34:30,281: EPOCH 16: training on 40200 raw words (37441 effective words) took 0.1s, 282194 effective words/s
INFO - 2023-11-28 03:34:30,414: EPOCH 17: training on 40200 raw words (37424 effective words) took 0.1s, 287548 effective words/s
INFO - 2023-11-28 03:34:30,547: EPOCH 18: training on 40200 raw words (37489 effective words) took 0.1s, 286101 effective words/s
INFO - 2023-11-28 03:34:30,680: EPOCH 19: training on 40200 raw words (37363 effective words) took 0.1s, 298581 effective words/s
INFO - 2023-11-28 03:34:30,680: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748289 effective words) took 2.8s, 270914 effective words/s', 'datetime': '2023-11-28T03:34:30.680214', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:30,680: collecting all words and their counts
INFO - 2023-11-28 03:34:30,680: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:30,686: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:30,687: Updating model with new vocabulary
INFO - 2023-11-28 03:34:30,690: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:30.690307', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:30,693: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:30,693: sample=0.001 downsamples 73 most-common words
INFO - 2023-11-28 03:34:30,694: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37303.61214603628 word corpus (92.8%% of prior 40200)', 'datetime': '2023-11-28T03:34:30.693979', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:30,699: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:30,699: updating layer weights
INFO - 2023-11-28 03:34:30,700: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:30.700097', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:30,700: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:30,700: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:30.700280', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:30,841: EPOCH 0: training on 40200 raw words (37321 effective words) took 0.1s, 268162 effective words/s
INFO - 2023-11-28 03:34:30,975: EPOCH 1: training on 40200 raw words (37313 effective words) took 0.1s, 284025 effective words/s
INFO - 2023-11-28 03:34:31,112: EPOCH 2: training on 40200 raw words (37294 effective words) took 0.1s, 276292 effective words/s
INFO - 2023-11-28 03:34:31,251: EPOCH 3: training on 40200 raw words (37302 effective words) took 0.1s, 274439 effective words/s
INFO - 2023-11-28 03:34:31,387: EPOCH 4: training on 40200 raw words (37294 effective words) took 0.1s, 287532 effective words/s
INFO - 2023-11-28 03:34:31,526: EPOCH 5: training on 40200 raw words (37280 effective words) took 0.1s, 272556 effective words/s
INFO - 2023-11-28 03:34:31,667: EPOCH 6: training on 40200 raw words (37382 effective words) took 0.1s, 268840 effective words/s
INFO - 2023-11-28 03:34:31,812: EPOCH 7: training on 40200 raw words (37342 effective words) took 0.1s, 262576 effective words/s
INFO - 2023-11-28 03:34:31,950: EPOCH 8: training on 40200 raw words (37256 effective words) took 0.1s, 275407 effective words/s
INFO - 2023-11-28 03:34:32,089: EPOCH 9: training on 40200 raw words (37318 effective words) took 0.1s, 273329 effective words/s
INFO - 2023-11-28 03:34:32,230: EPOCH 10: training on 40200 raw words (37311 effective words) took 0.1s, 268165 effective words/s
INFO - 2023-11-28 03:34:32,372: EPOCH 11: training on 40200 raw words (37300 effective words) took 0.1s, 275682 effective words/s
INFO - 2023-11-28 03:34:32,510: EPOCH 12: training on 40200 raw words (37278 effective words) took 0.1s, 275471 effective words/s
INFO - 2023-11-28 03:34:32,650: EPOCH 13: training on 40200 raw words (37282 effective words) took 0.1s, 271141 effective words/s
INFO - 2023-11-28 03:34:32,790: EPOCH 14: training on 40200 raw words (37294 effective words) took 0.1s, 270081 effective words/s
INFO - 2023-11-28 03:34:32,925: EPOCH 15: training on 40200 raw words (37276 effective words) took 0.1s, 281816 effective words/s
INFO - 2023-11-28 03:34:33,065: EPOCH 16: training on 40200 raw words (37305 effective words) took 0.1s, 270358 effective words/s
INFO - 2023-11-28 03:34:33,206: EPOCH 17: training on 40200 raw words (37275 effective words) took 0.1s, 268533 effective words/s
INFO - 2023-11-28 03:34:33,345: EPOCH 18: training on 40200 raw words (37330 effective words) took 0.1s, 272209 effective words/s
INFO - 2023-11-28 03:34:33,485: EPOCH 19: training on 40200 raw words (37287 effective words) took 0.1s, 270934 effective words/s
INFO - 2023-11-28 03:34:33,486: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (746040 effective words) took 2.8s, 267813 effective words/s', 'datetime': '2023-11-28T03:34:33.486067', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:33,486: collecting all words and their counts
INFO - 2023-11-28 03:34:33,486: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
INFO - 2023-11-28 03:34:33,493: collected 1005 word types from a corpus of 40200 raw words and 1005 sentences
INFO - 2023-11-28 03:34:33,493: Updating model with new vocabulary
INFO - 2023-11-28 03:34:33,496: Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 1005) and increased the count of 1005 pre-existing words (100.00% of original 1005)', 'datetime': '2023-11-28T03:34:33.496315', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:33,499: deleting the raw counts dictionary of 1005 items
INFO - 2023-11-28 03:34:33,499: sample=0.001 downsamples 76 most-common words
INFO - 2023-11-28 03:34:33,499: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 37448.61913541693 word corpus (93.2%% of prior 40200)', 'datetime': '2023-11-28T03:34:33.499893', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}
INFO - 2023-11-28 03:34:33,505: estimated required memory for 1005 words and 128 dimensions: 1531620 bytes
INFO - 2023-11-28 03:34:33,506: updating layer weights
INFO - 2023-11-28 03:34:33,506: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-11-28T03:34:33.506190', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'build_vocab'}
WARNING - 2023-11-28 03:34:33,506: Effective 'alpha' higher than previous training cycles
INFO - 2023-11-28 03:34:33,506: Word2Vec lifecycle event {'msg': 'training model with 10 workers on 1005 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-11-28T03:34:33.506380', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:33,666: EPOCH 0: training on 40200 raw words (37460 effective words) took 0.2s, 247322 effective words/s
INFO - 2023-11-28 03:34:33,794: EPOCH 1: training on 40200 raw words (37402 effective words) took 0.1s, 297805 effective words/s
INFO - 2023-11-28 03:34:33,931: EPOCH 2: training on 40200 raw words (37400 effective words) took 0.1s, 277117 effective words/s
INFO - 2023-11-28 03:34:34,067: EPOCH 3: training on 40200 raw words (37447 effective words) took 0.1s, 280672 effective words/s
INFO - 2023-11-28 03:34:34,207: EPOCH 4: training on 40200 raw words (37511 effective words) took 0.1s, 272548 effective words/s
INFO - 2023-11-28 03:34:34,337: EPOCH 5: training on 40200 raw words (37469 effective words) took 0.1s, 291475 effective words/s
INFO - 2023-11-28 03:34:34,477: EPOCH 6: training on 40200 raw words (37493 effective words) took 0.1s, 273545 effective words/s
INFO - 2023-11-28 03:34:34,610: EPOCH 7: training on 40200 raw words (37457 effective words) took 0.1s, 286393 effective words/s
INFO - 2023-11-28 03:34:34,743: EPOCH 8: training on 40200 raw words (37398 effective words) took 0.1s, 287090 effective words/s
INFO - 2023-11-28 03:34:34,872: EPOCH 9: training on 40200 raw words (37471 effective words) took 0.1s, 293552 effective words/s
INFO - 2023-11-28 03:34:35,012: EPOCH 10: training on 40200 raw words (37437 effective words) took 0.1s, 281663 effective words/s
INFO - 2023-11-28 03:34:35,149: EPOCH 11: training on 40200 raw words (37407 effective words) took 0.1s, 278578 effective words/s
INFO - 2023-11-28 03:34:35,288: EPOCH 12: training on 40200 raw words (37449 effective words) took 0.1s, 274843 effective words/s
INFO - 2023-11-28 03:34:35,423: EPOCH 13: training on 40200 raw words (37409 effective words) took 0.1s, 283086 effective words/s
INFO - 2023-11-28 03:34:35,557: EPOCH 14: training on 40200 raw words (37481 effective words) took 0.1s, 284056 effective words/s
INFO - 2023-11-28 03:34:35,687: EPOCH 15: training on 40200 raw words (37392 effective words) took 0.1s, 292598 effective words/s
INFO - 2023-11-28 03:34:35,820: EPOCH 16: training on 40200 raw words (37461 effective words) took 0.1s, 287864 effective words/s
INFO - 2023-11-28 03:34:35,960: EPOCH 17: training on 40200 raw words (37392 effective words) took 0.1s, 272699 effective words/s
INFO - 2023-11-28 03:34:36,092: EPOCH 18: training on 40200 raw words (37460 effective words) took 0.1s, 299446 effective words/s
INFO - 2023-11-28 03:34:36,223: EPOCH 19: training on 40200 raw words (37531 effective words) took 0.1s, 290370 effective words/s
INFO - 2023-11-28 03:34:36,224: Word2Vec lifecycle event {'msg': 'training on 804000 raw words (748927 effective words) took 2.7s, 275577 effective words/s', 'datetime': '2023-11-28T03:34:36.224154', 'gensim': '4.3.2', 'python': '3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]', 'platform': 'Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'train'}
INFO - 2023-11-28 03:34:36,224: storing 1005x128 projection weights into cora.txt
