{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalability experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import sys\n",
    "import datetime\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a .mat file into a numpy array\n",
    "def load_mat(filename):\n",
    "    data = sio.loadmat(filename)\n",
    "    # return data['data']\n",
    "    return data\n",
    "    # return data['network']\n",
    "    # Extract the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Wed Nov  4 23:51:23 2015', '__version__': '1.0', '__globals__': [], 'group': <4777x40 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6770 stored elements in Compressed Sparse Column format>, 'network': <4777x4777 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 184812 stored elements in Compressed Sparse Column format>}\n",
      "(4777, 4777)\n",
      "[[2.080e+02 9.895e+02 1.003e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [9.895e+02 1.547e+03 4.125e+02 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.003e+03 4.125e+02 8.800e+01 ... 5.000e-01 1.000e+00 2.000e+00]\n",
      " ...\n",
      " [0.000e+00 1.000e+00 5.000e-01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 2.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "data_np = load_mat('../datasets/POS.mat')\n",
    "print(data_np)\n",
    "data_np = data_np['network'].astype('float32')\n",
    "\n",
    "# Convert the sparse matrix to a dense adjacency matrix\n",
    "adjmat = data_np.toarray()\n",
    "\n",
    "print(adjmat.shape)\n",
    "print(adjmat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Ground Truth Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4777, 40)\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Also obtain the labels\n",
    "data_np = load_mat('../datasets/POS.mat')\n",
    "labels_one_hot = data_np['group'].toarray()\n",
    "\n",
    "print(labels_one_hot.shape)     # (10312, 39)\n",
    "\n",
    "'''Now we know that the labels are one-hot encoded'''\n",
    "# labels = np.argmax(labels_one_hot, axis=1)\n",
    "# print(labels.shape)     # (10312,)\n",
    "# print(labels)\n",
    "\n",
    "label_sample = labels_one_hot[10]      # Thus, each node can have multiple labels (indicated by 2 ones in the array)\n",
    "print(label_sample)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the node embedding using Deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec():\n",
    "        def __init__(\n",
    "                        self, \n",
    "                        graph : \"list[list[int]]\", \n",
    "                        window_size : int, \n",
    "                        embedding_size : int, \n",
    "                        walks_per_vertex : int, \n",
    "                        walk_length : int,\n",
    "                        p : float,\n",
    "                        q : float\n",
    "                ) -> None:\n",
    "                \"\"\"\n",
    "                Initialize the DeepWalk model. This directly from the paper https://arxiv.org/pdf/1403.6652.pdf.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                graph : list[list[int]]\n",
    "                        The adjacency list to be embedded. This is a list of lists, where each list is a vertex and its neighbors.\n",
    "                window_size : int\n",
    "                        The window size for the skipgram model.\n",
    "                embedding_size : int\n",
    "                        The size of the embedding. The final output matrix will be of size |V| x embedding_size.\n",
    "                walks_per_vertex : int\n",
    "                        The number of walks to perform per vertex.\n",
    "                walk_length : int\n",
    "                        The length of each walk.\n",
    "                p : float\n",
    "                        The return parameter.\n",
    "                q : float\n",
    "                        The in-out parameter.\n",
    "\n",
    "                Methods\n",
    "                -------\n",
    "                generate_n_walks()\n",
    "                        Generate n walks from the graph.\n",
    "                train()\n",
    "                        Train the model.\n",
    "                update()\n",
    "                        Feed model new walks.\n",
    "                get_embeddings()\n",
    "                        Return the embeddings.\n",
    "                \"\"\"\n",
    "\n",
    "                # DeepWalk parameters\n",
    "                self.g = graph\n",
    "                self.w = window_size\n",
    "                self.d = embedding_size\n",
    "                self.gamma = walks_per_vertex\n",
    "                self.epochs = self.gamma\n",
    "                self.t = walk_length\n",
    "                self.n = len(graph)\n",
    "                self.p = p\n",
    "                self.q = q\n",
    "                \n",
    "                # Cutoffs for sampling\n",
    "                self.p0 = 1 / self.p / max(1, self.p, self.q)\n",
    "                self.p1 = 1/  max(1, self.p, self.q)\n",
    "                self.p2 = 1 / self.q / max(1, self.p, self.q)\n",
    "                \n",
    "                # Make the adjacency list using the graph\n",
    "                self.adj_list = []\n",
    "                for i in range(len(self.g)):\n",
    "                    neighbors = np.where(self.g[i] > 0)[0]  # Get neighbor indices\n",
    "                    weights = self.g[i, neighbors]  # Get corresponding edge weights\n",
    "    \n",
    "                    # Sort neighbors and weights by weight\n",
    "                    sorted_neighbors_weights = sorted(zip(neighbors, weights), key=lambda x: x[0])\n",
    "                    sorted_neighbors, sorted_weights = zip(*sorted_neighbors_weights)\n",
    "\n",
    "                    self.adj_list.append(list(zip(sorted_neighbors, sorted_weights / np.sum(sorted_weights))))\n",
    "        \n",
    "        def get_random_neighbour(self, vertex : 'int') -> 'int':\n",
    "                \"\"\"\n",
    "                Fetches a random neighbour of a given vertex\n",
    "                by sampling on the basis of the edge weights\n",
    "                \n",
    "                Parameters\n",
    "                ----------\n",
    "                vertex : int\n",
    "                        The vertex whose neighbour we will sample\n",
    "                        \n",
    "                Returns\n",
    "                -------\n",
    "                int\n",
    "                        The neighbour that was sampled\n",
    "                \"\"\"\n",
    "                # Sample a neighbour with probability proportional\n",
    "                # to the edge weight from vertex --> neighbour\n",
    "                neighbours, weights = zip(*self.adj_list[vertex])\n",
    "                \n",
    "                # Sample a vertex with probability proportional \n",
    "                # to the weight of the edge joining it.\n",
    "                return np.random.choice(neighbours, p=weights/np.sum(weights))\n",
    "                    \n",
    "        def second_order_biased_random_walk(\n",
    "                        self,\n",
    "                        adj_mat : 'list[list[int]]', \n",
    "                        walk_len : 'int', \n",
    "                        start_node : 'int', \n",
    "                        return_parameter :'float', \n",
    "                        in_out_parameter : 'float'\n",
    "                        ) -> np.array:\n",
    "                \"\"\"\n",
    "                Return a walk based on a 2nd order Markov Chain like transition.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                adj_mat : list[list[int]]\n",
    "                        Adjacency matrix of the graph.\n",
    "                walk_len : int\n",
    "                        Length of the random walk.\n",
    "                start_node : int\n",
    "                        Starting node of the random walk.\n",
    "                return_parameter : float\n",
    "                        The value of the \"p\" parameter\n",
    "                in_out_parameter : float\n",
    "                        The value of the \"q\" parameter\n",
    "                \n",
    "                Returns\n",
    "                -------\n",
    "                np.array\n",
    "                        List of nodes in the random walk.  \n",
    "                \n",
    "                \"\"\"\n",
    "                # Array to store the walk\n",
    "                walk = [\n",
    "                        start_node,\n",
    "                        self.get_random_neighbour(start_node) # The prev_node is never Null\n",
    "                ]\n",
    "\n",
    "                # Generate the rest of the walk\n",
    "                for i in range(2, walk_len):\n",
    "                    # Variable to check whether we added to walk\n",
    "                    found = False\n",
    "                    \n",
    "                    # Kep running until sampled in the red region\n",
    "                    while not found:\n",
    "                        new_node = self.get_random_neighbour(walk[-1])\n",
    "                        r = np.random.rand()\n",
    "                        \n",
    "                        # Check if we will go back to the same node\n",
    "                        if new_node == walk[-2]:\n",
    "                            if r < self.p0:\n",
    "                                found = True\n",
    "                        \n",
    "                        # Check if we are going to move by a distance of 1\n",
    "                        elif self.g[walk[-2]][new_node]:\n",
    "                            if r < self.p1:\n",
    "                                found = True\n",
    "                                    \n",
    "                        else: # So we are moving by a distance of 2\n",
    "                            if r < self.p2:\n",
    "                                found = True\n",
    "                                \n",
    "                    walk.append(new_node)\n",
    "            \n",
    "                return walk\n",
    "\n",
    "        def generate_n_walks(self, num_iters : int) -> 'list[list[str]]':\n",
    "                \"\"\"\n",
    "                Generate a list of num_iters random walks. These will be used to train the model\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                num_iters : int\n",
    "                        Number of walks to generate.\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                np.ndarray\n",
    "                        List of random walks.\n",
    "                \"\"\"\n",
    "\n",
    "                # List to store the walks\n",
    "                walks = []\n",
    "                \n",
    "                count = 0\n",
    "                # For each vertex in the graph\n",
    "                for vertex in range(self.n):\n",
    "                        # Generate gamma walks of length t starting from this \"vertex\"\n",
    "                        for _ in range(self.gamma):\n",
    "                                walks.append(self.second_order_biased_random_walk(self.g, self.t, vertex, self.p, self.q))\n",
    "                        count += 1\n",
    "                        if count % 100 == 0:\n",
    "                            # print number of nodes done with timestamp\n",
    "                            print(\"Done with \", count, \" nodes at \", datetime.datetime.now(), file=sys.stdout)\n",
    "\n",
    "                walks = [[str(node) for node in walk] for walk in walks]\n",
    "\n",
    "                return walks\n",
    "\n",
    "        def train(self, epochs : int, lr : float) -> None:\n",
    "                \"\"\"\n",
    "                Train the model.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                epochs : int\n",
    "                        Number of epochs to train the model for.\n",
    "                lr : float\n",
    "                        Learning rate for the optimizer.                \n",
    "                \"\"\"         \n",
    "\n",
    "                print(\"Start geneerating random walks\", file=sys.stdout) \n",
    "                # Generate many walks\n",
    "                walks = self.generate_n_walks(self.gamma)\n",
    "                print(\"Done generating random walks\", file=sys.stdout)\n",
    "\n",
    "                print(f\"Creating word2vec model for {epochs} epochs\", file=sys.stdout)\n",
    "\n",
    "                # Initialize the model\n",
    "                self.model = Word2Vec(\n",
    "                        walks,\n",
    "                        negative= 10,\n",
    "                        sg=1,\n",
    "                        alpha=0.05,\n",
    "                        epochs=epochs, \n",
    "                        vector_size=self.d,        # embedding dimension\n",
    "                        window=self.w,             # context window size\n",
    "                        min_count=0,\n",
    "                        workers=cores-2\n",
    "                )\n",
    "\n",
    "                print(\"Done creating word2vec model\", file=sys.stdout)\n",
    "\n",
    "        def get_embeddings(self) -> np.ndarray:\n",
    "                \"\"\"\n",
    "                Return the embeddings.\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                np.ndarray\n",
    "                        Embeddings.\n",
    "                \"\"\"\n",
    "                return [self.model.wv[str(n)] for n in range(self.n)]\n",
    "        \n",
    "        def plot_embeddings(self, num_dimensions : int, gt_labels : 'list[str]') -> None:\n",
    "                \"\"\"\n",
    "                Plot the embeddings.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                num_dimensions : int\n",
    "                        Number of dimensions to plot.\n",
    "                gt_labels : list[str]\n",
    "                        List of ground truth labels.\n",
    "                \"\"\"\n",
    "                embeddings = np.array(self.get_embeddings())\n",
    "\n",
    "                # dimensionality reduction to 2 dimensions using t-SNE for visualization\n",
    "                embeddings = TSNE(n_components=2).fit_transform(embeddings)\n",
    "\n",
    "                # Convert gt into numbers\n",
    "                gt_labels = np.array(gt_labels)\n",
    "\n",
    "                # Iterate over all labels and assign them an integer\n",
    "                for i, label in enumerate(np.unique(gt_labels)):\n",
    "                        gt_labels[gt_labels == label] = i\n",
    "                gt_labels = gt_labels.astype(int)\n",
    "\n",
    "                # plot the embeddings\n",
    "                plt.figure(figsize=(6,6))\n",
    "                plt.scatter(embeddings[:,0], embeddings[:,1], c=gt_labels)\n",
    "\n",
    "                # Plot node numbers\n",
    "                for i in range(len(embeddings)):\n",
    "                        plt.annotate(i , (embeddings[i,0], embeddings[i,1]))\n",
    "                        \n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjmat, window_size, embedding_size, walks_per_vertex, walk_length\n",
    "dw = Node2Vec(adjmat, 10, 128, 80, 40,4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start geneerating random walks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dw\u001b[39m.\u001b[39;49mtrain(\u001b[39m20\u001b[39;49m, \u001b[39m0.05\u001b[39;49m)\n",
      "\u001b[1;32m/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=203'>204</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart geneerating random walks\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstdout) \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39m# Generate many walks\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=205'>206</a>\u001b[0m walks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_n_walks(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgamma)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone generating random walks\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstdout)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=208'>209</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreating word2vec model for \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m epochs\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstdout)\n",
      "\u001b[1;32m/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39mfor\u001b[39;00m vertex \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m         \u001b[39m# Generate gamma walks of length t starting from this \"vertex\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m         \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m                 walks\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msecond_order_biased_random_walk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mg, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt, vertex, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m         count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m         \u001b[39mif\u001b[39;00m count \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m             \u001b[39m# print number of nodes done with timestamp\u001b[39;00m\n",
      "\u001b[1;32m/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39m# Kep running until sampled in the red region\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m found:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_random_neighbour(walk[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     \u001b[39m# Check if we will go back to the same node\u001b[39;00m\n",
      "\u001b[1;32m/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m neighbours, weights \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj_list[vertex])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# Sample a vertex with probability proportional \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# to the weight of the edge joining it.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anika/Desktop/smai/project-lmailmai/wikipedia/wiki_testing.ipynb#X14sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(neighbours, p\u001b[39m=\u001b[39;49mweights\u001b[39m/\u001b[39;49mnp\u001b[39m.\u001b[39;49msum(weights))\n",
      "File \u001b[0;32mmtrand.pyx:955\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/numpy/core/getlimits.py:484\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mfinfo(dtype)\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m _finfo_cache \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, dtype):\n\u001b[1;32m    485\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_finfo_cache\u001b[39m.\u001b[39mget(dtype)  \u001b[39m# most common path\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dw.train(20, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the embeddings from the model\n",
    "embeddings = np.array(dw.get_embeddings())\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a multi-label classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(range(label_sample.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a one-vs-rest logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy using hamming loss and F1-score\n",
    "print(\"F1-score: \", f1_score(mlb.fit_transform(y_test),mlb.fit_transform(y_pred), average=\"micro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
