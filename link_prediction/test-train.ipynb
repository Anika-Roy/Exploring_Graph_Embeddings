{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/lucashu1/link-prediction/blob/master/gae/preprocessing.py\n",
    "\n",
    "# Convert sparse matrix to tuple\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "# Takes in adjacency matrix in sparse format\n",
    "# Returns: adj_train, train_edges, val_edges, val_edges_false, \n",
    "# test_edges, test_edges_false\n",
    "def mask_test_edges(adj, test_frac=.1, val_frac=.05, prevent_disconnect=True, verbose=False):\n",
    "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('preprocessing...')\n",
    "\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    # Check that diag is zero:\n",
    "    assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "    g = nx.from_scipy_sparse_array(adj)\n",
    "    orig_num_cc = nx.number_connected_components(g)\n",
    "\n",
    "    adj_triu = sp.triu(adj) # upper triangular portion of adj matrix\n",
    "    adj_tuple = sparse_to_tuple(adj_triu) # (coords, values, shape), edges only 1 way\n",
    "    edges = adj_tuple[0] # all edges, listed only once (not 2 ways)\n",
    "    # edges_all = sparse_to_tuple(adj)[0] # ALL edges (includes both ways)\n",
    "    num_test = int(np.floor(edges.shape[0] * test_frac)) # controls how large the test set should be\n",
    "    num_val = int(np.floor(edges.shape[0] * val_frac)) # controls how alrge the validation set should be\n",
    "\n",
    "    # Store edges in list of ordered tuples (node1, node2) where node1 < node2\n",
    "    edge_tuples = [(min(edge[0], edge[1]), max(edge[0], edge[1])) for edge in edges]\n",
    "    all_edge_tuples = set(edge_tuples)\n",
    "    train_edges = set(edge_tuples) # initialize train_edges to have all edges\n",
    "    test_edges = set()\n",
    "    val_edges = set()\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('generating test/val sets...')\n",
    "\n",
    "    # Iterate over shuffled edges, add to train/val sets\n",
    "    np.random.shuffle(edge_tuples)\n",
    "    for edge in edge_tuples:\n",
    "        # print edge\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "\n",
    "        # If removing edge would disconnect a connected component, backtrack and move on\n",
    "        g.remove_edge(node1, node2)\n",
    "        if prevent_disconnect == True:\n",
    "            if nx.number_connected_components(g) > orig_num_cc:\n",
    "                g.add_edge(node1, node2)\n",
    "                continue\n",
    "\n",
    "        # Fill test_edges first\n",
    "        if len(test_edges) < num_test:\n",
    "            test_edges.add(edge)\n",
    "            train_edges.remove(edge)\n",
    "\n",
    "        # Then, fill val_edges\n",
    "        elif len(val_edges) < num_val:\n",
    "            val_edges.add(edge)\n",
    "            train_edges.remove(edge)\n",
    "\n",
    "        # Both edge lists full --> break loop\n",
    "        elif len(test_edges) == num_test and len(val_edges) == num_val:\n",
    "            break\n",
    "\n",
    "    if (len(val_edges) < num_val or len(test_edges) < num_test):\n",
    "        print (\"WARNING: not enough removable edges to perform full train-test split!\")\n",
    "        print (\"Num. (test, val) edges requested: (\", num_test, \", \", num_val, \")\")\n",
    "        print (\"Num. (test, val) edges returned: (\", len(test_edges), \", \", len(val_edges), \")\")\n",
    "\n",
    "    if prevent_disconnect == True:\n",
    "        assert nx.number_connected_components(g) == orig_num_cc\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('creating false test edges...')\n",
    "\n",
    "    test_edges_false = set()\n",
    "    while len(test_edges_false) < num_test:\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if false_edge in all_edge_tuples:\n",
    "            continue\n",
    "        if false_edge in test_edges_false:\n",
    "            continue\n",
    "\n",
    "        test_edges_false.add(false_edge)\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('creating false val edges...')\n",
    "\n",
    "    val_edges_false = set()\n",
    "    while len(val_edges_false) < num_val:\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge in not an actual edge, not in test_edges_false, not a repeat\n",
    "        if false_edge in all_edge_tuples or \\\n",
    "            false_edge in test_edges_false or \\\n",
    "            false_edge in val_edges_false:\n",
    "            continue\n",
    "            \n",
    "        val_edges_false.add(false_edge)\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('creating false train edges...')\n",
    "\n",
    "    train_edges_false = set()\n",
    "    while len(train_edges_false) < len(train_edges):\n",
    "        idx_i = np.random.randint(0, adj.shape[0])\n",
    "        idx_j = np.random.randint(0, adj.shape[0])\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (min(idx_i, idx_j), max(idx_i, idx_j))\n",
    "\n",
    "        # Make sure false_edge in not an actual edge, not in test_edges_false, \n",
    "            # not in val_edges_false, not a repeat\n",
    "        if false_edge in all_edge_tuples or \\\n",
    "            false_edge in test_edges_false or \\\n",
    "            false_edge in val_edges_false or \\\n",
    "            false_edge in train_edges_false:\n",
    "            continue\n",
    "\n",
    "        train_edges_false.add(false_edge)\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('final checks for disjointness...')\n",
    "\n",
    "    # assert: false_edges are actually false (not in all_edge_tuples)\n",
    "    assert test_edges_false.isdisjoint(all_edge_tuples)\n",
    "    assert val_edges_false.isdisjoint(all_edge_tuples)\n",
    "    assert train_edges_false.isdisjoint(all_edge_tuples)\n",
    "\n",
    "    # assert: test, val, train false edges disjoint\n",
    "    assert test_edges_false.isdisjoint(val_edges_false)\n",
    "    assert test_edges_false.isdisjoint(train_edges_false)\n",
    "    assert val_edges_false.isdisjoint(train_edges_false)\n",
    "\n",
    "    # assert: test, val, train positive edges disjoint\n",
    "    assert val_edges.isdisjoint(train_edges)\n",
    "    assert test_edges.isdisjoint(train_edges)\n",
    "    assert val_edges.isdisjoint(test_edges)\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('creating adj_train...')\n",
    "\n",
    "    # Re-build adj matrix using remaining graph\n",
    "    adj_train = nx.adjacency_matrix(g)\n",
    "\n",
    "    # Convert edge-lists to numpy arrays\n",
    "    train_edges = np.array([list(edge_tuple) for edge_tuple in train_edges])\n",
    "    train_edges_false = np.array([list(edge_tuple) for edge_tuple in train_edges_false])\n",
    "    val_edges = np.array([list(edge_tuple) for edge_tuple in val_edges])\n",
    "    val_edges_false = np.array([list(edge_tuple) for edge_tuple in val_edges_false])\n",
    "    test_edges = np.array([list(edge_tuple) for edge_tuple in test_edges])\n",
    "    test_edges_false = np.array([list(edge_tuple) for edge_tuple in test_edges_false])\n",
    "\n",
    "    if verbose == True:\n",
    "        print ('Done with train-test split!')\n",
    "        print ('')\n",
    "\n",
    "    # NOTE: these edge lists only contain single direction of edge!\n",
    "    return adj_train, train_edges, train_edges_false, \\\n",
    "        val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a .mat file into a numpy array\n",
    "def load_mat(filename):\n",
    "    data = sio.loadmat(filename)\n",
    "    # return data['data']\n",
    "    # print(type(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csc.csc_matrix'>\n",
      "False\n",
      "3890\n",
      "38739\n"
     ]
    }
   ],
   "source": [
    "sparse_mat = load_mat('../datasets/ppi.mat')['network']\n",
    "print(type(sparse_mat))\n",
    "G = nx.from_scipy_sparse_array(sparse_mat)\n",
    "print(nx.is_connected(G))\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "edge_list = list(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n",
      "generating test/val sets...\n",
      "creating false test edges...\n",
      "creating false val edges...\n",
      "creating false train edges...\n",
      "final checks for disjointness...\n",
      "creating adj_train...\n",
      "Done with train-test split!\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# load the adjacency matrix\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_array(G)\n",
    "\n",
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.1,verbose=True)\n",
    "g_train = nx.from_scipy_sparse_array(adj_train) # new graph object with only non-hidden edges\n",
    "print(nx.is_connected(g_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 3890\n",
      "Total edges: 38292\n",
      "Training edges (positive): 22708\n",
      "Training edges (negative): 22708\n",
      "Validation edges (positive): 3784\n",
      "Validation edges (negative): 3784\n",
      "Test edges (positive): 11353\n",
      "Test edges (negative): 11353\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print (\"Total nodes:\", adj_sparse.shape[0])\n",
    "print (\"Total edges:\", int(adj_sparse.nnz/2)) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print (\"Training edges (positive):\", len(train_edges))\n",
    "print (\"Training edges (negative):\", len(train_edges_false))\n",
    "print (\"Validation edges (positive):\", len(val_edges))\n",
    "print (\"Validation edges (negative):\", len(val_edges_false))\n",
    "print (\"Test edges (positive):\", len(test_edges))\n",
    "print (\"Test edges (negative):\", len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adjacency matrix\n",
    "adj_train = nx.to_scipy_sparse_array(g_train)\n",
    "sio.savemat('adj_train.mat', {'adj_train':adj_train})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
