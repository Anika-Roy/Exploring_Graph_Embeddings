{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a .mat file into a numpy array\n",
    "def load_mat(filename):\n",
    "    data = sio.loadmat(filename)\n",
    "    # return data['data']\n",
    "    # print(type(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-11-28 00:06:05,924: loading projection weights from ../embeddings/blogcatalog_n2v.txt\n",
      "INFO - 2023-11-28 00:06:06,479: KeyedVectors lifecycle event {'msg': 'loaded (10312, 128) matrix of type float32 from ../embeddings/blogcatalog_n2v.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-11-28T00:06:06.479635', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul  5 2023, 13:45:01) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-88-generic-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=128, 10312 keys>\n"
     ]
    }
   ],
   "source": [
    "# Step 1: load the embeddings from word_2_vec format using keyedvectors\n",
    "model = KeyedVectors.load_word2vec_format('../embeddings/blogcatalog_n2v.txt', binary=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the node embeddings in a numpy array\n",
    "node_embeddings = np.zeros((model.vectors.shape[0], model.vectors.shape[1]))\n",
    "\n",
    "for i in range(model.vectors.shape[0]):\n",
    "    node_embeddings[i] = model[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csc.csc_matrix'>\n",
      "10312\n",
      "333983\n"
     ]
    }
   ],
   "source": [
    "# Next step will be to get the edge list\n",
    "# - load a networkx graph from the .mat file\n",
    "# - get the edge list from the graph\n",
    "\n",
    "sparse_mat = load_mat('../datasets/blogcatalog.mat')['network']\n",
    "print(type(sparse_mat))\n",
    "G = nx.from_scipy_sparse_array(sparse_mat)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "edge_list = list(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        node1  node2                                     edge_embedding\n",
      "0           0    175  [-0.010408797394451996, -0.00572047360224065, ...\n",
      "1           0    232  [0.013740495769570482, 0.005690894386413126, -...\n",
      "2           0    282  [0.03690906314616882, -0.02001184203271278, -0...\n",
      "3           0    370  [0.13434024211433382, 0.009192588322365636, 0....\n",
      "4           0    393  [0.009477176926681374, 0.014309214989318697, 0...\n",
      "...       ...    ...                                                ...\n",
      "333978  10301  10309  [0.19505496597020588, 0.037573853164098114, -0...\n",
      "333979  10302  10309  [0.03149758006600334, -0.0018957392103583215, ...\n",
      "333980  10304  10310  [0.266293744464452, 0.32625420589451437, -0.00...\n",
      "333981  10306  10309  [0.21423885739163673, 0.10656689676583131, 0.0...\n",
      "333982  10307  10309  [0.0054022755788777355, 0.07144771219926094, 0...\n",
      "\n",
      "[333983 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store edge embeddings and information\n",
    "edge_data = []\n",
    "\n",
    "# Iterate through the edges and construct edge embeddings\n",
    "for edge in G.edges():\n",
    "    node1, node2 = edge\n",
    "    embedding1 = node_embeddings[node1]\n",
    "    embedding2 = node_embeddings[node2]\n",
    "    concatenated_embedding = np.multiply(embedding1, embedding2)  # Concatenate embeddings\n",
    "    \n",
    "    edge_dict = {\n",
    "        'node1': node1,\n",
    "        'node2': node2,\n",
    "        'edge_embedding': concatenated_embedding\n",
    "    }\n",
    "    \n",
    "    edge_data.append(edge_dict)\n",
    "\n",
    "# Convert the list of edge dictionaries into a DataFrame\n",
    "edge_df = pd.DataFrame(edge_data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the edge DataFrame into training and test sets\n",
    "train_df, test_df = train_test_split(edge_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate negative edges for training and test sets -> completed by Co-pilot\n",
    "def get_negative_edges(graph, num_edges_to_gen):\n",
    "    '''\n",
    "    Function to generate negative edges for a graph.\n",
    "    '''\n",
    "    edge_list = list(graph.edges())\n",
    "    nodes = list(graph.nodes())\n",
    "    num_nodes = len(nodes)\n",
    "    \n",
    "    edges_to_gen = num_edges_to_gen\n",
    "    num_edges = len(edge_list)\n",
    "    num_edges_gen = 0\n",
    "    \n",
    "    negative_edges = []\n",
    "    \n",
    "    while num_edges_gen < edges_to_gen:\n",
    "        # generate random edge\n",
    "        edge = np.random.choice(nodes, size=2, replace=False)\n",
    "        \n",
    "        # check if edge exists in graph\n",
    "        if not graph.has_edge(*edge):\n",
    "            negative_edges.append(tuple(edge))\n",
    "            num_edges_gen += 1\n",
    "    \n",
    "    return negative_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate negative edges for training and test sets\n",
    "num_neg_train = len(train_df)\n",
    "num_neg_test = len(test_df)\n",
    "\n",
    "train_negatives = get_negative_edges(G, num_neg_train)\n",
    "test_negatives = get_negative_edges(G, num_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641855173136518\n"
     ]
    }
   ],
   "source": [
    "total_train = np.concatenate((train_df[['node1', 'node2']].values, np.array(train_negatives)), axis=0)\n",
    "total_test = np.concatenate((test_df[['node1', 'node2']].values, np.array(test_negatives)), axis=0)\n",
    "\n",
    "# Create labels for training and test sets\n",
    "train_labels = np.concatenate((np.ones(num_neg_train), np.zeros(num_neg_train)))\n",
    "test_labels = np.concatenate((np.ones(num_neg_test), np.zeros(num_neg_test)))\n",
    "\n",
    "# Create a logistic regression model to use for edge classification\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "lr.fit(total_train, train_labels)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "lr_predictions = lr.predict(total_test)\n",
    "\n",
    "# compute AUC score for the model\n",
    "lr_auc = roc_auc_score(test_labels, lr_predictions)\n",
    "print(lr_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
